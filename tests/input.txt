>
 ТОМАС КОРМЕН 
ЧАРЛЬЗ ЛЕЙЗЕРСОН
 АЛ ГОРИТМЫ
 ПОСТРОЕНИЕ И АНАЛИЗ
Thomas H. Cormen 
Charles E. Leiserson 
Ronald L. Rivest 
Clifford Stein
 INTRODUCTION TO
 ALGORITHMS
 The MIT Press 
Cambridge, Massachusetts
 London, England
 THIRD EDITION
Томас Кормен 
Чарльз Лейзерсон 
Рональд Ривест 
Клиффорд Штайн
 АЛГОРИТМЫ
 ПОСТРОЕНИЕ И АНАЛИЗ
 ТРЕТЬЕ ИЗДАНИЕ
 Москва • Санкт-Петербург • Киев 
2013
ББК 32.973.26-018.2.75 
А45
 УДК 681.3.07
 Издательский дом “Вильямс”
 Зав. редакцией С. Я. Тригуб
 Перевод с английского и редакция канд. техн. наук И. В. Красикова
 По общим вопросам обращайтесь в Издательский дом “Вильямс” по адресу: 
i n fO 0w illiam spublishing.com, h ttp ://www.w illiam sp u blish in g.com
 Кормен, Томас X. и др.
 А45 
Алгоритмы: построение и анализ, 3-е изд. : Пер. с англ. — М. : ООО 
“И. Д. Вильямс”, 2013. — 1328 с. : ил. — Парал. тит. англ.
 ISBN 978-5-8459-1794-2 (рус.)
 ББК 32.973.26-018.2.75
 Все названия программных продуктов являются зарегистрированными торговыми марками соответствую
 щих фирм. Никакая часть настоящего издания ни в каких целях не может быть воспроизведена в какой бы 
то ни было форме и какими бы то ни было средствами, будь то электронные или механические, включая фо
 токопирование и запись на магнитный носитель, если на это нет письменного разрешения издательства MIT 
Press.
 Authorized translation from the English language edition published by MIT Press, Copyright © 2009 by Massa
 chusetts Institute of Technology.
 All rights reserved. No part of this book may be reproduced in any form or by any electronic or mechanical 
means (including photocopying, recording, or information storage and retrieval) without permission in writing from 
the publisher.
 Russian language edition published by Williams Publishing House according to the Agreement with R&I Enterprises 
International, Copyright © 2013
 Научно-популярное издание
 Томас X. Кормен, Чарльз И. Лейзерсон, Рональд Л. Ривест, Клиффорд Штайн
 Алгоритмы: построение и анализ
 3-е издание
 Литературный редактор 
Верстка
 Художественный редактор 
Корректор
 Л. Н. Красножон 
А. Н. Полинчик 
Е. 77. Дынник 
И. В. Красиков
 Подписано в печать 31.06.2013. Формат 70x100/16.
 Гарнитура Times. Печать офсетная.
 Уел. печ. л. 125,1. Уч.-изд. л. 96,2.
 Тираж 1500 эю. Заказ № 3726.
 Первая Академическая типография “Наука”, 199034, Санкт-Петербург, 9-я линия, 12/28 
ООО “И. Д. Вильямс”, 127055, г. Москва, ул. Лесная, д. 43, стр. 1
 ISBN 978-5-8459-1794-2 (рус.) 
ISBN 978-0-2620-3384-8 (англ.)
 © Издательский дом “Вильямс”, 2013 
© Massachusetts Institute of Technology, 2009
Оглавление
 Предисловие 14 
Часть I. Основы 23
 Глава 1. Роль алгоритмов в вычислениях 26 
Глава 2. Приступаем к изучению 38 
Глава 3. Рост функций 67 
Глава 4. Разделяй и властвуй 90
 Глава 5. Вероятностный анализ и рандомизированные алгоритмы 140
 Часть II. Сортировка и порядковая статистика 173
 Глава 6. Пирамидальная сортировка 179 
Глава 7. Быстрая сортировка 198 
Глава 8. Сортировка за линейное время 220 
Глава 9. Медианы и порядковые статистики 243
 Часть III. Структуры данных 259
 Глава 10. Элементарные структуры данных 264 
Глава 11. Хеширование и хеш-таблицы 285 
Глава 12. Бинарные деревья поиска 319 
Глава 13. Красно-черные деревья 341 
Глава 14. Расширение структур данных 372
 Часть IV. Усовершенствованные методы разработки и анализа 389
 Глава 15. Динамическое программирование 392 
Глава 16. Жадные алгоритмы 448 
Глава 17. Амортизационный анализ 487
 Часть V. Сложные структуры данных 517
 Глава 18. В-деревья 521
6
 Оглавление
 Глава 19. Фибоначчиевы пирамиды 542 
Глава 20. Деревья ван Эмде Боаса 568
 Глава 21. Структуры данных для непересекающихся множеств 597
 Часть VI. Алгоритмы для работы с графами 623
 Глава 22. Элементарные алгоритмы для работы с графами 626 
Глава 23. Минимальные остовные деревья 661 
Глава 24. Кратчайшие пути из одной вершины 680 
Глава 25. Кратчайшие пути между всеми парами вершин 722 
Глава 26. Задача о максимальном потоке 747
 Часть VII. Избранные темы 807
 Глава 27. Многопоточные алгоритмы 811
 Глава 28. Работа с матрицами 852
 Глава 29. Линейное программирование 883
 Глава 30. Полиномы и быстрое преобразование Фурье 940
 Глава 31. Теоретико-числовые алгоритмы 968
 Глава 32. Поиск подстрок 1031
 Глава 33. Вычислительная геометрия 1060
 Глава 34. NP-полнота 1096
 Глава 35. Приближенные алгоритмы 1157
 Часть VIII. Приложения: математические основы 1195
 Приложение А. Суммы и ряды 1198 
Приложение Б. Множества и прочие художества 1210 
Приложение В. Комбинаторика и теория вероятности 1235 
Приложение Г. Матрицы 1269
 Литература 1282 
Предметный указатель 1299
Содержание
 Предисловие 
I 
1 
Основы 23 
Введение 
24
 14
 Роль алгоритмов в вычислениях 26
 1.1 
Что такое алгоритмы 26
 1.2 
2 
Алгоритмы как технология 32
 Приступаем к изучению 38
 2.1 
Сортировка вставкой 38
 2.2 
2.3 
3 
Анализ алгоритмов 45
 Разработка алгоритмов 52
 Рост функций 67
 3.1 
Асимптотические обозначения 68
 3.2 
4 
Стандартные обозначения и часто встречающиеся функции 78
 Разделяй и властвуй 90
 4.1 
Задача поиска максимального подмассива 93
 4.2 
4.3 
4.4 
4.5 
Алгоритм Штрассена для умножения матриц 100
 Метод подстановки решения рекуррентных соотношений 108
 Метод деревьев рекурсии 113
 Основной метод 119
 к 4.6 Доказательство основной теоремы 123
 5 
Вероятностный анализ и рандомизированные алгоритмы 140
 5.1 
Задача о найме 140
 5.2 
5.3 
Индикаторная случайная величина 144
 Рандомизированные алгоритмы 148
 к 5.4 Вероятностный анализ и дальнейшее применение индикаторных 
случайных величин 156
8
 II 
6 
7 
8 
9 
III Структуры данных 259
 Введение 
260
 10 Элементарные структуры данных 264
 10.1 Стеки и очереди 264
 10.2 Связанные списки 268
 10.3 Реализация указателей и объектов 273
 10.4 Представление корневых деревьев 277
 11 Хеширование и хеш-таблицы 285
 11.1 Таблицы с прямой адресацией 286
 11.2 Хеш-таблицы 288
 11.3 Хеш-функции 294
 11.4 Открытая адресация 302
 * 11.5 Идеальное хеширование 310
 Содержание
 Сортировка и порядковая статистика 173 
Введение 
174
 Пирамидальная сортировка 179
 6.1 
Пирамиды 179
 6.2 
6.3 
6.4 
6.5 
Поддержка свойства пирамиды 182
 Построение пирамиды 185
 Алгоритм пирамидальной сортировки 188
 Очереди с приоритетами 190
 Быстрая сортировка 198
 7.1 
Описание быстрой сортировки 198
 7.2 
7.3 
7.4 
Производительность быстрой сортировки 202
 Рандомизированная быстрая сортировка 207
 Анализ быстрой сортировки 208
 Сортировка за линейное время 220
 8.1 
Нижние границы для алгоритмов сортировки 220
 8.2 
8.3 
8.4 
Сортировка подсчетом 223
 Поразрядная сортировка 226
 Карманная сортировка 230
 Медианы и порядковые статистики 243
 9.1 
Минимум и максимум 244
 9.2 
9.3 
Выбор в течение линейного ожидаемого времени 245
 Алгоритм выбора с линейным временем работы в наихудшем случае 
250
Содержание
 12 Бинарные деревья поиска 319
 12.1 Что такое бинарное дерево поиска 319
 12.2 Работа с бинарным деревом поиска 322
 12.3 Вставка и удаление 327
 ★ 
12.4 Случайное построение бинарных деревьев поиска 332
 13 Красно-черные деревья 341
 13.1 Свойства красно-черных деревьев 341
 13.2 Повороты 345
 13.3 Вставка 348
 13.4 Удаление 356
 14 Расширение структур данных 372
 14.1 Динамические порядковые статистики 372
 14.2 Расширение структур данных 378
 14.3 Деревья отрезков 381
 IV Усовершенствованные методы разработки и анализа 389
 Введение 
390
 15 Динамическое программирование 392
 15.1 Разрезание стержня 393
 15.2 Перемножение цепочки матриц 403
 15.3 Элементы динамического программирования 412
 15.4 Наидлиннейшая общая подпоследовательность 424
 15.5 Оптимальные бинарные деревья поиска 431
 16 Жадные алгоритмы 448
 16.1 Задача о выборе процессов 449
 16.2 Элементы жадной стратегии 457
 16.3 Коды Хаффмана 463
 ★ 
16.4 Матроиды и жадные методы 471
 ★ 
16.5 Планирование заданий как матроид 479
 17 Амортизационный анализ 487
 17.1 Групповой анализ 488
 17.2 Метод бухгалтерского учета 492
 17.3 Метод потенциалов 495
 17.4 Динамические таблицы 500
 9
10
 V Сложные структуры данных 517
 Введение 
518
 18 В-деревья 521
 18.1 Определение В-деревьев 525
 18.2 Основные операции с В-деревьями 528
 18.3 Удаление ключа из В-дерева 536
 19 Фибоначчиевы пирамиды 542
 19.1 Структура фибоначчиевых пирамид 544
 19.2 Операции над объединяемыми пирамидами 547
 19.3 Уменьшение ключа и удаление узла 555
 19.4 Оценка максимальной степени 559
 20 
Деревья ван Эмде Боаса 568
 20.1 Предварительные подходы 569
 20.2 Рекурсивная структура 573
 20.3 Дерево ван Эмде Боаса 582
 21 Структуры данных для непересекающихся множеств 597
 21.1 Операции над непересекающимися множествами 597
 21.2 Представление непересекающихся множеств 
с помощью связанных списков 600
 21.3 Леса непересекающихся множеств 604
 'к 21.4 Анализ объединения по рангу со сжатием пути 608
 VI Алгоритмы для работы с графами 623
 Введение 
624
 22 Элементарные алгоритмы для работы с графами 626
 22.1 Представление графов 626
 22.2 Поиск в ширину 630
 22.3 Поиск в глубину 639
 22.4 Топологическая сортировка 649
 22.5 Сильно связные компоненты 652
 23 Минимальные остовные деревья 661
 23.1 Выращивание минимального остовного дерева 662
 23.2 Алгоритмы Крускала и Прима 667
 24 Кратчайшие пути из одной вершины 680
 24.1 Алгоритм Беллмана-Форда 688
 24.2 Кратчайшие пути из одной вершины в ориентированных 
ациклических графах 693
 24.3 Алгоритм Дейкстры 696
 24.4 Разностные ограничения и кратчайшие пути 702
 24.5 Доказательства свойств кратчайших путей 709
 Содержание
Содержание
 25 Кратчайшие пути между всеми парами вершин 722
 25.1 Задача о кратчайших путях и умножение матриц 724
 25.2 Алгоритм Флойда-Уоршелла 731
 25.3 Алгоритм Джонсона для разреженных графов 738
 26 Задача о максимальном потоке 747
 26.1 Транспортные сети 748
 26.2 Метод Форда-Фалкерсона 753
 26.3 Максимальное паросочетание 771
 ★ 
26.4 Алгоритмы проталкивания предпотока 775
 ★ 
26.5 Алгоритм “поднять-в-начало” 788
 VII Избранные темы 807 
Введение 
II
 808
 27 Многопоточные алгоритмы 811
 21Л Основы динамической многопоточности 813
 27.2 Многопоточное умножение матриц 832
 21.3 Многопоточная сортировка слиянием 836
 28 Работа с матрицами 852
 28.1 Решение систем линейных уравнений 852
 28.2 Обращение матриц 866
 28.3 Симметричные положительно определенные матрицы 
и метод наименьших квадратов 872
 29 Линейное программирование 883
 29.1 Стандартная и каноническая формы задачи линейного 
программирования 891
 29.2 Формулировка задач в виде задач линейного программирования 899
 29.3 Симплекс-алгоритм 905
 29.4 Двойственность 921
 29.5 Начальное базисное допустимое решение 927
 30 Полиномы и быстрое преобразование Фурье 940
 30.1 Представление полиномов 942
 30.2 ДПФиБПФ 949
 30.3 Эффективные реализации БПФ 957
12 
31 Теоретико-числовые алгоритмы 968
 31.1 Элементарные понятия теории чисел 970
 31.2 Наибольший общий делитель 976
 31.3 Модульная арифметика 982
 31.4 Решение модульных линейных уравнений 990
 31.5 Китайская теорема об остатках 994
 31.6 Степени элемента 997
 31.7 Криптосистема с открытым ключом RSА 1002
 ★ 
31.8 Проверка простоты 1009
 * 31.9 Целочисленное разложение 1021
 32 Поиск подстрок 1031
 32.1 Простейший алгоритм поиска подстрок 1034
 32.2 Алгоритм Рабина-Карпа 1036
 32.3 Поиск подстрок с помощью конечных автоматов 1041 
'к 32.4 Алгоритм Кнута-Морриса-Пратта 1048
 33 Вычислительная геометрия 1060
 33.1 Свойства отрезков 1061
 33.2 Определение наличия пересекающихся отрезков 1068
 33.3 Поиск выпуклой оболочки 1075
 33.4 Поиск пары ближайших точек 1086
 34 
NP-полнота 1096
 34.1 Полиномиальное время 1102
 34.2 Проверка за полиномиальное время 1110
 34.3 NP-полнота и приводимость 1115
 34.4 Доказательства NP-полноты 1127
 34.5 NP-полные задачи 1136
 35 
Приближенные алгоритмы 1157
 35.1 Задача о вершинном покрытии 1159
 35.2 Задача о коммивояжере 1163
 35.3 Задача о покрытии множества 1169
 35.4 Рандомизация и линейное программирование 1175
 35.5 Задача о сумме подмножества 1180
 VIII Приложения: математические основы 1195
 Введение 
А 
1196
 Суммы и ряды 1198
 АЛ Суммы и их свойства 1198 
А.2 Оценки сумм 1202
 Содержание
Содержание
 Б Множества и прочие художества 1210
 Б.1 
Множества 1210 
Б.2 
Отношения 1215 
Б.З Функции 1218 
Б.4 
Графы 1221 
Б. 5 Деревья 1226
 В Комбинаторика и теория вероятности 1235
 В.1 Основы комбинаторики 1235 
В.2 Вероятность 1241 
В.З Дискретные случайные величины 1248 
В.4 
Геометрическое и биномиальное распределения 1254 
* В.5 Хвосты биномиального распределения 1260
 Г 
Матрицы 1269
 Г. 1 Матрицы и матричные операции 1269 
Г.2 Основные свойства матриц 1274
 Литература 
1282 
Предметный указатель 
1299
 13
Предисловие
 Вначале были компьютеры, но перед компьютерами были алгоритмы. Теперь же, 
когда есть множество компьютеров, есть еще больше алгоритмов, и алгоритмы 
лежат в основе вычислений.
 Эта книга служит исчерпывающим вводным курсом по современным компью
 терным алгоритмам. В ней представлено большое количество конкретных алго
 ритмов, которые описываются достаточно глубоко, однако таким образом, чтобы 
разработка и анализ были доступны читателям всех уровней подготовки. Мы ста
 рались обойтись элементарными пояснениями, но при этом не нанести ущерба 
ни глубине изложения, ни математической строгости.
 В каждой главе представлен определенный алгоритм и описаны метод его раз
 работки, область применения и другие связанные с ним вопросы. Алгоритмы 
описываются и простым человеческим языком, и с помощью псевдокода, разра
 ботанного таким образом, чтобы быть понятным любому, у кого есть хотя бы ми
 нимальный опыт программирования. В книге представлены 244 рисунка, иллю
 стрирующих работу алгоритмов, и многие из них состоят из нескольких частей. 
Поскольку один из важнейших критериев разработки алгоритмов — их эффектив
 ность, каждое описание алгоритма включает в себя тщательный анализ времени 
его работы.
 Данный учебник предназначен, в первую очередь, для студентов и аспирантов, 
изучающих тот или иной курс по алгоритмам и структурам данных. Он также бу
 дет полезен для технических специалистов, желающих повысить свой уровень 
в этой области, поскольку описание процесса разработки алгоритмов сопровож
 дается изложением технических и математических вопросов.
 В этом, третьем, издании книга вновь существенно изменена. В ней появились 
новые главы, пересмотренный псевдокод и более активный стиль изложения.
 Преподавателю
 Мы составляли эту книгу так, чтобы разнообразие рассматриваемых в ней тем 
сочеталось с полнотой изложения. Она будет полезной при чтении разнообразных 
курсов — от курса по структурам данных для студентов до курса по алгоритмам 
для аспирантов. Поскольку в книге намного больше материала, чем необходи
 мо для обычного курса, рассчитанного на один семестр, можно выбрать только 
тот материал, который точнее всего соответствует курсу, который вы собираетесь 
преподавать.
Предисловие
 15
 Курсы удобно разрабатывать на основе отдельных глав. Книга написана так, 
что ее главы сравнительно независимы одна от другой. В каждой главе материал 
изложен по мере его усложнения и разбит на разделы. В студенческом курсе 
можно использовать только сравнительно легкие разделы, а в аспирантском — 
всю главу в полном объеме.
 В книгу вошли 957 упражнений и 158 задач. Упражнения даются в конце каж
 дого раздела, а задачи — в конце каждой главы. Упражнения представлены в виде 
кратких вопросов для проверки степени освоения материала. Одни из них просты 
и предназначены для самоконтроля, в то время как другие — посложнее и могут 
быть рекомендованы в качестве домашних заданий. Решение задач требует боль
 ших усилий, и с их помощью часто вводится новый материал. Обычно задачи 
сформулированы так, что в них содержатся наводящие вопросы, помогающие 
найти верное решение.
 Отступив от принятой в предыдущих изданиях практики, мы сделали общедо
 ступными решения ко многим, но не ко всем, задачам и упражнениям. На веб-сай
 те h ttp : //m itp ress .m it. edu/algorithm s / имеются ссылки на эти реше
 ния. Вы можете зайти на сайт, чтобы узнать, есть ли решение тех задач, которые 
вы планируете задать студентам. Ожидается, что со временем набор представлен
 ных решений будет понемногу расти, так что мы рекомендуем посещать сайт при 
каждом очередном чтении вашего курса.
 Разделы и упражнения, которые больше подходят для аспирантов, чем для 
студентов, обозначены звездочкой (★ ). Они не обязательно сложнее тех, возле 
которых звездочка отсутствует; просто для их понимания может понадобиться 
владение более сложным математическим аппаратом. Для того чтобы справиться 
с упражнениями со звездочкой, может понадобиться более основательная подго
 товка или неординарная сообразительность.
 Студенту
 Надеемся, что этот учебник станет хорошим введением в теорию алгоритмов. 
Авторы попытались изложить каждый алгоритм в доступной и увлекательной 
форме. Чтобы облегчить освоение незнакомых или сложных алгоритмов, каждый 
из них описывается поэтапно. В книге также подробно объясняются математи
 ческие вопросы, необходимые для понимания проводимого анализа алгоритмов. 
Для тех читателей, которые уже в некоторой мере знакомы с какой-то темой, 
материал глав организован таким образом, чтобы эти читатели могли опустить 
вводные разделы и перейти непосредственно к более сложному материалу.
 Книга получилась довольно большой, поэтому не исключено, что в курсе лек
 ций будет представлена лишь часть изложенного в ней материала. Однако авторы 
попытались сделать ее такой, чтобы она стала полезной как сейчас в качестве 
учебника, способствующего усвоению курса лекций, так и позже, в профессио
 нальной деятельности, в качестве настольного справочного пособия для матема
 тиков и инженеров.
 Ниже перечислены необходимые предпосылки, позволяющие освоить материал 
этой книги.
16
 Предисловие
 • Читатель должен обладать некоторым опытом в программировании. В част
 ности, он должен иметь представление о рекурсивных процедурах и простых 
структурах данных, таких как массивы и связанные списки.
 • Читатель должен обладать определенными математическими навыками, в осо
 бенности навыками доказательства теорем методом математической индукции. 
Для понимания некоторых вопросов, изложенных в этой книге, потребуется 
умение выполнять некоторые простые математические преобразования. По
 мимо этого, в частях I и VIII рассказывается обо всех используемых матема
 тических методах.
 Мы получили множество просьб предоставить решения к задачам и упраж
 нениям из книги. На нашем веб-сайте h ttp ://m itp re ss.m it.e d u / 
a lg o rith m s/ имеются ссылки на решения некоторых задач и упражнений, так 
что вы запросто можете сравнивать собственные решения с нашими. Однако мы 
просим вас не присылать нам свои решения.
 Профессионалу
 Широкий круг вопросов, которые излагаются в этой книге, позволяет говорить 
о том, что она станет прекрасным учебником по теории алгоритмов. Поскольку 
каждая глава является относительно самостоятельной, читатель сможет сосредо
 точить внимание на вопросах, интересующих его больше других.
 Основная часть обсуждаемых здесь алгоритмов обладает большой практичес
 кой ценностью. Поэтому не обойдены вниманием особенности реализации алго
 ритмов и другие инженерные вопросы. Часто предлагаются реальные альтерна
 тивы алгоритмам, представляющим преимущественно теоретический интерес.
 Если вам понадобится реализовать любой из предложенных здесь алгоритмов, 
вы должны суметь достаточно легко преобразовать приведенный псевдокод в код 
на вашем любимом языке программирования. Мы разработали псевдокод таким 
образом, чтобы каждый алгоритм был представлен ясно и лаконично. Вследствие 
этого не рассматриваются обработка ошибок и другие связанные с разработкой 
программного обеспечения вопросы, требующие определенных предположений, 
касающихся конкретной среды программирования. Авторы попытались предста
 вить каждый алгоритм просто и непосредственно, не используя индивидуальных 
особенностей того или иного языка программирования, что могло бы усложнить 
понимание сути алгоритма.
 Мы понимаем, что, работая с книгой, не будучи студентом, вы не сможете 
проконсультироваться по поводу решения вами задач и упражнений с препо
 давателем. Поэтому на нашем веб-сайте h ttp ://m itp re ss.m it.e d u / 
a lg o rith m s/ имеются ссылки на решения некоторых задач и упражнений, так 
что у вас есть возможность проверить свою работу. Однако мы просим вас не 
присылать нам свои решения.
 Коллеге
 В книге приведена обширная библиография и представлены ссылки на совре
 менную литературу. В конце каждой главы есть раздел “Заключительные заме
Предисловие
 17
 чания” содержащий исторические подробности и ссылки. Однако эти замечания 
не могут служить исчерпывающим руководством в области алгоритмов. Возмож
 но, в это будет сложно поверить, но даже в такую объемную книгу не удалось 
включить многие интересные алгоритмы из-за недостатка места.
 Несмотря на огромное количество писем от студентов с просьбами предоста
 вить решения задач и упражнений, политика авторов — не приводить ссылки на 
источники, из которых эти задачи и упражнения были заимствованы. Это сдела
 но для того, чтобы студенты не искали готовых решений в литературе, а решали 
задачи самостоятельно.
 Изменения в третьем издании
 Что же изменилось в третьем издании книги по сравнению со вторым? Коли
 чество этих изменений находится на том же уровне, что и количество изменений 
во втором издании по сравнению с первым. Как мы писали в предыдущем изда
 нии, в зависимости от точки зрения, можно сказать, что их достаточно мало или 
довольно много.
 Беглый взгляд на оглавление книги показывает, что большая часть глав и раз
 делов второго издания осталась на месте. Мы убрали из книги две главы и один 
раздел, но при этом добавили три новые главы и два новых раздела, помимо этих 
новых глав.
 Мы сохранили смешанную схему первых двух изданий. Вместо организации 
глав в соответствии с проблемной областью задач или в соответствии с методами 
решения задач, мы использовали оба подхода одновременно. В книге имеются 
главы, посвященные методу “разделяй и властвуй”, динамическому программиро
 ванию, амортизационному анализу, NP-полноте и приближенным алгоритмам. Но 
в ней же есть целые части, посвященные сортировке, структурам данных для ди
 намических множеств и алгоритмам для решения задач на графах. Мы считаем, 
что, хотя вы и должны знать, как применять методы проектирования и анали
 за алгоритмов, задачи редко подсказывают, какие именно методы в наибольшей 
степени подходят для их решения.
 Вот краткая информация о наиболее существенных изменениях в третьей ре
 дакции книги.
 • Мы добавили новые главы, посвященные деревьям ван Эмде Боаса и много
 поточным алгоритмам, и убрали из приложений материал о матрицах.
 • Мы пересмотрели главу, посвященную рекуррентности, в сторону большего 
охвата метода “разделяй и властвуй” и ее первых двух разделов, посвященных 
применению этого метода для решения двух задач. Во втором разделе этой 
главы описан алгоритм Штрассена умножения матриц, которые был перенесен 
сюда из главы об операциях с матрицами.
 • Мы убрали две главы с достаточно редко изучаемым материалом: биномиаль
 ными пирамидами и сортирующими сетями. Одна из ключевых идей главы, 
посвященной сортирующим сетям, а именно 0-1 принцип, в этом издании на
 ходится в задаче 8.7 в виде леммы 0-1 сортировки для алгоритмов, работаю
 щих путем сравнения и обмена. Рассмотрение пирамид Фибоначчи больше не
18
 Предисловие
 основывается на биномиальных пирамидах как на предшественницах пирамид 
Фибоначчи.
 • Мы пересмотрели подход к динамическому программированию и жадным ал
 горитмам. Динамическое программирование теперь иллюстрируется более ин
 тересной задачей разрезания стержня, чем задача сборочного конвейера во 
втором издании. Кроме того, мы сделали больший, чем во втором издании, 
акцент на технологии запоминания и ввели понятие графа подзадачи как спо
 соба улучшения определения времени работы алгоритма динамического про
 граммирования. В нашем вводном примере для жадных алгоритмов — в задаче 
о выборе процессов — мы переходим к жадным алгоритмам более прямым пу
 тем, чем во втором издании.
 • Способ удаления узла из бинарных деревьев поиска (включающих красно-чер
 ные деревья) теперь гарантирует, что будет удален именно тот узел, который 
нужно удалить. В двух первых изданиях в некоторых случаях удалялся некото
 рый другой узел с перемещением его содержимого в узел, переданный проце
 дуре удаления. При таком, новом, способе удаления узлов в случае, когда дру
 гие компоненты программы поддерживают указатели на узлы дерева, они не 
окажутся в ситуации с устаревшими указателями на удаленные из дерева узлы.
 • В материале, посвященном транспортным сетям, потоки теперь полностью ба
 зируются на ребрах, что представляет более интуитивно понятный подход, чем 
в первых двух изданиях.
 • Поскольку материал об основах работы с матрицами и алгоритм Штрассена 
перенесены в другие главы, глава, посвященная матричным операциям, стала 
существенно меньше по сравнению со вторым изданием.
 • Изменено рассмотрение алгоритма сравнения строк Кнута-Морриса-Пратта.
 • Исправлен ряд ошибок. Информация о большинстве из них (но не обо всех) 
была получена нами через наш сайт, посвященный второму изданию книги.
 • Идя навстречу многочисленным пожеланиям, мы заменили синтаксис нашего 
псевдокода. Теперь для указания присвоения мы используем “ = ” а для про
 верки на равенство — “==” как это делается в С, C++, Java и Python. Точно 
так же мы удалили ключевые слова do и then и приняли в качестве симво
 лов начала комментария до окончания строки “//”. Кроме того, для указания 
атрибутов объектов используется запись с точкой. Но мы не зашли настолько 
далеко, чтобы сделать псевдокод объектно-ориентированным; он остался про
 цедурным. Другими словами, вместо выполнения методов объектов мы просто 
вызываем процедуры, передавая им объекты в качестве параметров.
 • Мы добавили 100 новых упражнений и 28 новых задач. Мы также обновили 
и расширили библиографию.
 • Наконец мы прошлись по всей книге и переписали многие разделы, абзацы 
и отдельные предложения, делая изложение более понятным.
Предисловие
 Веб-сайт
 19
 Вы можете воспользоваться нашим веб-сайтом по адресу h ttp :// 
m itpress.m it.ed u /alg o rith m s/ для получения дополнительных матери
 алов и для обратной связи с авторами. На сайте имеются ссылки на список из
 вестных ошибок, на решения избранных упражнений и задач и многие другие 
дополнительные материалы. Веб-сайт также позволяет читателю сообщить о за
 меченных ошибках или внести свои предложения по поводу книги.
 Как создавалась эта книга
 Третье издание книги, как и второе, выполнено в 
2^. Для математических 
формул мы использовали шрифт Times вместе со шрифтами MathTime Pro 2. Мы 
выражаем признательность за техническую поддержку Майклу Спиваку (Michael 
Spivak) из Publish or Perish, Inc., Лансу Карнесу (Lance Cames) из Personal TeX, 
Inc., и Тиму Трегубову (Tim Tregubov) из Dartmouth College. Как и в двух преды
 дущих изданиях, предметный указатель компилировался с помощью Windex, на
 писанной нами программы на языке С, а библиография — с применением BrnT^X. 
PDF-файлы этой книги созданы на МасВоок под управлением 0S 10.5.
 Иллюстрации к третьему изданию созданы с использованием MacDraw Pro 
с соответствующими пакетами для DTfX 2^ для вставки в иллюстрации матема
 тических формул. К сожалению, MacDraw Pro — устаревшее программное обес
 печение, не выпускающееся уже более десятилетия. Но к счастью, у нас все еще 
есть пара “Макинтошей”, на которых можно запускать классическую среду под 
управлением OS 10.4, а следовательно, как правило, и MacDraw Pro. Но даже 
с этими сложностями мы пришли к выводу, что MacDraw Pro гораздо проще 
любого другого программного обеспечения для создания иллюстраций, сопро
 вождающих текст на компьютерную тематику, и позволяет получить отличные 
результаты.1 Кто знает, сколько еще протянут наши доинтеловские Маки, так что 
если кто-то из Apple читает эти строки, то услышьте нашу просьбу: пожалуйста, 
создайте OS Х-совместимую версию MacDraw Pro!
 Благодарности к третьему изданию
 К настоящему времени мы сотрудничаем с MIT Press уже более двух десятиле
 тий, и это были очень плодотворные десятилетия! Мы благодарны Эллен Фаран 
(Ellen Faran), Бобу Приору (Bob Prior), Аде Брунштейн (Ada Brunstein) и Мэри 
Рейли (Магу Reilly) за помощь и поддержку.
 При написании третьего издания мы были сильно разбросаны географиче
 ски, работая в Dartmouth College Department of Computer Science, MIT Computer
 'Мы изучили несколько различных программ, работающих под управлением Mac OS X, но все они обла
 дают значительными недостатками по сравнению с MacDraw Pro. Мы пробовали создавать иллюстрации для 
этой книги с помощью других, хорошо известных программ, но получалось, что в результате мы тратили как 
минимум в пять раз больше времени, чем для создания тех же иллюстраций в MacDraw Pro, причем результат 
оставлял желать лучшего. Так что нам пришлось скрепя сердце принять решение вернуться к MacDraw Pro на 
старых “Макинтошах”
20
 Предисловие
 Science and Artificial Intelligence Laboratory и Columbia University Department 
of Industrial Engineering and Operations Research. Мы благодарны нашим универси
 тетам и колледжам за создание поддерживающей и стимулирующей обстановки.
 Джули Сассман (Julie Sussman, RRA.) вновь согласилась быть нашим техни
 ческим редактором. И вновь мы удивлялись как количеству сделанных нами оши
 бок, так и умению Джули их вылавливать. Она также помогла нам улучшить в ря
 де мест представление материала. Если бы существовал Зал славы технических 
редакторов, Джули, несомненно, заняла бы в нем достойное место. Она — просто 
феномен! Спасибо, спасибо, большое спасибо, Джули! Прия Натараджан (Priya 
Natarajan) также обнаружил ряд ошибок, которые мы смогли исправить еще до 
того, как книга была отправлена в типографию. Все оставшиеся в книге ошибки, 
несомненно, находятся на совести авторов (и, вероятно, были внесены в книгу 
после того, как ее прочла Джули).
 Рассмотрение деревьев ван Эмде Боаса порождено замечаниями Эрика Демей- 
на (Erik Demaine), на которые, в свою очередь, повлиял Майкл Бендер (Michael 
Bender). Мы также включили в книгу идеи Джейведа Аслама (Javed Aslam), Бред
 ли Кусмаула (Bradley Kuszmaul) и Хью Жа (Hui Zha).
 Глава, посвященная многопоточности, основана на материале, изначально на
 писанном вместе с Гаральдом Прокопом (Harald Prokop). На этот материал боль
 шое влияние оказали некоторые другие работы в рамках проекта Cilk в MIT, 
включая работы Бредли Кусмаула (Bradley Kuszmaul) и Маттео Фриго (Matteo 
Frigo). Дизайн многопоточного псевдокода основан на расширениях MIT Cilk для 
языка С и расширениях Cilk Arts’s Cilk++ для языка C++.
 Мы также благодарим множество читателей первого и второго изданий, кото
 рые сообщали нам об ошибках или давали советы о том, как улучшить книгу. 
Мы исправили все найденные ошибки и приняли столько предложений, сколько 
смогли. Количество таких читателей столь велико, что нет никакой практической 
возможности перечислить их здесь.
 Наконец мы выражаем благодарность нашим женам Николь Кормен (Nicole 
Cormen), Венди Лейзерсон (Wendy Leiserson), Гейл Ривест (Gail Rivest) и Ребекке 
Иври (Rebecca Ivry), а также нашим детям Рикки (Ricky), Вильяму (William), Деб
 би (Debby) и Кати (Katie) Лейзерсонам, Алексу (Alex) и Кристоферу (Christopher) 
Ривестам, а также Молли (Molly), Ною (Noah) и Бенджамену (Benjamin) Штай
 нам — за любовь и поддержку во время написания этой книги. Этот проект стал 
возможным благодаря поддержке и поощрению членов наших семей. С любовью 
посвящаем эту книгу им.
 Томас Кормен 
Чарльз Лейзерсон 
Рональд Ривест 
Клиффорд Штайн
 Ливан, Нью-Гемпшир 
Кэмбридж, Массачусеттс 
Кэмбридж, Массачусеттс 
Нью-Йорк, Нью-Йорк
 Февраль 2009
От издательства
 Вы, читатель этой книги, и есть главный ее критик. Мы ценим ваше мнение 
и хотим знать, что было сделано нами правильно, что можно было сделать луч
 ше и что еще вы хотели бы увидеть изданным нами. Нам интересно услышать 
и любые другие замечания, которые вам хотелось бы высказать в наш адрес.
 Мы ждем ваших комментариев и надеемся на них. Вы можете прислать нам 
бумажное или электронное письмо либо просто посетить наш Web-сервер и оста
 вить свои замечания там. Одним словом, любым удобным для вас способом дайте 
нам знать, нравится ли вам эта книга, а также выскажите свое мнение о том, как 
сделать наши книги более интересными для вас.
 Посылая письмо или сообщение, не забудьте указать название книги и ее ав
 торов, а также ваш обратный адрес. Мы внимательно ознакомимся с вашим мне
 нием и обязательно учтем его при отборе и подготовке к изданию последующих 
книг. Наши координаты:
 E-mail: 
WWW: 
i n fo@ w illiam spublishing. com
 h ttp : //www. w illiam spublishing. com
 Адреса для писем из:
 России: 
127055, г. Москва, ул. Лесная, д. 43, стр. 1
 Украины: 
03150, Киев, а/я 152

I Основы
Введение
 Эта часть книги заставит вас задуматься о вопросах, связанных с разработкой 
и анализом алгоритмов. Она была запланирована как вводный курс, в котором 
рассматриваются способы определения алгоритмов, некоторые стратегии их раз
 работки, использующиеся в этой книге, а также применяемые в ходе анализа 
алгоритмов различные основополагающие идеи. Кратко рассмотрим содержание 
глав части I.
 В главе 1 представлены обзор алгоритмов и их роль в современных вычисли
 тельных системах. В ней приводится определение алгоритма и даются некоторые 
примеры. Здесь также обосновывается положение о том, что алгоритмы следует 
рассматривать как такой же технологический продукт, как, например, аппаратное 
обеспечение, графические интерфейсы пользователя, объектно-ориентированные 
системы или сети.
 В главе 2 читатель получит возможность ознакомиться с алгоритмами, с помо
 щью которых решается задача о сортировке последовательности из п чисел. Эти 
алгоритмы сформулированы в виде псевдокода. Несмотря на то что используе
 мый псевдокод напрямую не преобразуется ни в один из общепринятых языков 
программирования, он вполне адекватно передает структуру алгоритма, поэтому 
для вас не должно составлять трудности реализовать его на любом языке про
 граммирования. Для изучения выбраны алгоритм сортировки вставкой, в котором 
используется инкрементный подход, и алгоритм сортировки слиянием, который 
характеризуется применением рекурсивного метода, известного также как метод 
“разделяй и властвуй” (метод разбиения). В обоих алгоритмах время выполнения 
возрастает с увеличением количества сортируемых элементов, однако скорость 
этого роста зависит от выбранного алгоритма. В этой главе будет определено 
время работы изучаемых алгоритмов; кроме того, вы познакомитесь со специаль
 ными обозначениями для описания времени работы алгоритмов.
 В главе 3 дается точное определение обозначений, введенных в главе 2 (ко
 торые называются асимптотическими обозначениями). В начале главы 3 опре
Часть I. Основы
 25
 деляется несколько асимптотических обозначений для оценки времени работы 
алгоритма сверху и/или снизу. Остальные разделы главы в основном посвящены 
математическим обозначениям. Их предназначение состоит не столько в том, что
 бы ознакомить читателя с новыми математическими концепциями, сколько в том, 
чтобы он смог убедиться, что используемые им обозначения совпадают с приня
 тыми в данной книге.
 В главе 4 представлено дальнейшее развитие метода “разделяй и властвуй”, 
введенного в главе 2. В главе 4 приведены дополнительные примеры алгорит
 мов “разделяй и властвуй”, включая удивительный метод Штрассена для умноже
 ния двух квадратных матриц. В ней также представлены методы решения рекур
 рентных соотношений, с помощью которых описывается время работы рекурсив
 ных алгоритмов. Одним из мощных методов является “основной метод” (master 
method), который используется для решения рекуррентных соотношений, возни
 кающих в алгоритмах разбиения. Хотя немалая часть главы посвящена доказа
 тельству корректности метода контроля, вы можете его опустить, что не помешает 
применению метода на практике.
 Глава 5 служит введением в анализ вероятностей и рандомизированные алго
 ритмы (т.е. алгоритмы, которые основаны на использовании случайных чисел). 
Анализ вероятностей обычно применяется для определения времени работы ал
 горитма в тех случаях, когда оно может изменяться для различных наборов вход
 ных параметров, несмотря на то что эти наборы содержат одно и то же количе
 ство параметров. В некоторых случаях можно предположить, что распределение 
входных величин описывается некоторым известным законом распределения ве
 роятностей, а значит, время работы алгоритма можно усреднить по всем возмож
 ным наборам входных параметров. В других случаях распределение возникает 
не из-за входных значений, а в результате случайного выбора, который делает
 ся во время работы алгоритма. Алгоритм, поведение которого определяется не 
только входными значениями, но и величинами, полученными с помощью гене
 ратора случайных чисел, называется рандомизированным алгоритмом. Мы мо
 жем использовать рандомизированные алгоритмы для обеспечения вероятност
 ного распределения входных данных, тем самым гарантируя, что никакой набор 
входных данных не приведет к низкой производительности алгоритма, или даже 
для ограничения числа ошибок в алгоритмах, которые могут давать ограниченное 
количество некорректных результатов.
 В приложениях А-Г содержится дополнительный математический материал, 
который будет полезным в процессе чтения книги. Скорее всего, вы уже знако
 мы с основной частью материала, содержащегося в приложениях (хотя некоторые 
из встречавшихся вам ранее обозначений иногда могут отличаться от принятых 
в данной книге). Поэтому к приложениям следует относиться как к справочному 
материалу. С другой стороны, не исключено, что вы еще не знакомы с большин
 ством вопросов, рассматриваемых в части I.
Глава 1 Роль алгоритмов в вычислениях
 Что такое алгоритмы? Стоит ли тратить время на их изучение? Какова роль ал
 горитмов и как они соотносятся с другими компьютерными технологиями? В этой 
главе мы ответим на поставленные здесь вопросы.
 1.1. Что такое алгоритмы
 Говоря неформально, алгоритм — это любая корректно определенная вычис
 лительная процедура, на вход (input) которой подается некоторая величина или 
набор величин и результатом выполнения которой является выходная (output) ве
 личина или набор значений. Таким образом, алгоритм представляет собой после
 довательность вычислительных шагов, преобразующих входные величины в вы
 ходные.
 Алгоритм также можно рассматривать как инструмент, предназначенный для 
решения корректно поставленной вычислительной задачи (computational prob
 lem). В постановке задачи в общих чертах задаются отношения между входом 
и выходом. В алгоритме описывается конкретная вычислительная процедура, 
с помощью которой удается добиться выполнения указанных отношений.
 Например, может понадобиться выполнить сортировку последовательности 
чисел в неубывающем порядке. Эта задача часто возникает на практике и служит 
благодатной почвой для ознакомления на ее примере со многими стандартными 
методами разработки и анализа алгоритмов. Задача сортировки (sorting problem) 
формально определяется следующим образом.
 Вход. Последовательность из п чисел (ai, аг,..., ап).
 Выход. Перестановка (переупорядочение) (а[, а2, ..., а!п) входной последова
 тельности, такая, что а'х < а'2 < • • ■ < а'п.
 Например, если на вход подается последовательность (31, 41, 59, 26, 41, 58), то 
вывод алгоритма сортировки должен быть таким: (26,31,41,41,58,59). Подобная 
входная последовательность называется экземпляром (instance) задачи сортиров
 ки. Вообще говоря, экземпляр задачи состоит из входных данных (удовлетворяю
Глава I. Роль алгоритмов в вычислениях
 27
 щих всем ограничениям, наложенным при постановке задачи), необходимых для 
решения задачи.
 Поскольку многие программы используют ее в качестве промежуточного ша
 га, сортировка является основополагающей операцией в информатике, в результа
 те чего появилось большое количество хороших алгоритмов сортировки. Выбор 
наиболее подходящего алгоритма зависит от многих факторов, в том числе от 
количества сортируемых элементов, от их порядка во входной последовательно
 сти, от возможных ограничений, накладываемых на члены последовательности, 
от архитектуры компьютера, а также от того, какое устройство используется для 
хранения последовательности: основная память, магнитные диски или даже на
 копители на магнитных лентах.
 Говорят, что алгоритм корректен (correct), если для любых входных данных 
результатом его работы являются корректные выходные данные. Мы говорим, что 
корректный алгоритм решает данную вычислительную задачу. Если алгоритм 
некорректный, то для некоторых вводов он может вообще не завершить свою ра
 боту или выдать неправильный ответ. Правда, некорректные алгоритмы иногда 
могут оказаться полезными, если в них есть возможность контролировать часто
 ту возникновения ошибок. Такой пример алгоритма с контролируемой частотой 
ошибок рассматривается в главе 31, в которой изучаются алгоритмы определе
 ния больших простых чисел. Тем не менее обычно мы заинтересованы только 
в корректных алгоритмах.
 Алгоритм может быть задан на естественном языке, в виде компьютерной про
 граммы или даже воплощен в аппаратном обеспечении. Единственное требова
 ние — его спецификация должна предоставлять точное описание вычислительной 
процедуры, которую требуется выполнить.
 Какие задачи решаются с помощью алгоритмов
 Вычислительные задачи, для которых разработаны алгоритмы, отнюдь не огра
 ничиваются сортировкой. (Возможно, об их разнообразии можно судить по объе
 му данной книги.) Практическое применение алгоритмов чрезвычайно широко, 
о чем свидетельствуют приведенные ниже примеры.
 • Проект по расшифровке генома человека далеко продвинулся по направлению 
к своей цели — к идентификации всех ста тысяч генов, входящих в состав ДНК 
человека, определению последовательностей, образуемых тремя миллиардами 
базовых пар, из которых состоит ДНК, к сортировке этой информации в базах 
данных и разработке инструментов для ее анализа. Для реализации всех пере
 численных этапов нужны сложные алгоритмы. Хотя решение разнообразных 
задач, являющихся составными частями данного проекта, выходит за рамки 
настоящей книги, идеи, описанные во многих ее главах, используются для ре
 шения упомянутых биологических проблем. Это позволяет ученым достигать 
поставленных целей, эффективно используя вычислительные ресурсы. При 
этом экономятся время (как машинное, так и затрачиваемое сотрудниками) 
и деньги, а также повышается эффективность использования лабораторного 
оборудования.
28
 Часть I. Основы
 • Интернет позволяет пользователям в любой точке мира быстро получать до
 ступ к информации и извлекать ее в больших объемах. Благодаря помощи 
хитроумных алгоритмов сайты в Интернете способны работать с этими огром
 ными объемами данных. Примерами задач, для которых жизненно необходимо 
применение эффективных алгоритмов, могут служить определение оптималь
 ных маршрутов, по которым перемещаются данные (методы для решения этой 
задачи описываются в главе 24), и быстрый поиск страниц, на которых нахо
 дится та или иная информация, с помощью специализированных поисковых 
машин (соответствующие методы приводятся в главах 11 и 32).
 • Электронная коммерция позволяет заключать сделки и предоставлять товары 
и услуги с помощью различных электронных технических средств. Ее рас
 пространенность существенно зависит от способности защищать такую ин
 формацию, как номера кредитных карт, пароли и банковские счета. В число 
базовых технологий в этой области входят криптография с открытым ключом 
и цифровые подписи (они описываются в главе 31), основанные на численных 
алгоритмах и теории чисел.
 • В производстве и коммерции очень важно распорядиться ограниченными ре
 сурсами так, чтобы получить максимальную выгоду. Нефтяной компании мо
 жет понадобиться информация о том, где пробурить скважины, чтобы полу
 чить от них как можно более высокую прибыль. Кандидат в президенты может 
задаться вопросом, как потратить деньги, чтобы максимально повысить свои 
шансы победить на выборах. Авиакомпаниям важно знать, какую минималь
 ную цену можно назначить за билеты на тот или иной рейс, чтобы уменьшить 
количество свободных мест и не нарушить при этом законы, регулирующие 
авиаперевозку пассажиров. Провайдер Интернета должен уметь так размещать 
дополнительные ресурсы, чтобы повышался уровень обслуживания клиентов. 
Все эти задачи можно решить с помощью линейного программирования, к изу
 чению которого мы приступим в главе 29.
 Хотя некоторые детали представленных примеров и выходят за рамки настоя
 щей книги, в ней приводятся основные методы, применяющиеся для их решения. 
В книге также показано, как решить многие конкретные задачи, в том числе пе
 речисленные ниже.
 • Пусть имеется карта дорог, на которой обозначены расстояния между каж
 дой парой соседних перекрестков. Наша цель — определить кратчайший путь 
от одного перекрестка к другому. Количество возможных маршрутов может 
быть огромным, даже если исключить те из них, которые содержат самопе
 ресечения. Как найти наиболее короткий из всех возможных маршрутов? При 
решении этой задачи карта дорог (которая сама по себе является моделью 
настоящих дорог) моделируется в виде графа (мы подробнее познакомимся 
с графами в части VI и приложении Б). Задача будет заключаться в опре
 делении кратчайшего пути от одной вершины графа к другой. Эффективное 
решение этой задачи представлено в главе 24.
Глава 1. Роль алгоритмов в вычислениях
 29
 • У нас имеются две упорядоченные последовательности символов, X = (х\, 
Х2, ■ ■ ■, хт) и Y = (yi,у2,..., уп), и нам надо найти длиннейшую общую под
 последовательность X и Y. Подпоследовательностью X является сама после
 довательность X с некоторыми (возможно, всеми или никакими) удаленными 
элементами. Например, одной из подпоследовательностей (А, В, С, D, Е, F, G) 
является (В, С, Е, G). Наидлиннейшая общая подпоследовательность X и У 
дает меру схожести двух последовательностей. Например, если этими двумя 
последовательностями являются базовые пары в цепочках ДНК, то мы можем 
считать их сходными, если они имеют длинную общую подпоследователь
 ность. Если X имеет т символов, a Y — п символов, то X и Y имеют 2т и 2П 
возможных подпоследовательностей соответственно. Выбирая все возможные 
подпоследовательности X и У и сопоставляя их, можно решить поставлен
 ную задачу только за очень длительное время (конечно, если только т и п не 
оказываются очень малыми величинами). В главе 15 мы познакомимся с об
 щим методом гораздо более эффективного решения этой задачи, известным 
как динамическое программирование.
 • У нас имеется проект, который представлен в виде библиотеки составных ча
 стей, причем каждая часть может включать экземпляры из других частей. Нам 
требуется перечислить все части в таком порядке, чтобы каждая часть появля
 лась в списке до любой другой части, ее использующей. Если проект состоит 
из п частей, имеется п\ возможных упорядочений, где п! — обозначение факто
 риала. Поскольку факториал растет быстрее даже показательной функции, мы 
не можем просто сгенерировать все возможные упорядочения и для каждого 
из них проверить, соответствует ли расположение частей нашему требованию 
(если, конечно, частей достаточно много). Эта задача представляет собой эк
 земпляр топологической сортировки, и в главе 22 мы узнаем о способе ее 
эффективного решения.
 • Пусть имеется п принадлежащих плоскости точек, и нужно найти выпуклую 
оболочку этих точек. Выпуклой оболочкой точек называется минимальный 
выпуклый многоугольник, содержащий эти точки. Для решения этой задачи 
удобно воспользоваться такой наглядной картиной: если представить точки 
в виде вбитых в доску и торчащих из нее гвоздей, то выпуклую оболочку мож
 но получить, намотав на них резинку таким образом, чтобы все гвозди вошли 
внутрь замкнутой линии, образуемой резинкой. Каждый гвоздь, вокруг кото
 рого обвивается резинка, становится вершиной выпуклой оболочки (рис. 33.6 
на с. 1076). В качестве набора вершин может выступать любое из 2п под
 множеств множества точек. Однако недостаточно знать, какие точки являются 
вершинами выпуклой оболочки, нужно еще указать порядок их обхода. Таким 
образом, чтобы найти выпуклую оболочку, придется перебрать множество ва
 риантов. В главе 33 описаны два хороших метода поиска выпуклой оболочки.
 Приведенные выше случаи применения алгоритмов отнюдь не являются ис
 черпывающими, однако на их примере выявляются две общие характеристики,
 присущие многим интересным алгоритмам.
30
 Часть I. Основы
 1. Они имеют множество вариантов-кандидатов, подавляющее большинство ко
 торых решениями не являются. Поиск среди них работающего (или “наилуч
 шего”) кандидата является довольно сложным делом.
 2. Они имеют практическое применение. Простейший пример среди перечислен
 ных задач — определение кратчайшего пути, соединяющего два перекрестка. 
Любая компания, занимающаяся автомобильными или железнодорожными пе
 ревозками, финансово заинтересована в том, чтобы определить кратчайший 
маршрут. Это способствовало бы снижению затрат труда и расходов горюче
 го. Маршрутизатору в Интернете также нужно иметь возможность находить 
кратчайшие пути в сети, чтобы как можно быстрее доставлять сообщения. 
Водитель, едущий из одного города в другой, может захотеть найти маршрут 
на веб-сайте или использовать в поездке GPS.
 Не всякая задача, решаемая с помощью алгоритма, имеет просто идентифи
 цируемое множество вариантов-кандидатов. Например, предположим, что нам 
дано множество числовых значений, представляющих дискретные отсчеты сиг
 нала, и мы хотим выполнить их дискретное Фурье-преобразование. Такое дис
 кретное Фурье-преобразование преобразует временную характеристику в частот
 ную, выдавая набор числовых коэффициентов, позволяющих определить вклад 
различных частот в оцифрованный сигнал. Помимо того что дискретное Фурье- 
преобразование представляет собой основу всей обработки сигналов, оно имеет 
приложения в сжатии данных и умножении больших полиномов и целых чисел. 
В главе 30 приведены как эффективный алгоритм быстрого Фурье-преобразова- 
ния (обычно именуемого БПФ (FFT)) для решения этой задачи, так и наброски 
проекта микросхемы для вычисления БПФ.
 Структуры данных
 В книге также представлен ряд структур данных. Структура данных (data 
structure) — это способ хранения и организации данных, облегчающий доступ 
к этим данным и их модификацию. Ни одна структура данных не является уни
 версальной и не может подходить для всех целей, поэтому важно знать преиму
 щества и ограничения, присущие некоторым из них.
 Методические указания
 Данную книгу можно рассматривать как “сборник рецептов” для алгоритмов. 
Правда, однажды вам встретится задача, для которой вы не сможете найти опуб
 ликованный алгоритм (например, таковы многие из приведенных в книге упраж
 нений и задач). Данная книга научит вас методам разработки алгоритмов и их 
анализа. Это позволит вам разрабатывать корректные алгоритмы и оценивать их 
эффективность самостоятельно. В разных главах рассматриваются различные ас
 пекты решения алгоритмических задач. Одни главы посвящены конкретным за
 дачам, таким как поиск медиан и порядковых статистик в главе 9, вычисление 
минимальных остовных деревьев в главе 23 и определение максимального пото
 ка в сети в главе 26. Другие главы ориентированы на методы, такие как “разделяй
Глава I. Роль алгоритмов в вычислениях
 31
 и властвуй” в главе 4, динамическое программирование в главе 15 и амортизаци
 онный анализ в главе 17.
 Сложные задачи
 Большая часть этой книги посвящена эффективным алгоритмам. Обычной ме
 рой эффективности алгоритма является скорость — время, в течение которого 
алгоритм выдает результат. Однако существуют задачи, для которых неизвестны 
эффективные методы решения. В главе 34 рассматривается интересный вопрос, 
имеющий отношение к подобным задачам, известным как NP-полные.
 Почему NP-полные задачи представляют такой интерес? Во-первых, несмотря 
на то что до сих пор не найден эффективный алгоритм их решения, также не 
доказано, что такого алгоритма не существует. Другими словами, никто не знает, 
существует ли эффективный алгоритм для NP-полных задач. Во-вторых, набор 
NP-полных задач обладает замечательным свойством. Оно заключается в том, 
что если эффективный алгоритм существует хотя бы для одной из этих задач, то 
его можно сформулировать и для всех остальных. Эта взаимосвязь между NP- 
полными задачами и отсутствие методов их эффективного решения вызывают 
еще больший интерес к ним. В-третьих, некоторые NP-полные задачи похожи 
(но не идентичны) на задачи, для которых известны эффективные алгоритмы. 
Ученых волнует вопрос о том, как небольшое изменение формулировки задачи 
может значительно ухудшить эффективность самого лучшего из всех известных 
алгоритмов.
 Вы должны знать об NP-полных задачах, поскольку в реальных приложениях 
некоторые из них возникают неожиданно часто. Если перед вами встанет задача 
найти эффективный алгоритм для NP-полной задачи, скорее всего, вы потратите 
много времени на безрезультатные поиски. Если же вы покажете, что данная 
задача принадлежит к разряду NP-полных, то можно будет вместо самого лучшего 
из всех возможных решений попробовать найти достаточно эффективное.
 В качестве конкретного примера рассмотрим компанию грузового автотранс
 порта, имеющую один центральный склад. Каждый день грузовики загружают
 ся на этом складе и отправляются по определенному маршруту, доставляя груз 
в несколько мест. В конце рабочего дня грузовик должен вернуться на склад, что
 бы на следующее утро его снова можно было загрузить. Чтобы сократить расхо
 ды, компании нужно выбрать оптимальный порядок доставки груза в различные 
точки. При этом расстояние, пройденное грузовиком, должно быть минимальным. 
Эта задача хорошо известна как “задача о коммивояжере”, и она является NP-пол- 
ной. Эффективный алгоритм решения для нее неизвестен, однако при некоторых 
предположениях можно указать такие алгоритмы, в результате выполнения кото
 рых полученное расстояние будет ненамного превышать минимально возможное. 
Подобные “приближенные алгоритмы” рассматриваются в главе 35.
 Параллельные вычисления
 Многие годы можно было считать скорость работы процессоров устойчиво 
возрастающей. Однако физика накладывает свои фундаментальные ограничения
32
 Часть I. Основы
 на скорость работы: поскольку с ростом тактовой частоты выделение тепловой 
мощности растет более чем линейно, микросхемы могут просто начать плавить
 ся. Для повышения количества вычислений, выполняемых за единицу времени, 
проектировщиками все активнее используется другой путь — разработка процес
 соров, содержащих несколько “ядер” Мы можем уподобить эти многоядерные 
компьютеры нескольким компьютерам на одном обычном процессоре; другими 
словами, это разновидность “параллельных компьютеров” Чтобы добиться более 
высокой производительности от многоядерных компьютеров, мы должны разра
 батывать алгоритмы с учетом возможности параллельных вычислений. В главе 27 
представлена модель для “многопоточных” (multithreaded) алгоритмов, которая 
использует преимущества многоядерности. Эта модель обладает рядом преиму
 ществ с теоретической точки зрения и образует основу для ряда успешных про
 грамм, включая программу для игры в шахматы.
 Упражнения
 1.1.1
 Приведите реальные примеры задач, в которых возникает потребность в сорти
 ровке или вычислении выпуклой оболочки.
 1.1.2
 Какими еще параметрами, кроме скорости, можно характеризовать алгоритм на 
практике?
 1.1.3
 Выберите одну из встречавшихся вам ранее структур данных и опишите ее пре
 имущества и ограничения.
 1.1.4
 Что общего между задачей об определении кратчайшего пути и задачей о комми
 вояжере? Чем они различаются?
 1.1.5
 Сформулируйте задачу, в которой необходимо только наилучшее решение. Сфор
 мулируйте также задачу, в которой может быть приемлемым решение, достаточно 
близкое к наилучшему.
 1.2. Алгоритмы как технология
 Предположим, быстродействие компьютера и объем его памяти можно уве
 личивать до бесконечности. Была бы в таком случае необходимость в изучении 
алгоритмов? Была бы, но только для того, чтобы продемонстрировать, что метод 
решения имеет конечное время работы и что он дает правильный ответ.
Глава 1. Роль алгоритмов в вычислениях
 33
 Если бы компьютеры были неограниченно быстрыми, подошел бы любой кор
 ректный метод решения задачи. Возможно, вы бы предпочли, чтобы реализация 
решения была выдержана в хороших традициях программирования (например, 
ваша реализация должна быть качественно разработана и аккуратно задокумен
 тирована), но чаще всего выбирался бы метод, который легче всего реализовать.
 Конечно же, сегодня есть весьма производительные компьютеры, но их быст
 родействие не может быть бесконечно большим. Память также дешевеет, но не 
может стать бесплатной. Таким образом, время вычисления — такой же ограни
 ченный ресурс, как и объем необходимой памяти. Вы должны разумно распоря
 жаться этими ресурсами, чему и способствует применение алгоритмов, эффек
 тивных в плане расходов времени и памяти.
 Эффективность
 Различные алгоритмы, разработанные для решения одной и той же задачи, 
часто очень сильно различаются по эффективности. Эти различия могут быть 
намного значительнее тех, которые вызваны применением неодинакового аппа
 ратного и программного обеспечения.
 В качестве примера можно привести два алгоритма сортировки, которые рас
 сматриваются в главе 2. Для выполнения первого из них, известного как сорти
 ровка вставкой, требуется время, которое оценивается как с\п2, где п — коли
 чество сортируемых элементов, а с\ — константа, не зависящая от п. Таким об
 разом, время работы этого алгоритма приблизительно пропорционально п2. Для 
выполнения второго алгоритма, сортировки слиянием, требуется время, прибли
 зительно равное С2П lg п, где lg п — краткая запись log2 п, а С2 — некоторая другая 
константа, не зависящая от п. Типичная константа метода вставок меньше кон
 станты метода слияния, т.е. с\ < С2. Давайте убедимся, что постоянные множи
 тели намного меньше влияют на время работы алгоритма, чем множители, зави
 сящие от п. Запишем время работы алгоритма сортировки вставкой как с\п ■ п, 
а сортировки слиянием — как С2П • lg п. Тогда мы увидим, что там, где сорти
 ровка вставкой имеет сомножитель п, сортировка слиянием содержит lgn, что 
существенно меньше. (Например, когда п = 1000, lgn приближенно равен 10, 
а когда п равно миллиону, lgn всего лишь около 20.) Хотя сортировка встав
 кой обычно работает быстрее сортировки слиянием для небольшого количества 
сортируемых элементов, когда размер входных данных п становится достаточ
 но большим, все заметнее проявляется преимущество сортировки слиянием, воз
 никающее благодаря тому, что для больших п незначительная величина lgn по 
сравнению с п полностью компенсирует разницу величин постоянных множите
 лей. Не имеет значения, во сколько раз константа с\ меньше, чем С2. С ростом 
количества сортируемых элементов обязательно будет достигнут переломный мо
 мент, когда сортировка слиянием окажется более производительной.
 В качестве примера рассмотрим два компьютера — А и Б. Компьютер А более 
быстрый, и на нем работает алгоритм сортировки вставкой, а компьютер Б бо
 лее медленный, и на нем работает алгоритм сортировки методом слияния. Оба 
компьютера должны выполнить сортировку множества, состоящего из десяти
 2 Зак. 3726
34
 Часть I. Основы
 миллионов чисел. (Хотя десять миллионов чисел и могут показаться огромным 
количеством, если эти числа представляют собой восьмибайтовые целые числа, 
то входные данные занимают около 80 Мбайт памяти, что весьма немного да
 же для старых недорогих лэптопов.) Предположим, что компьютер А выполняет 
десять миллиардов команд в секунду (что быстрее любого одного последователь
 ного компьютера на момент написания книги), а компьютер Б — только десять 
миллионов команд в секунду, так что компьютер А в тысячу раз быстрее компью
 тера Б. Чтобы различие стало еще большим, предположим, что код для метода 
вставок (т.е. для компьютера А) написан самым лучшим в мире программистом 
на машинном языке и для сортировки п чисел надо выполнить 2п2 команд. Сор
 тировка же методом слияния (на компьютере Б) реализована программистом-се- 
реднячком с помощью языка высокого уровня. При этом компилятор оказался не 
слишком эффективным, и в результате получился код, требующий выполнения 
50n lg п команд. Для сортировки десяти миллионов чисел компьютеру А понадо
 бится
 2 • (107)2 команд 
Ю10 команд в секунду = 20000 секунд (более 5.5 часов)
 в то время как компьютеру Б потребуется
 50 • 107 lg 107 команд 
107 команд в секунду
 1163 секунд (менее 20 минут) .
 Как видите, использование кода, время работы которого возрастает медленнее, 
даже при плохом компиляторе на более медленном компьютере требует более 
чем в 17 раз меньше процессорного времени! Если же нужно выполнить сор
 тировку ста миллионов чисел, то преимущество метода слияния становится еще 
более очевидным: там, где для сортировки вставкой потребуется более 23 дней, 
сортировка слиянием справится за четыре часа. Общее правило таково: чем боль
 ше количество сортируемых элементов, тем заметнее преимущество сортировки 
слиянием.
 Алгоритмы и другие технологии
 Приведенный выше пример демонстрирует, что алгоритмы, как и аппаратное 
обеспечение компьютера, следует рассматривать как технологию. Общая произ
 водительность системы настолько же зависит от эффективности алгоритма, на
 сколько и от мощности применяющегося аппаратного обеспечения. В области 
разработки алгоритмов происходит такое же быстрое развитие, как и в других 
компьютерных технологиях.
 Возникает вопрос, действительно ли так важны алгоритмы, работающие на 
современных компьютерах, если и так достигнуты выдающиеся успехи в других 
областях высоких технологий, таких как
 • усовершенствованные архитектуры компьютеров и технологий их изготов
 ления;
 • легкодоступные, интуитивно понятные графические интерфейсы (GUI);
Глава 1. Роль алгоритмов в вычислениях
 • объектно-ориентированные системы;
 • интегрированные веб-технологии;
 • быстрые сети, как проводные, так и беспроводные.
 35
 Ответ — да, безусловно. Несмотря на то что некоторые приложения не требуют 
алгоритмического наполнения явно (такие, как некоторые простые веб-приложе
 ния), для большинства приложений оно необходимо. Например, рассмотрим веб
 службу, определяющую, как добраться из одного места в другое. В основе ее ре
 ализации лежит высокопроизводительное аппаратное обеспечение, графический 
интерфейс пользователя, глобальная сеть и, возможно, объектно-ориентирован
 ный подход. Кроме того, использование алгоритмов необходимо для определен
 ных операций, выполняемых данной веб-службой, например таких, как поиск 
маршрутов (вероятно, использующий алгоритм поиска кратчайшего пути), визуа
 лизация карт и интерполяция адресов.
 Более того, даже приложение, не требующее алгоритмического наполнения на 
высоком уровне, сильно зависит от алгоритмов. Ведь известно, что работа при
 ложения зависит от производительности аппаратного обеспечения, а при его раз
 работке применяются разнообразные алгоритмы. Все мы также знаем, что прило
 жение тесно связано с графическим интерфейсом пользователя, а для разработки 
любого графического интерфейса пользователя требуются алгоритмы. Вспомним 
приложения, работающие в сети. Чтобы они могли функционировать, необхо
 димо осуществлять маршрутизацию, которая, как уже говорилось, основана на 
ряде алгоритмов. Чаще всего приложения составляются на языке, отличном от 
машинного. Их код обрабатывается компилятором или интерпретатором, который 
интенсивно использует различные алгоритмы. И таким примерам несть числа.
 Кроме того, ввиду постоянного роста вычислительных возможностей компью
 теров, они применяются для решения все более и более сложных задач. Как 
мы уже убедились на примере сравнительного анализа двух методов сортиров
 ки, с ростом сложности решаемой задачи различия в эффективности алгоритмов 
проявляются все значительнее.
 Знание основных алгоритмов и методов их разработки — одна из характери
 стик, отличающих действительно умелого, опытного программиста от новичка. 
Располагая современными компьютерными технологиями, некоторые задачи мож
 но решить и без основательного знания алгоритмов, однако знания в этой области 
позволяют достичь намного большего.
 Упражнения
 1.2.1
 Приведите пример приложения, для которого необходимо алгоритмическое на
 полнение на уровне приложений, и обсудите функции этих алгоритмов.
 1.2.2
 Предположим, на одной и той же машине проводится сравнительный анализ ре
 ализаций двух алгоритмов сортировки, работающих вставкой и слиянием. Для
36
 Часть I. Основы
 сортировки п элементов вставкой необходимо 8п2 шагов, а для сортировки слия
 нием — 64п lg п шагов. При каком значении п время сортировки вставкой превы
 сит время сортировки слиянием?
 1.2.3
 При каком минимальном значении п алгоритм, время работы которого опреде
 ляется формулой 100п2, работает быстрее, чем алгоритм, время работы которого 
выражается как 2П, если оба алгоритма выполняются на одной и той же машине?
 Задачи
 1.1. Сравнение времени работы алгоритмов
 Ниже приведена таблица, строки которой соответствуют различным функци
 ям f(n), а столбцы — значениям времени t. Заполните таблицу максимальными 
значениями п, для которых задача может быть решена за время t, если предпо
 лагается, что время работы алгоритма, необходимое для решения задачи, равно 
f(n) микросекунд.
 Секунда Минута
 lgn
 \/п
 п
 nlgn
 п2
 п3
 2П
 п\
 Заключительные замечания
 Час
 День
 Месяц
 Год
 Век
 Имеется множество отличных учебников, посвященных общим вопросам ал
 горитмов. К ним относятся книги Ахо (Aho), Хопкрофта (Hopcroft) и Ульма
 на (Ullman) [5, 6]1; Бейза (Baase) и Ван Гельдера (Van Gelder) [27]; Брассарда 
(Brassard) и Брейтли (Bratley) [53]; Дасгупта (Dasgupta), Пападимитроу (Рара- 
dimitriou) и Вазирани (Vazirani) [81]; Гудрича (Goodrich) и Тамазии (Tamassia) 
[147]; Гофри (Hofri) [174]; Горовитца (Horowitz), Сани (Sahni) и Раджасекара- 
на (Rajasekaran) [180]; Джонсонбауфа (Johnsonbaugh) и Шефера (Schaefer) [192];
 1 Имеется русский перевод: А. Ахо, Д. Хопкрофт, Д. Ульман. Структуры данных и алгоритмы. — М.: 
И.Д. “Вильямс”, 2000.
Глава 1. Роль алгоритмов в вычислениях
 37
 Кингстона [204]; Кляйнберга (Kleinberg) и Тардоса (Tardos) [207]; Кнута (Knuth) 
[208-210]2; Козена (Kozen) [219]; Левитина (Levitin) [234]; Манбера (Manber) 
[241]; Мельхорна (Mehlhom) [247-249]; Пурдома (Purdom) и Брауна (Brown) [285]; 
Рейнгольда (Reingold), Ньевергельта (Nievergelt) и Део (Deo) [291]; Седжевика 
(Sedgewick) [304]; Седжевика (Sedgewick) и Флажоле (Flajolet) [305]; Скьены 
(Skiena) [316]; и Вильфа (Wilf) [354]. Некоторые аспекты разработки алгорит
 мов, имеющие большую практическую направленность, обсуждаются в книгах 
Бентли (Bentley) [41,42] и Тонне (Gonnet) [144]. Обзоры по алгоритмам можно 
также найти в книгах Handbook of Theoretical Computer Science, Volume A [340] 
и CRC Algorithms and Theory of Computation Handbook [24]. Обзоры алгорит
 мов, применяющихся в вычислительной биологии, можно найти в учебниках Гас- 
филда (Gusfield) [155], Певзнера (Pevzner) [273], Сетубала (Setubal) и Мейданиса 
(Meidanis) [308], а также Вотермана (Waterman) [348].
 2Имеется русский перевод этих книг: Д. Кнут. Искусство программирования, т. 1. Основные алгоритмы, 
3-е изд. — М.: И.Д. “Вильямс”, 2000; Д. Кнут. Искусство программирования, т. 2. Получисленные алгоритмы, 
3-е изд. — М.: И.Д. “Вильямс”, 2000; Д. Кнут. Искусство программирования, т. 3. Сортировка и поиск, 2-е изд. — 
М.: И.Д. “Вильямс”, 2000. Кроме того, уже после написания данной книги вышел очередной том “Искусства 
программирования”: Д. Кнут. Искусство программирования, т. 4, А. Комбинаторные алгоритмы, часть 1. — 
М.: И.Д. “Вильямс”, 2013.
Глава 2 Приступаем к изучению
 В этой главе вы ознакомитесь с основными понятиями, с помощью которых 
на протяжении всей книги будет проводиться разработка и анализ алгоритмов. 
Глава самодостаточна, но включает ряд ссылок на материал, который будет вве
 ден в главах 3 и 4 (в ней также имеются некоторые суммы, работа с которыми 
рассматривается в приложении А).
 В начале главы исследуется алгоритм сортировки вставками. Он предназначен 
для решения задачи сортировки, поставленной в главе 1. Мы определим “псевдо
 код”, который должен быть понятен вам, если вы когда-либо занимались програм
 мированием, и применим его, чтобы показать, как будут определяться в книге 
наши алгоритмы. Определяя алгоритм сортировки вставкой, мы докажем его кор
 ректность и проанализируем время его работы. В ходе анализа вводятся обозна
 чения, используемые для указания зависимости времени работы алгоритма от ко
 личества сортируемых элементов. После обсуждения сортировки вставками опи
 сывается метод декомпозиции, основанный на принципе “разделяй и властвуй”. 
Этот подход используется для разработки различных алгоритмов; в данном слу
 чае с его помощью будет сформулирован алгоритм, называемый сортировкой сли
 янием. В конце главы анализируется время работы этого алгоритма сортировки.
 2.1. 
Сортировка вставкой
 Наш первый алгоритм, алгоритм сортировки вставкой, предназначен для ре
 шения задачи сортировки, поставленной в главе 1.
 Вход. Последовательность п чисел (ai, аг,..., ап).
 Выход. Перестановка (переупорядочение) (а[, а'2, 
а'п) входной последова
 тельности, такая, что а[ < а2 < ■ • • < а'п.
 Сортируемые числа также известны под названием ключи (keys). Хотя концеп
 туально мы сортируем последовательность, входные данные мы получаем в виде 
массива с п элементами.
 В этой книге алгоритмы обычно описываются в виде псевдокода, который во 
многих отношениях похож на языки программирования С, C++, Java, Python или 
Pascal. Тем, кто знаком хотя бы с одним из этих языков, не потребуется много
Глава 2. Приступаем к изучению
 Рис. 2.1. Сортировка карт вставкой.
 39
 усилий на чтение алгоритмов. От обычного кода псевдокод отличается тем, что 
он выразителен, а также лаконично, точно и понятно описывает алгоритм. Ино
 гда в качестве такового выступает литературный язык, поэтому не удивляйтесь, 
если в инструкции “настоящего” кода встретите обычную фразу или предложе
 ние. Другое различие между псевдокодом и обычным кодом заключается в том, 
что в псевдокоде, как правило, не рассматриваются некоторые вопросы, которые 
приходится решать разработчикам программного обеспечения. Такие вопросы, 
как абстракция данных, модульность и обработка ошибок, часто игнорируются, 
чтобы более выразительно передать суть алгоритма.
 Наше изучение алгоритмов начинается с рассмотрения сортировки вставкой 
(insertion sort). Этот алгоритм эффективно работает при сортировке небольшо
 го количества элементов. Сортировка вставкой напоминает способ, к которому 
прибегают игроки для сортировки имеющихся на руках карт. Пусть вначале в ле
 вой руке нет ни одной карты и все они лежат на столе рубашкой вверх. Далее 
со стола берется по одной карте, каждая из которых помещается в нужное ме
 сто среди карт, которые находятся в левой руке. Чтобы определить, куда нужно 
поместить очередную карту, ее масть и достоинство сравниваются с мастью и до
 стоинством карт в руке. Допустим, сравнение проводится в направлении слева 
направо (рис. 2.1). В любой момент карты в левой руке будут отсортированы, 
и это будут те карты, которые первоначально лежали в стопке на столе.
 Псевдокод сортировки вставкой представлен ниже в виде процедуры под 
названием Insertion-Sort, которая получает в качестве параметра массив 
А[1.. п], содержащий последовательность длиной п, которая должна быть от
 сортирована. (В коде количество элементов п в массиве А обозначается как 
A. length.) Алгоритм сортирует входные числа на месте, без привлечения до
 полнительной памяти: она выполняет перестановку чисел в пределах массива А, 
и объем используемой при этом дополнительной памяти в любой момент работы 
алгоритма не превышает некоторую постоянную величину. По завершении проце
40
 Часть I. Основы
 дуры Insertion-Sort входной массив А содержит отсортированную выходную 
последовательность.
 Insertion-Sort (Л)
 1 for j = 2 to A. length
 2 
key = A[j]
 3 
4 
5 
6
 7 
8
 / / Вставка A[j] в отсортированную
 последовательность A[l.. j — 1].
 i = j - 1
 while г > 0 и A[i] > key
 A[i + 1] = A[i]
 i = i - 1
 A[i + 1] = key
 Инварианты цикла и корректность сортировки вставкой
 На рис. 2.2 показано, как этот алгоритм работает с массивом А = (5, 2, 4, 6, 
1, 3). Индекс j указывает “текущую карту”, которая помещается в руку. В начале 
каждой итерации цикла for с индексом j массив А состоит из двух частей. Эле
 менты А[ 1.. j — 1] соответствуют отсортированным картам в руке, а элементы 
A[j + 1 .. п\ — стопке карт, которые пока что остались на столе. Заметим, что 
элементы А[ 1 .. j — 1] изначально также находились в позициях от 1 до j — 1, 
но в другом порядке, однако теперь они отсортированы. Назовем это свойство 
элементов А[ 1.. j — 1] инвариантом цикла (loop invariant) и сформулируем его 
еще раз.
 В начале каждой итерации цикла for, состоящего из строк 1-8, подмас
 сив А[1.. j — 1] состоит из элементов, которые изначально находились 
в А[1.. j — 1], но теперь расположены в отсортированном порядке.
 2 гл 5 р ' 3
 V
 1 2 3
 1
 4 5 6
 2 3 4 5 6
 Рис. 2.2. Операции процедуры Insertion-Sort над массивом А = (5, 2, 4, 6, 1, 3). Элементы 
массива обозначены квадратиками, над которыми находятся индексы, а внутри — значения соответ
 ствующих элементов. Части (а)-(д) этого рисунка соответствуют итерациям цикла for в строках 1-8 
псевдокода. В каждой итерации черный квадратик содержит значение ключа из A\j\, которое срав
 нивается со значениями серых квадратиков, расположенных слева от него (строка псевдокода 5). 
Серыми стрелками указаны те значения массива, которые сдвигаются на одну позицию вправо 
(строка 6), а черной стрелкой — перемещение ключа (строка 8). В части (е) показано конечное 
состояние отсортированного массива.
Глава 2. Приступаем к изучению
 41
 Инварианты цикла позволяют понять, корректно ли работает алгоритм. 
Необходимо показать, что инварианты циклов обладают следующими тремя 
свойствами.
 Инициализация. Они справедливы перед первой итерацией цикла.
 Сохранение. Если они истинны перед очередной итерацией цикла, то остаются 
истинны и после нее.
 Завершение. По завершении цикла инварианты позволяют убедиться в правиль
 ности алгоритма.
 Если выполняются первые два свойства, инварианты цикла остаются истинны
 ми перед каждой очередной итерацией цикла. (Конечно, для доказательства того, 
что инвариант остается истинным перед каждой итерацией, можно использовать 
любые другие установленные факты, помимо самого инварианта.) Обратите вни
 мание на сходство с математической индукцией, когда для доказательства опреде
 ленного свойства для всех элементов упорядоченной последовательности нужно 
доказать его справедливость для начального элемента этой последовательности, 
а затем обосновать шаг индукции. В данном случае первой части доказательства 
соответствует обоснование того, что инвариант цикла выполняется перед первой 
итерацией, а второй части — доказательство того, что инвариант цикла выполня
 ется после очередной итерации (шаг индукции).
 Для наших целей третье свойство, пожалуй, самое важное, так как нам нуж
 но с помощью инварианта цикла продемонстрировать корректность алгоритма. 
Обычно инвариант цикла используется вместе с условием, заставляющим цикл 
завершиться. Свойство завершения отличает рассматриваемый нами метод от 
обычной математической индукции, в которой шаг индукции используется в бес
 конечных последовательностях. В данном случае по окончании цикла “индукция” 
останавливается.
 Рассмотрим, соблюдаются ли эти свойства для сортировки методом вставки.
 Инициализация. Начнем с того, что покажем справедливость инварианта цикла 
перед первой итерацией, т.е. при j = 2.1 Таким образом, подмассив А[ 1.. j — l\ 
состоит только из одного элемента Л[1], сохраняющего исходное значение. Бо
 лее того, в этом подмножестве элементы рассортированы (тривиальное утвер
 ждение). Все вышесказанное подтверждает, что инвариант цикла соблюдается 
перед первой итерацией цикла.
 Сохранение. Далее обоснуем второе свойство: покажем, что инвариант цикла 
сохраняется после каждой итерации. Выражаясь неформально, можно сказать, 
что в теле внешнего цикла for происходит сдвиг элементов A[j — 1], A[j — 2],
 'Если рассматривается цикл for, момент времени, когда проверяется справедливость инварианта цикла 
перед первой итерацией, наступает сразу после начального присваивания значения индексу цикла, непосред
 ственно перед первой проверкой в заголовочной инструкции цикла. В процедуре INSERTION-SORT это момент, 
когда переменной j присвоено значение 2, но еще не выполнена проверка неравенства j < A. length.
42
 Часть /. Основы
 A[j — 3], ... на одну позицию вправо до тех пор, пока не освободится подхо
 дящее место для элемента A[j] (строки 4-7), куда и вставляется значение A[j] 
(строка 8). Подмассив А[ 1.. j] после этого состоит из элементов, изначально 
находившихся в А[1.. j], но в отсортированном порядке. Следующее за этим 
увеличение j для следующей итерации цикла for сохраняет инвариант цикла.
 При более формальном подходе к рассмотрению второго свойства потребова
 лось бы сформулировать и обосновать инвариант для внутреннего цикла while 
в строках 5-7. Однако на данном этапе мы предпочитаем не вдаваться в та
 кие формальные подробности, поэтому будем довольствоваться неформаль
 ным анализом, чтобы показать, что для внешнего цикла соблюдается второе 
свойство инварианта цикла.
 Завершение. Наконец посмотрим, что происходит по завершении работы цикла. 
Условие, приводящее к завершению цикла for, — j > A. length = п. Поскольку 
каждая итерация цикла увеличивает j на 1, мы должны в этот момент иметь 
j = п + 1. Подставив в формулировку инварианта цикла вместо j значение 
п+1, получим, что подмассив А[ 1.. п] состоит из элементов, изначально нахо
 дившихся в А[ 1 .. п\, но расположенных в отсортированном порядке. Заметим, 
что подмассив А[1.. п] и есть сам массив А, так что весь массив отсортирован, 
а следовательно, алгоритм корректен.
 Метод инвариантов циклов будет применяться далее в данной главе, а также
 в последующих главах книги.
 Соглашения, принятые при составлении псевдокода
 При составлении псевдокода используются следующие соглашения.
 • Блочная структура указывается с помощью отступов. Например, тело цикла 
for, начинающегося в строке 1, состоит из строк 2- 8, а тело цикла while, на
 чинающегося в строке 5, содержит строки 6 и 7, но не строку 8. Наш способ 
применения отступов применим и к инструкциям if-else2. Применение отсту
 пов вместо явного указания блочной структуры, такого, как с использованием 
ключевых слов begin и end, существенно уменьшает зашумленность кода при 
сохранении или даже при повышении его понятности3.
 • Конструкции циклов while, for и repeat-until, а также условная конструкция 
if-else интерпретируются, как в языках программирования С, C++, Java, Python
 2В инструкции if-else мы смещаем блок else точно так же, как и соответствующий ему блок if. Хотя 
мы опускаем слово then, мы время от времени ссылаемся на часть кода, выполняемую, когда проверка if 
оказывается истинной, как на блок then. В случае тестов с ветвлением мы используем ключевое слово elseif 
для проверок, следующих за первой.
 3В этой книге каждая процедура, записанная с применением псевдокода, располагается на одной странице, 
так что у вас не будет проблем с угадыванием уровня отступа в коде, размещенном на нескольких страницах.
Глава 2. Приступаем к изучению
 43
 и Pascal4. В этой книге счетчик цикла сохраняет свое значение после выхода 
из цикла, в отличие от некоторых ситуаций, встречающихся в языках С-н-, 
Java и Pascal. Таким образом, непосредственно после цикла for значение его 
счетчика представляет собой значение, которое впервые превышает границу 
цикла for. Мы использовали это свойство в нашем доказательстве корректно
 сти сортировки вставкой. Заголовок цикла for в строке 1 имеет вид for j = 2 
to A. length, так что, когда цикл завершает работу, j = A. length+ 1 (или, что то 
же самое, j = п + 1, поскольку п = A. length). Мы используем ключевое слово 
to, когда цикл for увеличивает значение счетчика цикла на каждой итерации, 
и слово downto, когда на каждой итерации цикла for значение счетчика умень
 шается. Когда значение счетчика цикла изменяется на значение, большее 1, это 
значение следует за необязательным ключевым словом by.
 • Символ “//” указывает, что остальная часть строки представляет собой ком
 ментарий.
 • Множественное присваивание вида г = j = е присваивает обеим переменным 
г и j значение выражения е; его следует рассматривать как эквивалентное 
присваиванию j = е, за которым следует присваивание i = j.
 • Переменные (такие, как г, j или key) являются локальными для данной проце
 дуры. Мы не будем использовать глобальные переменные без явного указания 
этого факта.
 • Доступ к элементам массива осуществляется путем указания имени массива, 
за которым в квадратных скобках следует индекс. Например, А[г\ указывает г-й 
элемент массива А. Запись “..” используется для того, чтобы указать диапазон 
значений индексов массива. Так, А[ 1.. j] определяет подмассив массива А, 
состоящий из j элементов А[1], Л[2],..., A\j).
 • Составные данные мы обычно организуем в объекты, которые состоят из 
атрибутов. К определенному атрибуту объекта мы обращаемся с примене
 нием синтаксиса, имеющегося во многих объектно-ориентированных языках 
программирования: за именем объекта следует точка, за которой следует имя 
атрибута. Например, мы рассматриваем массив как объект с атрибутом length, 
указывающим количество содержащихся в нем элементов. Чтобы указать ко
 личество элементов в массиве А, мы записываем A. length.
 Мы рассматриваем переменную, представляющую массив или объект, как ука
 затель на данные, представляющие этот массив или объект. Для всех атрибутов 
/ объекта х присваивание у = х приводит к тому, что y.f становится равным 
x.f. Более того, если мы теперь установим x.f = 3, то после этого не только 
x.f будет равным 3, но и y.f также станет равным 3. Другими словами, х и у 
после присваивания у = х указывают на один и тот же объект.
 4Большинство языков с блочной структурой имеют эквивалентные конструкции, хотя точные их синтаксисы 
могут различаться. В языке Python отсутствуют циклы repeat-until, а его циклы for работают немного не так, 
как циклы for в этой книге.
44
 Часть /. Основы
 Запись атрибутов может быть “каскадной” Например, предположим, что ат
 рибут / сам по себе является указателем на объект некоторого типа, который 
имеет атрибут д. Тогда запись x.f.g неявно подразумевает наличие скобок 
(x.f).g. Другими словами, если мы присвоим у = x.f, то x.f.g будет тем же, 
что и у.д.
 Иногда указатель вообще не ссылается ни на какой объект. В таком случае он 
имеет специальное значение nil.
 • Параметры в процедуру передаются по значению: вызываемая процедура по
 лучает собственную копию параметров, и если она присваивает параметру зна
 чение, то это изменение не будет видимым для вызывающей процедуры. При 
передаче объектов копируется указатель на представляющие объект данные, 
но не атрибуты объекта. Например, если х представляет собой параметр вы
 зываемой процедуры, присваивание х = у в вызываемой процедуре не будет 
видимым для вызывающей процедуры. Однако присваивание x.f = 3 являет
 ся видимым. Аналогично массивы передаются с помощью передачи указателя, 
а не целого массива, и изменения отдельных элементов массива видимы для 
вызывающей процедуры.
 • Инструкция return немедленно возвращает управление в точку вызова в вы
 зывающей процедуре. В большинстве случаев инструкция return получает 
значение для возврата вызывающей процедуре. Наш псевдокод отличается от 
многих языков программирования тем, что мы допускаем возврат нескольких 
значений одной инструкцией return.
 • Булевы операторы “и” и “или” вычисляются сокращенно (short circuiting). Это 
означает, что при вычислении выражения “ж и у” сначала вычисляется зна
 чение выражения х. Если это значение ложно (false), то все выражение не 
может быть истинным, и значение выражения у не вычисляется. Если же вы
 ражение х истинно (true), то для определения значения всего выражения 
необходимо вычислить выражение у. Аналогично в выражении “ж или у” ве
 личина у вычисляется только в том случае, если выражение х ложно. Сокра
 щенные операторы позволяют составлять такие логические выражения, как 
“ж Ф NIL и x.f — у”, не беспокоясь о том, что произойдет при попытке вычис
 лить выражение x.f, когда х равно NIL.
 • Ключевое слово error указывает на ошибку, произошедшую из-за неверных 
условий при вызове процедуры. За обработку ошибки отвечает вызывающая 
процедура, а потому мы не указываем, какие действия должны быть предпри
 няты.
 Упражнения
 2.1.1
 Используя рис. 2.2 в качестве образца, проиллюстрируйте работу процедуры
 Insertion-Sort по сортировке массива А = (31,41,59,26,41,58).
Глава 2. Приступаем к изучению
 45
 2.1.2
 Перепишите процедуру Insertion-Sort для сортировки в невозрастающем по
 рядке вместо неубывающего.
 2.1.3
 Рассмотрим задачу поиска.
 Вход. Последовательность из п чисел А = (ai, a2, ..., ап) и значение v.
 Выход. Индекс г, такой, что v = А [г], или специальное значение NIL, если v в А 
отсутствует.
 Составьте псевдокод линейного поиска, при работе которого выполняется скани
 рование последовательности в поисках значения v. Докажите корректность алго
 ритма с помощью инварианта цикла. Убедитесь, что выбранный инвариант цикла 
удовлетворяет трем необходимым условиям.
 2.1.4
 Рассмотрим задачу сложения двух n-битовых двоичных целых чисел, хранящих
 ся в n-элементных массивах А и В. Сумму этих двух чисел необходимо занести 
в двоичной форме в (п + 1)-элементный массив С. Приведите строгую формули
 ровку задачи и составьте псевдокод для сложения этих двух чисел.
 2.2. 
Анализ алгоритмов
 Анализ заключается в том, чтобы предсказать требуемые для его выполнения 
ресурсы. Иногда оценивается потребность в таких ресурсах, как память, пропуск
 ная способность сети или необходимое аппаратное обеспечение, но чаще всего 
определяется время вычисления. Путем анализа нескольких алгоритмов, предна
 значенных для решения одной и той же задачи, можно выбрать наиболее эффек
 тивный из них. В процессе такого анализа может также оказаться, что несколько 
алгоритмов примерно равноценны, а многие алгоритмы в процессе анализа часто 
приходится отбрасывать.
 Прежде чем мы научимся анализировать алгоритмы, необходимо разработать 
технологию, которая будет для этого использоваться. В эту технологию нужно 
будет включить модель ресурсов и величины их измерения. С учетом того, что 
алгоритмы реализуются в виде компьютерных программ, в этой книге в большин
 стве случаев в качестве технологии реализации принята модель обобщенной од
 нопроцессорной машины с памятью с произвольным доступом (Random-Access 
Machine — RAM). В этой модели команды процессора выполняются последова
 тельно; одновременно выполняемые операции отсутствуют.
 Строго говоря, в модели RAM следует точно определить набор инструкций 
и время их выполнения, однако это утомительно и мало способствует пониманию 
принципов разработки и анализа алгоритмов. С другой стороны, нужно соблю
 дать осторожность, чтобы не исказить модель RAM. Например, что будет, если 
в RAM встроена команда сортировки? В этом случае сортировку можно выпол
46
 Часть I. Основы
 нять с помощью всего одной команды процессора. Такая модель нереалистична, 
поскольку настоящие компьютеры не имеют подобных встроенных команд, а мы 
ориентируемся именно на их устройство. В рассматриваемую модель входят те 
команды, которые обычно можно найти в реальных компьютерах: арифметиче
 ские (сложение, вычитание, умножение, деление, вычисление остатка от деле
 ния, приближение действительного числа ближайшим меньшим или ближайшим 
большим целым), операции перемещения данных (загрузка, занесение в память, 
копирование) и управляющие (условное и безусловное ветвление, вызов подпро
 граммы и возврат из нее). Для выполнения каждой такой инструкции требуется 
определенный фиксированный промежуток времени.
 В модели RAM есть целочисленный тип данных и тип чисел с плавающей 
точкой (для хранения действительных чисел). Несмотря на то что обычно в этой 
книге точность не рассматривается, в некоторых приложениях она играет важ
 ную роль. Также предполагается, что существует верхний предел размера слова 
данных. Например, если обрабатываются входные данные с максимальным зна
 чением п, обычно предполагается, что целые числа представлены clgn битами 
для некоторой константы с > 1. Требование с > 1 обусловлено тем, что в каж
 дом слове должно храниться одно из п значений, что позволит индексировать 
входные элементы. Кроме того, предполагается, что с — это конечная константа, 
поэтому объем слова не может увеличиваться до бесконечности. (Если бы это бы
 ло возможно, в одном слове можно было бы хранить данные огромных объемов 
и осуществлять над ними операции в рамках одной элементарной команды, что 
нереально.)
 В реальных компьютерах содержатся команды, не упомянутые выше, которые 
представляют “серую область” модели RAM. Например, является ли возведение 
в степень командой с константным временем работы? В общем случае — нет; 
чтобы вычислить выражение ху, в котором х и у — действительные числа, потре
 буется несколько команд. Однако в некоторых случаях эту операцию можно пред
 ставить в виде элементарной команды. Во многих компьютерах имеется команда 
побитового сдвига влево, которая в течение времени, требуемого для выполнения 
элементарной команды, сдвигает биты целого числа на к позиций влево. В боль
 шинстве случаев такой сдвиг целого числа на одну позицию эквивалентен его 
умножению на 2. Сдвиг битов на к позиций влево эквивалентен его умножению 
на 2к. Таким образом, на этих компьютерах 2к можно вычислить с помощью од
 ной элементарной инструкции, сдвинув целое число 1 на к позиций влево; при 
этом к не должно превышать количество битов компьютерного слова. Мы по
 пытаемся избегать таких “серых областей” модели RAM, однако вычисление 2к 
будет рассматриваться как элементарная операция, если к — достаточно малое 
целое положительное число.
 В исследуемой модели RAM не предпринимаются попытки смоделировать 
иерархию запоминающих устройств, общепринятую на современных компьюте
 рах. Таким образом, мы не моделируем кеш и виртуальную память. В некоторых 
вычислительных моделях предпринимается попытка смоделировать эффекты, вы
 званные иерархией запоминающих устройств, которые иногда важны в реальных 
программах, работающих на реальных машинах. В ряде рассмотренных в данной
Глава 2. Приступаем к изучению
 47
 книге задач эти эффекты принимаются во внимание, но в большинстве случа
 ев они не учитываются. Модели, включающие в себя иерархию запоминающих 
устройств, заметно сложнее модели RAM и поэтому могут затруднить работу. 
Кроме того, анализ, основанный на модели RAM, обычно замечательно предска
 зывает производительность алгоритмов, выполняющихся на реальных машинах.
 Анализ даже простого алгоритма в модели RAM может потребовать значи
 тельных усилий. В число необходимых математических инструментов могут вой
 ти комбинаторика, теория вероятностей, навыки алгебраических преобразований 
и способность идентифицировать наиболее важные слагаемые в формуле. По
 скольку поведение алгоритма может различаться для разных наборов входных 
значений, потребуется методика учета, описывающая поведение алгоритма с по
 мощью простых и понятных формул.
 Даже когда для анализа данного алгоритма выбирается всего одна модель ма
 шины, нам все еще предстоит выбрать средства для выражения анализа. Хотелось 
бы выбрать простые обозначения, которые позволят легко с ними работать и вы
 являть важные характеристики требований, предъявляемых алгоритмом к ресур
 сам, а также избегать сложных деталей.
 Анализ сортировки вставкой
 Время работы процедуры Insertion-Sort зависит от набора входных значе
 ний: для сортировки тысячи чисел требуется больше времени, чем для сортиров
 ки трех чисел. Кроме того, время сортировки с помощью этой процедуры может 
быть разным для последовательностей, состоящих из одного и того же количества 
элементов, в зависимости от степени упорядоченности этих последовательностей 
до начала сортировки. В общем случае время работы алгоритма увеличивается 
с увеличением количества входных данных, поэтому общепринятая практика — 
представлять время работы программы как функцию, зависящую от количества 
входных элементов. Для этого понятия “время работы алгоритма” и “размер вход
 ных данных” нужно определить точнее.
 Наиболее адекватное понятие размера входных данных (input size) зависит от 
рассматриваемой задачи. Во многих задачах, таких как сортировка или дискрет
 ные преобразования Фурье, это количество входных элементов, например размер 
п сортируемого массива. Для многих других задач, таких как перемножение двух 
целых чисел, наиболее подходящая мера для измерения размера ввода — общее 
количество битов, необходимых для представления входных данных в обычных 
двоичных обозначениях. Иногда размер ввода удобнее описывать с помощью не 
одного, а двух чисел. Например, если на вход алгоритма подается граф, размер 
ввода можно описывать, указывая количество вершин и ребер графа. Для каж
 дой рассматриваемой далее задачи будет указываться способ измерения размера 
входных данных.
 Время работы алгоритма для тех или иных входных данных измеряется в ко
 личестве элементарных операций, или “шагов”, которые необходимо выполнить. 
Здесь удобно ввести понятие шага, чтобы рассуждения были как можно более 
машинно-независимыми. На данном этапе мы будем исходить из точки зрения, 
согласно которой для выполнения каждой строки псеводкода требуется фикси
48
 Часть I. Основы
 рованное время. Время выполнения различных строк может различаться, но мы 
предположим, что одна и та же г-я строка выполняется за время а, где а — кон
 станта. Эта точка зрения согласуется с моделью RAM и отражает особенности 
практической реализации псевдокода на реальных компьютерах5.
 В последующем рассмотрении формула для выражения времени работы ал
 горитма Insertion-Sort, которая сначала будет сложным образом зависеть от 
всех величин сг, значительно упростится благодаря более лаконичным обозна
 чениям, с которыми проще работать. Эти более простые обозначения позволят 
легче определить, какой из двух алгоритмов эффективнее.
 Начнем с того, что введем для процедуры Insertion-Sort временную “сто
 имость” каждой инструкции и количество их повторений. Для каждого j = 
2 ,3,..., п, где п = A. length, обозначим через tj количество проверок условия 
в цикле while (строка 5). При нормальном завершении циклов for и while (т.е. 
когда перестает выполняться условие, заданное в заголовке цикла) условие про
 веряется на один раз больше, чем выполняется тело цикла. Само собой разуме
 ется, мы считаем, что комментарии не являются исполняемыми инструкциями, 
поэтому они не увеличивают время работы алгоритма.
 Insertion-Sort (А)
 1
 2
 3
 4
 5
 6
 7
 8
 for j = 2 to A. length
 key = A[j]
 / / Вставка A[j] в отсортированную
 последовательность
 A[l..j-l}.
 i = j ~ 1
 while i > 0 и A\i\ > key
 A[i + 1] = A[i]
 i = i — 1
 A[i + 1] = key
 Стоимость Повторы
 Cl
 C2
 0
 c4
 Cb
 C6
 c?
 C8
 n
 n — 1
 n — 1
 n — 1
 £ j=2 ti
 £ "= 2 ft - 1)
 E JU ft - 1)
 n — 1
 Время работы алгоритма — это сумма промежутков времени, необходимых 
для выполнения каждой входящей в его состав выполняемой инструкции. Если 
выполнение инструкции длится в течение времени с* и она повторяется в ал
 горитме п раз, то ее вклад в полное время работы алгоритма равен ап6. Чтобы 
вычислить время работы алгоритма Insertion-Sort (обозначим его через Т(п)), 
нужно просуммировать произведения значений, стоящих в столбцах стоимость
 53десь есть некоторые нюансы. Шаги вычислений, описанные на обычном языке, часто представляют собой 
разновидности процедур, состоящих из нескольких элементарных инструкций, имеющих более чем констант
 ное время работы. Например, далее в этой книге может встретиться строка “сортировка точек по координате 
х” Как вы увидите, эта команда требует больше чем постоянного количества времени работы. Заметим также, 
что команда вызова подпрограммы выполняется в течение фиксированного времени, однако сколько длится вы
 полнение вызванной подпрограммы, зависит от ее сложности. Таким образом, процесс вызова подпрограммы 
(передачу в нее параметров и другие действия) следует отличать от процесса выполнения этой подпрограммы.
 6 Это правило не всегда применимо к такому ресурсу, как память. Если инструкция оперирует т словами 
памяти и выполняется п раз, то это еще не означает, что всего при этом потребляется т п слов памяти.
Глава 2. Приступаем к изучению
 и повторы, в результате чего получим
 Т(п) = с\п + с2(п - 1) + 04(72 - 1) + с5 
П
 + 
3 = 2- 
1) + C8(n- 1) .
 49
 п
 3 =2 
п
 + се 
J —2- 1)
 Даже если размер входных данных является фиксированной величиной, время 
работы алгоритма может зависеть от самих входных данных — степени упоря
 доченности сортируемых величин, которой они обладали до ввода. Например, 
самый благоприятный случай для алгоритма Insertion-Sort — это когда все 
элементы массива уже отсортированы. Тогда для каждого j = 2,3,..., п мы на
 ходим, что A[i] < key в строке 5, еще когда г равно своему начальному значению 
j- 1. Таким образом, tj = 1 для j = 2,3,..., п, и время работы алгоритма в самом 
благоприятном случае вычисляется так:
 Т(п) = С\П + С2(п - 1) + С4(п - 1) + Сб(п - 1) + С8(п - 1) 
= (Cl + с2 + С4 + с5 + С8)п - (с2 + с4 + С5 + С8) .
 Это время работы можно записать как ап + Ь, где а и b — константы, зависящие 
от величин сг\ т.е. это время является линейной функцией от п.
 Если же массив находится в порядке, обратном требуемому (т.е. в порядке 
убывания элементов), то реализуется наихудший случай. При этом мы должны 
сравнивать каждый элемент A[j\ с каждым элементом всего отсортированного 
подмассива А[ 1.. j — 1], так что tj = j для j = 2,3,..., п. Заметив, что
 . 
/ 
^ Э 
3= 2
 и
 п{п + 1)
 о
 (см. обзор, посвященный таким суммам, в приложении А), мы находим, что в наи
 худшем случае время работы Insertion-Sort составляет- (с2 + с4 + с5 + с8) .
50
 Часть I. Основы
 Это время работы в наихудшем случае можно записать как ап2 + Ьп + с, где 
а, b и с — константы, зависящие от стоимостей а; таким образом, мы имеем 
квадратичную функцию от п.
 Обычно время работы алгоритма для определенных входных данных фиксиро
 вано, как в случае сортировки вставкой, однако в последующих главах мы озна
 комимся с некоторыми интересными “рандомизированными” алгоритмами, пове
 дение которых носит вероятностный характер. Время их работы может меняться 
даже для одних и тех же входных данных.
 Наихудшее и среднее время работы
 Анализируя алгоритм сортировки вставкой, мы рассматривали как наилучший, 
так и наихудший случай, когда элементы массива были рассортированы в поряд
 ке, обратном требуемому. Далее в этой книге мы будем уделять основное внима
 ние определению только времени работы в наихудшем случае, т.е. максимального 
времени работы для любых входных данных размером п. На то есть три причины.
 • Время работы алгоритма в наихудшем случае — это верхний предел этой ве
 личины для любых входных данных. Располагая этим значением, мы точно 
знаем, что для выполнения алгоритма не потребуется большее количество вре
 мени. Не нужно будет делать каких-то сложных предположений о времени 
работы и надеяться, что на самом деле эта величина не будет превышена.
 • В некоторых алгоритмах наихудший случай встречается достаточно часто. На
 пример, если в базе данных происходит поиск информации, то наихудшему 
случаю соответствует ситуация, когда нужная информация в базе данных от
 сутствует. В некоторых приложениях поиск отсутствующей информации мо
 жет происходить довольно часто.
 • Характер поведения “усредненного” времени работы часто ничем не лучше 
поведения времени работы для наихудшего случая. Предположим, что после
 довательность, к которой применяется сортировка методом вставок, сформи
 рована случайным образом. Сколько времени понадобится, чтобы определить, 
в какое место подмассива А[1.. j — 1] следует поместить элемент A\j]l В сред
 нем половина элементов подмассива А[1.. j — 1] меньше, чем A[j], а полови
 на — больше этого значения. Таким образом, в среднем нужно проверить по
 ловину элементов подмассива A[l.. j — 1], поэтому tj приблизительно равно 
Ц 2. В результате получается, что среднее время работы алгоритма является 
квадратичной функцией от количества входных элементов, т.е. характер этой 
зависимости такой же, как и для времени работы в наихудшем случае.
 В некоторых частных случаях нас будет интересовать среднее время работы 
алгоритма, или его математическое ожидание1. Позже будет продемонстриро- 7
 7Далее в книге строгий термин “математическое ожидание” некоторой величины зачастую для простоты из
 ложения заменяется термином “ожидаемое значение”, например “ожидаемое время работы алгоритма” означает 
“математическое ожидание времени работы алгоритма” — Примеч. ред.
Глава 2. Приступаем к изучению
 51
 ван метод вероятностного анализа, применяемый в книге к ряду алгоритмов. 
Однако область его использования ограничена, поскольку не всегда очевидно, 
какие входные данные для данной задачи являются “усредненными” Часто де
 лается предположение, что все наборы входных параметров одного и того же 
объема встречаются с одинаковой вероятностью. На практике это предположение 
может не соблюдаться, однако иногда можно применять рандомизированные ал
 горитмы, в которых используется случайный выбор, и это позволяет провести 
вероятностный анализ ожидаемого времени работы алгоритма. Более детально 
мы рассмотрим рандомизированные алгоритмы в главе 5 и некоторых последую
 щих главах.
 Порядок роста
 Для облегчения анализа процедуры Insertion-Sort были сделаны некоторые 
упрощающие предположения. Вначале мы проигнорировали фактическую стои
 мость выполнения каждой инструкции, представив эту величину в виде некото
 рой константы q . Далее мы увидели, что учет всех этих констант дает излишнюю 
информацию: время работы алгоритма в наихудшем случае выражается форму
 лой ап2 + Ьп + с, где а, Ъ и с — некоторые константы, зависящие от стоимостей 
Cj. Таким образом, мы игнорируем не только фактические стоимости команд, но 
и их абстрактные стоимости с*.
 Теперь введем еще одно абстрактное понятие, упрощающее анализ. Это ско
 рость роста (rate of growth), или порядок роста (order of growth), интересую
 щего нас времени работы. Таким образом, во внимание будет приниматься только 
главный член формулы (т.е. в нашем случае ап2), поскольку при больших значе
 ниях п членами меньшего порядка можно пренебречь. Кроме того, постоянный 
множитель при главном члене также будет игнорироваться, так как для оценки 
вычислительной эффективности алгоритма с входными данными большого объе
 ма они менее важны, чем порядок роста. В случае сортировки вставкой, когда мы 
игнорируем члены более низкого порядка и коэффициент при старшем члене, 
мы остаемся с единственным множителем п2 из старшего члена. Таким образом, 
время работы алгоритма, работающего по методу вставок, в наихудшем случае 
равно 0(п2) (произносится “тета от п в квадрате”). В этой главе ©-обозначения 
используются неформально; строго мы определим их в главе 3.
 Обычно один алгоритм рассматривается как более эффективный по сравнению 
с другим, если время его работы в наихудшем случае имеет более низкий порядок 
роста. Из-за константных множителей и членов более низкого порядка алгоритм 
с более высоким порядком роста может выполняться для небольших входных 
данных быстрее, чем алгоритм с более низким порядком роста. Но для достаточно 
больших входных данных алгоритм 0 (п2), например, будет в наихудшем случае 
работать быстрее алгоритма с 0 (п3).
 Упражнения
 2.2.1
 Выразите функцию п3/1000 — 100п2 — 100п + 3 в ©-обозначениях.
52
 Часть I. Основы
 2.2.2
 Рассмотрим сортировку элементов массива А, которая выполняется следующим 
образом. Сначала определяется наименьший элемент массива А, который ста
 вится на место элемента А[1]. Затем производится поиск второго наименьшего 
элемента массива А, который ставится на место элемента А[2]. Этот процесс про
 должается для первых п — 1 элементов массива А. Запишите псевдокод этого 
алгоритма, известного как сортировка выбором (selection sort). Какой инвариант 
цикла сохраняется для этого алгоритма? Почему его достаточно выполнить для 
первых п — 1 элементов, а не для всех п элементов? Определите время работы 
алгоритма в наилучшем и наихудшем случаях и запишите его в ©-обозначениях.
 2.2.3
 Вновь обратимся к алгоритму линейного поиска (см. упр. 2.1.3). Для скольких 
элементов входной последовательности в среднем нужно произвести проверку, 
если предполагается, что все элементы массива с равной вероятностью могут 
иметь искомое значение? Что происходит в наихудшем случае? Чему равно вре
 мя работы алгоритма линейного поиска в среднем и в наихудшем случаях в ©- 
обозначениях? Обоснуйте свой ответ.
 2.2.4
 Каким образом можно модифицировать почти каждый алгоритм, чтобы получить 
оптимальное время работы в наилучшем случае?
 2.3. 
Разработка алгоритмов
 У нас имеется богатый набор методов разработки алгоритмов. В случае сорти
 ровки вставкой мы использовали инкрементный подход: имея отсортированный 
подмассив А[ 1.. j — 1], мы вставляем один элемент A[j] в соответствующее ме
 сто, получая отсортированный подмассив А[ 1. .j].
 В этом разделе мы рассмотрим альтернативный подход, известный как метод 
декомпозиции, или метод “разделяй и властвуй”, который мы детально изучим 
в главе 4. Мы используем подход “разделяй и властвуй” для разработки алго
 ритма сортировки, время работы которого в наихудшем случае оказывается го
 раздо меньшим, чем время работы сортировки вставкой. Одно из преимуществ 
алгоритмов “разделяй и властвуй” заключается в том, что зачастую оказывается 
очень легко определить время работы такого алгоритма с применением методики, 
которая будет описана в главе 4.
 2.3.1. Метод декомпозиции
 Многие полезные алгоритмы имеют рекурсивную структуру: для решения по
 ставленной задачи они рекурсивно вызывают сами себя один или несколько раз, 
решая вспомогательные подзадачи, тесно связанные с основной задачей. Такие 
алгоритмы зачастую разрабатываются с помощью метода декомпозиции, или ме
 тода “разделяй и властвуй ”: сложная задача разбивается на несколько простых,
Глава 2. Приступаем к изучению
 53
 которые подобны исходной задаче, но имеют меньший объем; далее эти вспомога
 тельные задачи решаются рекурсивным методом, после чего полученные решения 
комбинируются для получения решения исходной задачи.
 Парадигма, лежащая в основе метода декомпозиции “разделяй и властвуй”, на 
каждом уровне рекурсии включает в себя три шага.
 Разделение задачи на несколько подзадач, которые представляют собой меньшие 
экземпляры той же задачи.
 Властвование над подзадачами путем их рекурсивного решения. Если размеры 
подзадач достаточно малы, такие подзадачи могут решаться непосредственно.
 Комбинирование решений подзадач в решение исходной задачи.
 Алгоритм сортировки слиянием (merge sort) точно следует парадигме “разде
 ляй и властвуй” Интуитивно он работает следующим образом.
 Разделение. Делим n-элементную сортируемую последовательность на две под
 последовательности по п/2 элементов.
 Властвование. Рекурсивно сортируем эти две подпоследовательности с исполь
 зованием сортировки слиянием.
 Комбинирование. Соединяем две отсортированные подпоследовательности для 
получения окончательного отсортированного ответа.
 Рекурсия достигает своего нижнего предела, когда длина сортируемой последова
 тельности становится равной 1. В этом случае вся работа уже сделана, поскольку 
любая такая последовательность уже является упорядоченной.
 Ключевая операция, которая производится в процессе сортировки по методу 
слияний, — это объединение двух отсортированных последовательностей в ходе 
комбинирования (последний этап). Это делается с помощью вызова вспомога
 тельной процедуры procedure MERGE (А, р, q, г), где А — массив, а р, q и г — 
индексы, нумерующие элементы массива, такие, что р < q < г. В этой процедуре 
предполагается, что элементы подмассивов А\р.. q] и A[q + 1.. г] упорядочены. 
Она сливает эти два подмассива в один отсортированный, элементы которого 
заменяют текущие элементы подмассива А\р. .г].
 Для выполнения процедуры MERGE требуется время @(п), где п — г — р+1 — 
общее количество подлежащих слиянию элементов. Процедура работает следу
 ющим образом. Возвращаясь к наглядному примеру сортировки карт, предпо
 ложим, что на столе лежат две стопки карт, обращенных лицевой стороной вниз. 
Карты в каждой стопке отсортированы, причем наверху находится карта наимень
 шего достоинства. Эти две стопки нужно объединить в одну выходную, в которой 
карты будут рассортированы и также будут обращены рубашкой вверх. Основ
 ной шаг состоит в том, чтобы из двух младших карт выбрать самую младшую, 
извлечь ее из соответствующей стопки (при этом в данной стопке верхней отка
 жется новая карта) и поместить в выходную стопку. Этот шаг повторяется до тех 
пор, пока в одной из входных стопок не закончатся карты, после чего оставшиеся 
в другой стопке карты нужно поместить в выходную стопку. С вычислительной
54
 Часть I. Основы
 точки зрения выполнение каждого основного шага занимает одинаковые проме
 жутки времени, так как все сводится к сравнению достоинства двух верхних карт. 
Поскольку необходимо выполнить по крайней мере п основных шагов, время ра
 боты процедуры слияния равно @(п).
 Описанная идея реализована в представленном ниже псевдокоде, однако в нем 
также есть дополнительное ухищрение, благодаря которому в ходе каждого ос
 новного шага не приходится проверять, является ли каждая из двух стопок пу
 стой. Мы помещаем в самый низ обеих объединяемых колод так называемую 
сигнальную карту-ограничитель особого достоинства, что позволяет упростить 
код. Здесь в качестве сигнального значения используется оо, так что, когда мы 
встречаем карту достоинством оо, меньшей карты мы не встретим до полного 
исчерпания обеих стопок. Как только мы встречаем такую карту, это означает, 
что все несигнальные карты уже помещены в выходную стопку. Поскольку зара
 нее известно, что в выходной стопке должна содержаться ровно г — р + 1 карта, 
выполнив соответствующее количество основных шагов, можно остановиться.
 1
 MERGE(yl,p, q, г)
 ni = q -р + 1
 2 П2 = г — q
 3 Пусть L[1.. п\ + 1] и Я[1.. П2 + 1] — новые массивы
 4 
for г = 1 to п\
 5 
L[i\ = А\р + г — 1]
 6 for j = 1 to П2
 7 
R[j}=A[q+j]
 8 L[n\ + 1] = оо
 9 R[n 2 + 1] = oo
 10 i = 1
 11 
12 
13 
14 
15 
16 
17 
j = 1
 for к = p to r
 if L\i}<R\j]
 A[k] = L[i\
 i = i + 1
 else A[k] = R[j]
 j = j + 1
 Подробно рассмотрим работу процедуры MERGE. В строке 1 вычисляется 
длина п\ подмассива A\p..q], а в строке 2 вычисляется длина П2 подмассива 
A[q + 1.. г]. Мы создаем массивы L и R (“левый” и “правый”) с длинами п\ + 1 
и П2 + 1 соответственно в строке 3; дополнительная ячейка в каждом массиве 
будут содержать ограничитель. Цикл for в строках 4 и 5 копирует подмассив 
А\р.. q\ в L[ 1. .щ], а цикл for в строках 6 и 7 копирует подмассив A[q + 1.. г] 
в 7?[1. .пг]. Строки 8 и 9 помещают ограничители в последние ячейки L и R. 
Строки 10-17, проиллюстрированные на рис. 2.3, выполняют г — р + 1 базовый 
шаг, сохраняющий инвариант цикла.
 В начале каждой итерации цикла for в строках 12-17 подмассив 
А\р..к — 1] содержит к — р наименьших элементов L[l..ni + 1]
Глава 2. Приступаем к изучению
 и 7?[1.. П2 +1] в отсортированном порядке. Кроме того, L[i\ и R[j] являют
 ся наименьшими элементами соответствующих массивов, которые еще не 
были скопированы назад в А.
 55
 Необходимо показать, что этот инвариант цикла соблюдается перед первой 
итерацией рассматриваемого цикла for в строках 12-17, что каждая итерация цик
 ла его сохраняет и что с его помощью можно продемонстрировать корректность 
алгоритма, когда цикл заканчивает свою работу.
 Инициализация. Перед первой итерацией цикла к = р, так что подмассив 
А \р..к — 1] пуст. Он содержит к — р = 0 наименьших элементов массивов 
L и R, а поскольку г = j = 1, элементы L [г] и R [j] — наименьшие элементы 
массивов L и R, не скопированные обратно в массив А.
 Сохранение. Чтобы убедиться, что инвариант цикла сохраняется после каждой 
итерации, сначала предположим, что L[i\ < R[j\. Тогда L[i\ — наименьший 
элемент, пока еще не скопированный в массив А. Поскольку в подмасси
 ве А \р.. к — 1] содержится к — р наименьших элементов, после копирования 
в строке 14 L[i\ в А[к\ в подмассиве А\р.. к\ будет содержаться к — р+ 1 наи
 меньших элементов. В результате увеличения параметра к цикла for и значе
 ния переменной i (строка 15), инвариант цикла восстанавливается перед сле
 дующей итерацией. Если же выполняется неравенство L[i\ > R\j], то в стро
 ках 16 и 17 выполняются соответствующие действия, в ходе которых также 
сохраняется инвариант цикла.
 Завершение. Алгоритм завершается, когда к = г + 1. В соответствии с ин
 вариантом цикла подмассив А\р..к — 1] (т.е. подмассив А\р..г]) содержит 
k—p=r—p+ 1 наименьших элементов массивов L[ 1.. п\ +1] и R[ 1.. П2 + 1] 
в отсортированном порядке. Суммарное количество элементов в массивах L 
и R равно п\ + П2 + 2 = г — р + 3. Все они, кроме двух самых больших, ско
 пированы обратно в массив А, а два оставшихся элемента являются сигналь
 ными.
 Чтобы убедиться, что время работы процедуры MERGE равно @(п), где п = 
г - р + 1, заметим, что каждая из строк 1-3 и 8-11 выполняется за констант
 ное время; длительность циклов for в строках 4-7 равна @(ni + П2) = @(п),8 
а в цикле for в строках 12-17 выполняются п итераций, на каждую из которых 
затрачивается константное время.
 Теперь процедуру MERGE можно использовать в качестве подпрограммы в ал
 горитме сортировки слиянием. Процедура Merge-Sort(A,p, г) выполняет сор
 тировку элементов в подмассиве А\р..г]. Если справедливо неравенство р > г, 
то в этом подмассиве содержится не более одного элемента, и, таким образом, 
он является уже отсортированным. В противном случае производится разбиение,
 8В главе 3 будет показано, как формально интерпретируются уравнения с 0-обозначениями.
56
 L 
/ Г¥Т
 Часть I. Основы
 8
 А ... 2 4 5 7-• j 1 2
 к
 1
 2
 3 4 5
 ь__ L^_ 3 Ш
 1
 2
 3 4 5
 1
 9 _19 11 12 13 14 15 1$ 17
 л ... 1 4 5 7 } 2 3 6
 к
 4 5
 2
 2
 4 5 7
 н R 1 2 3 6 J оо |
 3
 1
 2
 3 4 5
 H J 4 5 7 ОО R 1:2 3 6 о°
 * 
2
 j
 (а)
 8 9 IP 11 12
 1
 С 5 7 I 
l l 1* IS
 2 
к
 2 3 4 5
 1 2 3 4 5
 я И I I I
 (а)
 i 
16 17
 Я
 j
 (б)
 (г)
 Рис. 2.3. Операции в строках 10-17 процедуры Mer g er , 9,12,16), когда подмассив А’9 .. 16] 
содержит последовательность (2,4,5,7,1,2,3,6). После копирования и добавления ограничителей 
массив L содержит (2, 4, 5, 7, оо), а массив R содержит (1, 2, 3, 6, ос). Слабо заштрихованные 
ячейки А содержат окончательные значения, а такие же слабо заштрихованные ячейки в L и R — 
значения, которые должны быть скопированы назад в А. Вместе слабо заштрихованные ячейки 
всегда включают значения, изначально находившиеся в А Т9 .. 16], вместе с двумя ограничителями. 
Сильно заштрихованные ячейки А содержат значения, в которые будет выполнено перезаписыва
 ющее копирование, а такие же сильно заштрихованные ячейки в L и R содержат значения, уже 
скопированные обратно в А. (а)-(з) Массивы A, L и R и их индексы к, г и j перед каждой итера
 цией цикла в строках 12-17.
 в ходе которого вычисляется индекс q, разделяющий массив А\р.. г] на два под
 массива: А\р.. q] с \п/2] элементами и A[q + 1.. г] с п/2\ элементами.9
 M erge-So rt(A, р, г)
 1
 2 
3 
4 
i f р < г
 q = [(р + 
M erge-Sort (Д р , q)
 /
 )
 г
 2J
 M erge-So rt(A, q + 1, r)
 5 
M erge(A, p, q,r)
 Для сортировки всей последовательности А = {А[1\, А[2],..., А[п]) вызывается 
процедура M erge-So rt(^, 1, A. length), где A.length = п. На рис. 2.4 проил
 люстрирована работа этой процедуры в восходящем направлении, когда п пред
 ставляет собой степень двойки. В ходе работы алгоритма происходит попарное 
объединение одноэлементных последовательностей в отсортированные последо
Выражение [an обозначает наименьшее целое число, которое больше или равно х, а выражение 
9 
наибольшее целое число, которое меньше или равно х. Эти обозначения вводятся в главе 3 Чтобы убедиться 
в том, что в результате присваивания переменной q значения |_(р + r )/2J получаются подмассивы А\р . q\ 
и A[q + 1.. г] с размерами \п /2] и [п/2 , достаточно проверить четыре возможных случая, в которых каждое 
из чисел риг либо четное, либо нечетное,
 — 
Глава 2. Приступаем к изучению
 8 9 10 И 12 13 14 15 16 17
 А ... 1 2 2 3 I !2 :3 | б |
 к
 1 2 3 4 5
 1 .2 3 4 5
 i 2 ] 4 5 7 СО R1 2 3 \б ОО
 /
 (д)
 j
 8 9 10 11 12 П 14 15 !6 17
 А ... 1 2 2 3 4 5 3 б L
 к
 ! 
2 з 4 5
 2 з 4 5
 ! 
2 4 5 7 оо R11 2 з 6 I ОО
 (ж)
 j 
(И)
 57
 А
 8 9 10 11 12 13 14 15 16 17
 1 2 2 3 4 2 з
 к
 1 2 3 4 5
 2
 4 5
 L 2 4 5 7 ОО R 1 2 1 з | 6 ОО
 /
 j
 (е)
 8 9 10 11 12 13 14 15 16 17
 А ... > 2 2 3 4 5 6
 !
 1 з 4 5
 1 2
 к
 з
 5
 L 2 4 5 7 оо R 1 2 i 3 1 6 ; °°
 ' 
( 3)
 j
 Рис. 2.3 (продолжение), (и) Массивы и индексы при завершении процедуры. В этот момент под
 массив Л [9.. 16] отсортирован, а два ограничителя в L и R являются единственными элементами 
в этих массивах, которые не были скопированы в А.
 вательности длиной 2, затем — попарное объединение двухэлементных последо
 вательностей в отсортированные последовательности длиной 4 и так до тех пор, 
пока не будут получены две последовательности, состоящие из п/2 элементов, ко
 торые объединяются в конечную отсортированную последовательность длиной п.
 2.3.2. Анализ алгоритмов, основанных на принципе “разделяй и властвуй”
 Когда алгоритм рекурсивно вызывает сам себя, зачастую время его работы 
можно описать с помощью рекуррентного уравнения (или рекуррентности), 
которое выражает полное время, требующееся для решения всей задачи разме
 ром п, через время решения задач для меньших входных данных. Затем можно 
прибегнуть к соответствующему математическому аппарату для решения рекур
 рентности и получить границы производительности алгоритма.
 Получение рекуррентного соотношения для времени работы алгоритма, осно
 ванного на принципе “разделяй и властвуй”, базируется на трех этапах, соответ
 ствующих парадигме этого принципа. Как и ранее, обозначим через Т(п) время 
решения задачи, размер которой равен п. Если размер задачи достаточно мал, 
скажем, п < с для некоторой заранее известной константы с, то задача решает
 ся непосредственно в течение определенного константного времени, которое мы 
обозначим через 0(1). Предположим, что наша задача делится на а подзадач,
58
 Часть I. Основы
 Отсортированная последовательность
 1
 2 
4
 / 
2 
5 
/ \
 Слияние \
 2 
7
 3
 4 
Слияние
 5 
6
 1 
2
 7
 3 
/ \
 У Слияние \
 2 
5
 / \
 f Слияние \
 4 
7
 / \
 f СлияниеХ
 1 
/ 
3
 / \
 СлияниеХ
 2 
/ 
6
 6
 \
 f Слиянием
 5 
2
 4 
7 
| 1 | 
3 
Исходная последовательность
 Е 6
 Рис. 2.4. Процесс сортировки слиянием массива А = (5, 2, 4, 7,1, 3, 2, 6). Длины подлежащих 
слиянию отсортированных последовательностей возрастают в ходе работы алгоритма.
 объем каждой из которых равен 1/6 от объема исходной задачи. (В алгоритме 
сортировки методом слияния числа а и 6 были равны 2, однако нам предстоит 
ознакомиться со многими алгоритмами разбиения, в которых а ф 6.) Для решения 
подзадачи размером п/Ь требуется время Т(п/Ь), а для решения а таких подзадач 
требуется время аТ(п/Ь). Если разбиение задачи на вспомогательные подзадачи 
происходит за время D(n), а объединение решений подзадач в решение исход
 ной задачи — в течение времени С(п), то мы получим следующее рекуррентное 
соотношение:
 Т(п) = | 0(1)’ 
если 71 ^ с >
 \ aT(n/b) + D(n) + С{п) в противном случае .
 В главе 4 рассмотрим методы решения рекуррентных уравнений такого вида.
 Анализ алгоритма сортировки слиянием
 Хотя псевдокод Merge-Sort корректно работает для нечетного количества 
сортируемых элементов, анализ рекуррентного уравнения упрощается, если коли
 чество элементов в исходной задаче представляет собой степень двойки. В этом 
случае на каждом шаге деления будут получены две подпоследовательности, раз
 мер которых точно равен п/2. В главе 4 будет показано, что это предположение 
не влияет на порядок роста, полученный в результате решения рекуррентного 
уравнения.
 Чтобы получить рекуррентное уравнение для верхней оценки времени рабо
 ты Т(п) алгоритма, выполняющего сортировку п чисел методом слияния, будем 
рассуждать следующим образом. Сортировка одного элемента методом слияния
Глава 2. Приступаем к изучению
 59
 выполняется за константное время. Если п > 1, время работы распределяется 
следующим образом.
 Разделение. В ходе разбиения определяется, где находится средина подмассива. 
Эта операция выполняется за константное время, поэтому D(n) = 0(1).
 Властвование. Рекурсивно решаются две подзадачи, размер каждой из которых 
составляет п/2. Время решения этих подзадач равно 2Т(п/2).
 Комбинирование. Как уже упоминалось, процедура MERGE при работе с п-эле- 
ментным подмассивом выполняется за время 0 (п), так что С(п) = 0 (п).
 Складывая функции D(n) и С(п) для анализа алгоритма сортировки слиянием, 
мы складываем функции, которые представляют собой 0(п) и 0(1). Эта сумма 
является линейной функцией от п, т.е. 0(п). Добавление ее к члену 2Т(п/2) из 
шага “Властвование” дает следующее рекуррентное соотношение для времени 
работы сортировки слиянием в наихудшем случае:
 Т (п \ = ( 0 (Х)’ 
если п = 1 ’ 
[ 2Т(п/2) + 0(п), если п > 1 .
 H i )
 В главе 4 вы познакомитесь с теоремой, которую можно использовать для того, 
чтобы показать, что Т(п) представляет собой 0(nlgn), где lg п означает log2 n. 
Поскольку логарифмическая функция растет медленнее любой линейной функ
 ции, для достаточно больших входных данных сортировка слиянием со временем 
работы 0 (nlgn) превзойдет в наихудшем случае сортировку вставкой, время ра
 боты которой равно 0 (п2).
 Конечно, можно и без упомянутой теоремы интуитивно понять, почему ре
 шением рекуррентного соотношения (2.1) является выражение Т(п) = 0(nlgn). 
Давайте перепишем рекуррентное соотношение (2.1) в виде
 Т(п)
 с, 
если п = 1 ,
 2Т(п/2) + сп, если п > 1 ,
 (2.2)
 где константа с обозначает время, которое требуется для решения задачи, раз
 мер который равен 1, а также удельное (приходящееся на один элемент) время, 
требуемое для разделения и комбинирования.10
 На рис. 2.5 показано решение рекуррентного соотношения (2.2). Для удобства 
мы считаем, что п представляет собой точную степень 2. В части (а) рисунка
 10 Маловероятно, чтобы одна и та же константа представляла и время, необходимое для решения зада
 чи, размер который равен 1, и приходящееся на один элемент время, в течение которого выполняются этапы 
разбиения и объединения. Чтобы обойти эту проблему, достаточно предположить, что с — максимальный из 
перечисленных промежутков времени. В таком случае мы получим верхнюю границу времени работы алгорит
 ма. Если же в качестве с выбрать наименьший из всех перечисленных промежутков времени, то в результате 
решения рекуррентного соотношения можно получить нижнюю границу времени работы алгоритма. Принимая 
во внимание, что обе границы имеют порядок п lg п, делаем вывод, что время работы алгоритма ведет себя, 
как 0(nlgn).
60
 Часть I. Основы
 Т(п)
 (а)
 А
 lg п
 У
 СП
 Т(п/2) 
сп/2
 сп/4
 с
 с 
(б)
 сп14
 с 
СП
 Т(п/2)
 сп
 с 
п
 ^ 
Т(п/4) 
сп/2
 сп/4
 с
 Т(п/4) 
сп/4
 с
 с
 Всего: сп lg п + сп
 сп 12
 Т(п/4) 
(в)
 сп
 сп
 Т(п/4)
 Рис. 2.5. Построение дерева рекурсии для рекуррентного соотношения Т(п) = 2Т(п/2) + сп. 
В части (а) показано время Т(п), которое постепенно раскрывается в частях (б)-(г), образуя де
 рево рекурсии. Полностью раскрытое дерево в части (г) имеет lg п + 1 уровней (т.е. его высота, 
как и указано, равна lg п), а вклад каждого уровня в стоимость равен сп. Таким образом, общая 
стоимость равна сп lg п + сп, что представляет собой 0(n lg п).
Глава 2. Приступаем к изучению
 61
 показано время Т(п), которое в части (б) представлено в виде эквивалентного 
дерева, которое представляет рекуррентное уравнение. Корнем дерева является 
член сп (стоимость на верхнем уровня рекурсии), и от него идут два поддерева, 
представляющие меньшие рекуррентности Т{п/2). В части (в) показан очередной 
шаг рекурсии, состоящий в раскрытии Т(п/2). Стоимость каждого из двух подуз
 лов на втором уровне рекурсии равна сп/2. Мы продолжаем раскрывать каждый 
узел дерева, разбивая его на составные части, определяемые рекуррентным соот
 ношением, пока размеры задач не достигнут значений 1, со стоимостью с. В ча
 сти (г) показано получающееся в результате дерево рекурсии.
 После того как дерево построено, длительности выполнения всех его узлов 
суммируются по всем уровням. Полное время выполнения верхнего уровня равно 
сп, следующий уровень дает вклад, равный с(п/2) + с(п/2) — сп, общая стои
 мость уровня после него составляет с(п/4) + с(п/4) + с(п/4) + с(п/4) = сп, и т.д. 
В общем случае уровень i (если вести отсчет сверху) имеет 2г узлов, каждый из 
которых дает вклад в общее время работы алгоритма, равный с(п/2г), так что 
общая стоимость г-го уровня равна 2г с(п/2г) = сп. На нижнем уровне имеется п 
узлов, каждый из которых дает вклад с, что в сумме также дает время, равное сп.
 Общее количество уровней дерева рекурсии на рис. 2.5 равно lg + 1, где п — 
количество листьев, соответствующее размеру входных данных. Это легко понять 
из неформальных индуктивных рассуждений. В простейшем случае, когда п = 1, 
имеется всего один уровень. Поскольку lg 1 = 0 , выражение lg п + 1 дает пра
 вильное количество уровней. Теперь в качестве гипотезы индукции примем, что 
количество уровней рекурсивного дерева с 2г узлами равно lg 2г + 1 = г + 1 (так 
как для любого i выполняется соотношение lg 2г = г). Поскольку мы предполо
 жили, что количество входных элементов равно степени двойки, теперь нужно 
рассмотреть случай 2г+1 элементов. Дерево с 2г+1 узлами имеет на один уро
 вень больше, чем дерево с 2г узлами, поэтому общее количество уровней равно 
(г + 1) + 1 = lg2i+1 + 1.
 Для вычисления общей стоимости, представленной рекуррентным соотноше
 нием (2.2), нужно просто просуммировать вклады от всех уровней. Всего имеется 
lg п + 1 уровней, каждый из которых имеет стоимость сп, так что полная стои
 мость составляет cn(lgn + 1) = cnlgn + сп. Пренебрегая членом более низкого 
порядка и константой с, в результате получаем ©(nlgn).
 Упражнения
 2.3.1
 Используя в качестве образца рис. 2.4, проиллюстрируйте работу алгоритма сор
 тировки слиянием для массива А = (3,41,52,26,38,57,9,49).
 2.3.2
 Перепишите процедуру Merge так, чтобы в ней не использовались сигнальные 
значения. Сигналом к остановке должен служить тот факт, что все элементы мас
 сива L или массива R скопированы обратно в массив А, после чего в этот массив 
копируются элементы, оставшиеся в непустом массиве.
62
 2.3.3
 Часть I. Основы
 Воспользуйтесь методом математической индукции для доказательства того, что, 
когда п является точной степенью 2, решением рекуррентного соотношения
 Т(п\ = / 2’ 
\ 
если 71 = 2 '
 2Т{п/2) + п, если п = 2к, к > 1,
 является Т(п) = nig гг.
 2.3.4
 Сортировку вставкой можно представить в виде рекурсивной последовательно
 сти. Чтобы отсортировать массив А[1.. п], сначала нужно рекурсивно отсортиро
 вать массив А[ 1 .. тг — 1], после чего в этот отсортированный массив помещается 
элемент А[п\. Запишите рекуррентное уравнение для времени работы этой рекур
 сивной версии сортировки вставкой.
 2.3.5
 Возвращаясь к задаче поиска (см. упр. 2.1.3), нетрудно заметить, что если по
 следовательность А отсортирована, то можно сравнить значение среднего эле
 мента этой последовательности с искомым значением v и сразу исключить поло
 вину последовательности из дальнейшего рассмотрения. Бинарный поиск (binary 
search) — это алгоритм, в котором такая процедура повторяется неоднократно, что 
всякий раз приводит к уменьшению оставшейся части последовательности в два 
раза. Запишите псевдокод алгоритма бинарного поиска (либо итеративный, либо 
рекурсивный). Докажите, что время работы этого алгоритма в наихудшем случае 
составляет 0 (lgn).
 2.3.6
 Заметим, что в цикле while в строках 5-7 процедуры Insertion-Sort в раз
 деле 2.1 для сканирования (в обратном порядке) отсортированного подмассива 
А[1.. j — 1] используется линейный поиск. Можно ли использовать бинарный 
поиск (см. упр. 2.3.5) вместо линейного, чтобы время работы этого алгоритма 
в наихудшем случае улучшилось и стало равным 0 (nlgn)?
 2.3.7 ★
 Разработайте алгоритм со временем работы 0(nlgn), который для заданного 
множества S из п целых чисел и другого целого числа х определяет, имеются 
ли в множестве S два элемента, сумма которых равна х.
 Задачи
 2.1. Сортировка вставкой малых массивов в процессе сортировки слиянием
 Несмотря на то что с увеличением количества сортируемых элементов время 
сортировки методом слияний в наихудшем случае растет как 0 (nlgn), а время
Глава 2. Приступаем к изучению
 63
 сортировки вставкой — как @(п2), благодаря постоянным множителям на прак
 тике для малых размеров задач на большинстве машин сортировка вставкой вы
 полняется быстрее. Таким образом, есть смысл использовать сортировку вставок 
в процессе сортировки методом слияний, когда подзадачи становятся достаточно 
маленькими. Рассмотрите модификацию алгоритма сортировки слиянием, в ко
 тором п/к подмассивов длиной к сортируются вставкой, после чего они объе
 диняются с помощью обычного механизма слияния. Величина к должна быть 
найдена в процессе решения задачи.
 а. Покажите, что сортировка вставкой позволяет отсортировать п/к подпоследо
 вательностей длиной к каждая за время Q(nk) в худшем случае.
 б. Покажите, как выполнить слияние этих подпоследовательностей за время 
@(nlg(n/fc)) в наихудшем случае.
 в. Если такой модифицированный алгоритм выполняется за время Q(nk + 
nlg(n/fc)) в наихудшем случае, то чему равно наибольшее значение к как 
функции от п, для которого модифицированный алгоритм в ©-обозначениях 
имеет то же время работы, что и стандартная сортировка слиянием?
 г. Как следует выбирать к на практике?
 2.2. Корректность пузырьковой сортировки
 Пузырьковая сортировка представляет собой популярный, но не эффективный 
алгоритм сортировки. В его основе лежит многократная перестановка соседних 
элементов, нарушающих порядок сортировки.
 Bubblesort(A)
 1 for i = 1 to A. length — 1
 2 
for j = A. length downto i + 1
 3 
4 
if A\j] < A\j-1]
 поменять A\j] и A[j — 1] местами
 а. Пусть А' обозначает выход процедуры Bubblesort(A). Для доказательства 
корректности процедуры Bubblesort необходимо доказать, что она заверша
 ется и что
 А'[ 1] < А'[2] < 
< А'[п\ , 
(2.3)
 где п = A. length. Что еще необходимо доказать для того, чтобы показать, что 
процедура Bubblesort действительно выполняет сортировку?
 В следующих двух частях доказываются неравенства (2.3).
 б. Точно сформулируйте инвариант цикла for в строках 2-4 и докажите, что он 
выполняется. Доказательство должно иметь ту же структуру доказательства 
инварианта цикла, которая ранее использовалась в аналогичных доказатель
 ствах в данной главе.
64
 Часть I. Основы
 в. С помощью условия завершения инварианта цикла, доказанного в части (б), 
сформулируйте инвариант цикла for в строках 1-4, который позволил бы до
 казать неравенства (2.3). Доказательство должно иметь ту же структуру до
 казательства инварианта цикла, которая использовалась ранее в аналогичных 
доказательствах в данной главе.
 г. Определите время пузырьковой сортировки в наихудшем случае и сравните 
его со временем сортировки вставкой.
 2.3. Корректность правила Горнера
 Следующий фрагмент кода реализует правило Горнера для вычисления поли
 нома
 Р(х) = ^~2,akxk
 k=О
 = ао + x(ai + x(d2 H-------Ь x(an-1 + xan) • • •))
 для заданных коэффициентов ao,ai,... ,an и значения x.
 1 y = 0
 2 for i = n downto 0
 3 
у = cii + x-y
 а. Чему равно время работы этого фрагмента кода правила Горнера в ©-обозна
 чениях?
 б. Напишите псевдокод, реализующий алгоритм обычного вычисления поли
 нома, когда каждое слагаемое полинома вычисляется отдельно. Определите 
асимптотическое время работы этого алгоритма и сравните его со временем 
работы алгоритма, основанного на правиле Горнера.
 в. Рассмотрим следующий инвариант цикла.
 В начале каждой итерации цикла for в строках 2 и 3
 п-(г+1)
 У — ^ ^ Q'k+i+l^'
 k=О
 Рассматривайте сумму без членов как равную нулю. Следуя структуре дока
 зательства инварианта цикла, которая использовалась ранее в данной главе, 
воспользуйтесь указанным инвариантом цикла, чтобы показать, что по завер
 шении работы у — 
akXk.
 г. Сделайте заключение, что в приведенном фрагменте кода правильно вычисля
 ется значение полинома, который задается коэффициентами dQ,d\, ,ап.
Глава 2. Приступаем к изучению
 65
 2.4. Инверсии
 Пусть А[1.. п] представляет собой массив из п различных чисел. Если i < j 
и A[i] > A\j\, то пара (г, j) называется инверсией А.
 а. Перечислите пять инверсий массива (2,3,8,6,1).
 б. Какой массив из элементов множества {1,2,... ,п} содержит максимальное 
количество инверсий? Сколько инверсий в этом массиве?
 в. Какая существует взаимосвязь между временем сортировки методом вставок 
и количеством инверсий во входном массиве? Обоснуйте свой ответ.
 г. Разработайте алгоритм, определяющий количество инверсий, содержащихся 
в произвольной перестановке п элементов, время работы которого в наихуд
 шем случае равно ©(nlgn). (Указание: модифицируйте алгоритм сортировки 
слиянием.)
 Заключительные замечания
 В 1968 году Кнут (Knuth) опубликовал первый из трех томов, объединенных 
названием The Art of Computer Programming (Искусство программирования) [208- 
210]11. Этот первый том стал введением в современные компьютерные алгоритмы 
с акцентом на анализе времени их работы, а весь трехтомник до сих пор остается 
интереснейшим и ценнейшим пособием по многим темам, представленным в дан
 ной книге. Согласно Кнуту, слово “алгоритм” происходит от имени персидского 
математика IX века аль-Хорезми (al-Khowarizmi).
 Ахо (Aho), Хопкрофт (Hopcroft) и Ульман (Ullman) [5] являются сторонниками 
асимптотического анализа алгоритмов (с использованием обозначений, вводимых 
в главе 3, включая ©-обозначения), являющегося средством сравнения их отно
 сительной производительности. Они также популяризируют применение рекур
 рентных соотношений для описания времени работы рекурсивных алгоритмов.
 Кнут [210] с энциклопедической полнотой рассмотрел многие алгоритмы сор
 тировки. Его сравнение алгоритмов сортировки включает в себя подробный ана
 лиз с точным подсчетом шагов, подобный проведенному в этой книге для сорти
 ровки методом вставок. В ходе обсуждения Кнутом алгоритма сортировки встав
 кой приводится несколько вариаций этого алгоритма. Важнейшей из них являет
 ся сортировка Д.Л. Шелла (D.L. Shell), который использовал сортировку методом
 11 Имеется русский перевод этих книг: Д. Кнут. Искусство программирования, т. 1. Основные алгоритмы, 
3-е изд. — М.: И.Д. “Вильямс”, 2000; Д. Кнут. Искусство программирования, т. 2. Получисленные алгоритмы, 
3-е изд. — М.: И.Д. “Вильямс”, 2000; Д. Кнут. Искусство программирования, т. 3. Сортировка и поиск, 2-е изд. — 
М.: И.Д. “Вильямс”, 2000. Кроме того, уже после написания данной книги вышел очередной том “Искусства 
программированияД. Кнут. Искусство программирования, т. 4, А. Комбинаторные алгоритмы, часть 1. — 
М.: И.Д. “Вильямс”, 2013.
 3 Зак. 3726
66
 Часть I. Основы
 вставок для упорядочения периодических подпоследовательностей, чтобы полу
 чить более производительный алгоритм сортировки.
 В книге Кнута также описана сортировка слиянием. В ней же упоминается, что 
в 1938 году была создана механическая машина, способная за один проход объе
 динять две стопки перфокарт. По всей видимости, первым программу для сорти
 ровки методом слияния (предназначенную для компьютера EDVAC) в 1945 году 
разработал Джон фон Нейман (J. von Neumann), который был одним из создателей 
теории вычислительных машин.
 Ранние этапы развития в области доказательства корректности программ опи
 саны Гризом (Gries) [152], который считает, что первая статья по этой теме была 
написана П. Науром (Р. Naur). Авторство понятия инварианта цикла Гриз при
 писывает Р. Флойду (R. W. Floyd). В учебнике Митчелла (Mitchell) [254] описы
 вается прогресс, достигнутый в области доказательства корректности программ 
в настоящее время.
Глава 3 Рост функций
 Определенный в главе 2 порядок роста, характеризующий время работы алго
 ритма, является наглядным показателем эффективности алгоритма, а также поз
 воляет сравнивать производительность различных алгоритмов. Если количество 
сортируемых элементов тг становится достаточно большим, производительность 
алгоритма сортировки по методу слияний, время работы которого в наихудшем 
случае возрастает как ©(nlgn), становится выше производительности алгоритма 
сортировки вставкой, время работы которого в наихудшем случае возрастает как 
0(п2). Несмотря на то что в некоторых случаях можно определить точное вре
 мя работы алгоритма, как это было сделано для алгоритма сортировки методом 
вставок в главе 2, обычно не стоит тратить лишние усилия для получения оценки 
с высокой точностью. Для достаточно больших входных данных постоянные мно
 жители и слагаемые низшего порядка, фигурирующие в выражении для точного 
времени работы алгоритма, подавляются эффектами, вызванными увеличением 
размера входных данных.
 Рассматривая входные данные достаточно больших размеров для оценки толь
 ко такой величины, как порядок роста времени работы алгоритма, мы тем самым 
изучаем асимптотическую эффективность алгоритмов. Это означает, что нас 
интересует только то, как время работы алгоритма растет с увеличением размера 
входных данных в пределе, когда этот размер увеличивается до бесконечности. 
Обычно алгоритм, более эффективный в асимптотическом смысле, будет более 
производительным для всех входных данных, за исключением очень маленьких.
 В этой главе приводится несколько стандартных методов, позволяющих упро
 стить асимптотический анализ алгоритмов. В начале следующего раздела вводит
 ся несколько видов “асимптотических обозначений”, одним из которых являются 
уже известные нам ©-обозначения. Далее представлены некоторые соглашения по 
поводу обозначений, принятых в данной книге. Наконец, в завершающей части 
главы, рассматривается поведение функций, часто встречающихся в ходе анализа 
алгоритмов.
68
 3.1. Асимптотические обозначения
 Часть I. Основы
 Обозначения, используемые нами для описания асимптотического поведения 
времени работы алгоритма, используют функции, областью определения которых 
является множество неотрицательных целых чисел N = {0,1,2,...}. Подобные 
обозначения удобны для описания времени работы Т(п) в наихудшем случае как 
функции, определенной только для целых чисел, представляющих собой размер 
входных данных. Однако иногда удобно изменить толкование асимптотических 
обозначений тем или иным не совсем корректным образом. Например, можно 
распространить эти обозначения на действительные числа или, наоборот, огра
 ничить их областью, являющейся подмножеством натуральных чисел. При этом 
важно понимать точный смысл обозначений, чтобы изменение толкования не при
 вело к некорректному их использованию. В данном разделе вводятся основные 
асимптотические обозначения, а также описывается, как чаще всего неверно из
 меняется их толкование.
 Асимптотические обозначения, функции и время работы
 Асимптотические обозначения будут использоваться, в первую очередь, для 
описания времени работы алгоритмов, как, например, мы записывали время ра
 боты сортировки вставкой в наихудшем случае как @(п2). Однако фактически 
асимптотические обозначения применяются к функциям. Вспомним, что мы оха
 рактеризовали время работы сортировки вставкой в наихудшем случае как ап2 + 
Ьп + с для некоторых констант а, Ъ и с. Записывая время работы сортировки 
вставкой как О (гг2), мы абстрагируемся от некоторых деталей этой функции. По
 скольку асимптотические обозначения применимы к функциям, то то, что мы 
записываем просто как 0(гг2), представляет собой функцию ап2 + Ьп + с, которая 
в данном случае, помимо прочего, описывает время работы сортировки вставкой 
в наихудшем случае.
 В этой книге функции, к которым мы применяем асимптотические обозначе
 ния, обычно характеризуют время работы алгоритма. Но эти обозначения могут 
применяться и к функциям, которые характеризуют некоторые другие аспекты 
алгоритмов (например, количество используемой памяти), или даже к функциям, 
не имеющим никакого отношения к алгоритмам.
 Даже когда мы используем асимптотические обозначения для времени работы 
алгоритма, нам надо понимать, какое время работы мы имеем в виду. В основном 
нас интересует время работы в наихудшем случае, однако зачастую мы хотим 
охарактеризовать время работы независимо от входных данных. Другими сло
 вами, часто желательно получить всеобъемлющее утверждение, охватывающее 
все варианты входных данных, а не только наихудший случай. Мы познакомимся 
с асимптотическими обозначениями, которые хорошо подходят для характеристи
 ки времени выполнения безотносительно ко входным данным.
Глава 3. Рост функций
 ©-обозначения
 69
 В главе 2 было показано, что время работы сортировки вставкой в наихудшем 
случае составляет Т(п) = 0(п2). Давайте разберемся в смысле данного обозначе
 ния. Для заданной функции д(п) запись 0(д(п)) обозначает множество функций
 0(д(п)) = {/(п) : существуют положительные константы с\, С2 
и по, такие, что 0 < с\д{п) < f(n) < С2р(п) 
для всех п > no} -1
 Функция /(п) принадлежит множеству Q(g(n)), если существуют положитель
 ные константы с\ и С2, такие, что при достаточно больших п эта функция может 
быть заключена в рамки между с\д{п) и С2д{п). Поскольку Q(g(n)) представля
 ет собой множество, можно записать “/(п) е 0(р(п))”, чтобы указать тот факт, 
что /(п) является членом 0(р(п)). Вместо этого мы обычно будем использовать 
эквивалентную запись “/(п.) = 0(д(п))” Такое толкование знака равенства для 
обозначения принадлежности множеству поначалу может сбить с толку, однако 
далее мы убедимся, что у этой записи есть свои преимущества.
 Лп)=9Ш) 
(а) 
° 
ЛиИХ*(и))
 (б)
 fin)=n(g(n))
 (в)
 Рис. 3.1. Графические примеры @-, О- и fi-обозначений. В каждой части значение по является 
минимально возможным; подходит также любое большее значение, (а) 0-обозначение ограничи
 вает функцию константными множителями. Мы записываем /(n) = 0(д(п)), если существуют 
положительные константы no, ci и сг, такие, что в точке по и справа от нее значение /(п) всегда 
лежит между С\д(п) и Сгд(п) включительно, (б) О-обозначение дает верхнюю оценку функции 
с точностью до постоянного множителя. Мы записываем /(п) = 0(д(п)), если существуют поло
 жительные константы по и с, такие, что в точке по и справа от нее значение /(п) всегда лежит не 
выше сд(п). (в) ^-обозначение дает нижнюю оценку функции с точностью до постоянного множи
 теля. Мы записываем /(n) = S7(g(n)), если существуют положительные константы по и с, такие, 
что в точке по и справа от нее значение /(п) всегда лежит не ниже сд(п).
 На рис. 3.1, (а) показано интуитивное изображение функций /(п) и д(п), таких, 
что f(n) = ©(0(71)). Для всех значений п, лежащих справа от по, функция / (п) 
больше или равна функции с\д (п), но не превосходит функцию С2д (п). Другими 
словами, для всех п > по функция / (п) равна функции д (п) с точностью до
 теории множеств двоеточие следует читать как “такие, что” или “для которых выполняется условие”
70
 Часть I. Основы
 постоянного множителя. Говорят, что функция д (п) является асимптотически 
точной оценкой функции / (п).
 Согласно определению множества 0(д(п)) необходимо, чтобы каждый эле
 мент f(n) е &(д(п)) этого множества был асимптотически неотрицателен. 
Это означает, что при достаточно больших и функция / (п) является неотрица
 тельной. {Асимптотически положительной называется такая функция, кото
 рая является положительной при любых достаточно больших п.) Следовательно, 
функция д (п) должна быть асимптотически неотрицательной, потому что в про
 тивном случае множество 0(д(п)) окажется пустым. Поэтому будем считать, что 
все функции, используемые в ©-обозначениях, асимптотически неотрицательные. 
Это предположение справедливо и для других асимптотических обозначений, 
определенных в данной главе.
 В главе 2 ©-обозначения вводятся неформально. При этом отбрасываются сла
 гаемые низшего порядка и игнорируется коэффициент при старшем слагаемом. 
Подтвердим интуитивные представления, рассмотрев небольшой пример, в кото
 ром с помощью формального определения показано, что \п 2 — Зп = 0(н2). Для 
этого необходимо определить, чему равны положительные константы ci, с2 и по, 
такие, что
 С1П2 < - п2 — 3п < С2П2
 для всех п > щ. Деление на п2 дает
 1 3
 ci < -------< с2 .
 2 п
 Можно сделать правое неравенство выполняющимся для любого значения п > 1, 
выбирая любую константу с2 > 1/2. Аналогично можно сделать выполняющимся 
для любого значения п > 7 левое неравенство, если выбрать произвольную кон
 станту ci < 1/14. Таким образом, выбирая ci = 1/14, с2 = 1/2 и по = 7, можно 
убедиться, что ^п2 — Зп = 0(п2). Конечно, имеются и другие варианты выбора 
констант, но главное заключается в том, что такой выбор существует. Заметим, 
что эти константы зависят от функции \п 2 — Зп; другой функции, принадлежащей 
0(п2), скорее всего, потребуются другие константы.
 Можно воспользоваться формальным определением для того, чтобы убедить
 ся, что 6н3 Ф 0(п2). Пойдем от противного, предположив, что существуют кон
 станты с2 и по, такие, что 6н 3 < с2н 2 для всех п > щ. Но тогда деление на п2 
дает п < с2/6, а это неравенство не может выполняться при произвольно больших 
п, поскольку с2 является константой.
 Интуитивно понятно, что при асимптотически точной оценке асимптотически 
положительных функций, слагаемыми низших порядков в них можно пренебречь, 
поскольку при больших п они становятся несущественными. При больших п да
 же небольшой доли слагаемого самого высокого порядка достаточно для того, 
чтобы превзойти слагаемые низших порядков. Таким образом, для выполнения 
неравенств, фигурирующих в определении ©-обозначений, достаточно в качестве 
ci выбрать значение, которое несколько меньше коэффициента при самом стар
 шем слагаемом, а в качестве с2 — значение, которое несколько больше этого ко
Глава 3. Рост функций
 71
 эффициента. Поэтому коэффициент при старшем слагаемом можно не учитывать, 
так как он лишь изменяет указанные константы.
 В качестве примера рассмотрим произвольную квадратичную функцию 
/ (п) = ап2 + Ъп + с, где а, b и с — константы, причем а > 0. Отбросив сла
 гаемые низших порядков и проигнорировав константу, получим /(п) = 0(п2). 
Чтобы показать то же самое формально, выберем константы с\ = а/4, С2 = 7а/4 
и по = 2 • тах(|6| /а, у/\с\ /а). Читатель может сам убедиться в том, что неравен
 ство 0 < cin2 < ап2 + Ьп + с < С2П2 выполняется для всех п > по. В общем 
случае для любого полинома р(п) = Yli=о аг^\ где а* представляют собой кон
 станты и ad > 0, мы имеем р(п) = Q(nd) (см. задачу 3.1).
 Поскольку любая константа — это полином нулевой степени, постоянную 
функцию можно выразить как 0 (п°) или 0(1). Однако последнее обозначение 
не совсем точное, поскольку непонятно, по отношению к какой переменной ис
 следуется асимптотика2. Мы часто будем употреблять запись © (1) для обозна
 чения либо константы, либо постоянной функции по отношению к некоторой 
переменной.
 О-обозначения
 В ©-обозначениях функция асимптотически ограничивается сверху и снизу. 
Если же достаточно определить только асимптотическую верхнюю границу, 
используются О-обозначения. Для данной функции д (п) обозначение О (д (п)) 
(произносится как мо большое от д от п” или просто “о от д от п”) означает 
множество функций
 0(д(п)) = {/(п) : существуют положительные константы с и по, 
такие, что 0 < /(п) < сд(п) для всех п > по} .
 О-обозначения применяются, когда нужно указать верхнюю границу функции 
с точностью до постоянного множителя. Интуитивное представление об О-обо
 значениях позволяет получить рис. 3.1, (б). Для всех значений п, лежащих справа 
от по, значение функции / (п) не превышает значения функции сд (п).
 Чтобы указать, что функция / (п) принадлежит множеству О (д (п)), использу
 ется запись /(п) = 0(д(п)). Обратите внимание, что из /(n) = Q(g(n)) следует 
f(n) = 0(д(п)), поскольку ©-обозначения более сильные, чем О-обозначения. 
В обозначениях теории множеств &(д(п)) С 0(д(п)). Таким образом, доказа
 тельство того, что функция ап2 + Ьп + с, где а > 0, принадлежит множеству 
0(п2), одновременно доказывает, что любая такая квадратичная функция являет
 ся элементом множества 0(п2). Может показаться удивительным то, что любая 
линейная функция ап + Ъ при а > 0 также принадлежит множеству 0(п2). В этом 
легко убедиться, выбрав с = а + |Ь|ипо = тах(1, —Ь/а).
 2 На самом деле проблема заключается в том, что в наших обычных обозначениях функций не делается 
различия между функциями и обычными величинами. В Л-исчислении четко указываются параметры функций: 
функцию от п2 можно обозначить как Ап.п2 или даже как Аг.г2. Однако если принять более строгав обозна
 чения, то алгебраические преобразования могут усложниться, поэтому мы предпочли нестрогие обозначения.
72
 Часть I. Основы
 Некоторым читателям, уже знакомым с О-обозначениями, может показаться 
странным, например, соотношение п = 0(п2). В литературе О-обозначения ино
 гда неформально используются для описания асимптотической точной оценки, 
т.е. так, как мы определили ©-обозначения. Однако в данной книге, когда мы пи
 шем /(п) = 0(д(п)), подразумевается, что произведение некоторой константы 
на функцию д(п) является асимптотическим верхним пределом функции /(п). 
При этом не играет роли, насколько близко функция /(п) находится к этой верх
 ней границе. В литературе, посвященной алгоритмам, стало стандартом различать 
асимптотически точную оценку и верхнюю асимптотическую границу.
 Чтобы записать время работы алгоритма в О-обозначениях, зачастую доста
 точно просто изучить его общую структуру. Например, наличие двойного вложен
 ного цикла в структуре алгоритма сортировки вставкой, представленного в гла
 ве 2, свидетельствует о том, что верхний предел времени работы в наихудшем 
случае выражается как 0(п2): стоимость каждой итерации во внутреннем цикле 
ограничена сверху константой 0(1), индексы i и j — числом п, а внутренний 
цикл выполняется самое большее один раз для каждой из п2 пар значений г и j.
 Поскольку О-обозначения описывают верхнюю границу, когда мы используем 
их для ограничения времени работы алгоритма в наихудшем случае, мы полу
 чаем верхнюю границу этой величины для любых входных данных — то самое 
всеобъемлющее утверждение, о котором мы говорили ранее. Таким образом, гра
 ница 0(п2) для времени работы алгоритма в наихудшем случае применима для 
времени решения задачи с любыми входными данными, чего нельзя сказать о ©- 
обозначениях. Например, оценка @(п2) для времени сортировки вставкой в наи
 худшем случае неприменима для любых входных данных. Например, в главе 2 мы 
имели возможность убедиться в том, что если входные элементы уже отсортиро
 ваны, то время работы алгоритма сортировки вставкой составляет @(п).
 Технически неверно говорить, что время, необходимое для сортировки по ме
 тоду вставок, равно 0(п2), так как для данного п фактическое время работы алго
 ритма изменяется в зависимости от конкретных входных данных. Когда говорит
 ся, что “время работы равно 0(п2)”, то подразумевается, что существует функция 
/(п), принадлежащая 0(п2), такая, что при любых входных данных размером п 
время решения задачи с этими входными данными ограничено сверху значением 
функции /(п). В конечном счете подразумевается, что в наихудшем случае время 
работы равно 0(п2).
 Г2-обозначения
 Подобно тому, как в О-обозначениях дается асимптотическая верхняя граница 
функции, в ^-обозначениях дается ее асимптотическая нижняя граница. Для 
данной функции д(п) выражение Щд(тг)) (произносится как “омега большое от 
д от п” или просто как “омега от д от п”) обозначает множество функций
 fl(g(n)) = {/(п) : существуют положительные константы с и по, 
такие, что 0 < сд(п) < /(п) для всех п > по} .
Глава 3. Рост функций
 73
 Интуитивное представление об ^-обозначениях дает рис. 3.1, (в). Для всех п, ле
 жащих справа от по, значения функции /(п) больше или равны значениям сд(п).
 Пользуясь введенными определениями асимптотических обозначений, легко 
доказать сформулированную ниже теорему (см. упр. 3.1.5).
 Теорема 3.1
 Для любых двух функций /(п) и д(п) мы имеем /(n) = 0(д(п)) тогда и только 
тогда, когда /(п) = 0(д(п)) и /(п) = Щд(п)). 
я
 В качестве примера применения этой теоремы отметим, что из соотношения 
ап2 + Ьп + с = 0(п2) для произвольных констант а, b и с, где а > 0, непосред
 ственно следует, что ап2 + Ьп + с = 0(п2) и ап2 + Ьп + с = 0(п2). На практике 
теорема 3.1 применяется не для получения асимптотических верхней и нижней 
границ, как это сделано выше, а наоборот — для определения асимптотически 
точной оценки с помощью асимптотических верхней и нижней границ.
 Когда мы говорим, что время работы (без указания модификатора) алгорит
 ма равно Щд(п)), мы имеем в виду, что независимо от того, какие конкретно 
входные данные размером п выбраны для каждого значения п, время работы для 
этих входных данных будет для достаточно больших п как минимум константой, 
умноженной на д(п). Или, что то же самое, мы даем нижнюю границу време
 ни работы алгоритма в наилучшем случае. Например, в наилучшем случае время 
работы сортировки вставкой составляет Щп), откуда следует, что время работы 
сортировки вставкой представляет собой Щп).
 Таким образом, время работы алгоритма сортировки вставкой принадлежит 
как Щп), так и 0(п2), поскольку оно располагается между линейной и квадра
 тичной функциями от п. Более того, эти границы охватывают асимптотику на
 столько плотно, насколько это возможно. Например, нижняя оценка для времени 
работы алгоритма сортировки вставкой не может быть равной П(п2), потому что 
существуют входные данные, для которых эта сортировка выполняется за время 
0(п) (когда входные элементы уже отсортированы). Это не противоречит утвер
 ждению о том, что время работы алгоритма сортировки вставкой в наихудшем 
случае равно Щп2), поскольку существуют входные данные, для которых этот 
алгоритм работает в течение времени Щп2).
 Асимптотические обозначения в уравнениях и неравенствах
 Мы уже видели, как асимптотические обозначения используются в матема
 тических формулах. Например, при введении О-обозначения мы писали “п = 
0(п2)’! Можно также записать “2n2 + Зп + 1 = 2п2 + 0(п)” Как же интерпрети
 руются подобные формулы?
 Если в правой части уравнения (или неравенства) находится только асимпто
 тическое обозначение (не являющееся частью большей формулы), как в случае 
уравнения п = 0(п2), то знак равенства используется для указания принадлеж
 ности множеству: п G 0(п2). Однако если асимптотические обозначения встре
 чаются в формуле в другой ситуации, они рассматриваются как подставляемые 
вместо некоторой неизвестной функции, имя которой не имеет значения. Напри
74
 Часть I. Основы
 мер, формула 2п2+Зп+1 = 2п2 + @(п) означает, что 2п2+Зп+1 = 2п2 + /(п), где 
/(п) — некоторая функция из множества @(п). В данном случае /(n) = Зп + 1, 
и эта функция действительно принадлежит множеству @(п).
 Подобное использование асимптотических обозначений позволяет избежать 
несущественных деталей и неразберихи в уравнениях. Например, в главе 2 время 
работы сортировки слиянием в наихудшем случае было выражено в виде рекур
 рентного уравнения
 Т(п) = 2Т(п/2) + &(п) .
 Если нас интересует только асимптотическое поведение Т(п), то нет смысла точ
 но выписывать все слагаемые низших порядков; подразумевается, что все они 
включены в безымянную функцию, обозначенную как @(п).
 Предполагается, что таких функций в выражении столько, сколько раз в нем 
встречаются асимптотические обозначения. Например, в выражении Yli=i ^(0 
имеется только одна функция без имени (аргументом которой является г). Таким 
образом, это выражение — не то же самое, что и 0(1) + 0(2) + • • • + О(п), 
выражение, которое действительно не имеет однозначной интерпретации.
 В некоторых случаях асимптотические обозначения появляются в левой части 
уравнения, как, например, в
 2п2 + 0(п) = 0(п2) .
 Подобные уравнения интерпретируются в соответствии со следующим правилом: 
при любом выборе безымянных функций, подставляемых вместо асимптотиче
 ских обозначений в левую часть уравнения, можно выбрать и подставить в пра
 вую часть такие безымянные функции, что уравнение будет правильным. Таким 
образом, наш пример означает, что для любой функции /(n) G 0(гг) существу
 ет некоторая функция g(n) G 0(п2), такая, что 2п2 + /(п) = д(п) для всех п. 
Другими словами, правая часть уравнения предоставляет меньший уровень дета
 лизации, чем левая.
 Такие соотношения могут быть объединены в цепочку, как в
 2гг2 + Зп + 1 = 2п2 + 0(п)
 = ©(и2) .
 При этом в соответствии со сформулированными выше правилами можно ин
 терпретировать каждое уравнение отдельно. Согласно первому уравнению суще
 ствует некоторая функция /(n) G 0(п), такая, что для всех п выполняется со
 отношение 2п2 + Зп + 1 = 2п2 + /(п). Второе уравнение гласит, что для любой 
функции д(п) G 0(п) (такой, как только что упоминавшаяся /(п)) существует 
некоторая функция h(n) G 0(п2), такая, что для всех п выполняется соотно
 шение 2п2 + д(п) = h(n). Заметим, что такая интерпретация подразумевает вы
 полнение соотношения 2п2 + Зп + 1 = 0(п2), которое согласуется с нашими 
интуитивными представлениями о цепочке уравнений.
Глава 3. Рост функций
 75
 о- обозначения
 Асимптотическая верхняя граница, предоставляемая О-обозначениями, может 
описывать асимптотическое поведение функции с разной точностью. Граница 
2п2 = 0(п2) дает правильное представление об асимптотическом поведении 
функции, а граница 2п — 0(п2) — нет. Для указания того, что верхняя грани
 ца не является асимптотически точной оценкой функции, применяются о-обозна- 
чения. Приведем формальное определение множества о(д(п)) (произносится как 
“о малое от д от гг”):
 о(д(п)) = {/(п) : для любой положительной константы с> О 
существует константа по > 0, такая, что 
О < /(п) < сд(п) для всех п > по} .
 Например, 2п = о(п2), но 2п2 ф о(п2).
 Определения О-обозначений и о-обозначений похожи между собой. Основное 
отличие в том, что определение /(п) = 0(д(п)) ограничивает функцию /(п) 
неравенством 0 < /(п) < сд(п) лишь для некоторой константы с > 0, а опре
 деление /(п) = о{д{п)) ограничивает ее неравенством 0 ^ /(п) < сд(п) для 
всех констант с > 0. Интуитивно понятно, что в о-обозначениях функция /(п) 
пренебрежимо мала по сравнению с функцией д{п) при п, стремящемся к беско
 нечности, т.е.
 f i n)
 lim i ^ 
n-^oo g[n) = 0
 (3.1)
 Некоторые авторы используют этот предел в качестве определения о-обозначе- 
ний. Добавим, что определение, данное в этой книге, накладывает на безымян
 ную функцию ограничение, согласно которому она должна быть асимптотически 
неотрицательной.
 ^-обозначения
 По аналогии и-обозначения соотносятся с ^-обозначениями точно так, как 
о-обозначения с О-обозначениями. С помощью и-обозначений указывается ниж
 ний предел, не являющийся асимптотически точной оценкой. Один из возможных 
способов определения ^-обозначения следующий:
 /(п) 6 ы(^(п)) тогда и только тогда, когда д(п) е о(/(п)) .
 Формально же ui(g(n)) (произносится как “омега малое от д от п”) определяется 
как множество
 и(д(п)) = {/(п) : для любой положительной константы с > 0 
существует константа по > 0, такая, что
 0 < сд(п) < f{n) для всех п > по} .
"6
 Часть I. Основы
 Например, п2/ 2 = и(тг), но п2/ 2 ф и(п2). Из соотношения /(п) = ы(^(п)) 
вытекает, что
 lim
 / и = ОО ,
 П—► оо
 если этот предел существует. Таким образом, функция /(п) становится сколь 
угодно большой по сравнению с функцией д(п) при п, стремящемся к бесконеч
 ности.
 Сравнение функций
 Асимптотические сравнения обладают многими свойствами отношений обыч
 ных действительных чисел, показанными далее. Здесь предполагается, что функ
 ции /(п) и д(п) асимптотически положительны.
 Транзитивность
 Из /(п) = @(д{п)) 
Из /(п) = 0(д(п)) 
Из /(п) = Щд(п)) 
Из /(п) = о(0(п)) 
Из /(п) = и(д(п))
 Рефлексивность
 Симметрия
 и д(п) = e{h(n)) следует / н = в(Н(п))
 и д(п) = 0(h(n)) следует / н = 0(h(n))
 и д(п) = П(Л(п)) следует / н = Q(h{n))
 и д(п) = o(h{n)) следует / н = o(h{n))
 и д{п) = u(h(n)) следует / н
 /(п) = ©(/(гг)) 
/(п) = 0(/(п)) 
/(п) = П(/(п))
 /(n) = Q(g(n)) тогда и только тогда, когда д(п) = @(/(п))
 Перестановочная симметрия
 /(п) = 0{д(п)) тогда и только тогда, когда д(п) = Q,(f(n))
 /(п) = о(д(п)) тогда и только тогда, когда д(п) = ы(/(п))
 Из-за выполнения указанных свойств для асимптотических обозначений мож
 но провести аналогию между асимптотическим сравнением двух функций / и д
Глава 3. Рост функций
 и сравнением двух действительных чисел а и 6.
 / И = 0(д(п)) аналогично а <Ь
 / О ) = Щд(п)) аналогично а > b
 / О ) = в(д(п)) аналогично 0 = 6
 / ы =: о($(п)) аналогично о < 6
 / О ) = и(д(п)) аналогично о > 6
 77
 Говорят, что функция /(п) асимптотически меньше функции д(п), если /(п) = 
о(д(п)), и асимптотически больше функции д(п), если /(п) = ш(д(п)).
 Однако одно из свойств действительных чисел в асимптотических обозначе
 ниях не выполняется.
 Трихотомия
 Для любых двух действительных чисел о и 6 должно выполняться только одно 
из соотношений a< b, a = bna> b.
 Хотя можно сравнивать любые два действительных числа, в отношении асимп
 тотического сравнения функций это утверждение не является справедливым. Для 
двух функций /(п) и д{п) может не выполняться ни отношение f(n) = 0(д(п)), 
ни отношение /(п) = Щд(п)). Например, нельзя асимптотически сравнивать 
функции п и n1+smn, поскольку показатель степени в функции n1+smn колеблет
 ся между значениями 0 и 2, принимая все значения в этом интервале.
 Упражнения
 3.1.1
 Пусть /(гг) и д(п) — асимптотически неотрицательные функции. Докажите с по
 мощью базового определения ©-обозначений, что таx(f(n),g(n)) = @(/(п) + 
9(п)).
 3.1.2
 Покажите, что для любых действительных констант а и Ь, где b > 0, выполняется 
соотношение
 (п + а)ь = 0(пь) . 
(3.2)
 3.1.3
 Поясните, почему утверждение “время работы алгоритма А равно как минимум 
0 (гс2)” лишено смысла.
 3.1.4
 Справедливы ли соотношения 2n+1 = 0(2П) и 22п = 0(2П)?
 3.1.5
 Докажите теорему 3.1.
78
 3.1.6
 Часть I. Основы
 Докажите, что время работы алгоритма равно 0(д(п)) тогда и только тогда, когда 
его время работы в наихудшем случае равно 0(д(п)), а в наилучшем — Q,(g(n)).
 3.1.7
 Докажите, что множество о(д(п)) Пш(д(п)) является пустым.
 3.1.8
 Можно обобщить наши обозначения на случай двух параметров пит, которые 
могут возрастать до бесконечности по отдельности с разными скоростями. Для 
данной функции д(п,т) обозначим как 0(д(п,т )) множество функций
 0(g(n,m)) = {/(n,m) : существуют положительные константы
 с, по и то, такие, что 0 < /(п, т) < сд(п, т) 
для всех п > по или т > то} .
 Приведите соответствующие определения для Q,(g(n,ni)) и Q(g(n,m)).
 3.2. 
Стандартные обозначения и часто встречающиеся функции
 В этом разделе рассматриваются некоторые стандартные математические 
функции и обозначения, а также исследуются взаимоотношения между ними. 
В нем, кроме того, иллюстрируется применение асимптотических обозначений.
 Монотонность
 Функция /(п) является монотонно неубывающей (monotonically increasing), 
если из т < п вытекает /(т ) < /(п). Аналогично она является монотонно 
невозрастающей (monotonically decreasing), если из т < п вытекает /(т ) > 
/(п). Функция f(n) является монотонно возрастающей (strictly increasing), если 
из т < п вытекает /(т ) < /(п), и монотонно убывающей (strictly decreasing), 
если из т < п вытекает /(т ) > /(п).
 Полы И ПОТОЛКИ
 Для любого действительного числа х обозначим наибольшее целое число, 
меньшее или равное х, как [xj (читается как “пол (floor) х”), а наименьшее целое 
число, большее или равное х, — как [х] (читается как “потолок (ceil) х”). Для 
всех действительных х
 х — 1 < [zj < х < [х] < х + 1 . 
Для любого целого п
 (3.3)
 \ п /2] + \ n/2\ = п ,
Глава 3. Рост функций
 а для любого действительного числа х > 0 и целых чисел о, Ь > О,
 ~\х/а\
 Ъ
 [х/а\
 Ь-ап
 Ъ
 а-Ъ.
 ' 
X ‘
 аЪ
 X
 .аЪ.
 < а + (6 — 1)
 > а — (b — 1)
 79
 (3.4)
 (3.5)
 (3.6)
 (3.7)
 Функция f(x) = |xj является монотонно неубывающей, как и функция f(x) =
 W
Модульная арифметика
 Для любого целого числа а и любого натурального п величина a mod п пред
 ставляет собой остаток от деления а на п:
 a mod п = а — п\а/п\ . 
(3.8)
 Отсюда следует, что
 О < a mod п < п . 
(3.9)
 Располагая подобным определением, удобно ввести специальные обозначения 
для указания того, что два целых числа имеют одинаковые остатки при делении 
на какое-то натуральное число. Тот факт, что (a mod п) = (6 mod п), записыва
 ется как а = b (mod п); при этом говорят, что число а эквивалентно, или равно, 
числу Ъ по модулю п (или что числа а и 6 сравнимы по модулю п). Другими 
словами, а = Ъ (mod п), если числа а и Ь дают одинаковые остатки при делении 
на п. Это эквивалентно утверждению, что а = b (mod п) тогда и только тогда, 
когда п является делителем числа Ь—а. Запись а ф b (mod п) означает, что число 
а не эквивалентно числу b по модулю п.
 Полиномы
 Для заданного неотрицательного целого d полиномом степени d от аргумента 
п называется функция р(п) вида
 d
 р{п) = ^2 
г=0
 где константы ao, ai,..., 
’
 — коэффициенты полинома и ф 0. Полином явля
 ется асимптотически положительной функцией тогда и только тогда, когда ад > 0. 
Для асимптотически положительных полиномов р(п) степени d справедливо со
 отношение р(п) = &(nd). Для любой действительной константы а > 0 функция 
па монотонно неубывающая, а для а < 0 эта функция монотонно невозраста
80
 Часть I. Основы
 ющая. Говорят, что функция f(n) полиномиально ограничена, если существует 
такая константа к, что f(n) = 0(пк).
 Показательные функции
 Для всех действительных чисел о > 0, т и п справедливы следующие тожде
 ства.
 ои = 1 
о1 = о 
о-1= 1/о 
(ат)п = атп
 (О ) = (О )
 атап = ат+п
 Для всех п и о > 1 функция ап является монотонно неубывающей функцией 
аргумента п. Для удобства будем считать, что 0° = 1.
 Соотношение между скоростями роста полиномов и показательных функций 
можно определить исходя из того факта, что для любых действительных констант 
о и Ь, таких, что о > 1,
 lim — = 0 ,
 и—>оо а-71 
откуда можно заключить, что
 пь = о(ап) .
 ’
 (ЗЛО)
 Таким образом, любая показательная функция, основание о которой строго боль
 ше единицы, возрастает быстрее любой полиномиальной функции.
 Обозначив через е основание натурального логарифма (приблизительно рав
 ное 2.718281828...), можем записать следующее соотношение, справедливое для 
любого действительного х:
 т 
О Q оо ,•
 хг 
ХЛ 
х
 е - 1 + 1 + ^ + ^ +------И тг >
 г=0
 (3.11)
 где “!” обозначает факториал, определенный ниже в этом разделе. Для всех дей
 ствительных х справедливо следующее неравенство:
 ех>1 + 2 , 
(3.12)
 где равенство выполняется только при х = 0. Когда |х| < 1, можно использовать 
такое приближение:
 1 + х<ех<1 + х + х2.
 (3.13)
 При х —> 0 приближение ех функцией 1 + х вполне удовлетворительно:
 ех = 1 + х + @(х2) .
Глава 3. Рост функций
 81
 В этом уравнении асимптотические обозначения используются для описания пре
 дельного поведения при х —> 0, а не при х —> оо. Для всех х мы имеем
 / 
х \ п
 lim (1 Н— ) = ё . 
п —юо V п /
 Логарифмы
 Мы будем использовать следующие обозначения.
 lg П = log 2 п 
Inn = loge n 
lg*n = (lgn)fc 
lg lg n = lg(lg n)
 (бинарный логарифм) 
(натуральный логарифм) 
(возведение в степень) 
(композиция)
 (3.14)
 Важное соглашение, которое мы приняли в книге, — логарифмические функции 
применяются только к ближайшему члену выражения. Например, lg п + к озна
 чает (lgn) + к, а не lg(n + к). Если основание логарифма b > 1, то при п > О 
функция logb п монотонно возрастает.
 Для всех действительных о>0, 6 > 0, оОип
 а
 logc(o6) 
logb ап
 log ьа
 l°gb(l/a)
 logb a
 alog*c
 6log*a ,
 logc a + logc b , 
n logb a ,
 logcQ
 logc6 ’- logb a >
 1
 loga b ’
 c l°gba
 (3.15)
 (3.16)
 где в каждом из приведенных уравнений основание логарифма не равно 1.
 Согласно уравнению (3.15) изменение основания логарифма приводит к умно
 жению значения этого логарифма только на постоянный множитель, поэтому мы 
часто будем использовать обозначение “lg п'\ не заботясь о постоянном множите
 ле, как это делается в О-обозначениях. Специалисты в области вычислительной 
техники считают наиболее естественной основой логарифма число 2, так как во 
многих алгоритмах и структурах данных производится разбиение задачи на две 
части.
 При |х| < 1 имеется простое разложение в ряд
 ч 
X2 X3 X4 X5
 1п(1+х)=х-у + у- — + у
82
 Кроме того, для х > — 1 выполняются следующие неравенства:
 —-— < 1п(1 + х) < х, 
1 + х
 Часть I. Основы
 (3.17)
 где равенство достигается только при х = 0.
 Говорят, что функция fin) полилогарифмически ограничена, если существует 
такая константа к, что /(n) = 0(lgkn). Соотношение между скоростью роста 
полиномов и полилогарифмов можно найти, подставив в уравнение (3.10) lgn 
вместо п и 2“ вместо а, в результате чего получим
 цт 
Т1—ЮС (2°) 
Иш 11^ = 0.
 п—ЮО Па
 Из приведенного выше соотношения можно заключить, что для произвольной 
константы а > 0
 lgb п = о(па) .
 Таким образом, любая положительная полиномиальная функция возрастает быст
 рее, чем любая полилогарифмическая функция.
 Факториалы
 Обозначение п\ (читается как “п факториал”) определено для целых чисел 
п > 0 следующим образом:
 {1 , 
если п = 0 ,
 п • (п — 1)! , если п > 0 .
 Таким образом, п\ = 1 ■ 2 • 3 • • • п.
 Слабой верхней границей факториала является п\ < пп, поскольку каждый из 
п членов, входящих в факториальное произведение, не превышает п. Формула 
Стирлинга,
 n! = v/2^ (^ )"(l + ©(^)) , 
(3.18)
 где е — основание натуральных логарифмов, дает более точную верхнюю (а также 
нижнюю) границу. В упр. 3.2.3 требуется доказать, что
 п\ = о(пп) , 
п! = ш(2п) ,
 lg(ra!) = ©(nigra) , 
(3.19)
 причем при доказательстве уравнения (3.19) удобно использовать формулу Стир
 линга. Для всех п > 1 справедливо также следующее равенство:
Глава 3. Рост функций
 где
 83
 1 
1
 12n + 1 < п < Yin
 (3.21)
 Функциональная итерация
 Запись /^ (п ) используется для обозначения функции f(n), итеративно при
 мененной i раз к исходному значению п. Подходя формально, пусть /(п) является 
функцией от действительного аргумента. Для неотрицательных целых i рекурсив
 но определим
 п ,
 / ( / (<_1)(п)) 
Например, если /(п) = 2п, то /W(n) = 2гп.
 если г = 0, 
если i > 0 .
 Итерированная логарифмическая функция
 Обозначение lg* п (читается как “логарифм со звездочкой от п”) будет при
 меняться для указания повторно применяемого логарифма, который определя
 ется следующим образом. Пусть lg (i>ra представляет собой итерацию функции 
f{n) = lg п. Поскольку логарифм от отрицательных чисел не определен, функция 
lg^ п определена, только если lg V-Vn > 0. Не перепутайте обозначения lg (i)n 
(логарифм, примененный последовательно г раз к аргументу п) и lg1 п (логарифм 
п, возведенный в г-ю степень). Итерированный логарифм определяется следую
 щим образом:
 lg* п = min {г > 0 : lg^ гг < 1} .
 Это очень медленно растущая функция.
 lg* 2 = 1 
lg* 4 = 2 
lg* 16 = 3 
lg* 65536 = 4 
lg*(265536) = 5
 Поскольку количество атомов в видимой Вселенной оценивается примерно в Ю80, 
что гораздо меньше 265536, мы вряд ли встретимся с входными данными разме
 ром п, таким, что lg* п > 5.
84
 Часть I. Основы
 Числа Фибоначчи
 Числа Фибоначчи определяются с помощью следующего рекуррентного со
 отношения.
 F0 = О
 Fi = 1 
Fi = F ^ i + Fi- 2 
(3.22)
 для i > 2
 Таким образом, каждое число Фибоначчи представляет собой сумму двух преды
 дущих, что дает нам последовательность
 О, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, ... .
 Числа Фибоначчи тесно связаны с золотым сечением ф и сопряженным с ним 
значением ф, которые определяются уравнением
 х2 = х + 1 , 
и задаются следующими формулами (см. упр. 3.2.6).
 , 
i +v's 
0 = _ 2~
 = 1.61803...
 Ф = ~ Т ~
 = -0.61803...
 В частности, мы имеем
 • “ 
у/5 
’
 что можно доказать по индукции (упр. 3.2.7). Поскольку \ф\ < 1, мы имеем
 л/5 
откуда вытекает, что
 у/Ъ
 1
 Fs = V- + 1
 (3.23)
 (3.24)
 (3.25)
 У5 2.
 что в переводе на обычный язык гласит: “г-е число Фибоначчи Fi равно фг/у/Е, 
округленного до ближайшего целого числа’! Таким образом, числа Фибоначчи 
растут экспоненциально.
Глава 3. Рост функций
 Упражнения
 85
 3.2.1
 Покажите, что если функции /(п) и д(п) монотонно неубывающие, то таковыми 
же являются и функции /(п) + д{п) и f(g(n)), а если вдобавок /(п) и д(п) 
неотрицательны, то монотонно неубывающей является и функция f(n)-g(n).
 3.2.2
 Докажите уравнение (3.16).
 3.2.3
 Докажите уравнение (3.19). Докажите также, что п\ = о;(2п) и п\ = о{пп).
 3.2.4 ★
 Является ли функция |"lg п \! полиномиально ограниченной? А функция |"lg lg n]! ?
 3.2.5 ★
 Какая из функций lg(lg* п) и lg*(lgn) является асимптотически большей?
 3.2.6
 Покажите, что золотое сечение ф и сопряженное с ним ф удовлетворяют уравне
 нию х2 = х + 1.
 3.2.7
 Докажите по индукции, что г-е число Фибоначчи удовлетворяет уравнению
 где ф — золотое сечение, а ф — сопряженное с ним.
 3.2.8
 Покажите, что из k In к = 0(п) вытекает к = 0(п/1пп).
 Задачи
 3.1. Асимптотическое поведение полиномов
 Пусть
 d
 Р(п) = Л а{П% ’
 г=0
 где ad > 0, представляет собой полином степени d от п, и пусть к является кон
 стантой. Используя определения асимптотических обозначений, докажите следу
 ющие свойства.
 а. Если к > d, то р(п) = 0(пк).
86
 б. Если к < d, то р(п) = Q(nfc).
 в. Если к = d, то р(п) = &(пк).
 г. Если к > d, то р(п) = о(пк).
 д. Если к < d, то р{п) = ш(пк).
 Часть I. Основы
 3.2. Относительный асимптотический рост
 Для каждой пары приведенных в таблице выражений (А, В) укажите, каким 
отношением А связано с В\ О, о, Q, ш или 0. Предполагается, что k > 1, е > О 
и с > 1 — константы. Ваш ответ должен выражаться таблицей, в каждой ячейке 
которой указано значение “Да” или “Нет”
 А
 lg k n
 fc
 пк
 у/п
 2n
 n1^
 lg(n!)
 В
 ne
 cn
 ^sin n
 2n/2
 cign
 lg(nn)
 О
 0
 n
 Ш 0
 3.3. Упорядочение по скорости асимптотического роста
 а. Расположите приведенные ниже функции по скорости их асимптотического 
роста, т.е. постройте такую последовательность функций gi,g2, • • • ,<7зо> что 
gi = Щд2), <72 = П(дз), ..., <729 = ^(<7зо)- Разбейте свой список на классы 
эквивалентности так, чтобы функции /(п) и д(п) находились в одном и том 
же классе тогда и только тогда, когда /(n) = Q(g(n)).
 lg(lg* n)
 d r
 In Inn
 2lgn
 lg*(lg n)
 (V2)lgn
 n3
 lg *n
 lg 2n
 n2
 lg(n!)
 n!
 22"
 n ■ 2n nlglgn Inn
 (lgn)lgn
 en
 4ig^
 (lgn)!
 n1/ lgn
 1
 (n + 1)! yfign
 2>/2 lgn
 n
 2n
 nlgn
 22"+1
 б. Приведите пример неотрицательной функции /(п), такой, что для всех функ
 ций gi(n) из части (а) /(п) не принадлежит ни множеству 0(^(п)), ни мно
 жеству Q(<7i(n)).
 3.4. Свойства асимптотических обозначений
 Пусть /(п) и д(п) — асимптотически положительные функции. Докажите или 
опровергните справедливость каждого из приведенных ниже утверждений.
Глава 3. Рост функций
 а. Из /(п) = 0(д{п)) вытекает д{п) = 0(/(п)).
 & f(n)+g(n) = Q(min(f(n),g(n))).
 87
 в. Из /(га) = 0($(га)) вытекает lg(/(ra)) = 0(lg(^(n))), где lg($(n)) > 1 и /(га) > 
1 для всех достаточно больших п.
 г. Из f{n) = 0{д(п)) вытекает 
Л /(**) = О ((/(п))2).
 = О (2 
е. Из /(га) = 0(д(п)) вытекает #(п) = Q(/(n)).
 ж . /(п) = 0(/(га/2)).
 з. /(га) + о(/(га)) = 0(/(га)).
 5.5. Вариации определений О и О
 Некоторые авторы определяют Q несколько иначе, чем это делали мы; давайте 
для такого альтернативного определения будем использовать символ (читается 
как “омега бесконечность”). Будем говорить, что /(n) = fl(g{n)), если существу
 ет положительная константа с, такая, что /(n) > сд{п) > 0 для бесконечного 
количества целых чисел п.
 а. Покажите, что для любых двух асимптотически неотрицательных функ
 ций /(п) и д{п) выполняется одно из соотношений /(п) = 0(д(п)) и /(п) = 
^(^(n)) (или они оба), в то время как при использовании П вместо ?? это 
утверждение ложно.
 б. Опишите потенциальные преимущества и недостатки применения вместо П 
для характеристики времени работы программ.
 Некоторые авторы определяют несколько иначе и О; для такого альтернативного 
определения будем использовать символ О'. Будем говорить, что /(п) = 0 ’(д(п)) 
тогда и только тогда, когда |/(п)| = 0{д{п)).
 в. Что произойдет в теореме 3.1 с каждым из направлений “тогда и только тогда, 
когда”, если заменить О на О', но оставить без изменений П?
 Некоторые авторы определяют О (читается как “о с тильдой”) для обозначения О, 
в котором игнорируются логарифмические множители:
 0(д(п)) = {/(п) : существуют положительные константы с, к и по,
 такие, что 0 < /(п) < сд{п) lgfc(n) для всех п > по} .
 г. Определите П и 0 аналогичным образом. Докажите соответствующий аналог 
теоремы 3.1.
88
 3.6. Итерированные функции
 Часть I. Основы
 Оператор итерации *, используемый в функции lg*, можно применить к лю
 бой монотонно возрастающей функции /(п), определенной на множестве дей
 ствительных чисел. Для заданной константы с € R итерированная функция /* 
определяется следующим образом:
 f*{n) = min {г > 0 : /^(п) < с} .
 Она может не быть вполне определенной во всех случаях. Другими словами, ве
 личина /* (п) представляет собой количество итерированных применений функ
 ции /, требующееся для того, чтобы уменьшить ее аргумент до значения, не 
превышающего с.
 Для каждой из приведенных далее функций /(п) и констант с дайте макси
 мально точную оценку функции /*(п).
 с
 f(n)
 а.
 б.
 в.
 г.
 д.
 е.
 ж.
 3.
 п — 1 0
 lgn
 п /2
 п/ 2
 у/п
 у/п
 п1/3
 n/lgn
 / с »
 1
 1
 2
 2
 1
 2
 2
 Заключительные замечания
 Кнут (Knuth) [208]3 попытался выяснить происхождение О-обозначений и об
 наружил, что впервые они появились в 1892 году в учебнике П. Бахманна (Р. Bach- 
mann) по теории чисел. О-обозначения были введены в 1909 году Э. Ландау 
(Е. Landau) при обсуждении распределения простых чисел. Введение Q- и ©-обо
 значений приписывают Кнуту [212], который исправил неточность популярного 
в литературе, но технически неаккуратного применения О-обозначений как для 
верхней, так и для нижней асимптотических границ. Многие продолжают исполь
 зовать О-обозначения там, где более уместны были бы ©-обозначения. Дальней
 шее обсуждение исторического развития асимптотических обозначений можно 
найти у Кнута [208,212], а также Брассарда (Brassard) и Брейтли (Bratley) [53].
 Определения асимптотических обозначений у разных авторов иногда различа
 ются, однако в большинстве часто встречающихся ситуаций они дают согласу
 3Имеется русский перевод: Д. Кнут. Искусство программирования, т. 1. Основные алгоритмы, 3-е изд. — 
М.: И.Д. “Вильямс”, 2000.
Глава 3. Рост функций
 89
 ющиеся результаты. В некоторых альтернативных случаях подразумевается, что 
функции не являются асимптотически неотрицательными, поэтому ограничению 
подлежит их абсолютное значение.
 Равенство (3.20) было получено Роббинсом (Robbins) [295]. Другие свойства 
элементарных математических функций можно найти в любом хорошем справоч
 нике по математике, например, в справочнике Абрамовича (Abramowitch) и Сте
 ган (Stegun) [1] или Цвиллингера (Zwillinger) [360], а также в книгах по вы
 числительной математике, таких как книги Апостола (Apostol) [18] или Томаса 
(Thomas) и др. [332]. В книгах Кнута [208], а также Грехема (Graham), Кнута 
и Паташника (Patashnik) [151]4 содержится множество материала по дискретной 
математике, который используется в информатике.
 4Имеется русский перевод: Р. Грэхем, Д. Кнут, О. Паташиик. Конкретная математика. Математические 
основы информатики, 2-е изд. — М.: И.Д. “Вильямс”, 2010.
Глава 4 Разделяй и властвуй
 В разделе 2.3.1 вы познакомились с применением парадигмы “разделяй 
и властвуй” на примере сортировки слиянием. Напомним, что при данном под
 ходе мы решаем задачу рекурсивно, применяя на каждом уровне рекурсии три 
шага.
 Разделение задачи на несколько подзадач, которые представляют собой меньшие 
экземпляры той же задачи.
 Властвование над подзадачами путем их рекурсивного решения. Если размеры 
подзадач достаточно малы, такие подзадачи могут решаться непосредственно.
 Комбинирование решений подзадач в решение исходной задачи.
 Если подзадачи достаточно велики для рекурсивного решения, мы называем эту 
ситуацию рекурсивным случаем. Если подзадачи становятся достаточно малы для 
того, чтобы не прибегать к рекурсии, мы говорим, что рекурсия “достигает дна” 
и опускается до базового случая. Иногда, в дополнение к подзадачам, которые 
представляют собой меньшие экземпляры той же задачи, приходится решать под
 задачи, несколько отличающиеся от исходной задачи. Мы рассматриваем решение 
таких подзадач как часть шага комбинирования.
 В этой главе мы рассмотрим новые алгоритмы, основанные на подходе “раз
 деляй и властвуй” Первый из них решает задачу максимального подмассива: на 
вход алгоритма поступает массив чисел, и необходимо найти непрерывный под
 массив, значения которого дают наибольшую сумму. Затем мы рассмотрим два 
алгоритма “разделяй и властвуй”, предназначенные для умножения матриц раз
 мером п х п. Один из них имеет время работы 0(п3), что не лучше, чем время 
работы обычного алгоритма непосредственного умножения, но второй, алгоритм 
Штрассена, выполняет умножение за время 0(n2 81), так что он асимптотически 
лучше, чем алгоритм непосредственного умножения.
 Рекуррентные соотношения
 Рука об руку с парадигмой “разделяй и властвуй” идут рекуррентные соот
 ношения, поскольку они предоставляют естественный способ описания времени 
работы соответствующих алгоритмов. Рекуррентное соотношение представляет 
собой уравнение или неравенство, которое описывает функцию через ее значения
Глава 4. Разделяй и властвуй
 91
 для меньших аргументов. Например, в разделе 2.3.2 мы описывали время Т{п) 
работы процедуры M erge-Sort в наихудшем случае с помощью рекуррентного 
соотношения
 если п = 1 , 
если п > 1 ,
 (4.1)
 решением которого является функция Т{п) = 0(nlgn).
 Рекуррентные соотношения могут принимать множество разных форм. Напри
 мер, рекурсивный алгоритм может делить задачу на подзадачи разного размера, 
например, разбивая на части, представляющие собой 2/3 и 1/3 исходной зада
 чи. Если при этом разделение и комбинирование выполняются за линейное вре
 мя, время работы такого алгоритма определяется рекуррентным соотношением 
Т(п) = Г(2п/3) + Т(п/3) + в(п).
 Подзадачи не обязаны быть ограниченными некоторыми постоянными долями 
размера исходной задачи. Например, рекурсивная версия линейного поиска (см. 
упр. 2.1.3) создает только одну подзадачу, содержащую только на один элемент 
меньше, чем исходная задача. Каждый рекурсивный вызов требует константного 
времени плюс время на рекурсивный вызов, в свою очередь осуществляемый им, 
что приводит к рекуррентному соотношению Т(п) = Т(п — 1) + 0(1).
 В этой главе предлагаются три метода решения рекуррентных соотношений,
 т.е. получения асимптотических границ решения “0 ” или “О” •
 • В методе подстановки мы делаем предположение о границе, а затем исполь
 зуем метод математической индукции для доказательства его корректности.
 • В методе деревьев рекурсии рекуррентное соотношение преобразуется в де
 рево, узлы которого представляют стоимости на разных уровнях рекурсии. 
Затем для решения рекуррентного соотношения используются методы оценки 
сумм.
 • В основном методе (master method) граничные оценки рекуррентных соотно
 шений представляются в виде
 Т(п) = аТ(п/Ъ) + /(п)
 (4.2)
 где а > 1, b > 1, а /(п) — заданная функция. Такие рекуррентные соотноше
 ния возникают очень часто. Рекуррентное соотношение вида (4.2) описывает 
алгоритм “разделяй и властвуй”, который создает а подзадач, каждая из кото
 рых имеет размер, равный 1/6 размера исходной задачи, и шаги разделения 
и комбинирования которого в сумме занимают время /(п).
 Для использования основного метода вам нужно запомнить три разных слу
 чая, после чего вы сможете легко определять асимптотические границы для 
многих простых рекуррентных соотношений. Мы будем использовать данный 
метод для определения времени работы алгоритмов “разделяй и властвуй” для 
поиска максимального подмассива и для умножения матриц, а также для мно
 жества алгоритмов, основанных на этой парадигме, в других местах книги.
92
 Часть I. Основы
 Иногда нам будут встречаться рекуррентные соотношения, которые представ
 ляют собой неравенства, такие как Т(п) < 2Т(п/2) + 0(п). Поскольку такие 
рекуррентные соотношения указывают только верхнюю границу Т(п), их реше
 ния мы будем записывать с применением О-обозначений (а не ©-обозначений). 
Аналогично, если это неравенство обратить (так, что оно примет вид Т(п) > 
2Т(п/2)+0(п)), то, поскольку такое рекуррентное соотношение дает только ниж
 нюю границу Т(п), в его решении будут использоваться П-обозначения.
 Технические детали рекуррентных соотношений
 На практике при составлении и решении рекуррентных соотношений мы пре
 небрегаем рядом технических деталей. Например, если мы вызываем процедуру 
Merge-Sort для нечетного количества элементов п, то в результате мы получа
 ем подзадачи размером [п/2J и \п/2]. Ни один из этих размеров в действитель
 ности не равен п /2, поскольку п /2 не является целым числом при нечетном п. 
Технически рекуррентное соотношение, описывающее время работы процедуры 
Merge-Sort в наихудшем случае, в действительности равно
 если п = 1 , 
если п > 1 .
 (4.3)
 Граничные условия — еще один пример технических особенностей, которые 
обычно игнорируются. Поскольку время работы алгоритма с входными данными 
фиксированного размера выражается константой, то в рекуррентных соотноше
 ниях, описывающих время работы алгоритмов, для достаточно малых п обычно 
справедливо соотношение Т(п) = 0(1). Поэтому для удобства граничные усло
 вия рекуррентных соотношений, как правило, опускаются и предполагается, что 
для малых п время работы алгоритма Т(п) является константой. Например, ре
 куррентное соотношение (4.1) обычно записывается как
 Т{п) = 2Г(п/2) + 0(п)
 (4.4)
 без явного указания значений Т(п) для малых п. Причина состоит в том, что 
хотя изменение значения Т( 1) и приводит к изменению решения рекуррентно
 го соотношения, это решение обычно изменяется не более чем на постоянный 
множитель, так что порядок роста остается неизменным.
 Формулируя и решая рекуррентные соотношения, мы часто опускаем полы, 
потолки и граничные условия. Мы продвигаемся вперед без этих деталей, а затем 
выясняем, важны они или нет. Обычно они не играют никакой роли, но мы долж
 ны знать, когда это не так. В подобных ситуациях помогают опыт, а также некото
 рые теоремы. В этих теоремах формулируются условия, когда упомянутые детали 
не влияют на асимптотическое поведение рекуррентных соотношений, возника
 ющих в ходе анализа алгоритмов (см. теорему 4.1). Однако в данной главе мы 
не будем опускать технические детали, так как это позволит продемонстрировать 
некоторые тонкости, присущие методам решения рекуррентных соотношений.
Глава 4. Разделяй и властвуй
 4.1. Задача поиска максимального подмассива
 93
 Предположим, что у вас появилась возможность вложить деньги в корпорацию 
по производству неустойчивых химических соединений Volatile Chemical Corpo
 ration. Подобно производимой продукции цена акций Volatile Chemical Corpora
 tion тоже очень неустойчива. Вы можете купить только один комплект акций 
и продать его в какой-то другой день, осуществляя покупки и продажи после за
 крытия торгов. Ваши неудобства компенсируются тем, что вы владеете информа
 цией о будущих ценах на акции. Ваша цель — получить максимальную прибыль. 
На рис. 4.1 показана цена акций за 17-дневный период. Вы можете покупать ак
 ции в любой день, начиная с нулевого дня, когда цена равна $100. Конечно, вы 
захотите купить подешевле, а продать подороже, но — увы! — так может и не по
 лучиться. На рис. 4.1 наименьшая цена достигается после седьмого дня, т.е. после 
того, как будет достигнута максимальная цена после первого дня.
 День
 Цена
 Изменение
 7 
8 
9 
10 11 12 13 14 15 16
 100 113 110 85 105 102 86 63 81 101 94 106 101 79 94 90 97
 13 - 3 -25 20 -3 -16 -23 18 20 -7 12 -5 -22 15 -4 7
 Рис. 4.1. Информация о цене акций Volatile Chemical Corporation после закрытия торгов за 
17-дневный период. На горизонтальной оси диаграммы указан день торгов, на вертикальной — 
цена. В нижней строке таблицы указано изменение цены по сравнению с предыдущим днем.
 Можно решить, что прибыль всегда можно максимизировать, либо покупая 
по наименьшей цене, либо продавая по наибольшей. Например, на рис. 4.1 мож
 но было бы максимизировать прибыль, выполняя покупку по наименьшей цене, 
которая достигается после торгов седьмого дня. Если бы такая стратегия всегда 
работала, то было бы просто определить, как максимизировать прибыль: най
 ти наибольшую и наименьшую цены, а затем слева от наивысшей цены выпол
 нить поиск наинизшей, а справа от наинизшей цены выполнить поиск наивыс
 шей и взять пару с максимальным отличием. Но на рис. 4.2 показан контрпример, 
демонстрирующий, что иногда максимальная прибыль достигается и не при по
 купке по наинизшей цене, и не при продаже по наивысшей.
 Перебор
 Можно легко разработать решение этой задачи, основанное на грубой силе: 
просто испытать все возможные пары дат покупки и продажи, в которых дата
94
 Часть I. Основы
 День
 Цена
 Изменение
 0
 1
 2
 3
 10 11 7 10 6
 1-4 3-4
 4
 Рис. 4.2. Пример, демонстрирующий, что максимальная прибыль не всегда начинается с мини
 мальной цены и не всегда заканчивается максимальной. Здесь вновь на горизонтальной оси диа
 граммы указан день торгов, на вертикальной — цена. Максимальная прибыль в $3 достигается при 
покупке после торгов во второй день и продаже после торгов в третий день. Но цена $7 во второй 
день не является наинизшей, как и цена $10 в третий день не является наивысшей.
 покупки предшествует дате продажи. Период из п дней имеет Q) таких пар дат. 
Поскольку (”) представляет собой 0(п2), и лучшее, на что мы можем надеять
 ся, — это вычисление каждой пары за константное время, такой подход будет 
давать время работы П(п2). Нельзя ли достичь чего-то лучшего?
 Преобразование
 Чтобы получить алгоритм со временем работы о(п2), взглянем на входные дан
 ные под несколько иным углом. Мы хотим найти последовательность дней, для 
которых итоговая разница между первым и последним днем максимальна. Вместо 
того чтобы работать с ежедневными ценами, давайте рассмотрим ежедневное из
 менение цены, где изменение в день г представляет собой разность между ценой 
после торгов в день г и ценой в день г — 1. На рис. 4.1 эти изменения показа
 ны в нижней строке. Если рассматривать эту строку как массив А, показанный 
на рис. 4.3, то задача заключается в поиске непустого непрерывного подмасси
 ва А, значения которого имеют наибольшую сумму. Назовем такой непрерывный 
подмассив максимальным подмассивом. Например, в массиве на рис. 4.3 макси
 мальным подмассивом массива А[ 1.. 16] является Л[8.. 11] с суммой 43. Таким 
образом, лучше всего покупать акции непосредственно перед восьмым днем (т.е. 
после торгов седьмого дня), а продавать после торгов одиннадцатого дня, получая 
при этом прибыль в $43 с акции.
 На первый взгляд, такое преобразованием ничем не может нам помочь. Нам 
все равно нужно проверить (п“ *) = 0(п2) подмассивов в случае периода из п 
дней. В упр. 4.1.2 требуется показать, что хотя вычисление стоимости одного 
подмассива может потребовать времени, пропорционального длине этого подмас
1
 2
 3
 4
 5
 7
 8
 9
 10 и 12 13 14 15 16
 6
 13-3-25 20-3-16-23 18 20-7 12-5-22 15-4 7
 Максимальный подмассив
 Рис. 4.3. Изменения цен как входные данные для задачи поиска максимального подмассива. Здесь 
подмассив Л [8.. 11] с суммой 43 имеет наибольшую сумму среди всех непрерывных подмассивов 
массива А.
Глава 4. Разделяй и властвуй
 95
 сива, при вычислении всех ©(гг2) сумм подмассивов можно организовать вычис
 ления таким образом, что каждый подмассив с учетом уже вычисленных ранее 
сумм подмассивов будет вычисляться за время 0(1). Таким образом, решение 
методом грубой силы потребует 0(п2) времени.
 Так что давайте поищем более эффективное решение задачи максимального 
подмассива. Говоря о максимальном подмассиве в единственном числе, следу
 ет отдавать себе отчет в том, что таких подмассивов, сумма элементов которых 
достигает максимального значения, может быть несколько.
 Задача поиска максимального подмассива интересна только в том случае, ко
 гда массив содержит некоторое количество отрицательных значений. Если же все 
элементы массива положительны, то задача поиска максимального подмассива 
становится тривиальной, так как в этом случае наибольшую сумму имеет весь 
массив целиком.
 Решение “разделяй и властвуй”
 Давайте подумаем о том, как можно решить задачу поиска максимального 
подмассива с использованием метода “разделяй и властвуй” Предположим, что 
мы хотим найти максимальный подмассив подмассива A[low.. high]. Техноло
 гия “разделяй и властвуй” предполагает, что мы делим массив на две части, по 
возможности одинакового размера, т.е. мы находим среднюю точку подмасси
 ва, скажем, mid, и рассматриваем подмассивы A[low .. mid] и A[mid + 1.. high]. 
Как показано на рис.4.4,(а), любой непрерывный подмассив A[i..j] масси
 ва A[low.. high] должен находиться только в одном из следующих положений: •
 • полностью располагаться в подмассиве A[low.. mid], так что low < i < j < 
mid;
 • полностью располагаться в подмассиве A[mid + 1.. high], так что mid < i < 
3 < high;
 • пересекать среднюю точку, так что low < i < mid < j < high.
 Следовательно, максимальный подмассив массива A[low.. high] должен рас
 полагаться ровно одним из этих способов. Фактически максимальный под
 массив массива A[low.. high] должен иметь наибольшую сумму среди всех
 Пересекает среднюю точку 
low
 mid
 Г
 mid+1
 Полностью в A[low.. mid] Полностью в A[mid+l..high]
 (а)
 A[mid+l..j]
 high 
low
 i 
mid.--------------" 
4----------^----------■'mid+l 
A[i.. mid]
 (6)
 ^ 
j
 high
 Рис. 4.4. (а) Возможные размещения подмассивов массива A[low.. high]: полностью
 в A[low.. mid], полностью в A[mid + 1.. high] или с пересечением средней точки mid. (б) Лю
 бой подмассив массива A[low.. high], пересекающий среднюю точку, содержит два подмассива 
A[i.. mid] и A[mid + 1. .j], где low <i< mid и mid < j < high.
96
 Часть I. Основы
 подмассивов, полностью находящихся в A[low .. mid], полностью находящихся 
в A[mid +1.. high] или пересекающих среднюю точку. Максимальные подмасси
 вы A[low .. mid] и A[mid + 1.. high] можно найти рекурсивно, поскольку эти две 
подзадачи представляют собой экземпляры задачи поиска максимального подмас
 сива меньшего размера. Таким образом, все, что осталось сделать, — это найти 
максимальный подмассив, пересекающий среднюю точку, и выбрать из этих трех 
подмассивов тот, у которого будет наибольшая сумма.
 Можно легко найти максимальный подмассив, пересекающий среднюю точ
 ку, за время, линейно зависящее от размера подмассива A[low.. high]. Эта за
 дача не является меньшим экземпляром нашей исходной задачи, поскольку при 
этом добавлено ограничение, что подмассив должен пересекать среднюю точку. 
Как показано на рис. 4.4, (б), любой подмассив, пересекающий среднюю точку, 
состоит из двух подмассивов A[i.. mid] и A[mid + 1.. j], где low < i < mid 
и mid < j < high. Следовательно, нужно просто найти максимальные под
 массивы вида A[i..mid] и A[mid + l..j], а затем объединить их. Процедура 
Find-Max-Crossing-Subarray получает в качестве входных данных массив А 
и индексы low, mid и high, и возвращает кортеж, содержащий индексы, опреде
 ляющие пересекающий среднюю точку максимальный подмассив, а также сумму 
значений элементов этого максимального подмассива.
 Find-Max-Crossing-Subarray {A, low, mid, high)
 1 left-sum = —ос
 2 sum = 0
 3 for i = mid downto low
 4 
sum = sum + A[i]
 5 
6 
7 
if sum > left-sum
 left-sum = sum
 max-left = i
 8 right-sum = — oc
 9 sum = 0
 10 for j = mid + 1 to high
 11 
sum = sum + A[j]
 12 
13 
14 
if sum > right-sum
 right-sum = sum
 max-right = j
 15 return (max-left, max-right, left-sum + right-sum)
 Эта процедура работает следующим образом. Строки 1-7 находят максималь
 ный подмассив в левой половине, A[low .. mid]. Поскольку этот подмассив дол
 жен содержать A[mid], цикл for в строках 3-7 начинает работу со значения индек
 са г, равного mid, и идет вниз до значения low, так что каждый рассматриваемый 
подмассив имеет вид А [г., mid]. В строках 1 и 2 выполняется инициализация 
переменной left-sum, в которой хранится наибольшая найденная к этому момен
 ту сумма, и sum, хранящей сумму элементов в A[i.. mid]. Когда в строке 5 мы 
находим подмассив A[i.. mid] с суммой значений, большей, чем left-sum, мы об
Глава 4. Разделяй и властвуй
 97
 новляем значение переменной left-sum, делая его равным этой сумме в строке 6, 
а в строке 7 мы обновляем переменную max-left, записывая в нее индекс г. Стро
 ки 8-14 аналогично работают в правой половине, A[mid+1.. high]. Здесь цикл for 
в строках 10-14 начинает работу со значения индекса j, равного mid + 1, и идет 
вверх до значения high, так что каждый рассматриваемый подмассив имеет вид 
A[mid+1. .j]. Наконец строка 15 возвращает индексы max-left и max-right, кото
 рые определяют максимальный подмассив, пересекающий среднюю точку, вместе 
с суммой left-sum + right-sum значений в подмассиве A[max-left.. max-right].
 Если подмассив A [low .. high] содержит п элементов (так что п = high — low + 
1), мы утверждаем, что вызов Find-Max-Crossing-Subarray (A, low, mid, 
high) выполняется за время 0(п). Поскольку каждая итерация каждого из двух 
циклов for требует 0(1) времени, нужно просто подсчитать, сколько всего ите
 раций выполняется. Цикл for в строках 3-7 выполняет mid — low + 1 итераций, 
а цикл for в строках 10-14 — high — mid итераций, так что общее количество 
итераций равно
 (mid — low + 1) + (high — mid) = high — low + 1
 = n .
 Имея процедуру Find-Max-Crossing-Subarray с линейным временем ра
 боты, можно записать псевдокод алгоритма “разделяй и властвуй”, решающего 
задачу поиска максимального подмассива.
 Find-Maximum-Subarray (Л, low, high)
 1 if high == low
 2 
return (low, high, A[low]) // Базовый случай:
 / / только один элемент
 3 else mid = [(low + high)/2J
 4 
(left-low, left-high, left-sum) =
 Find-Maximum-Subarray (A, low, mid)
 5 
6 
7 
8 
9 
10 
11 
(right-low, right-high, right-sum) =
 Find-Maximum-Subarray (A, mid + 1, high)
 (cross-low, cross-high, cross-sum) =
 Find-Max-Crossing-Subarray (A, low, mid, high)
 if left-sum > right-sum и left-sum > cross-sum
 return (left-low, left-high, left-sum)
 elseif right-sum > left-sum и right-sum > cross-sum
 return (right-low, right-high, right-sum)
 else return (cross-low, cross-high, cross-sum)
 Начальный вызов Find-Maximum-Subarray (A, 1, A .length) находит макси
 мальный подмассив массива А[1.. п].
 Подобно процедуре Find-Max-Crossing-Subarray, рекурсивная процеду
 ра Find-Maximum-Subarray возвращает кортеж, состоящий из индексов, опре
 деляющих максимальный подмассив, и суммы значений этого максимального 
подмассива. В строке 1 выполняется проверка базового случая — когда подмассив
 4 Зак. 3726
98
 Часть I. Основы
 состоит только из одного элемента. Подмассив с единственным элементом имеет 
только один подмассив — себя, так что строка 2 возвращает кортеж с началь
 ным и конечным индексами для единственного элемента вместе с его значением. 
Строки 3-11 обрабатывают рекурсивный случай. Строка 3 выполняет разделение, 
вычисляя индекс mid средней точки. Будем называть подмассив A[low .. mid\ ле
 вым подмассивом, a A[mid + 1.. high] — правым подмассивом. Поскольку мы 
знаем, что подмассив A[low.. high] содержит как минимум два элемента, и ле
 вый, и правый подмассивы содержат хотя бы по одному элементу. Строки 4 и 5 
“властвуют”, рекурсивно находя максимальные подмассивы в левом и правом под
 массивах соответственно. Строки 6-11 образуют часть комбинирования. В стро
 ке 6 выполняется поиск максимального подмассива, который пересекает среднюю 
точку. (Вспомним, что, поскольку в строке 6 решается подзадача, не являющаяся 
экземпляром меньшего размера исходной задачи, мы рассматриваем ее как вхо
 дящую в часть комбинирования.) В строке 7 выполняется проверка, содержится 
ли максимальный подмассив в левом подмассиве, и если содержится, то строка 8 
возвращает его. В противном случае строка 9 проверяет наличие максимального 
подмассива в правом подмассиве, а строка 10 возвращает его. Если же ни ле
 вый, ни правый подмассивы не содержат подмассива с максимальной суммой, то 
последний должен пересекать среднюю точку, и он возвращается в строке 11.
 Анализ алгоритма “разделяй и властвуй”
 Теперь запишем рекуррентное соотношение, которое описывает время рабо
 ты рекурсивной процедуры Find-Maximum-Subarray. Как и в ходе анализа 
сортировки слиянием в разделе 2.3.2, сделаем упрощающее допущение о том, 
что размер исходной задачи представляет собой степень 2, так что размеры всех 
подзадач — целые числа. Обозначим время работы Find-Maximum-Sub array 
над подмассивом из п элементов как Т(п). Для начала строка 1 выполняется за 
константное время. Базовый случай п = 1 прост: строка 2 выполняется за кон
 стантное время, так что
 П 1) = 0(1) • 
(4.5)
 При п > 1 осуществляется рекурсивный случай. Строки 1 и 3 выполняются 
за константное время. Каждая из подзадач, решаемых в строках 4 и 5, работа
 ет с подмассивами, состоящими из п/2 элементов (наше предположение о том, 
что размер исходной задачи представляет собой степень 2, гарантирует, что п/2 
является целым), так что мы тратим время Т(п/2) на решение каждой из них. 
Поскольку мы должны решить две подзадачи (для левого и правого подмасси
 вов), вклад в общее время работы от строк 4 и 5 составляет 2Т(п/2). Как мы 
уже видели, вызов Find-Max-Crossing-Subarray в строке 6 требует време
 ни 0(п). Строки 7-11 выполняются за время 0(1). Итак, для рекурсивного случая 
мы имеем
 Т(п) = 0(1) + 2Т(п/2) + 0(п) + 0(1) 
= 2Т(п/2) + 0(п) .
 (4.6)
Глава 4. Разделяй и властвуй
 99
 Объединив уравнения (4.5) и (4.6), мы получаем рекуррентное соотношение 
для времени работы Т(п) процедуры Find-Maximum-Sub array:
 Т(п) = 0(1) , 
если n = 1 ,
 2Т(п/2) + 0(п) , если п > 1 .
 (4.7)
 Это рекуррентное соотношение такое же, как и рекуррентное соотношение (4.1) 
для сортировки слиянием. Как мы узнаем, познакомившись в разделе 4.5 с основ
 ным методом, это рекуррентное соотношение имеет решение Т(п) = 0(nlgn). 
Вы можете также обратиться к дереву рекурсии на рис. 2.5, чтобы понять, поче
 му решение указанного рекуррентного соотношения должно иметь вид Т(тг) = 
e(nign).
 Таким образом, мы видим, что метод “разделяй и властвуй” дает алгоритм, 
который оказывается асимптотически быстрее метода грубой силы. Сортировка 
слиянием, а теперь еще и поиск максимального подмассива демонстрируют нам, 
насколько мощным может оказаться метод “разделяй и властвуй” Иногда он да
 ет асимптотически самые быстрые алгоритмы для решения задачи, но иногда 
можно найти еще лучшие алгоритмы. Как показано в упр. 4.1.5, задача поиска 
максимального подмассива решается за линейное время и не использует метод 
“разделяй и властвуй”
 Упражнения
 4.1.1
 Что возвращает процедура Find-Maximum-Subarray, когда все элементы А 
отрицательны?
 4.1.2
 Напишите псевдокод для решения задачи поиска максимального подмассива ме
 тодом грубой силы. Ваша процедура должна выполняться за время 0(п2).
 4.1.3
 Реализуйте и метод грубой силы, и рекурсивный алгоритм на своем компьютере. 
Каким оказывается размер задачи точки пересечения по, в которой рекурсивный 
алгоритм превосходит алгоритм грубой силы? Далее измените базовый случай 
рекуррентного алгоритма, применяя алгоритм грубой силы при размере задачи, 
не превосходящем по. Меняет ли это точку пересечения?
 4.1.4
 Предположим, что мы меняем определение задачи поиска максимального под
 массива, позволяя конечному результату быть пустым массивом и полагая, что 
сумма значений пустого массива равна нулю. Как бы вы изменили любой алго
 ритм, не допускающий решения в виде пустого массива, чтобы такой результат 
в виде пустого подмассива стал возможным?
100
 4.1.5
 Часть I. Основы
 Воспользуйтесь приведенными далее идеями для разработки нерекурсивного ал
 горитма поиска максимального подмассива за линейное время. Начните с левого 
конца массива и двигайтесь вправо, отслеживая найденный к данному моменту 
максимальный подмассив. Зная максимальный подмассив массива A[l..j], рас
 пространите ответ на поиск максимального подмассива, заканчивающегося ин
 дексом j -1-1, воспользовавшись следующим наблюдением: максимальный под
 массив массива А[ 1. .j + 1] представляет собой либо максимальный подмассив 
массива А[\ .. j], либо подмассив A[i..j + 1] для некоторого 1 < г < j + 1. Опре
 делите максимальный подмассив вида A[i..j + 1] за константное время, зная 
максимальный подмассив, заканчивающийся индексом j.
 4.2. 
Алгоритм Штрассена для умножения матриц
 Если вы уже встречались с матрицами, то наверняка знаете, как их перемно
 жать. (В противном случае прочтите раздел Г.1 в приложении Г.) Если А = (а^) 
и В = (bij) представляют собой квадратные матрицы размером п х п, то элемен
 ты Cij их произведения С = А - В определяются для г, j = 1,2,..., п следующим 
образом:
 Т1
 Cij — ^ ^ Q>ik ' bkj ■ 
(4-8)
 к—1
 Нам нужно вычислить п2 элементов матрицы, каждый из которых представля
 ет собой сумму п значений. Приведенная далее процедура получает в качестве 
входных данных п х n-матрицы А и В и перемножает их, возвращая их п х п- 
произведение С. Мы считаем, что каждая матрица имеет атрибут rows, указыва
 ющий количество строк матрицы.
 Square-Matrix-Multiply(A, В)
 1 п = A. rows
 2 Пусть С — новая матрица размером п х п
 3 for г = 1 to п
 4 
for j = 1 to п
 5 
6 
7 
Cij = О
 for к = 1 to п
 Cij = с^ + fljfc ■ bkj
 8 return C
 Процедура Square-Matrix-Multiply работает следующим образом. Цикл 
for в строках 3-7 вычисляет элементы каждой строки г, а в пределах данной 
строки г цикл for в строках 4-7 вычисляет каждый из элементов Cij для каждого 
столбца j. Строка 5 инициализирует 
значением 0 в начале вычисления суммы
Глава 4. Разделяй и властвуй
 101
 из уравнения (4.8), и каждая итерация цикла for в строках 6 и 7 добавляет еще 
один член из (4.8).
 Из-за того, что каждый из циклов в тройной вложенности циклов for выполня
 ет ровно п итераций, а каждое выполнение строки 7 занимает константное время, 
вся процедура Square-Matrix-Multiply выполняется за время 0(п3).
 На первый взгляд, можно решить, что любой алгоритм умножения матриц 
должен выполняться за время П(п3), поскольку естественное определение умно
 жения матриц требует именно этого количества умножений. Однако это не так: 
имеется способ умножения матриц за время о(п3). В этом разделе вы позна
 комитесь с замечательным рекурсивным алгоритмом Штрассена для умножения 
матриц размером п х п. Его время работы составляет 0(nlg7), как будет показа
 но в разделе 4.5. Поскольку lg7 лежит между 2.80 и 2.81, алгоритм Штрассена 
выполняется за время 0(п2 81), что асимптотически лучше простой процедуры 
Square-Matrix-Multiply.
 Простой алгоритм “разделяй и властвуй”
 Для простоты при использовании алгоритма “разделяй и властвуй” для вы
 числения произведения матриц С = А ■ В будем считать, что в каждой из этих 
матриц размером п х п значение п представляет собой точную степень 2. Мы 
делаем это предположение потому, что на каждом шаге разделения мы будем раз
 бивать матрицы размером п х п на четыре матрицы размером п/2 х п/2, и то, 
что п представляет собой точную степень 2, гарантирует, что пока п > 2, размер
 ность п/2 является целым числом.
 Допустим, что мы разделяем каждую из матриц А, В и С на четыре матрицы 
размером п/2 х п/2
 \ 
^21 Л.22 ) 
А =( а ' а 2 )■ в =( В 1 в12 )■ с =( си с12
 \ &21 £>22 ) 
так что уравнение С = А - В можно переписать как
 / 
\ 
С\\ С\2 \ = ( 
С21 С22 ) -А 12 \ 
V ^21 -422 / 
Уравнение (4.10) соответствует четырем уравнениям
 Сц = Ац • Вц + А\2 ■ В21 ,
 С\2 = Ац • В\2 + А12 • В22 ,
 С21 = -А21 • Вц + А22 ■ В21 ,
 С22 = -4-21 • в 12 + А22 • В22 ■
 \ ^21 ^22
 В\2 \
 \ 
В21 В22 )
 , 
(4.9)
 (4.10)
 (4.11)
 (4.12)
 (4.13)
 (4.14)
 В каждом из этих четырех уравнений присутствуют два умножения матриц раз
 мером п/2 х п/2 и сложение полученных произведений размером п/2 х п/2. 
Эти уравнения можно использовать для создания прямолинейного рекурсивного 
алгоритма “разделяй и властвуй”
102
 Square-Matrix-M ultiply-Recursive (А, В)
 1 п = A. rows
 2 Пусть С — новая матрица размером п х п
 3 if п == 1
 4 
сц = ап ■ Ьц
 5 else разбиение А, В и С как в (4.9)
 6 
Сц = Square-Matrix-Multiply-Recursive(A11,5 11)-I- Square-Matrix-Multiply-Recursive(A12, В2i)
 7 
С12 = Square-Matrix-Multiply-Recursive (Ац , B\2)
 Часть I. Основы-I- SQUARE-MATRIX-MULTIPLY-RECURSIVE(Ai2, В22)
 8 
9 
C2i = Square-M atrix-Multiply-Recursive (A2i ,Вц)-I- SQUARE-MATRIX-MULTIPLY-RECURSIVE(A22, в 2i)
 C2 2 = Square-Matrix-Multiply-Recursive (A2i , B\2)-I- Square-Matrix-Multiply-Recursive(A22, B22)
 10 return C
 Этот псевдокод скрывает одну важную тонкость реализации. Как мы разбива
 ем матрицы в строке 5? Если мы создаем 12 новых матриц размером п/ 2 х п/2, то 
мы платим за это временем 0(п2), затраченным на копирование элементов мат
 риц. В действительности матрицы можно разбивать без копирования. Весь фокус 
заключается в вычислениях индексов. Мы определяем подматрицу как диапазон 
индексов строк и диапазон индексов столбцов исходной матрицы. В результа
 те мы представляем подматрицу немного не так, как исходную матрицу, и эта 
тонкость не указана явно. Преимущество заключается в том, что поскольку мы 
можем указать подматрицу с помощью индексов, выполнение строки 5 требу
 ет только времени 0(1) (хотя, как мы увидим в дальнейшем, асимптотическое 
поведение общего времени работы не зависит от того, будем ли мы копировать 
матрицы или разбивать их без привлечения дополнительной памяти).
 Теперь выведем рекуррентное соотношение, описывающее время работы про
 цедуры Square-M atrix-M ultiply-Recursive. Пусть Т(п) — время, необхо
 димое для умножения двух матриц размером п х п с использованием этой про
 цедуры. В базовом случае, когда п = 1, мы выполняем только одно скалярное 
умножение в строке 4, так что
 Г(1) = 0(1). 
(4.15)
 При п > 1 осуществляется рекуррентный случай. Как говорилось, разбие
 ние матриц в строке 5 требует при использовании вычисления индексов време
 ни 0(1). В строках 6-9 мы восемь раз рекурсивно вызываем процедуру SQUARE- 
Matrix-Multiply-Recursive. Поскольку каждый рекурсивный вызов перемно
 жает две матрицы размером п/ 2 х п/2, его вклад в общее время работы составля
 ет Т(п/2), а все восемь вызовов выполняются за время 8Т(п/2). Следует также 
учесть четыре сложения матриц в строках 6-9. Каждая из этих матриц содер
 жит п2/4 элементов, так что каждое из сложений матриц требует времени 0(п2). 
Поскольку количество матричных сложений является константой, общее время
Глава 4. Разделяй и властвуй
 103
 сложения в строках 6-9 равно 0(п2). (Мы вновь прибегаем к вычислению индек
 сов для размещения результатов сложения матриц в корректных позициях матри
 цы С с накладными расходами 0(1) для каждого элемента.) Общее время вычис
 ления в рекуррентном случае, таким образом, равно сумме времени разделения, 
времен всех рекуррентных вызовов и времени сложения матриц, получающихся 
после рекуррентных вызовов:
 Т(п) = 0(1) + 8Т(п/2) + 0(п2) 
= 8Т(п/2) + 0(п2) .
 (4.16)
 Заметим, что если мы реализуем разбиение с применением копирования, стои
 мость которого составляет 0(п2), рекуррентное соотношение не изменится, а сле
 довательно, общее время работы просто увеличится на постоянный множитель.
 Объединяя уравнения (4.15) и (4.16), мы получим рекуррентное соотношение 
для времени работы процедуры Square-Matrix-Multiply-Recursive:
 если п = 1 , 
если п > 1 .
 (4.17)
 Как мы увидим из основного метода из раздела 4.5, рекуррентное соотноше
 ние (4.17) имеет решение Т(п) = 0(п3). Таким образом, этот простой подход 
“разделяй и властвуй” оказывается ничуть не быстрее прямолинейной процедуры 
Square-Matrix-Multiply.
 Перед тем как продолжить изучение алгоритма Штрассена, давайте рассмот
 рим происхождение компонентов уравнения (4.16). Разбиение каждой матрицы 
п х п с помощью вычисления индексов требует времени 0(1), но у нас разби
 ваются две матрицы. Хотя можно сказать, что разбиение двух матриц требует 
времени 0(2), константа 2 поглощается ©-обозначением. Сложение двух матриц 
со, скажем, к элементами занимает время Q(k). Поскольку суммируемые нашим 
алгоритмом матрицы имеют по п2/4 элементов, можно утверждать, что суммиро
 вание каждой пары выполняется за время 0(п2/4). Однако ©-обозначения вновь 
поглощают постоянный множитель 1/4, и мы говорим, что сложение двух матриц 
размером п/2 х п/2 выполняется за время 0(п2). У нас есть четыре таких сложе
 ния, и вновь вместо того, чтобы записать время их выполнения как 0(4п2), мы 
говорим, что они выполняются за время 0(п2). (Конечно, вы можете заметить, 
что об этих четырех сложениях можно сказать, что они выполняются за время 
0(4п2/4) и что 4п2/4 = п2, но главное в том, что ©-обозначение потощает по
 стоянные множители, какими бы они ни были.) Таким образом, в конечном итоге 
у нас имеются два члена 0(п2), которые мы можем объединить в один.
 Однако, когда мы учитываем восемь рекурсивных вызовов, мы не можем про
 сто поглотить постоянный множитель 8. Другими словами, мы должны говорить, 
что вместе они требуют времени 8Т(п/2), а не просто Т(п/2). Вы можете про
 чувствовать эту разницу, взглянув на дерево рекурсии на рис. 2.5 для рекуррент
 ного соотношения (2.1) (которое идентично рекуррентному соотношению (4.7)), 
в котором рекурсивный случай имеет вид Т(п) = 2T(n/2) -I- 0(п). Множитель 2
104
 Часть I. Основы
 определяет, сколько дочерних узлов имеет каждый узел дерева, что, в свою оче
 редь, определяет количество членов, вносящих вклад в общую сумму на каждом 
уровне дерева. Если бы мы проигнорировали множитель 8 в уравнении (4.16) 
или множитель 2 в рекуррентном соотношении (4.1), то дерево рекурсии было 
бы линейным, а не “кустистым”, и каждый уровень добавлял бы в сумму только 
один член.
 Таким образом, следует помнить, что хотя асимптотическая запись поглоща
 ет константные мультипликативные множители, рекурсивная запись, такая как 
Т(п/2), этого не делает.
 Метод Штрассена
 Ключевым моментом метода Штрассена является некоторое уменьшение “ку
 стистости” дерева рекурсии, т.е. вместо восьми рекурсивных умножений матриц 
п/ 2 х п/2 он выполняет только семь. Цена устранения одного умножения мат
 риц — несколько дополнительных сложений матриц размером п/ 2 х п/2, но ко
 личество сложений при этом остается константой. Как и ранее, постоянное коли
 чество сложений матриц поглощается при записи рекуррентного уравнения для 
времени работы алгоритма 0-обозначением.
 Метод Штрассена не так очевиден. (Наверное, это наибольшее преуменьше
 ние, сделанное в данной книге.) Он состоит из четырех шагов.
 1. Разделить входные матрицы А и В и выходную матрицу С на подматрицы 
размером п/ 2 х п/2, как в (4.9). Этот шаг выполняется за время 0(1) с по
 мощью вычисления индексов, как и в процедуре Square-Matrix-Multiply- 
Recursive.
 2. Создать 10 матриц Si, S2, • • •, S10, каждая из которых имеет размер п/2 х п/2 
и представляет собой сумму или разность двух матриц, созданных на шаге 1. 
Все 10 матриц можно создать за время 0(п2).
 3. Используя подматрицы, созданные на шаге 1, и 10 матриц, созданных на 
шаге 2, рекурсивно вычислить семь матричных произведений Pi, Р2,..., Р7. 
Каждая матрица Pi имеет размер п/2 х п/2.
 4. Вычислить подматрицы Си, С12, С21, С22 результирующей матрицы С путем 
сложения и вычитания различных комбинаций матриц Pi. Все четыре подмат
 рицы можно вычислить за время 0(п2).
 Детально шаги 2-4 будут рассмотрены ниже, но у нас уже имеется достаточно 
информации для написания рекуррентного соотношения для времени работы ме
 тода Штрассена. Будем считать, что, когда размер матрицы п снижается до 1, мы 
выполняем простое скалярное умножение, как в строке 4 процедуры SQUARE- 
Matrix-Multiply-Recursive. При п > 1 шаги 1, 2 и 4 выполняются за общее 
время, равное 0(п2), а шаг 3 требует выполнения семи перемножений матриц 
размером п/ 2 х п/2. Следовательно, мы получаем следующее рекуррентное со
Глава 4. Разделяй и властвуй
 отношение для времени работы Т(п) алгоритма Штрассена:
 {0(1) , 
105
 если п = 1 ,
 7Т(п/2) -I- 0(п2) , если п > 1 .
 Мы обменяли одно матричное умножение на фиксированное количество сложе
 ний матриц. Когда мы научимся работать с рекуррентными соотношениями и по
 лучать их решения, мы увидим, что это ведет к меньшему асимптотическому 
времени работы. Согласно основному методу из раздела 4.5, рекуррентное соот
 ношение (4.18) имеет решение Т(п) = 0(nlg7).
 Теперь рассмотрим метод Штрассена более подробно. На шаге 2 мы создаем 
следующие 10 матриц.
 (4.18)
 S\ = В12 - В22
 52 = Ац + А12
 53 — А21 + А22
 5 4 = В21 — Вц 
S$ = Ац + А22 
Se = Вц + В22 
S 7 = А12 — A22 
Ss = B21 + B22 
Sq = Ац ~ A21
 Siq = Вц -f B12
 Поскольку мы должны 10 раз складывать или вычитать матрицы размером п/2 х 
п/2, этот шаг выполняется за время 0(п2).
 На шаге 3 мы рекурсивно перемножаем п/2 х n/2-матрицы семь раз и вычис
 ляем следующие семь матриц размером п/2 х п/2, каждая из которых представ
 ляет собой сумму или разность произведений подматриц А и В.
 P l == Ап • Si == AU В12- А ц B22
 Р2--= S2-В 22 == Ац B22 + А12 B22
 Рз--= s 3- В ц-= A21 Вц + А22 Вц
 Р а--= А22 ■S4 == A22 В 21- А22 Вц
 Ръ == S5-5 6 == Ац Вц + Ац В22 + А22 ■Вц + А22 В22
 Рб == S7 • 5 8 == A12 В 21 + А12 В22- А22 В 21 — А22 В22
 Pi~-= S q • ‘S'io == А ц Вц + А п Bi2 — А21 ■Вц — А21 В12
 Заметим, что необходимо выполнять только те умножения, которые приведены 
в среднем столбце представленных выше уравнений; правый столбец просто по
 казывает, чему равны получающиеся произведения в терминах исходных подмат
 риц, созданных на шаге 1.
106
 Часть I. Основы
 Шаг 4 суммирует и вычитает матрицы Р{, созданные на шаге 3, и строит че
 тыре подматрицы размером п/2 х п/2 окончательного произведения С. Мы на
 чинаем с
 Сц = Ръ + #4 — #2 + #6 •
 Раскрывая правую часть и расписывая каждую подматрицу Pi в отдельной строке, 
размещая при этом сокращающиеся члены один под другим, мы видим, чему 
в конечном итоге равна подматрица Сц
 Ац ' Вц 4- Ац ■ В22 + А22 • Вп 4- А22 ■ В22
 — А22‘Вц - Ац ■ В22 
+А22-В21
 — А12 • В22
 — А22 ■ В22 — А22 ■ В21 ■+■ А\2 • В22 ■+■ А\2 • B21 ’
 Ац ’Вц 
что соответствует уравнению (4.11).
 Аналогично мы присваиваем
 С и = Pi 4- Р2 ,
 так что С и равна
 А ц-В и - Ац-В22
 + Ац ■ В22 + А\2 • В22
 Ац • #12 
что соответствует уравнению (4.12). 
Установка
 С21
 делает С21 равной
 А21 • # п 4- А22 • Вц
 — А22 • #Ц -I" А22 • #21
 Л21 ' #11 
в соответствии с уравнением (4.13).
 Наконец мы присваиваем
 С22 = #5 4- #i - #з - #7 »
 так что С22 равна
 Ац ‘ #11+^11 ’ В22 + А22 • ВЦ+А22 ' #22
 — Л ц-#22 
— Ац Вц 
— ^22 '#11 
+Ai2-B2l
 4 " А12 • В22
 # з + #4
 +А22- #21
 + Ац-#12
 — ^ 21‘#11
 —Ац -#12+Л п ' #11 4 " -^21 ’ #12
 + А 21 • #12
 А 22 ■ #22
Глава 4. Разделяй и властвуй
 107
 в соответствии с уравнением (4.14). Всего на шаге 4 мы суммируем или вычитаем 
п/2 х n/2-матрицы восемь раз, что требует времени 0(п2).
 Таким образом, мы видим, что алгоритм Штрассена, состоящий из шагов 1-4, 
возвращает корректное матричное произведение и что рекуррентное соотноше
 ние (4.18) описывает время его работы. Поскольку, как мы узнаем из разде
 ла 4.5, это рекуррентное соотношение имеет решение T(n) = 0(nlg7), ме
 тод Штрассена асимптотически быстрее прямолинейной процедуры SQUARE- 
Matrix-Multiply. В заключительных замечаниях в конце этой главы рассмат
 риваются некоторые практические аспекты алгоритма Штрассена.
 Упражнения
 Примечание: хотя в упр. 4.2.3-4.2.5 описаны варианты алгоритма Штрассена, 
прежде чем приступить к их решению, следует прочесть раздел 4.5.
 4.2.1
 Воспользуйтесь алгоритмом Штрассена для вычисления произведения матриц
 Покажите, как вы это делаете.
 4.2.2
 Запишите псевдокод алгоритма Штрассена.
 4.2.3
 Как модифицировать алгоритм Штрассена для перемножения матриц размером 
п х п, где п не является точной степенью 2? Покажите, что получающийся в ре
 зультате алгоритм выполняется за время 0(nlg7).
 4.2.4
 Чему равно наибольшее к, такое, что если вы можете перемножить 3 х 3-матрицы 
с помощью к умножений (не предполагая коммутативности умножения), то вы 
можете перемножить матрицы размером п х п за время o(nlg7)? Каким должно 
быть время работы такого алгоритма?
 4.2.5
 В. Пан (V. Рал) открыл способ перемножения матриц размером 68 х 68 с ис
 пользованием только 132 464 умножений, способ перемножения матриц размером 
70 х 70 с использованием 143 640 умножений и способ перемножения матриц раз
 мером 72 х 72 с использованием 155424 умножений. Какой из методов дает нам 
лучшее асимптотическое время работы при его использовании в алгоритме “раз
 деляй и властвуй” для перемножения матриц? Проведите сравнение с алгоритмом 
Штрассена.
108
 Часть /. Основы
 4.2.6
 Насколько быстро вы сумеете умножить матрицу размером кпхп на матрицу раз
 мером п х кп, применяя алгоритм Штрассена в качестве подпрограммы? Ответьте 
на тот же вопрос для ситуации, когда мы меняем входные матрицы местами.
 4.2.7
 Покажите, как перемножить комплексные числа а + Ы и с + di, используя только 
три умножения действительных чисел. Алгоритм должен получать а, Ь, с и d 
в качестве входных данных и возвращать действительную (ас — bd) и мнимую 
(ad + be) части произведения по отдельности.
 4.3. 
Метод подстановки решения рекуррентных соотношений
 Теперь, когда вы познакомились с описанием времени работы алгоритмов “раз
 деляй и властвуй” рекуррентными соотношениями, рассмотрим способы решения 
таких рекуррентных соотношений. В этом разделе начнем рассмотрение с метода 
подстановки.
 Метод подстановки для решения рекуррентных соотношений состоит из 
двух шагов:
 1. делается предположение о виде решения;
 2. с помощью метода математической индукции определяются константы и до
 казывается, что решение правильное.
 Название “метод подстановки” связано с тем, что мы подставляем предполагае
 мое решение вместо функции при применении гипотезы индукции для меньших 
значений. Это мощный метод, но для его применения нужно суметь сделать пред
 положение о виде решения.
 Метод подстановки можно применять для определения либо верхней, либо 
нижней границы рекуррентного соотношения. В качестве примера определим 
верхнюю границу рекуррентного соотношения
 Т(п) = 2Т(|_п/2_|) + п , 
(4.19)
 подобного соотношениям (4.3) и (4.4). Мы предполагаем, что решение имеет вид 
Т(п) = O(nlgn). Наш метод заключается в доказательстве того, что при подхо
 дящем выборе константы с > 0 выполняется неравенство Т(п) < cnlgn. Начнем 
с того, что предположим справедливость этого неравенства для всех положитель
 ных ш < п, в частности для га = [п/2\, что дает T(|_n/2J) < с |_n/2j lg(|_n/2_|).
Глава 4. Разделяй и властвуй
 Подстановка в рекуррентное соотношение приводит к
 Т(п) < 2(с [п/2J lg([n/2j)) + п
 < сп lg(n/2) + п
 = сп lg п — сп lg2 + n
 = сп lg п — сп + п
 < сп lg п ,
 109
 ще последний шаг выполняется при с > 1.
 Теперь, согласно методу математической индукции, необходимо доказать, что 
наше решение справедливо для граничных условий. Обычно для этого достаточ
 но показать, что граничные условия являются подходящей базой для доказатель
 ства по индукции. В рекуррентном соотношении (4.19) необходимо доказать, что 
константу с можно выбрать достаточно большой для того, чтобы соотношение 
Т(п) < cnlgn было справедливо и для граничных условий. Такое требование 
иногда приводит к проблемам. Предположим, например, что Т( 1) = 1 — един
 ственное граничное условие рассматриваемого рекуррентного соотношения. Да
 лее, для п = 1 соотношение Т(п) < cnlgn дает нам Т( 1) < с ■ 1 ■ lg 1 = 0, что 
противоречит условию Т( 1) = 1. Следовательно, данный базис индукции нашего 
доказательства не выполняется.
 Эту сложность, возникающую при доказательстве предположения индукции 
для указанного граничного условия, легко обойти. Например, в рекуррентном 
соотношении (4.19) можно воспользоваться преимуществами асимптотических 
обозначений, требующих доказать неравенство Т(п) < cnlgn для п > по, где 
по — выбранная нами константа. Идея по устранению возникшей проблемы за
 ключается в том, чтобы в доказательстве по методу математической индукции 
не учитывать граничное условие Т( 1) = 1. Обратите внимание, что при п > 3 
рассматриваемое рекуррентное соотношение явным образом от Т(1) не зависит. 
Таким образом, выбрав по = 2, в качестве базы индукции можно рассматри
 вать не Т(1), а Т(2) и Т(3). Заметим, что здесь делается различие между базой 
рекуррентного соотношения (n = 1) и базой индукции (п = 2 и п = 3). Из рекур
 рентного соотношения следует, что Т(2) = 4, а Г(3) = 5. Теперь доказательство 
по методу математической индукции соотношения T(n) < cnlgn для некоторой 
константы с > 1 можно завершить, выбрав ее достаточно большой для того, что
 бы были справедливы неравенства Т(2) < c21g2 и Т(3) < c31g3. Оказывается, 
что для этого достаточно выбрать с > 2. В большинстве рекуррентных соотно
 шений, которые нам предстоит рассмотреть, легко расширить граничные условия 
таким образом, чтобы гипотеза индукции оказалась верна для малых п.
 Как угадать решение
 К сожалению, не существует общего способа, позволяющего угадать пра
 вильное решение рекуррентного соотношения. Для этого требуются опыт, уда
 ча и творческое мышление. К счастью, существуют определенные эвристические 
приемы, которые могут помочь сделать правильную догадку. Кроме того, для
по
 Часть I. Основы
 получения предполагаемого вида решения можно воспользоваться деревьями ре
 курсии, с которыми мы познакомимся в разделе 4.4.
 Если рекуррентное соотношение подобно тому, которое мы уже рассматрива
 ли, то разумно предположить, что решения этих соотношений будут похожими. 
Например, рассмотрим рекуррентное соотношение
 Т(п) = 2Т([п/2\ + 17 ) + п,
 которое выглядит более сложным, поскольку в аргументе функции Т в его правой 
части добавлено слагаемое “17”. Однако интуитивно понятно, что это дополни
 тельное слагаемое не может сильно повлиять на асимптотическое поведение ре
 шения. При достаточно больших п разность между [п/2J и [гг/2] +17 невелика: 
оба эти числа приблизительно равны половине числа гг. Следовательно, можно 
предположить, что T(n) = O(nlgn); проверить корректность этого предположе
 ния можно методом подстановки (см. упр. 4.3.6).
 Другой способ найти решение — выполнить грубую оценку его верхней и ниж
 ней границ, а затем свести неопределенность до минимальной. Например, в ре
 куррентном соотношении (4.19) в качестве начальной нижней границы можно 
было бы выбрать Т(п) = П(п), поскольку в нем содержится слагаемое п; мож
 но также доказать, что грубой верхней границей является Т(п) = 0(п2). Да
 лее верхняя граница постепенно понижается, а нижняя — повышается до тех 
пор, пока не будет получено правильное асимптотическое поведение решения 
T(n) = 0(nlgn).
 Тонкие нюансы
 Иногда сделать правильное предположение об асимптотическом поведении ре
 шения рекуррентного соотношения можно, но при этом возникают трудности, 
связанные с выполнением доказательства по методу математической индукции. 
Обычно проблема заключается в том, что выбрано недостаточно сильное пред
 положение индукции, которое не позволяет доказать точную границу. Натолкнув
 шись на такое препятствие, пересмотрите предположение индукции, избавившись 
от членов низшего порядка. При этом часто удается провести строгое математи
 ческое доказательство.
 Рассмотрим рекуррентное соотношение
 T(n) = T(Ln/2J) + T([n/2l) + l.
 Можно предположить, что его решением является Т(п) = О(п), и попытаться 
показать, что Т(п) < сп для подходящего выбора константы с. Подставив пред
 полагаемое решение в рекуррентное соотношение, получим выражение
 Т{п) < с\п/2\ + с \п/2] + 1 
— сп + 1 ,
 из которого не следует Т(п) < сп ни для какого выбора с. Можно попытаться 
сделать другие предположения, например о том, что решение — Т(п) = 0(п2).
Глава 4. Разделяй и властвуй
 111
 Хотя это предположение и можно доказать, наше первоначальное предположение 
вполне корректно. Однако чтобы это показать, необходимо выбрать более силь
 ную гипотезу индукции.
 Интуитивно понятно, что наша догадка была почти правильной: мы ошиблись 
всего лишь на константу, равную 1, т.е. на величину низшего порядка. Тем не 
менее математическая индукция не работает, если в предположении индукции 
допущена даже такая, казалось бы, незначительная ошибка. Эту трудность мож
 но преодолеть, если вычесть из первоначального предположения член низшего 
порядка. Таким образом, теперь гипотеза индукции имеет вид Т{п) < сп — d, где 
6 > 0 — константа. Теперь мы имеем
 Т(п) < (с [п/2\ — d) + (с \п/2] — d) + 1 
= сп — 2d + 1 
< сп — d ,
 которое справедливо при d > 1. Как и раньше, чтобы выполнялись граничные 
условия, константу с необходимо выбрать достаточно большой.
 Идея вычитания члена более низкого порядка может показаться противореча
 щей интуитивным представлениям. Ведь если предположение не сработало, его 
следует ослабить, не так ли? Не обязательно! При доказательстве верхней гра
 ницы по индукции в действительности может оказаться сложнее доказать более 
слабую верхнюю границу, поскольку при ее доказательстве мы вынуждены ис
 пользовать в доказательстве ее же. В наших примерах, в которых рекуррентное 
соотношение имеет более одного рекурсивного члена, мы вычитаем член более 
низкого порядка из предложенной границы по одному разу для каждого рекурсив
 ного члена. В приведенном выше примере константа d вычитается дважды, один 
раз для члена Т([п/2\ ) и второй — для члена Т(\п/2]). В результате получается 
неравенство Т(п) < cn — 2d+1, и можно легко найти значения d, которые делают 
сп - 2d + 1 меньшим или равным сп — d.
 Остерегайтесь ошибок
 Используя асимптотические обозначения, легко допустить ошибку. Например, 
для рекуррентного соотношения (4.19) легко “доказать”, что Т(п) = О(п), пред
 положив, что Т(п) < сп, а затем рассуждая следующим образом:
 Т(п) < 2(с |n/2j) + п 
< сп + п
 = 0(п) , 
<= Ошибка!!
 поскольку с представляет собой константу. Ошибка заключается в том, что не 
была доказана гипотеза индукции в точном виде, т.е. что Т(п) < сп. Таким 
образом, мы неявно доказали, что Т{п) < сп, в то время как мы хотели показать,
 что Т(п) = 0(п).
112
 Замена переменных
 Часть I. Основы
 Иногда с помощью небольших алгебраических преобразований удается до
 биться того, что неизвестное рекуррентное соотношение становится похожим 
на то, с которым мы уже знакомы. Например, рассмотрим рекуррентное соот
 ношение
 r(n) = 2T(Lv^J) + lgn,
 которое выглядит довольно сложным. Однако его можно упростить, выполнив 
замену переменных. Для удобства мы не станем беспокоиться об округлении до 
целых таких значений, как у/п. Переименование т = lg п дает
 Г(2т ) = 2Г(2т/2) + ш .
 Теперь можно переименовать S(m) = Т(2т), чтобы получить новое рекуррент
 ное соотношение
 S(m) = 2S(m/2) + m ,
 которое очень похоже на рекуррентное соотношение (4.19). Это новое рекуррент
 ное соотношение имеет то же самое решение: S(m) = O(mlgm). Выполнив об
 ратную замену 5(ш) на Т(п), мы получаем
 Т(п) = Т(2m) = 5(т) = O(ralgra) = O(lgnlglgn) .
 Упражнения
 4.3.1
 Покажите, что решением Т(п) = Т(п — 1) + п является 0(п2).
 4.3.2
 Покажите, что решением Т(п) = Т(\п/2~\) + 1 является O(lgn).
 4.3.3
 Мы видели, что решением Т(п) = 2T([n/2j) + п является O(nlgn). Покажи
 те, что решение этого рекуррентного соотношения также представляет собой 
n(nlgn). Сделайте вывод, что решением рассматриваемого рекуррентного со
 отношения является ©(nlgn).
 4.3.4
 Покажите, что преодолеть трудность, связанную с граничным условием Т(1) = 1 
в рекуррентном соотношении (4.19) можно путем выбора другого предположения 
индукции, не меняя при этом граничных условий.
 4.3.5
 Покажите, что ©(nlgn) является решением “точного” рекуррентного соотноше
 ния (4.3) для сортировки слиянием.
Глава 4. Разделяй и властвуй
 113
 4.3.6
 Покажите, что решением рекуррентности Т(п) = 2Т{\п/2\ + 17) + п является 
0(п lgn).
 4.3.7
 Используя основной метод из раздела 4.5, можно показать, что решением рекур
 рентного соотношения Т(п) = 4Г(п/3)+п является Т(п) = @(nlog34). Покажите, 
что не получается выполнить доказательство методом подстановок с гипотезой 
индукции Т(п) < cnlog34. Затем покажите, как вычитание члена меньшего по
 рядка делает доказательство возможным.
 4.3.8
 Используя основной метод из раздела 4.5, можно показать, что решением рекур
 рентного соотношения Т(п) = 4Г(п/2) + п является Т(п) = @(п2). Покажите, 
что не получается выполнить доказательство методом подстановок с гипотезой 
индукции Т(п) < сп2. Затем покажите, как вычитание члена меньшего порядка 
делает доказательство возможным.
 4.3.9
 Решите рекуррентное соотношение Т(п) = 3Т{у/п) + log п путем замены пере
 менных. Ваше решение должно быть асимптотически точным. При решении не 
беспокойтесь о том, чтобы все значения являлись целыми числами.
 4.4. Метод деревьев рекурсии
 Метод подстановок способен обеспечить краткий путь к доказательству того 
факта, что предполагаемое решение рекуррентного соотношения является пра
 вильным, однако сделать хорошую догадку зачастую довольно трудно. Построе
 ние дерева рекурсии, подобного тому, с которым мы имели дело в разделе 2.3.2 
в ходе анализа рекуррентного соотношения, описывающего время сортировки 
слиянием, — прямой путь к хорошей догадке. В дереве рекурсии каждый узел 
представляет стоимость выполнения отдельно взятой подзадачи, которая реша
 ется при одном из многочисленных рекурсивных вызовов функций. Далее стои
 мости отдельных этапов суммируются в пределах каждого уровня, а затем — по 
всем уровням дерева, в результате чего получаем полную стоимость всех уровней 
рекурсии.
 Деревья рекурсии лучше всего подходят для того, чтобы помочь сделать до
 гадку о виде решения, которая затем проверяется методом подстановок. При этом 
в догадке часто допускается наличие небольших неточностей, поскольку впослед
 ствии она все равно проверяется. Если же построение дерева рекурсии и сумми
 рование времени работы по всем его составляющим производится достаточно 
тщательно, то само дерево рекурсии может стать средством доказательства кор
 ректности решения. В данном разделе деревья рекурсии применяются для полу
114
 Часть I. Основы
 чения предположений о виде решения, а в разделе 4.6 — непосредственно для 
доказательства теоремы, на которой базируется основной метод.
 Например, посмотрим, как с помощью дерева рекурсии можно догадаться о ви
 де решения рекуррентного соотношения T(n) = ЗТ(|_п/4_|)-|-@(п2). Начнем с по
 иска верхней границы решения. Как известно, при решении рекуррентных соот
 ношений тот факт, что от аргументов функций берется целая часть, при решении 
рекуррентных соотношений обычно является несущественным (это пример от
 клонений, которые можно допустить), поэтому построим дерево рекурсии для 
рекуррентного соотношения Т(п) = ЗТ(п/4) + сп2, записанного с использовани
 ем константы с > 0.
 На рис. 4.5 проиллюстрирован процесс построения дерева рекурсии для ре
 куррентного соотношения Т(п) = ЗТ(п/4) + сп2. Для удобства предположим, 
что п — степень четверки (еще один пример допустимых отклонений), так что 
размеры всех подзадач — целые. В части (а) показана функция Т(п), которая 
затем, в части (б), раскрывается в эквивалентное дерево рекурсии, представля
 ющее анализируемое рекуррентное соотношение. Член сп2 в корне дерева пред
 ставляет время верхнего уровня рекурсии, а три поддерева, берущих начало из 
корня, — времена выполнения подзадач размером п/4. В части (в) добавлен еще 
один шаг раскрытия, т.е. выполнено представление в виде поддерева каждого 
узла с временем Т(п/4) из части (б). Время выполнения, соответствующее каж
 дому из трех дочерних поддеревьев, равно с(п/4)2. Далее каждый лист дерева 
преобразуется в поддерево аналогичным образом в соответствии с рекуррентным 
соотношением.
 Поскольку по мере удаления от корня дерева размер подзадач уменьшается на 
каждом уровне в четыре раза, в конце концов мы должны дойти до граничных 
условий. Сколько же уровней дерева нужно построить, чтобы их достичь? Раз
 мер вспомогательной задачи, соответствующей уровню, который находится на г-м 
уровне глубины, равен п/4г. Таким образом, размер подзадачи достигает п = 1, 
когда п/4г = 1 или, что то же самое, когда г = log4n. Таким образом, всего 
в дереве log4 п + 1 уровней (с глубинами 0,1,2,..., log4 п).
 Затем мы определяем стоимость каждого уровня дерева. На каждом уровне 
в три раза больше узлов, чем на предыдущем, поэтому количество узлов на г-м 
уровне равно Зг. Поскольку размеры вспомогательных подзадач при спуске на 
один уровень уменьшаются в четыре раза, время выполнения каждого узла на г-м 
уровне (для г = 0,1,2,..., log4 п — 1) равно Згс(п/4г)2 = (3/16)гсп2. На нижнем 
уровне на глубине log4 п имеется 3log4 п = nlog4 3 узлов, каждый из которых дает 
в общее время работы вклад, равный Т( 1). Поэтому время работы этого уровня 
равно величине nlog43T(l), что представляет собой @(nlog43), так как мы счита
 ем, что Т(1) является константой.















































































































































































































































354
 Часть III. Структуры данных
 Случай 2 
Случай 3
 Рис. 13.6. Случаи 2 и 3 процедуры RB-Insert-Fixup. Как и в случае 1, свойство 4 нарушается 
либо случаем 2, либо случаем 3, поскольку z и его родительский узел z.p красные. Каждое из 
поддеревьев а, (3, 7 и «5 имеет черный корень (а, /3 и 7 согласно свойству 4, а 5 — поскольку 
в противном случае мы получили бы случай 1), и каждое из них имеет одну и ту же черную 
высоту. Мы преобразуем случай 2 в случай 3 левым поворотом, который сохраняет свойство 5: 
все нисходящие простые пути от узла к листу содержат одно и то же количество черных узлов. 
Случай 3 приводит к определенному перекрашиванию и правому повороту, что также сохраняет 
свойство 5. Затем цикл while завершается, поскольку свойство 4 удовлетворено: в одной строке 
больше нет двух красных узлов.
 и г , 
и г .
 псевдокода соответствуют случаю 2, который показан на рис. 13.6 вместе со 
случаем 3. В случае 2 узел г является правым потомком своего родительского 
узла. Мы используем левый поворот для преобразования сложившейся ситуа
 ции в случай 3 (строки 12-14), когда г является левым потомком. Поскольку 
р — красные узлы, поворот не влияет ни на черную высоту узлов, 
ни на выполнение свойства 5. Когда мы приходим к случаю 3 (либо непо
 средственно, либо поворотом из случая 2), узел у, дядя узла г , 
имеет черный 
цвет (поскольку иначе мы бы получили случай 1). Кроме того, обязательно 
существует узел z.p.p, так как мы доказали, что этот узел существовал при 
выполнении строк 2 и 3, а также что после перемещения узла z на один узел 
вверх в строке 10 с последующим опусканием на один уровень в строке 11 
узел z.p.p остается неизменным. В случае 3 мы выполняем ряд изменений 
цвета и правый поворот, которые сохраняют свойство 5. После этого, так как 
у нас нет двух идущих подряд красных узлов, работа процедуры завершается. 
Больше тело цикла while не выполняется, так как узел z.p теперь черный.
 Покажем, что случаи 2 и 3 сохраняют инвариант цикла. (Как мы только что 
доказали, перед следующей проверкой в строке 1 узел z.p будет черным и тело 
цикла больше выполняться не будет.)
 а. В случае 2 выполняется присвоение, после которого г указывает на красный 
узел z.p. Никаких других изменений г или его цвета в случаях 2 и 3 не 
выполняется.
 б. В случае 3 узел z.p делается черным, так что если z.p в начале следующей 
итерации является корнем, то этот корень — черный.
 в. Как и в случае 1, в случаях 2 и 3 свойства 1, 3 и 5 сохраняются.
 Поскольку узел 2 в случаях 2 и 3 не является корнем, нарушение свойства 2 
невозможно. Случаи 2 и 3 не могут приводить к нарушению свойства 2.
Глава 13. Красно-черные деревья
 355
 поскольку при повороте в случае 3 сделанный красным узел становится 
дочерним по отношению к черному.
 Таким образом, случаи 2 и 3 приводят к коррекции нарушения свойства 4, 
при этом не внося никаких новых нарушений красно-черных свойств.
 Показав, что при любой итерации инвариант цикла сохраняется, мы тем самым 
показали, что процедура RB-Insert-Fixup корректно восстанавливает красно
 черные свойства дерева.
 Анализ
 Чему равно время работы процедуры RB-Insert? Поскольку высота крас
 но-черного дерева с п узлами равна O(lgn), выполнение строк 1-16 процедуры 
RB-Insert требует времени O(lgn). В процедуре RB-Insert-Fixup цикл while 
повторно выполняется только в случае 1, и указатель г при этом перемещается 
вверх по дереву на два уровня. Таким образом, общее количество возможных вы
 полнений тела цикла while равно O(lgn). Следовательно, общее время работы 
процедуры RB-Insert равно O(lgn). Интересно, что в ней никогда не выпол
 няется больше двух поворотов, поскольку цикл while в случаях 2 и 3 завершает 
работу.
 Упражнения
 13.3.1
 В строке 16 процедуры RB-Insert мы окрашиваем вновь вставленный узел 
в красный цвет. Заметим, что если бы мы окрашивали его в черный цвет, то 
свойство 4 красно-черного дерева не было бы нарушено. Так почему же мы не 
делаем этого?
 13.3.2
 Изобразите красно-черные деревья, которые образуются при последовательной 
вставке ключей 41,38,31,12,19,8 в изначально пустое красно-черное дерево.
 13.3.3
 Предположим, что черная высота каждого из поддеревьев a, /3, 7, <5 и е на 
рис. 13.5 и 13.6 равна к.
 Найдите черные высоты каждого узла на этих рисунках, 
чтобы убедиться, что свойство 5 сохраняется при указанных преобразованиях.
 13.3.4
 Профессор озабочен вопросом, не может ли в процедуре RB-Insert-Fixup про
 изойти присвоение значения RED узлу Т. nil. color, ведь в этом случае проверка 
в строке 1 не вызовет окончания работы цикла, если г — корень дерева. Покажи
 те, что страхи профессора безосновательны, доказав, что процедура RB-Insert- 
Fixup никогда не окрашивает Т. nil. color в красный цвет.
356
 13.3.5
 Часть III. Структуры данных
 Рассмотрим красно-черное дерево, образованное вставкой п узлов с помощью 
процедуры RB-Insert. Докажите, что если п > 1, то в дереве имеется как мини
 мум один красный узел.
 13.3.6
 Предложите эффективную реализацию процедуры RB-Insert в случае, когда 
представление красно-черных деревьев не включает указатель на родительский 
узел.
 13.4. Удаление
 Как и остальные базовые операции над красно-черными деревьями с п узлами, 
удаление узла выполняется за время O(lgn). Удаление оказывается несколько 
более сложной задачей, чем вставка.
 Процедура для удаления узла из красно-черного дерева основана на процеду
 ре Tree-Delete (раздел 12.3). Сначала нужно внести изменения в подпрограм
 му Transplant, которую процедура Tree-Delete вызывает в процессе работы 
с красно-черным деревом.
 RB-Transplant (Г, и, и)
 1 if и.р == Т. nil
 2 
Т. root = v
 3 elseif и == и.р. left
 4 
и.р.left = v
 5 else и.р.right = v
 6 v.p = и.р
 Процедура RB-Transplant имеет два отличия от процедуры Transplant. Во- 
первых, строка 1 обращается к ограничителю Т. nil, а не к NIL. Во-вторых, при
 сваивание атрибуту и.р в строке 6 выполняется безусловно: возможно выполне
 ние присваивания, даже если и указывает на ограничитель. В действительности 
мы будем использовать возможность присваивания атрибуту и.р при и = T.nil.
 Процедура RB-Delete подобна процедуре Tree-Delete, но имеет дополни
 тельные строки псевдокода. Некоторые из них отслеживают узел у, который мо
 жет вызвать нарушения красно-черных свойств. Если нужно удалить узел г и г 
имеет меньше двух дочерних узлов, то г удаляется из дерева, и мы делаем у сов
 падающим с г. Если у г два дочерних узла, то узел у должен быть преемником г 
в дереве, и у перемещается в дереве в позицию узла г. Мы также запоминаем 
цвет у перед его удалением или перемещением и отслеживаем узел х, который 
перемещается в исходную позицию узла у в дереве, поскольку узел х также может 
привести к нарушению красно-черных свойств. После удаления узла г процедура 
RB-DELETE вызывает вспомогательную процедуру RB-DELETE-FIXUP, которая
Глава 13. Красно-черные деревья
 357
 изменяет цвета и выполняет повороты для восстановления свойств красно-черно
 го дерева.
 RB-Delete (Г, 2)
 1 у = z
 2 у-original-color = у. color
 3 if 2. left == T. nil
 4 
5 
x = z. right
 RB-Transplant (T, 2,2. right)
 6 elseif 2. right ==T. nil
 I 
8 
x = z.left
 RB-Transplant (T, 2,2. left)
 9 else у = Tree-Minimum(2. right)
 10 
y-original- color = y. color
 II 
12 
13 
14 
15 
16 
17 
18 
19 
20 
x = y. right
 if y.p == z
 x.p = у
 else RB-Transplant(T, у, у. right)
 y. right = 2. right
 y.right.p = у
 RB-Transplant (T, 2, y)
 y. left = 2. left
 у .left, p = у
 у. color = z. color
 21 if y-original-color -- BLACK
 22 
RB-Delete-Fixup (T, x )
 Хотя процедура RB-Delete содержит почти в два раза больше строк, чем 
псевдокод Tree-Delete, обе эти процедуры имеют одинаковую базовую струк
 туру. Каждую строку Tree-Delete можно найти в RB-Delete (с тем отличи
 ем, что nil заменено T.nil, а вызов Transplant — вызовом RB-Transplant), 
и выполняются эти строки при одних и тех же условиях.
 А вот отличия между этими двумя процедурами. •
 • Мы поддерживаем узел у в качестве узла, либо удаленного из дерева, либо 
перемещенного в пределах последнего. В строке 1 у становится указываю
 щим на узел 2, если 2 имеет меньше двух дочерних узлов и, таким образом, 
оказывается удаленным. Когда 2 имеет два дочерних узла, в строке 9 у стано
 вится указывающим на узел, следующий в дереве за 2, так же, как в процеду
 ре Tree-Delete, и у перемещается в дереве в позицию узла 2.
 • Поскольку цвет узла у может измениться, переменная у-original-color хранит 
цвет узла у до любых изменений цвета. В строках 2 и 10 выполняется установ
 ка этой переменной немедленно после присваивания значения переменной у. 
Когда 2 имеет два дочерних узла, у ф z и узел у перемещается в исходную 
позицию узла 2 в красно-черном дереве; строка 20 назначает у тот же цвет, что
358
 Часть III. Структуры данных
 и цвет узла г. Необходимо хранить исходный цвет у для его проверки в конце 
процедуры RB-Delete; если он был черным, то удаление или перемещение у 
может привести к нарушениям свойств красно-черного дерева.
 • Как уже говорилось, мы отслеживаем узел х, который перемещается в исход
 ную позицию узла у. Присваивания в строках 4, 7 и 11 делают х указывающим 
либо на единственный дочерний узел узла у, либо, если у не имеет дочерних 
узлов, на ограничитель Т.пй. (Вспомним из раздела 12.3, что у узла у нет 
левого дочернего узла.)
 • Поскольку узел х перемещается в исходную позицию узла у, атрибут х.р 
всегда устанавливается указывающим на исходную позицию родительского 
по отношению к у узла в дереве, даже если х в действительности является 
ограничителем Т.пй. Присваивание атрибуту х.р в строке 6 процедуры RB- 
Transplant имеет место во всех случаях, кроме ситуации, когда г исходно 
является родителем у (что осуществляется, только когда 2 имеет два дочерних 
узла и следующий за г элемент у представляет собой правый дочерний узел г). 
(Заметим, что когда RB-Transplant вызывается в строке 5, 8 или 14, третий 
передаваемый параметр совпадает с х.)
 Однако если исходным родительским узлом узла у является узел 2, нам не 
нужно, чтобы атрибут х.р указывал на исходный родитель у, поскольку мы 
удаляем этот узел из дерева. Поскольку узел у передвинется вверх и займет 
в дереве позицию узла 2, установка х.р равным у в строке 13 приведет к тому, 
что х.р будет указывать на исходную позицию родителя у, даже если х = 
Т. nil.
 • Наконец, если узел у был черным, в свойства красно-черного дерева может 
быть внесено одно или несколько нарушений, так что для восстановления 
свойств красно-черного дерева в строке 22 выполняется вызов RB-Delete- 
Fixup. Если узел у был красным, при переименовании или удалении узла у 
красно-черные свойства сохраняются по следующим причинам.
 1. Ни одна черная высота в дереве не меняется.
 2. Никакие красные узлы не делаются смежными. Поскольку у занимает в де
 реве место 2 вместе с цветом узла 2, мы не можем получить два смежных 
красных узла в новой позиции узла у в дереве. Кроме того, если у не был 
правым дочерним узлом 2, исходный правый дочерний узел х узла у заме
 няет последний в дереве. Если у красный, то х должен быть черным, так 
что замена у на х не может привести к тому, что два красных узла станут 
смежными.
 3. Поскольку узел у не может быть корнем, если он был красным, корень 
остается черным.
 Если узел у был черным, то могут возникнуть три проблемы, которые испра
 вит вызов RB-Delete-Fixup. Во-первых, если у был корнем, а теперь новым 
корнем стал красный потомок у, нарушается свойство 2. Во-вторых, если и .г. 
и х.р красные, то нарушается свойство 4. И в-третьих, перемещение у в дереве
Глава 13. Красно-черные деревья
 359
 приводит к тому, что любой простой путь, ранее содержавший у, теперь имеет 
на один черный узел меньше. Таким образом, для всех предков у оказывается 
нарушенным свойство 5. Мы можем исправить ситуацию, утверждая, что узел х, 
ныне занимающий исходную позицию у, — “сверхчерный”, т.е. при рассмотрении 
любого простого пути, проходящего через х, следует добавлять дополнительную 
единицу к количеству черных узлов. При такой интерпретации свойство 5 оста
 ется выполняющимся. При удалении или перемещении черного узла у мы пере
 даем его “черноту” узлу х. Проблема заключается в том, что теперь узел х не 
является ни черным, ни красным, что нарушает свойство 1. Вместо этого узел 
х окрашен либо “дважды черным”, либо “красно-черным” цветом, что дает при 
подсчете черных узлов на простых путях, содержащих х, вклад, равный соответ
 ственно 2 или 1. Атрибут color узла х при этом остается равным либо RED (если 
узел красно-черный), либо BLACK (если узел дважды черный). Другими словами, 
цвет узла х не соответствует его атрибуту color.
 Теперь рассмотрим процедуру RB-DELETE-FlXUP и то, как она восстанавли
 вает красно-черные свойства дерева поиска.
 RB-Delete-Fixup (Г, х)
 1 while х ф Т. root и х. color == BLACK
 2
 3
 4
 5
 6
 7
 8
 9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 if х == х.р. left
 w = x.p. right
 if w. color == RED
 W. color = BLACK
 x.p. color = RED
 Left-Rotate (T, x.p)
 w = x.p. right
 if w. left, color == BLACK и w. right, color == BLACK
 W. color = RED
 X = x.p
 else if w. right, color == BLACK
 w. left, color = BLACK n
 nw. color = RED
 Right-Rotate (T, w )
 w = x.p. right
 w. color = x.p. color
 x.p. color = BLACK
 w. right, color = BLACK
 Left- Rotate (T, x.p)
 x = T. root
 else (то же, что и в части then, но с заменой
 “правого” (right) “левым” (left) и наоборот)
 23 х. color = BLACK
 / / Случай I
 / / Случай 1
 / / Случай 1
 / / Случай 1
 / / Случай 2
 / / Случай 2
 / / Случай 3
 / / Случай 3
 / / Случай 3
 / / Случай 3
 / / Случай 4
 / / Случай 4
 / / Случай 4
 / / Случай 4
 / / Случай 4
 Процедура RB-Delete-Fixup восстанавливает свойства 1, 2 и 4. В упр. 13.4.1 
и 13.4.2 требуется показать, что эта процедура восстанавливает свойства 2 и 4,
360
 Часть III. Структуры данных
 так что в оставшейся части раздела мы обратим свое внимание на свойство 1. 
Цель цикла while в строках 1-22 заключается в перенесении дополнительной 
“черноты” вверх по дереву до тех пор, пока не выполнится одно из следующих 
условий.
 1
 2
 . х указывает на красно-черный узел — в этом случае мы просто делаем узел х
 “единожды черным” в строке 23.
 . х указывает на корень — в этом случае мы просто убираем излишнюю черноту.
 3. Выполнив некоторые повороты и перекраску, мы выходим из цикла.
 Внутри цикла while х всегда указывает на дважды черный узел, не являющий
 ся корнем. В строке 2 мы определяем, является ли х левым или правым дочерним 
узлом своего родителя х.р. (Приведен подробный код для ситуации, когда х — 
левый потомок. Для правого потомка код аналогичен, симметричен и скрыт за 
описанием в строке 22.) Поддерживается указатель w, который указывает на вто
 рой потомок родителя х. Поскольку узел х дважды черный, узел w не может 
быть Т. nil, в противном случае количество черных узлов на простом пути от х.р 
к (единожды черному) листу w было бы меньше, чем количество черных узлов 
на простом пути от х.р к а:.
 Четыре разных возможных случая2 показаны на рис. 13.7. Перед тем как при
 ступить к детальному рассмотрению каждого случая, убедимся, что в каждом 
из случаев преобразования сохраняется свойство 5. Ключевая идея заключается 
в необходимости убедиться, что применяемые преобразования в каждом случае 
сохраняют количество черных узлов (включая дополнительную черноту в х) на 
пути от корня включительно до каждого из поддеревьев а, 
Таким обра
 зом, если свойство 5 выполнялось до преобразования, оно выполняется и после 
него. Например, на рис. 13.7, (а), который иллюстрирует случай 1, количество чер
 ных узлов на пути от корня до поддеревьев а и /3 равно 3 как до, так и после 
преобразования (не забудьте о том, что узел х — дважды черный). Аналогично 
количество черных узлов на пути от корня до любого из поддеревьев 7, S, е 
и С равно 2 как до, так и после преобразования. На рис. 13.7, (б) подсчет должен 
включать значение с, равное значению атрибута color корня показанного поддере
 ва, которое может быть либо RED, либо BLACK. Если определить count (red) = О 
и count(BLACK) = 1, то на пути от корня до поддерева а количество черных 
узлов равно 2 + count (с); эта величина одинакова до и после выполнения преоб
 разований. В такой ситуации после преобразования новый узел х имеет атрибут 
color, равный с, но реально это либо красно-черный узел (если с = RED), либо 
дважды черный (если с = BLACK). Прочие случаи могут быть проверены анало
 гично (см. упр. 13.4.5).
 2Как и в процедуре RB-Insert-Fixup, случаи в процедуре RB-Delete-Fixup не являются взаимоисклю- 
чающими.
Глава 13. Красно-черные деревья
 361
 Рис. 13.7. Случаи цикла while процедуры RB-Delete-Fixup. У черных узлов атрибут color 
равен BLACK, у темно-серых — атрибут color равен RED, а у светлых узлов атрибут color представ
 лен значениями с и с', которые могут быть либо RED, либо BLACK. Буквы а, /3 ,..., £ представляют 
произвольные поддеревья. Каждый случай преобразует конфигурацию, показанную слева, в конфи
 гурацию, показанную справа, путем изменения некоторых цветов и/или поворота. Любой узел, на 
который указывает х, имеет дополнительный черный цвет и является либо дважды черным, либо 
красно-черным. Цикл повторяется только в случае 2. (а) Случай 1 преобразуется в случай 2, 3 или 4 
путем изменения цвета узлов В и D и выполнения левого поворота, (б) В случае 2 дополнитель
 ная чернота, представленная указателем х, перемещается вверх по дереву путем окраски узла D 
в красный цвет и установки х указывающим на узел В. Если мы попадаем в случай 2 из случая 1, 
цикл while завершается, поскольку новый узел х — черно-красный, и, следовательно, значение с 
его атрибута color равно RED. (в) Случай 3 преобразуется в случай 4 путем обмена цветов узлов С 
и D и выполнения правого поворота, (г) Случай 4 убирает дополнительную черноту, представлен
 ную х, путем изменения некоторых цветов и выполнения левого поворота (без нарушения красно
 черных свойств), после чего цикл завершается.
362
 Часть III. Структуры данных
 Случай 1. Брат w узла х — красный
 Случай 1 (строки 5-8 процедуры RB-Delete-Fixup и рис. 13.7, (а)) возникает, 
когда узел w (“брат” узла х) — красный. Поскольку w должен иметь черные по
 томки, можно обменять цвета w и х.р, а затем выполнить левый поворот вокруг 
х.р без нарушения каких-либо красно-черных свойств. Новый “брат” х, до пово
 рота бывший одним из дочерних узлов ии, теперь черный. Таким путем случай 1 
приводится к случаю 2, 3 или 4.
 Случаи 2, 3 и 4 возникают при черном узле w и отличаются один от другого 
цветами дочерних по отношению к w узлов.
 Случай 2. Узел w — черный, оба его дочерних узла — черные
 В этом случае (строки 10 и 11 процедуры RB-Delete-Fixup и рис. 13.7, (б)) 
оба дочерних узла w — черные. Поскольку узел w также черный, мы можем за
 брать черную окраску у х и w, сделав х единожды черным, a w — красным. Для 
того чтобы компенсировать удаление черной окраски х и w, мы можем добавить 
дополнительный черный цвет узлу х.р, который до этого мог быть как красным, 
так и черным. После этого будет выполнена следующая итерация цикла, в ко
 торой роль х будет играть текущий узел х.р. Заметим, что если мы переходим 
к случаю 2 от случая 1, новый узел х — красно-черный, поскольку исходный узел 
х.р был красным. Следовательно, значение с атрибута color нового узла х равно 
RED и цикл завершается при проверке условия цикла. После этого новый узел х 
окрашивается в обычный черный цвет в строке 23.
 Случай 3. Брат w узла х — черный, левый дочерний узел узла w — красный, 
а правый — черный
 В этом случае (строки 13-16 процедуры RB-Delete-Fixup и рис. 13.7, (в)) 
узел w — черный, его левый дочерний узел — красный, а правый — черный. Мы 
можем обменять цвета w и его левого дочернего узла w.left, а затем выполнить 
правый поворот вокруг w без нарушения каких-либо красно-черных свойств. Но
 вым “братом” узла х после этого будет черный узел с красным правым дочерним 
узлом, и, таким образом, случай 3 приводится к случаю 4.
 Случай 4. Брат w узла х черный, а правый дочерний узел узла w красный
 В этом случае (строки 17-21 процедуры RB-Delete-Fixup и рис. 13.7, (г)) 
узел w — черный, а его правый дочерний узел — красный. Выполняя обмен цветов 
и левый поворот вокруг х. р, мы можем устранить излишнюю черноту в х, делая 
его просто черным, без нарушения каких-либо красно-черных свойств. Присво
 ение х указателя на корень дерева приводит к завершению работы цикла при 
проверке условия при следующей итерации.
 Анализ
 Чему равно время работы процедуры RB-Delete? Поскольку высота дере
 ва с п узлами равна O(lgn), общая стоимость процедуры без вызова вспомога
Глава 13. Красно-черные деревья
 363
 тельной процедуры RB-Delete-Fixup равна O(lgn). В процедуре RB-Delete- 
Fixup в случаях 1, 3 и 4 завершение работы происходит после выполнения фик
 сированного числа изменений цвета и не более трех поворотов. Случай 2 — 
единственный, после которого возможно выполнение очередной итерации цик
 ла while, причем указатель х перемещается вверх по дереву не более чем O(lgn) 
раз и никакие повороты при этом не выполняются. Таким образом, время рабо
 ты процедуры RB-Delete-Fixup составляет O(lgn), причем она выполняет не 
более трех поворотов. Общее время работы процедуры RB-Delete, само собой 
разумеется, также равно O(lgn).
 Упражнения
 13.4.1
 Покажите, что после выполнения процедуры RB-Delete-Fixup корень дерева 
должен быть черным.
 13.4.2
 Покажите, что если в процедуре RB-Delete и х, и х.р красные, то при вызове 
RB-Delete-Fixup (Т,х) свойство 4 будет восстановлено.
 13.4.3
 В упр. 13.3.2 вы построили красно-черное дерево, которое является результатом 
последовательной вставки ключей 41,38,31,12,19,8 в изначально пустое дерево. 
Покажите теперь красно-черные деревья, которые будут получаться в результате 
последовательного удаления ключей в порядке 8,12,19,31,38,41.
 13.4.4
 В каких строках кода процедуры RB-Delete-Fixup мы можем обращаться 
к ограничителю Т. nil или изменять его?
 13.4.5
 Для каждого из случаев, показанных на рис. 13.7, подсчитайте количество чер
 ных узлов на пути от корня показанного поддерева до каждого из поддеревьев 
а, Д,..., С и убедитесь, что оно не меняется при выполнении преобразований. 
Если узел имеет атрибут color, равный с или d , воспользуйтесь символьными 
обозначениями count (с) или count (с7).
 13.4.6
 Профессор озабочен вопросом, не может ли узел х.р не быть черным в начале 
случая 1 в процедуре RB-Delete-Fixup. Если профессор прав, то строки 5 и 6 
процедуры ошибочны. Покажите, что в начале случая 1 узел х.р не может не 
быть черным, так что профессору нечего волноваться.
 13.4.7
 Предположим, что узел х вставлен в красно-черное дерево с помощью процеду
 ры RB-Insert, после чего немедленно удален из этого дерева процедурой RB
364
 Часть III. Структуры данных
 Delete. Будет ли полученное в результате красно-черное дерево таким же, как 
и исходное? Обоснуйте свой ответ.
 Задачи
 13.1. Перманентные динамические множества
 Иногда полезно сохранять предыдущие версии динамического множества 
в процессе его обновления. Такие множества называются перманентными 
(persistent). Один из способов реализации перманентного множества состоит в ко
 пировании всего множества при внесении в него изменений, однако такой подход 
может существенно замедлить работу программы и вызвать перерасход памяти. 
Зачастую эту задачу можно решить гораздо более эффективно.
 Рассмотрим перманентное множество S с операциями Insert, Delete 
и Search, которое реализуется с использованием бинарных деревьев поиска, 
как показано на рис. 13.8, (а). Для каждой версии множества мы поддерживаем 
отдельный корень. Для добавления ключа 5 в множество создается новый узел 
с ключом 5, который становится левым дочерним узлом нового узла с ключом 7, 
так как менять существующий узел с ключом 7 мы не можем. Аналогично новый 
узел с ключом 7 становится левым потомком нового узла с ключом 8, правым 
потомком которого является существующий узел с ключом 10. Новый узел с клю
 чом 8 становится, в свою очередь, правым потомком нового корня г' с ключом 4, 
левым потомком которого является существующий узел с ключом 3. Таким обра
 зом, мы копируем только часть дерева, а в остальном используем старое дерево, 
как показано на рис. 13.8, (б).
 Предположим, что каждый узел дерева имеет атрибуты key, left и right, но не 
имеет атрибута с указателем на родительский узел (см. также упр. 13.3.6).
 Рис. 13.8. (а) Бинарное дерево поиска с ключами 2,3,4,7,8,10. (б) Перманентное бинарное де
 рево поиска, полученное в результате вставки ключа 5. Последняя версия множества состоит из 
узлов, достижимых из корня г', а предыдущая версия состоит из узлов, достижимых из г. Темные 
узлы добавлены при вставке ключа 5.
Глава 13. Красно-черные деревья
 365
 а. Определите, какие узлы перманентного бинарного дерева поиска должны быть 
изменены при вставке в него ключа к или удалении узла у в общем случае.
 б. Напишите процедуру Persistent-Tree-Insert, которая для данного перма
 нентного дерева Т и вставляемого ключа к возвращает новое перманентное 
дерево Т', получающееся в результате вставки к в Т.
 в. Если высота перманентного бинарного дерева поиска Т равна h, сколько вре
 мени будет работать ваша реализация Persistent-Tree-Insert и какие тре
 бования к памяти она предъявляет? (Количество требуемой памяти пропорци
 онально количеству новых узлов.)
 г. Предположим, что в каждом узле имеется атрибут, который представляет со
 бой указатель на родительский узел. В этом случае процедура PERSISTENT- 
Tree-Insert должна выполнять дополнительное копирование. Докажите, что 
в этом случае время работы процедуры и объем необходимой памяти равны 
fi(n), где п — количество узлов в дереве.
 д. Покажите, как можно использовать красно-черные деревья для того, чтобы 
гарантировать при вставке и удалении в наихудшем случае равенство O(lgn) 
времени работы процедуры и объема необходимой памяти.
 13.2. Операция соединения красно-черных деревьев
 Операция соединения (join) применяется к двум динамическим множествам 
S\ и и элементу х (такому, что для любых х\ € S\ и Х2 £ 
выполняется 
неравенство х \.key < x.key < Х2.key). Результатом операции является множе
 ство S = S1 U {х} U В данной задаче мы рассмотрим реализацию операции 
соединения красно-черных деревьев.
 а. Будем хранить черную высоту красно-черного дерева Т как новый атрибут 
T.bh. Покажите, что этот атрибут может поддерживаться процедурами RB- 
INSERT и RB-Delete без использования дополнительной памяти в узлах де
 рева и без увеличения асимптотического времени работы процедур. Покажите, 
что при спуске по дереву Т можно определить черную высоту каждого посе
 щаемого узла за время 0(1) на каждый посещенный узел.
 Мы хотим реализовать операцию RB-Join(Ti,х,Т2), которая, разрушая деревья 
Т\ и Х2, возвращает красно-черное дерево Т = Т\ U {х} U Т^. Пусть п — общее 
количество узлов в деревьях Т\ и Т2.
 б. Считая, что Т\. bh > Т2. bh, разработайте алгоритм, который за время O(lgn) 
находит в дереве Т\ среди узлов, черная высота которых равна Т2. bh, черный 
узел у с наибольшим значением ключа.
 в. Пусть Ту — поддерево с корнем у. Опишите, как заменить Ту на Ту U {х} U Т? 
за время 0(1) с сохранением свойства бинарного дерева поиска.
366
 Часть III. Структуры данных
 г. В какой цвет нужно окрасить х, чтобы сохранились красно-черные свойства 1, 
3 и 5? Опишите, как восстановить свойства 2 и 4 за время O(lgn).
 д. Докажите, что предположение в п. (б) данной задачи не приводит к поте
 ре общности. Опишите симметричную ситуацию, возникающую при T\.bh < 
T2.bh.
 е. Покажите, что время работы процедуры RB-JOIN равно O(lgn).
 13.3. AVL-деревья
 AVL-дерево представляет собой бинарное дерево поиска со сбалансированной 
высотой: для каждого узла х высота левого и правого поддеревьев х отличается 
не более чем на 1. Для реализации AVL-деревьев мы воспользуемся дополнитель
 ным атрибутом x.h в каждом узле дерева, в котором хранится высота данного 
узла. Как и в случае обычных деревьев поиска, мы считаем, что Т. root указывает 
на корневой узел.
 а. Докажите, что AVL-дерево с п узлами имеет высоту O(lgn). (Указание: дока
 жите, что в AVL-дереве высотой h имеется как минимум 
узлов, где 
h-Q число Фибоначчи.)
 — 
б. Для вставки узла в AVL-дерево он сначала размещается в соответствующем 
месте бинарного дерева поиска. После этого дерево может оказаться несба
 лансированным, в частности, высота левого и правого потомков некоторого 
узла может отличаться на 2. Разработайте процедуру Balance(x), которая 
получает в качестве параметра поддерево с корнем в узле х, левый и правый 
потомки которого сбалансированы по высоте и имеют высоту, отличающую
 ся не более чем на 2 (т.е. |х. right, h — x.left.h\ < 2), и изменяет его таким 
образом, что поддерево с корнем в узле х становится сбалансированным по 
высоте. (Указание: воспользуйтесь поворотами.)
 в. Используя решение подзадачи (б), разработайте рекурсивную процедуру 
AVL-Insert (х, 2), которая получает в качестве параметров узел х в AVL- 
дереве и вновь созданный узел 2 (с заполненным полем ключа) и вставляет 
г в поддерево, корнем которого является узел х, сохраняя при этом свойство, 
заключающееся в том, что х — корень AVL-дерева. Как и в случае процеду
 ры Tree-Insert из раздела 12.3, считаем, что атрибут z.key заполнен и что 
z.left = NIL и 2. right = NIL. Кроме того, полагаем, что z.h = 0. Таким об
 разом, для вставки узла 2 в AVL-дерево Т мы должны осуществить вызов 
AVL-Insert (Г. root, 2).
 г. Покажите, что время работы операции AVL-Insert для AVL-дерева с п узла
 ми равно O(lgn) и она выполняет 0(1) поворотов.
Глава 13. Красно-черные деревья
 367
 13.4. Дерамиды3
 Если мы вставляем в бинарное дерево поиска набор из п элементов, то по
 лученное в результате дерево может оказаться ужасно несбалансированным, что 
приводит к большому времени поиска. Однако, как мы видели в разделе 12.4, 
случайные бинарные деревья поиска обычно оказываются достаточно сбаланси
 рованными. Таким образом, стратегия построения сбалансированного дерева для 
фиксированного множества элементов состоит в их случайной перестановке с по
 следующей вставкой в дерево.
 Но что делать, если все элементы недоступны одновременно? Если мы полу
 чаем элементы по одному, можем ли мы построить из них случайное бинарное 
дерево поиска?
 Рассмотрим структуру данных, которая позволяет положительно ответить на 
этот вопрос. Дерамида представляет собой бинарное дерево поиска с модифици
 рованным способом упорядочения узлов. Пример дерамиды показан на рис. 13.9. 
Как обычно, каждый узел х в дереве имеет значение ключа х.кеу. Кроме того, 
мы назначим каждому узлу атрибут х.priority, который представляет собой слу
 чайное число, выбираемое для каждого узла независимо от других. Мы считаем, 
что все приоритеты и все ключи в дереве различны. Узлы дерамиды упорядочены 
таким образом, чтобы ключи подчинялись свойству бинарных деревьев поиска, 
а приоритеты — свойству неубывающей пирамиды.
 • Если v является левым дочерним узлом узла и, то v. key < и. key.
 • Если v является правым дочерним узлом узла и, то v. key > и. key.
 • Если v является дочерним узлом узла и, то v. priority > и. priority.
 Рис. 13.9. Дерамида. Каждый узел х помечен атрибутами х.кеу. х.priority. Например, корень 
имеет ключ G и приоритет 4.
 Именно эта комбинация свойств дерева и пирамиды и дала название “дерамида” 
(treap).
 Помочь разобраться в дерамидах может следующая интерпретация. Предпо
 ложим, что мы вставляем в дерамиду узлы х\,Х2,... ,хп со связанными с ни
 3В оригинале — “treap”; слово, образованное из двух — “tree” и “heap” Аналогично из слов “дерево” и “пи
 рамида” получился русский эквивалент. — Примеч. пер.
368
 Часть III. Структуры данных
 ми ключами. Тогда полученная в результате дерамида представляет собой де
 рево, которое получилось бы в результате вставки узлов в обычное бинарное 
дерево поиска в порядке, определяемом (случайно выбранными) приоритетами, 
т.е. Xi.priority < xj.priority означает, что узел Xi был вставлен до узла Xj.
 а. Покажите, что для каждого заданного множества узлов х\, Х2,..., хп со свя
 занными с ними ключами и приоритетами (все ключи и приоритеты различны) 
существует единственная дерамида.
 б. Покажите, что математическое ожидание высоты дерамиды равно 0(lgn) 
и, следовательно, время поиска заданного значения в дерамиде составляет
 0(lgn).
 Рассмотрим процесс вставки нового узла в существующую дерамиду. Первое, что 
мы делаем, — назначаем новому узлу случайное значение приоритета. Затем мы 
вызываем процедуру вставки, названную нами Treap-Insert, работа которой 
показана на рис. 13.10.
 в. Объясните, как работает процедура Treap-Insert. Поясните принцип ее ра
 боты обычным русским языком и приведите ее псевдокод. (Указание: выпол
 ните обычную вставку в бинарное дерево поиска, а затем выполните повороты 
для восстановления свойства неубывающей пирамиды.)
 г. Покажите, что ожидаемое время работы процедуры Treap-Insert составляет
 0(lgn).
 Процедура Treap-Insert выполняет поиск с последующей последовательно
 стью поворотов. Хотя эти две операции имеют одно и то же ожидаемое время 
работы, на практике стоимость этих операций различна. Поиск считывает инфор
 мацию из дерамиды, никак ее не изменяя. Повороты, напротив, приводят к изме
 нению указателей на дочерние и родительские узлы в дерамиде. На большинстве 
компьютеров операция чтения существенно более быстрая, чем операция запи
 си. Соответственно, желательно, чтобы поворотов при выполнении процедуры 
Treap-Insert было как можно меньше. Мы покажем, что ожидаемое количе
 ство выполняемых процедурой поворотов ограничено константой.
 Для этого необходимо дать несколько определений, проиллюстрированных на 
рис. 13.11. Левый хребет бинарного дерева поиска Т представляет собой простой 
путь от корня к узлу с минимальным значением ключа. Другими словами, левый 
хребет представляет собой простой путь, состоящий только из левых ребер. Соот
 ветственно, правый хребет представляет собой простой путь, состоящий только 
из правых ребер. Длина хребта — это количество составляющих его узлов.
 д. Рассмотрите дерамиду Т непосредственно после того, как в нее с помощью 
процедуры Treap-Insert вставляется узел х. Пусть С — длина правого хреб
 та левого поддерева х, a D — длина левого хребта правого поддерева х. Дока
 жите, что общее количество поворотов, которые были выполнены в процессе 
вставки х, равно С + D.
Глава 13. Красно-черные деревья
 369
 Рис. 13.10. Работа процедуры TREAP-INSERT. (а) Исходная дерамида до вставки, (б) Дерамида 
после вставки узла с ключом С и приоритетом 25. (в)-(г) Промежуточные стадии при вставке 
узла с ключом D и приоритетом 9. (д) Дерамида после выполнения вставки в частях (в) и (г), 
(е) Дерамида после вставки узла с ключом F и приоритетом 2.
 Рис. 13.11. Хребты бинарного дерева поиска. Левый хребет выделен в части (а), правый — в ча
 сти (Ь).
370
 Часть III. Структуры данных
 Теперь мы вычислим математическое ожидание значений С и D. Без потери 
общности будем считать, что ключи представляют собой натуральные числа 
1,2,..., п, поскольку мы сравниваем их только друг с другом.
 Пусть для узлов х и у (у ф х) дерамиды Т k = х. key и г = у. key. Определим 
индикаторную случайную величину
 Xik = I {у находится в правом хребте левого поддерева х] .
 е. Покажите, что Х^к = 1 тогда и только тогда, когда у.priority > х. priority, 
у. key < х. key, а для каждого г, такого, что у. key < z. key < х. key, мы имеем
 у.priority < z.priority.
 ж. Покажите, что
 з. Покажите, что
 Рг {Xik = 1} —(к — i — 1)! 
(к — i + 1)! 
1
 (к — i + 1 )(к — г)
 fc-i
 1 к
 и. Воспользуйтесь симметрией, чтобы показать, что
 1
 Е [D] = 1 —п — к + 1
 к. Сделайте вывод о том, что математическое ожидание количества поворотов, 
выполняемых при вставке узла в дерамиду, меньше 2.
 Заключительные замечания
 Идея балансировки деревьев поиска принадлежит советским математикам 
Г.М. Адельсону-Вельскому и Е.М. Ландису [2], которые в 1962 году предло
 жили класс сбалансированных деревьев поиска, получивших название “AVL-де- 
ревья” (описаны в задаче 13.3). Еще один класс деревьев поиска, называемых
 2-3-деревьями, был предложен Д.Э. Хопкрофтом (J.E. Hopcroft, не опубликова
 но) в 1970 году. Баланс этих деревьев поддерживается с помощью изменения 
степеней ветвления в узлах. Обобщение 2-3-деревьев, предложенное Байером
Глава 13. Красно-черные деревья
 371
 (Bayer) и Мак-Крейтом (McCreight) [34] под названием “В-деревья”, рассматри
 вается в главе 18.
 Красно-черные деревья были предложены Байером [33] под названием “сим
 метричные бинарные В-деревья” Гибас (Guibas) и Седжвик (Sedgewick) [154] 
детально изучили их свойства и предложили использовать концепцию красного 
и черного цветов. Андерссон (Andersson) [15] предложил вариант красно-черных 
деревьев, обладающих повышенной простотой кодирования (который был назван 
Вейссом (Weiss) [349] АА-деревьями). Эти деревья подобны красно-черным де
 ревьям с тем отличием, что левый потомок в них не может быть красным.
 Дерамиды, рассмотренные в задаче 13.4, были предложены Сиделем (Siedel) 
и Арагоном (Aragon) [307]. Они представляют собой реализацию словаря по 
умолчанию в LEDA [251], тщательно разработанном наборе структур данных 
и алгоритмов.
 Имеется множество других вариантов сбалансированных бинарных деревьев, 
включая взвешенно-сбалансированные деревья [262], деревья с к соседями [243], 
так называемые “деревья — козлы отпущения” (scapegoat trees) [126] и др. Воз
 можно, наиболее интересны “косые” деревья (splay trees), разработанные Слито- 
ром (Sleator) и Таржаном (Taijan) [318] и обладающие свойством саморегуляции 
(хорошее описание косых деревьев можно найти в работе Таржана [328]). Ко
 сые деревья поддерживают сбалансированность без использования дополнитель
 ных условий балансировки типа цветов. Вместо этого всякий раз при обращении 
над ним выполняются “косые” операции (включающие, в частности, повороты). 
Амортизированная стоимость (см. главу 17) таких операций в дереве с п узлами 
составляет O(lgn).
 Альтернативой сбалансированным бинарным деревьям поиска являются спис
 ки с пропусками (skip list) [284], которые представляют собой связанные списки, 
оснащенные рядом дополнительных указателей. Все словарные операции в таких 
списках с п элементами имеют ожидаемое время выполнения, равное O(lgn).
Глава 14. Расширение структур данных
 Зачастую на практике возникают ситуации, когда “классических” структур 
данных — таких, как дважды связанные списки, хеш-таблицы или бинарные дере
 вья поиска — оказывается недостаточно для решения поставленных задач. Одна
 ко только в крайне редких ситуациях приходится изобретать совершенно новые 
структуры данных; как правило, достаточно расширить существующую структуру 
путем хранения в ней дополнительной информации, что позволяет запрограмми
 ровать необходимую для данного приложения функциональность. Однако такое 
расширение структур данных — далеко не всегда простая задача, в первую оче
 редь, из-за необходимости обновления и поддержки дополнительной информации 
стандартными операциями над структурой данных.
 В этой главе рассматриваются две структуры данных, которые построены пу
 тем расширения красно-черных деревьев. В разделе 14.1 описывается структура, 
которая обеспечивает операции поиска порядковых статистик в динамическом 
множестве. С ее помощью мы можем быстро найти г-е по порядку наименьшее 
число или ранг данного элемента в упорядоченном множестве. В разделе 14.2 рас
 сматривается общая схема расширения структур данных и доказывается теорема, 
которая может упростить процесс расширения красно-черных деревьев. В разде
 ле 14.3 эта теорема используется при разработке структуры данных, поддержи
 вающей динамическое множество промежутков, например промежутков времени. 
Такая структура позволяет быстро находить в множестве промежуток, перекры
 вающийся с данным.
 14.1. Динамические порядковые статистики
 В главе 9 было введено понятие порядковой статистики. В частности, г-й по
 рядковой статистикой множества из п элементов (г Е {1,2,..., п}) является эле
 мент множества с г-м в порядке возрастания ключом. Мы видели, что любая по
 рядковая статистика может быть найдена в неупорядоченном множестве за время 
0{п). В этом разделе вы увидите, каким образом можно изменить красно-черные 
деревья для того, чтобы находить порядковую статистику за время O(lgn). Вы 
также узнаете, каким образом можно находить ранг элемента — его порядковый 
номер в линейно упорядоченном множестве — за то же время 0(lg п).
Глава 14. Расширение структур данных
 373
 Рис. 14.1. Дерево порядковой статистики, являющееся расширением красно-черного дерева. Свет
 лые узлы — красные, темные — черные. Помимо обычных атрибутов, каждый узел х имеет атрибут 
x.size, который представляет собой количество узлов, отличных от ограничителя, в поддереве 
с корнем х.
 На рис. 14.1 показана структура данных, которая поддерживает быстрые опе
 рации порядковой статистики. Дерево порядковой статистики Т (order-statistic 
tree) представляет собой просто красно-черное дерево с дополнительной инфор
 мацией, хранящейся в каждом узле. Помимо обычных атрибутов узлов красно
 черного дерева x.key, х. color, х.р, x.left и х. right, у каждого узла дерева по
 рядковой статистики имеется атрибут x.size. Этот атрибут содержит количество 
внутренних узлов в поддереве с корневым узлом х (включая сам х), т.е. размер 
поддерева. Если мы определим размер ограничителя как 0, т.е. Т. nil. size = 0, то 
получим тождество
 х. size = х. left, size + х. right, size + 1 .
 В дереве порядковой статистики условие различности всех ключей не ставит
 ся. Например, на рис. 14.1 имеются два ключа со значением 14, и два — со значе
 нием 21. При наличии одинаковых ключей определение ранга оказывается нечет
 ким, и мы устраняем неоднозначность дерева порядковой статистики, определяя 
ранг элемента как позицию, в которой будет выведен данный элемент при центри
 рованном обходе дерева. Например, на рис. 14.1 ключ 14, хранящийся в черном 
узле, имеет ранг 5, а в красном — ранг 6.
 Выборка элемента с заданным рангом
 Перед тем как будет изучен вопрос об обновлении информации о размере 
поддеревьев в процессе вставки и удаления, давайте посмотрим на реализацию 
двух запросов порядковой статистики, которые используют дополнительную ин
 формацию. Начнем с операции поиска элемента с заданным рангом. Процедура 
OS-Select(х , i) возвращает указатель на узел, содержащий г-й в порядке воз
 растания ключ в поддереве, корнем которого является х (так что для поиска г-го 
в порядке возрастания ключа в дереве порядковой статистики Т мы вызываем 
процедуру как OS-Select{Т.root, г)).
374
 OS-Select (x,i)
 1 г = х. left, size + 1
 2 if i == r
 3 
return x
 4 
5 
elseif i < r
 return OS-SELECT(x./e/£, г)
 6 else return OS-Select(x. right, i — r)
 Часть III. Структуры данных
 В строке 1 псевдокода процедуры OS-SELECT мы вычисляем г — ранг узла х 
в поддереве, для которого он является корнем. Значение х. left, size представляет 
собой количество узлов, которые идут до х в центрированном обходе поддерева 
с корнем х. Таким образом, х. left, size + 1 является рангом х в поддереве с кор
 нем х. Если i = г, то узел х является г-м в порядке возрастания элементом, и мы 
возвращаем его в строке 3. Если же г < г, то г-й в порядке возрастания элемент 
находится в левом поддереве, так что мы рекурсивно ищем его в поддереве x.left 
в строке 5. Если же г > г, то искомый элемент находится в правом поддереве, 
и мы делаем соответствующий рекурсивный вызов в строке 6 с учетом того, что 
г-й в порядке возрастания в дереве с корнем х элемент является (г — г)-м в по
 рядке возрастания в правом поддереве х с корнем в х. right.
 Для того чтобы увидеть описанную процедуру в действии, рассмотрим по
 иск 17-го в порядке возрастания элемента в дереве порядковой статистики на 
рис. 14.1. Мы начинаем поиск с корневого узла, ключ которого равен 26, с г = 17. 
Поскольку размер левого поддерева элемента с ключом 26 равен 12, ранг самого 
элемента — 13. Теперь мы знаем, что элемент с рангом 17 является 17 — 13 = 4-м 
в порядке возрастания элементом в правом поддереве элемента с ключом 26. По
 сле соответствующего рекурсивного вызова х становится узлом с ключом 41, 
а г = 4. Поскольку размер левого поддерева узла с ключом 41 равен 5, ранг этого 
узла в поддереве равен 6. Теперь мы знаем, что искомый узел находится в левом 
поддереве узла с ключом 41 и его номер в порядке возрастания — 4. После оче
 редного рекурсивного вызова х становится элементом с ключом 30, а его ранг — 
2, и мы рекурсивно ищем элемент с рангом 4 — 2 = 2 в поддереве, корнем которо
 го является узел с ключом 38. Размер его левого поддерева равен 1, так что ранг 
самого узла с ключом 38 равен 2, и это и есть наш искомый элемент, указатель 
на который и возвращает процедура.
 Поскольку каждый рекурсивный вызов опускает нас на один уровень в дереве 
порядковой статистики, общее время работы процедуры OS-Select в наихудшем 
случае пропорционально высоте дерева. Поскольку рассматриваемое нами дерево 
порядковой статистики является красно-черным, его высота равна 0(lg п), где п — 
количество узлов в дереве. Следовательно, время работы процедуры OS-Select 
в динамическом множестве из п элементов равно O(lgn).
 Определение ранга элемента
 Процедура О S-Rank, псевдокод которой приведен далее, по заданному ука
 зателю на узел х дерева порядковой статистики Т возвращает позицию данного 
узла при центрированном обходе дерева.
Глава 14. Расширение структур данных
 OS-Rank(T,x)
 1 г = х. left, size + 1
 2 у = х
 3 while у фТ. root
 4 
if у-- у.р. right
 5 
6 
г = г + у.р.left, size + 1
 у = у.р
 7 return г
 375
 Процедура работает следующим образом. Ранг х можно рассматривать как 
число узлов, предшествующих х при центрированном обходе дерева, плюс 1 для 
самого узла х. Процедура ОS-Rank поддерживает следующий инвариант цикла.
 В начале каждой итерации цикла while в строках 3-6 г представляет собой 
ранг х.кеу в поддереве, корнем которого является узел у.
 Мы воспользуемся этим инвариантом для того, чтобы показать корректность ра
 боты процедуры OS-Rank.
 Инициализация. Перед первой итерацией строка 1 устанавливает г равным ран
 гу х.кеу в поддереве с корнем х. Присвоение у = х в строке 2 делает инва
 риант истинным при первом выполнении проверки в строке 3.
 Сохранение. В конце каждой итерации цикла while выполняется присвоение 
у = у.р. Таким образом, необходимо показать, что если г — ранг х .key в под
 дереве с корнем у в начале выполнения тела цикла, то в конце г становится 
рангом х.кеу в поддереве, корнем которого является у.р. В каждой итерации 
цикла while мы рассматриваем поддерево, корнем которого является у.р. Мы 
уже подсчитали количество узлов в поддереве с корнем в узле у, который 
предшествует х при центрированном обходе дерева, так что теперь мы долж
 ны добавить узлы из поддерева, корнем которого является “брат” у (и который 
также предшествует х при центрированном обходе дерева), и добавить 1 для 
самого у.р, если, конечно, этот узел также предшествует х. Если у — левый 
дочерний узел, то ни у.р, ни любой узел из правого поддерева у.р не может 
предшествовать х, так что г остается неизменным. В противном случае у яв
 ляется правым дочерним узлом, и все узлы в поддереве левого потомка у.р 
предшествуют х, так же как и самому у.р. Соответственно, в строке 5 мы 
добавляем у.р. left, size + 1 к текущему значению г.
 Завершение. Цикл завершается, когда у = T.root, так что поддерево, корнем 
которого является у, представляет собой все дерево целиком, и, таким образом, 
г является рангом х. key в дереве в целом.
 В качестве примера рассмотрим работу процедуры OS-Rank с деревом по
 рядковой статистики, показанным на рис. 14.1. Если мы будем искать ранг узла 
с ключом 38, то получим следующую последовательность значений у.key и г 
в начале цикла while.
376
 Часть III. Структуры данных
 Итерация у.key г
 1
 38
 2
 3
 4
 30
 41
 26
 2
 4
 4
 17
 Процедура возвращает ранг 17.
 Поскольку каждая итерация цикла while занимает время 0(1), а у при каждой 
итерации поднимается на один уровень вверх, общее время работы процедуры 
OS-Rank в наихудшем случае пропорционально высоте дерева, т.е. равно 0(lg п) 
в случае дерева порядковой статистики с п узлами.
 Поддержка размера поддеревьев
 При наличии атрибута size в каждом узле процедуры OS-SELECT и OS-RANK 
позволяют быстро вычислять порядковые статистики. Однако этот атрибут будет 
совершенно бесполезным без корректного обновления базовыми модифицирую
 щими операциями над красно-черными деревьями. Давайте рассмотрим, какие 
изменения нужно внести в алгоритмы вставки и удаления для того, чтобы они 
поддерживали поля размеров поддеревьев при сохранении асимптотического вре
 мени работы каждой операции.
 В разделе 13.3 мы видели, что вставка в красно-черное дерево состоит из двух 
фаз. Первая фаза заключается в проходе вниз по дереву и вставке нового узла в ка
 честве дочернего для уже существующего. Во второй фазе выполняется проход 
вверх по дереву, при котором выполняются изменения цветов узлов и повороты 
для сохранения красно-черных свойств дерева.
 Для поддержки размеров поддеревьев в первой фазе достаточно просто уве
 личить значение х. size для каждого узла х на простом пути от корня к листьям. 
Новый узел получает значение атрибута size, равное 1. Поскольку вдоль пути 
имеется O(lgn) узлов, дополнительное время, требующееся для поддержания ат
 рибута size в первой фазе, составляет O(lgn).
 Во второй фазе структурные изменения дерева вызываются только поворота
 ми, которых, как мы знаем, может быть не больше двух. Кроме того, поворот 
является локальной операцией — после его выполнения становятся некорректны
 ми значения size только у двух узлов, вокруг связи между которыми выполняется 
поворот. Возвращаясь к коду Left-Rotate (Т, х ) в разделе 13.2, необходимо про
 сто добавить в него следующие строки.
 13 у. size — x.size
 14 х. size = х. left, size + x. right, size + 1
 На рис. 14.2 проиллюстрировано обновление атрибутов. Изменения процедуры 
Right-Rotate симметричны только что рассмотренным.
 Поскольку при вставке в красно-черное дерево выполняется не более двух 
поворотов, дополнительное время, требующееся для поддержки актуальности ат
 рибутов size во второй фазе, равно 0(1). Таким образом, общее время встав
Глава 14. Расширение структур данных
 377
 Рис. 14.2. Обновление размеров поддеревьев в процессе поворотов. Связь, вокруг которой осу
 ществляется поворот, соединяет два узла, атрибуты size которых следует обновить. Обновления 
локальны, требуют информации из атрибутов size узлов х, у и корней поддеревьев, показанных 
в виде треугольников.
 ки в дерево порядковой статистики с п узлами составляет O(lgn), т.е. остается 
асимптотически тем же, что и в случае обычного красно-черного дерева.
 Удаление узла из красно-черного дерева также представляет собой двухфаз
 ный процесс — первая фаза удаляет узел из дерева поиска, лежащего в основе 
красно-черного дерева, а вторая восстанавливает красно-черные свойства, выпол
 няя не более трех поворотов и не внося никаких других структурных изменений 
(см. раздел 13.4). В первой фазе из дерева извлекается узел у или выполняется 
его перемещение вверх по дереву. Для обновления размеров поддеревьев мы про
 сто проходим по простому пути от узла у (начиная с его исходного положения 
в дереве) до корня дерева, уменьшая величину атрибута size каждого узла на на
 шем пути. Поскольку длина этого пути в красно-черном дереве с п узлами равна 
O(lgn), дополнительное время, затрачиваемое на поддержку атрибута size в пер
 вой фазе, составляет 0(lg п). Во второй фазе обрабатываются 0(1) поворотов — 
тем же способом, что и в случае вставки. Итак, и вставка, и удаление в состоянии 
поддерживать корректность значений атрибутов size в дереве, при этом время их 
работы в дереве порядковой статистики с п узлами составляет O(lgn).
 Упражнения
 14.1.1
 Покажите, как работает вызов процедуры O S-Select (Т. root, 10) для красно-чер
 ного дерева Т, изображенного на рис. 14.1.
 14.1.2
 Покажите, как работает вызов процедуры OS-Rank(T, х ) для дерева Т, изобра
 женного на рис. 14.1, если х.кеу = 35.
 14.1.3
 Разработайте нерекурсивную версию процедуры OS-SELECT.
 14.1.4
 Разработайте рекурсивную процедуру OS-Key-Rank(T, к), которая получает 
в качестве входных параметров дерево порядковой статистики Т и ключ к и воз
 вращает значение ранга ключа к в динамическом множестве, представленном Т. 
Считаем, что все ключи в Т различны.
378
 Часть III. Структуры данных
 14.1.5
 Даны элемент х дерева порядковой статистики с п узлами и неотрицательное 
целое число г. Каким образом можно найти г-й в порядке возрастания элемент, 
начиная отсчет от х, за время O(lgn)?
 14.1.6
 Заметим, что процедуры OS-SELECT и OS-Rank используют атрибут size толь
 ко для вычисления ранга узла. Предположим, что вместо этого в каждом узле 
хранится его ранг в поддереве, корнем которого он является. Покажите, каким 
образом можно под держивать актуальность этой информации в процессе вставки 
и удаления (вспомните, что эти две операции могут выполнять повороты).
 14.1.7
 Покажите, как использовать дерево порядковой статистики для подсчета числа 
инверсий (см. задачу 2.4) в массиве размером п за время O(nlgn).
 14.1.8 *
 Рассмотрим п хорд окружности, каждая из которых определяется своими конеч
 ными точками. Опишите алгоритм определения количества пар пересекающихся 
хорд за время O(nlgn). (Например, если все п хорд представляют собой диамет
 ры, пересекающиеся в центре круга, то правильным ответом будет Q)). Считаем, 
что все конечные точки хорд различны.
 14.2. 
Расширение структур данных
 При разработке алгоритмов процесс расширения базовых структур данных 
для поддержки дополнительной функциональности встречается достаточно ча
 сто. В следующем разделе он будет использован для построения структур дан
 ных, которые поддерживают операции с промежутками. В данном разделе мы 
рассмотрим шаги, которые необходимо выполнить в процессе такого расшире
 ния, а также докажем теорему, которая во многих случаях позволяет упростить 
расширение красно-черных деревьев.
 Расширение структур данных можно разбить на четыре шага.
 1. Выбор базовой структуры данных.
 2. Определение необходимой дополнительной информации, которую следует 
хранить в базовой структуре данных и актуальность которой следует поддер
 живать.
 3. Проверка того, что дополнительная информация может поддерживаться ос
 новными модифицирующими операциями над базовой структурой данных.
 4. Разработка новых операций.
 Приведенные правила представляют собой общую схему, которой вы не обязаны 
жестко следовать. Проектирование — это искусство, зачастую опирающееся на
Глава 14. Расширение структур данных
 379
 метод проб и ошибок, и все шаги могут на практике выполняться параллельно. 
Так, нет особого смысла в определении дополнительной информации и разработ
 ке новых операций (шаги 2 и 4), если мы не в состоянии эффективно поддержи
 вать эту дополнительную информацию. Тем не менее описанная схема позволяет 
с пониманием дела направлять свои усилия, а также помочь в организации доку
 ментирования расширенной структуры данных.
 Мы следовали описанной схеме при разработке деревьев порядковой статисти
 ки в разделе 14.1. На шаге 1 в качестве базовой структуры данных мы выбрали 
красно-черные деревья в связи с их эффективной поддержкой других порядко
 вых операций над динамическим множеством, таких как Minimum, Maximum, 
Successor и Predecessor.
 На шаге 2 мы добавили в структуру данных атрибут size, в котором каждый 
узел х хранит размер своего поддерева. В общем случае дополнительная инфор
 мация делает операции более эффективными, что наглядно видно на примере 
операций OS-Select и OS-Rank, которые можно было бы реализовать и с ис
 пользованием одних лишь хранящихся в узлах ключей, но тогда они не могли бы 
выполняться за время O(lgn). Зачастую дополнительная информация представ
 ляет собой не данные, а указатели, как, например, в упр. 14.2.1.
 На шаге 3 мы убедились в том, что модифицирующие операции вставки и уда
 ления в состоянии поддерживать атрибут size с неизменным асимптотическим 
временем работы O(lgn). В идеале для поддержки дополнительной информации 
требуется обновлять только малую часть элементов структуры данных. Напри
 мер, если хранить в каждом узле его ранг в дереве, то процедуры OS-Select 
и OS-Rank будут работать быстро, но вставка нового минимального элемен
 та потребует при такой схеме внесения изменений в каждый узел дерева. При 
хранении размеров поддеревьев вставка нового элемента требует изменения ин
 формации только в O(lgn) узлах.
 Шаг 4 состоял в разработке операций OS-Select и OS-Rank. В конце кон
 цов, именно необходимость новых операций, в первую очередь, приводит нас 
к расширению структуры данных. Иногда вместо разработки новых операций 
мы используем дополнительную информацию для ускорения существующих, как 
в упр. 14.2.1.
 Расширение красно-черных деревьев
 При использовании в качестве базовой структуры данных красно-черных де
 ревьев можно доказать, что определенные виды дополнительной информации мо
 гут эффективно обновляться при вставках и удалениях, делая тем самым шаг 3 
очень простым. Доказательство следующей теоремы аналогично рассуждениям 
из раздела 14.1 о возможности поддержки атрибута size деревьями порядковой 
статистики.
 Теорема 14.1 (Расширение красно-черных деревьев)
 Пусть / представляет собой атрибут, который расширяет красно-черное дерево Т 
из п узлов, и пусть значение / каждого узла х зависит только от информации, 
хранящейся в узлах х, x.left и х. right, возможно, включая x.left.f и х. right./.
380
 Часть III. Структуры данных
 В таком случае мы можем поддерживать актуальность информации / во всех 
узлах дерева Т в процессе вставки и удаления без влияния на асимптотическое 
время работы данных процедур O(lgn).
 Доказательство. Основная идея доказательства заключается в том, что измене
 ние атрибута / узла х воздействует на значения атрибута / только у предков узла 
х. Иначе говоря, изменение x.f может потребовать обновления x.p.f, но не бо
 лее того; обновление x.p.f может привести только к необходимости обновления 
x.p.p.f, и так далее вверх по дереву. При обновлении T.root.f от этого значе
 ния не зависят никакие другие, так что процесс обновлений на этом завершается. 
Поскольку высота красно-черного дерева равна O(lgn), изменение атрибута / 
в некотором узле требует времени O(lgn) для обновления всех зависящих от 
него узлов.
 Вставка узла х в дерево Т состоит из двух фаз (см. раздел 13.3). Во время пер
 вой фазы узел х вставляется в дерево в качестве дочернего узла некоторого су
 ществующего узла х.р. Значение x.f можно вычислить за время 0(1), поскольку 
в соответствии с условием теоремы оно зависит только от информации в других 
атрибутах х и информации в дочерних по отношению к х узлах; однако дочер
 ними узлами х являются ограничители T.nil. После вычисления x.f изменения 
распространяются вверх по дереву. Таким образом, общее время выполнения пер
 вой фазы вставки равно O(lgn). Во время второй фазы единственным преобразо
 ванием, способным вызвать структурные изменения дерева, являются повороты. 
Поскольку при повороте изменения затрагивают только два узла, общее время, 
необходимое для обновления атрибутов /, — O(lgn) на один поворот. Поскольку 
при вставке выполняется не более двух поворотов, общее время работы процеду
 ры вставки равно O(lgn).
 Так же, как и вставка, удаление выполняется в две стадии (см. раздел 13.4). 
Сначала выполняются изменения в дереве, при которых удаляемый узел извлека
 ется из дерева. Если удаляемый узел имел в этот момент два дочерних узла, то 
следующий за ним в дереве узел перемещается в позицию удаленного узла. Рас
 пространение обновлений / имеют стоимость не более 0(lg п) в силу локального 
характера вносимых изменений. На втором этапе при восстановлении красно-чер
 ных свойств выполняется не более трех поворотов, каждый из которых требует 
для распространения обновлений / времени, не превышающего O(lgn). Таким 
образом, общее время удаления составляет O(lgn). 
■
 Во многих случаях (в частности, в случае атрибутов size в деревьях порядко
 вой статистики) время, необходимое для обновления атрибутов после вращения, 
составляет 0(1), а не O(lgn), полученное в доказательстве теоремы 14.1. Пример 
такого поведения можно найти в упр. 14.2.3.
 Упражнения
 14.2.1
 Покажите, каким образом расширить дерево порядковой статистики, чтобы опе
 рации Maximum, Minimum, Successor и Predecessor выполнялись за время
Глава 14. Расширение структур данных
 381
 0(1) в наихудшем случае. Асимптотическая производительность остальных опе
 раций над деревом порядковой статистики должна при этом остаться неизменной.
 14.2.2
 Может ли черная высота узлов в красно-черном дереве поддерживаться как ат
 рибут узла дерева без изменения асимптотической производительности операций 
над красно-черными деревьями? Покажите, как этого достичь (или докажите, что 
это невозможно).
 14.2.3 ★
 Пусть ® представляет собой ассоциативный бинарный оператор, а а — атри
 бут, поддерживаемый в каждом узле красно-черного дерева. Предположим, что 
мы хотим включить в каждый узел х дополнительный атрибут /, такой, что 
x.f = х\. а ® Х2- a <S> • • • <8> хт. а, где х\, Х2, ■ ■ ■, хт — центрированный список 
узлов поддерева, корнем которого является х. Покажите, как обновлять атрибу
 ты / после поворотов за время 0(1). Примените свои рассуждения, слегка их 
модифицировав, к атрибутам size в дереве порядковой статистики.
 14.2.4 ★
 Мы хотим добавить к красно-черным деревьям операцию RB-Enumerate(x, 
а, 6), которая выводит все ключи а < k < b в красно-черном дереве, корнем ко
 торого является х. Опишите, как можно реализовать процедуру RB-Enumerate, 
чтобы время ее работы составляло 0(m + lgn), где т — число выводимых клю
 чей, ап — количество внутренних узлов в дереве. {Указание: нет необходимости 
добавлять новые атрибуты в красно-черное дерево.)
 14.3. 
Деревья отрезков
 В этом разделе мы расширим красно-черные деревья для поддержки операций 
над динамическими множествами отрезков. Отрезком называется упорядоченная 
пара действительных чисел 
таких, что t\ < £2. Отрезок [^,£2] представля
 ет множество {£ £ R : t\ < t < £2}- Интервал (£i, £2) представляет собой отрезок 
без конечных точек, т.е. множество (£Gl:£i<£< £2}, а полуинтервалы [£i, £2) 
и (£1, £2] образуются из отрезка при удалении из него одной из конечных точек. 
В случае, когда принадлежность концов несущественна, обычно говорят о про
 межутках. В данном разделе мы будем работать с отрезками, но расширение 
результатов на интервалы и полуинтервалы не должно составить для читателя 
никакого труда.
 Отрезки удобны для представления событий, которые занимают некоторый 
промежуток времени. Мы можем, например, сделать запрос к базе данных о том, 
какие события происходили в некоторый промежуток времени. Рассматриваемая 
в данном разделе структура данных обеспечивает эффективное средство для под
 держки такой базы данных, работающей с промежутками.
382
 Часть III. Структуры данных
 i
 (а)
 (б) 
(в)
 Рис. 14.3. Трихотомия отрезков гиг', (а) Если гиг' перекрываются, возможны четыре ситуации; 
в каждой из них г. low < г', high и г', low < г. high, (б) Отрезки не перекрываются и г. high < г', low. 
(в) Отрезки не перекрываются и г .high < г.low.
 Мы можем представить отрезок [<1,<г] в виде объекта г с атрибутами i.low = 
t\ {левый, или нижний, конец отрезка) и г. high = ty {правый, или верхний, 
конец). Мы говорим, что отрезки гиг ' перекрываются (overlap), если г П г' ф 
0, т.е. если i.low < г' .high и г' .low < i.high. Для любых двух отрезков гиг ' 
выполняется только одно из трех свойств (трихотомия отрезков) (рис. 14.3):
 а. гиг' перекрываются;
 б. г находится слева от г' (т.е. г. high < г', low);
 в. г находится справа от г' (т.е. г'.high < г.low).
 Дерево отрезков представляет собой красно-черное дерево, каждый элемент 
х которого содержит отрезок x.int. Деревья отрезков поддерживают следующие 
операции.
 Interval-Insert (Т, х) добавляет элемент х, атрибут int которого рассматрива
 ется как содержащий отрезок, в дерево отрезков Т.
 Interval-Delete (Т, х) удаляет элемент х из дерева отрезков Т.
 Interval-Search (Т, г) возвращает указатель на элемент х в дереве отрезков Т, 
такой, что x.int перекрывается с отрезком г, или указатель на ограничи
 тель Т. nil, если такого элемента во множестве нет.
 На рис. 14.4 показано, как дерево отрезков представляет множество отрезков. Да
 вайте рассмотрим этапы расширения структур данных из раздела 14.2 при реше
 нии задачи разработки дерева отрезков и реализации операций над ним.
 Шаг 1. Базовая структура данных
 В качестве базовой структуры данных мы выбираем красно-черное дерево, 
каждый узел х которого содержит отрезок x.int, а ключом узла является левый 
конец отрезка х. int. low. Таким образом, центрированный обход дерева приводит 
к перечислению отрезков в порядке сортировки по их левым концам.
Глава 14. Расширение структур данных
 (а)
 8i—19
 61----------------НО
 5>-------18
 01---------13
 I___I___I___L—
 о
 5 ' ' 10
 383
 26н26 
25i---------
19ы20
 17i--------119
 161-------------(21
 151-----------------------------
J___I___U
 15
 20
 н 23
 25
 н 30
 30
 Рис. 14.4. Дерево отрезков, (а) Множество из десяти отрезков, отсортированных снизу вверх 
по левой конечной точке, (б) Дерево отрезков, представляющее это множество. Каждый узел х 
содержит отрезок, показанный над пунктирной чертой, и максимальное значение конечной точки 
для всех отрезков поддерева с корнем х, показанное под пунктирной линией. Центрированный 
обход дерева перечисляет все узлы в отсортированном по левым концам порядке.
 Шаг 2. Дополнительная информация
 В дополнение к самим отрезкам каждый узел х содержит значение х. max, ко
 торое представляет собой максимальное значение всех конечных точек отрезков, 
хранящихся в под дереве, корнем которого является х.
 Шаг 3. Поддержка информации
 Необходимо убедиться в том, что вставка и удаление в дереве с п узлами могут 
быть выполнены за время O(lgn). Определить значение атрибута max в узле х 
можно очень просто с использованием атрибутов max дочерних узлов:
 х. max = max(x. int. high, x. left, max, x. right, max) .
 Таким образом, по теореме 14.1 вставка в дерево отрезков и удаление из него 
может быть выполнена за время O(lgn). В действительности, как показано 
в упр. 14.2.3 и 14.3.1, обновление атрибута max после вращения может быть 
выполнено за время 0(1).
384
 Часть III. Структуры данных
 Шаг 4. Разработка новых операций
 Единственная новая операция, которую мы хотим разработать, — это 
Interval-Search(T, г), которая осуществляет поиск в дереве Т отрезка, кото
 рый перекрывается с данным. Если такого отрезка в дереве нет, процедура воз
 вращает указатель на ограничитель Т. nil.
 Interval-Search (Т, г)
 1 х = T.root
 2 while х ф Т. nil и г не перекрывается с х. int
 3 
if х. left ф Т. nil и х. left, max > i. low
 4 
5 
x = x.left
 else x = x. right
 6 return x
 Для поиска отрезка, который перекрывается с г, мы начинаем с присвоения указа
 телю х корня дерева и выполняем спуск по дереву. Спуск завершается, когда мы 
находим перекрывающийся отрезок или когда х указывает на ограничитель Т. nil. 
Поскольку каждая итерация основного цикла выполняется за время 0(1), а вы
 сота красно-черного дерева с п узлами равна O(lgn), время работы процедуры 
Interval-Search равно O(lgn).
 Прежде чем убедиться в корректности процедуры Interval-Search, давайте 
посмотрим, как она работает, на примере дерева, показанного на рис. 14.4. Пред
 положим, что мы хотим найти отрезок, перекрывающийся с отрезком г = [22,25]. 
Мы начинаем работу с корня, в котором содержится отрезок [16,21], который 
не перекрывается с отрезком г. Поскольку значение х. left, max = 23 превышает
 г. low = 22, цикл продолжает выполнение с х, указывающим на левый дочерний 
узел корня. Этот узел содержит отрезок [8,9], который также не перекрывается 
с отрезком г. Теперь x.left. max = 10 меньше i.low = 22, так что мы переходим 
к правому дочернему узлу. В нем содержится отрезок [15,23], перекрывающийся 
с х, так что процедура возвращает указатель на данный узел.
 В качестве примера неудачного поиска попробуем найти в том же дереве отре
 зок, перекрывающийся с отрезком г = [11,14]. Мы вновь начинаем с корня. По
 скольку отрезок в корне [16,21] не перекрывается с г и поскольку х. left, max = 23 
больше, чем г. low = 11, мы переходим к левому дочернему узлу корня с отрезком 
[8,9]. Отрезок [8,9] также не перекрывается с г, a x.left. max = 10, что меньше, 
чем i.low = 11, поэтому мы переходим вправо (обратите внимание, что теперь 
в левом поддереве нет ни одного отрезка, перекрывающегося с г). Отрезок [15,23] 
не перекрывается с г, его левый дочерний узел — Т. nil, так что цикл завершается 
и процедура возвращает указатель на ограничитель Т. nil.
 Для того чтобы убедиться в корректности процедуры Interval-Search, нуж
 но разобраться, почему для поиска достаточно пройти по дереву всего лишь по 
одному пути от корня. Основная идея заключается в том, что в любом узле х, если 
х. int не перекрывается с г, дальнейший поиск всегда идет в безопасном направ
 лении, т.е. перекрывающийся отрезок, если таковой имеется в дереве, гаранти
 рованно будет обнаружен в исследуемой части дерева. Более точно это свойство 
сформулировано в следующей теореме.
Глава 14. Расширение структур данных
 385
 Теорема 14.2
 Любой вызов процедуры Interval-Search(Т, г) возвращает либо узел, отрезок 
которого перекрывается с отрезком г, либо, если в дереве Т не содержится отрез
 ка, перекрывающегося с г, Т. nil.
 Доказательство. Цикл while в строках 2-5 завершается, если х = Т. nil либо 
если г перекрывается с х. int. В последнем случае процедура тривиально возвра
 щает корректное значение х. Поэтому нас интересует первый случай, когда цикл 
завершается из-за того, что х = Т. nil.
 Воспользуемся следующим инвариантом цикла while в строках 2-5.
 Если дерево Т содержит отрезок, который перекрывается с г, то этот отре
 зок находится в поддереве, корнем которого является узел х.
 Исследуем этот инвариант цикла как обычно.
 Инициализация. Перед выполнением первой итерации в строке 1 переменной х 
присваивается указатель на корень дерева Т, так что инвариант выполняется.
 Сохранение. При каждой итерации цикла while выполняется либо строка 4, либо 
строка 5. Покажем, что инвариант цикла сохраняется в любом случае.
 Если выполняется строка 5, то в силу ветвления в строке 3 мы имеем х. left = 
Т. nil или х. left, max < i. low. Если x. left = T. nil, поддерево с корнем x. left, 
очевидно, не содержит отрезка, перекрывающегося с г, и присвоение х значе
 ния х. right сохраняет инвариант. Предположим, следовательно, что х. left ф 
Т. nil и х. left, max < i. low. Как показано на рис. 14.5, (а), для каждого отрезка 
i' в левом поддереве х имеем
 i'.high < х. left, max 
< i. low .
 Согласно трихотомии отрезков г' и г не перекрываются. Таким образом, левое 
поддерево х не содержит отрезков, перекрывающихся с г, так что присвоение х 
значения х. right сохраняет инвариант.
 /
 i
 (а) 
(б)
 Рис. 14.5. Отрезки в доказательстве теоремы 14.2. Значение х. left, max показано в обоих случаях 
пунктирной линией, (а) Поиск выполняется вправо. В левом поддереве х нет отрезка г', перекрыва
 ющегося с г. (б) Поиск выполняется влево. Левое поддерево х содержит отрезок, перекрывающийся 
с г (ситуация не показана), либо отрезок г', такой, что г', high = х. left. max. Поскольку г не пере
 крывается с Г, он не перекрывается и ни с одним из отрезков i" в правом поддереве х, поскольку 
i'. low < г". low.
 13 Зак. 3726
386
 Часть III. Структуры данных
 Если же выполняется строка 4, то, как мы покажем, если в левом поддереве х 
нет отрезка, перекрывающегося с г, то его вообще нет в дереве. Поскольку 
выполняется строка 4, в силу условия в строке 3 имеем х. left, max > i.low. 
Кроме того, по определению атрибута max в левом поддереве х должен быть 
некоторый интервал г', такой, что
 i'. high = х. left, max 
> i. low .
 (Эта ситуация проиллюстрирована на рис. 14.5, (б).) Поскольку г и г' не пере
 крываются и поскольку неверно, что г'.high < г. low, отсюда в соответствии со 
свойством трихотомии отрезков следует, что г. high < г', low. Поскольку дерево 
отрезков упорядочено в соответствии с левыми концами отрезков, из свойства 
дерева поиска вытекает, что для любого отрезка i" из правого поддерева х
 i.high < i'.low 
< i". low .
 Из трихотомии отрезков следует, что г и г" не перекрываются. Мы можем, 
таким образом, заключить, что независимо от того, имеется ли в левом подде
 реве х отрезок, перекрывающийся с г, присвоение х значения х. left сохраняет 
инвариант цикла.
 Завершение. Если цикл завершается по условию х = Т. nil, то в дереве, корнем 
которого является х, нет отрезков, перекрывающихся с г. Обращение инвари
 анта цикла приводит к заключению, что дерево Т не содержит отрезков, пе
 рекрывающихся с г. Следовательно, возвращаемое процедурой значение Т. nil 
совершенно корректно. 
■
 Таким образом, процедура Interval-Search работает корректно.
 Упражнения
 14.3.1
 Напишите псевдокод процедуры Left-Rotate, которая работает с узлами дерева 
отрезков и обновляет атрибуты max за время 0(1).
 14.3.2
 Перепишите код процедуры Interval-Search для корректной работы с интер
 валами (отрезками без конечных точек).
 14.3.3
 Разработайте эффективно работающий алгоритм, который для данного отрезка 
г возвращает отрезок, перекрывающийся с г и имеющий минимальное значение 
левого конца (либо Т. nil, если такого отрезка не существует).
Глава 14. Расширение структур данных
 387
 14.3.4
 Пусть имеется дерево отрезков Т и отрезок г. Опишите, каким образом 
найти в дереве Т все отрезки, перекрывающиеся с отрезком г, за время 
0(min(n, k lgn)), где к — количество отрезков в выводимом списке. (Указание: 
один простой метод выполняет запросы, меняя между ними само дерево. Попро
 буйте найти немного более сложное решение, не изменяющее дерево.)
 14.3.5
 Какие изменения следует внести в процедуры дерева отрезков для поддержки 
новой операции Interval-Search-Exactly(T, г), которая получает в качестве 
параметров дерево отрезков Т и отрезок г и возвращает указатель на узел х, 
такой, что x.int.low = i.low и x.int.high = i.high (либо T.nil, если такого узла 
в дереве Т нет). Все операции, включая Interval-Search-Exactly, должны 
выполняться в дереве с п узлами за время О (lgn).
 14.3.6
 Пусть есть динамическое множество чисел Q, поддерживающее операцию MIN- 
Gap, возвращающую минимальное расстояние между соседними числами в Q. 
Например, если Q = {1,5,9,15,18,22}, то Min-Gap(Q) возвратит значение 18 — 
15 = 3, так как 15 и 18 — ближайшие соседние числа в Q. Разработайте макси
 мально эффективные процедуры Insert, Delete, Search и Min-Gap и проана
 лизируйте их время работы.
 14.3.7 *
 Базы данных при разработке СБИС зачастую представляют интегральную схему 
как список прямоугольников. Предположим, что все прямоугольники ориентиро
 ваны вдоль осей х и у, так что представление прямоугольника состоит из мини
 мальных и максимальных координат х и у. Разработайте алгоритм для выяснения, 
имеются ли в данном множестве из п прямоугольников два перекрывающихся 
(искать все перекрывающиеся пары не нужно). Перекрытием считается также си
 туация, когда один прямоугольник лежит полностью внутри другого, пусть при 
этом их границы и не пересекаются. Время работы алгоритма должно составлять 
O(nlgn). (Указание: перемещайте “строку развертки” по множеству прямоуголь
 ников.)
 Задачи
 14.1. Точка максимального перекрытия
 Предположим, что необходимо найти точку максимального перекрытия мно
 жества отрезков, т.е. точку, в которой перекрывается наибольшее количество от
 резков множества.
 а. Покажите, что такая точка всегда имеется и представляет собой конечную 
точку одного из отрезков.
388
 Часть III. Структуры данных
 б. Разработайте структуру данных, которая поддерживает эффективную работу 
операций Interval-Insert, Interval-Delete и Find-POM (которая воз
 вращает точку максимального перекрытия). (Указание: воспользуйтесь крас
 но-черным деревом всех конечных точек отрезков. С каждым левым концом 
отрезка связано значение +1, с правым — значение —1. Добавьте к узлам дере
 ва некоторую дополнительную информацию для поддержки точки максималь
 ного перекрытия.)
 14.2. Перестановка Иосифа
 Задача Иосифа} формулируется следующим образом. Предположим, что п 
человек расставлены по кругу и задано некоторое натуральное число т < п. На
 чиная с определенного человека, мы идем по кругу, удаляя каждого m-го челове
 ка. После удаления человека счет продолжается дальше. Процесс продолжается, 
пока все п человек не будут удалены. Порядок, в котором люди удаляются из кру
 га, определяет (п, т)-перестановку Иосифа целых чисел 1,2,... ,п. Например,
 (7,3)-перестановка Иосифа имеет вид (3,6,2,7,5,1,4).
 а. Пусть т — некоторая фиксированная константа. Разработайте алгоритм, кото
 рый для данного п за время 0(п) выводит (п, га) -перестановку Иосифа.
 б. Пусть га не является константой. Разработайте алгоритм, который для данных 
питза время O(nlgn) выводит (п, га)-перестановку Иосифа.
 Заключительные замечания
 В книге [280] Препарата (Preparata) и Шамос (Shamos) описывают ряд дере
 вьев отрезков, встречавшихся литературе, и приводят результаты из работ Эдель- 
сбруннера (Н. Edelsbrunner, 1980) и Мак-Крейта (McCreight, 1981). В книге де
 тально описано дерево отрезков, в котором для данной статической базы данных 
из п отрезков все к отрезков, перекрывающихся с заданным, могут быть найдены 
за время О (к + lgn).
 1 Достаточно подробно об этой задаче, ее происхождении и вариациях, можно прочесть, например, в книге 
У. Болл, Г. Коксетер. Математические эссе и развлечения. — М.: Мир, 1986. — С. 43-47. — Примеч. ред.
IV Усовершенствованные методы 
разработки и анализа
Введение
 В этой части описаны три важных метода разработки и анализа эффективных 
алгоритмов: динамическое программирование (глава 15), жадные алгоритмы (гла
 ва 16) и амортизационный анализ (глава 17). В предыдущих частях были пред
 ставлены другие широко распространенные методы, такие как метод “разделяй 
и властвуй”, рандомизация и решение рекуррентных соотношений. Новые подхо
 ды, с которыми вам предстоит ознакомиться в этой части, более сложные, однако 
они полезны для решения многих вычислительных задач. К темам, рассмотрен
 ным в данной части, мы еще обратимся позже в данной книге.
 Динамическое программирование обычно находит применение в задачах оп
 тимизации, в которых для получения оптимального решения необходимо сделать 
определенное множество выборов. После того как каждый из выборов сделан, 
часто возникают вспомогательные подзадачи того же вида. Динамическое про
 граммирование эффективно тогда, когда определенная вспомогательная подзадача 
может возникнуть в результате нескольких вариантов выбора. Основной метод ре
 шения таких задач заключается в сохранении решения каждой подзадачи, которая 
может возникнуть повторно. В главе 15 показано, как благодаря этой простой идее 
алгоритм, время решения которого экспоненциально зависит от объема входных 
данных, иногда можно преобразовать в алгоритм с полиномиальным временем 
работы.
 Жадные алгоритмы, подобно алгоритмам, применяемым в динамическом про
 граммировании, используются в задачах оптимизации, для рационального реше
 ния которых требуется сделать ряд выборов. Идея, лежащая в основе жадного 
алгоритма, заключается в том, чтобы каждый выбор был локально оптимальным. 
В качестве простого примера приведем задачу о выдаче сдачи: чтобы свести к ми
 нимуму количество монет, необходимых для выдачи определенной суммы, доста
 точно каждый раз выбирать монету наибольшего достоинства, не превышающую
Часть IV. Усовершенствованные методы разработки и анализа
 391
 той суммы, которую осталось выдать.1 Можно сформулировать много таких за
 дач, оптимальное решение которых с помощью жадных алгоритмов получает
 ся намного быстрее, чем с помощью методов динамического программирования. 
Однако не всегда просто выяснить, окажется ли эффективным жадный алгоритм. 
В главе 16 приводится обзор теории матроида, которая часто оказывается полез
 ной для принятия подобных решений.
 Амортизационный анализ — это средство анализа алгоритмов, в которых вы
 полняется последовательность однотипных операций. Вместо того чтобы накла
 дывать границы на время выполнения каждой операции, с помощью амортизаци
 онного анализа оценивается длительность работы всей последовательности в це
 лом. Одна из причин эффективности этой идеи заключается в том, что в неко
 торых последовательностях операций невозможна ситуация, когда время работы 
всех индивидуальных операций является наихудшим. Зачастую одни операции 
в таких последовательностях оказываются дорогостоящими в плане времени ра
 боты, в то время как многие другие — дешевыми. Заметим, что амортизационный 
анализ — это не просто средство анализа. Его можно рассматривать и как метод 
разработки алгоритмов, поскольку разработка и анализ времени работы алгорит
 мов часто тесно переплетаются. В главе 17 излагаются основы трех способов 
амортизационного анализа алгоритмов.
 1Следует отметить, что возможны такие экзотические наборы монет, когда жадный алгоритм дает неверное 
решение. — Примеч. ред.
Глава 15 Динамическое программирование
 Динамическое программирование, как и метод “разделяй и властвуй”, позволя
 ет решать задачи, комбинируя решения вспомогательных подзадач. (Термин “про
 граммирование” в данном контексте означает табличный метод, а не составление 
компьютерного кода.) Мы уже видели в главах 2 и 4, как в алгоритмах “разделяй 
и властвуй” задача делится на несколько независимых подзадач, каждая из кото
 рых решается рекурсивно, после чего из решений подзадач формируется решение 
исходной задачи. Динамическое программирование, напротив, находит примене
 ние тогда, когда подзадачи перекрываются, т.е. когда разные подзадачи исполь
 зуют решения одних и тех же подзадач. В этом контексте алгоритм “разделяй 
и властвуй”, многократно решая задачи одних и тех же типов, выполняет больше 
действий, чем необходимо. В алгоритме динамического программирования каж
 дая подзадача решается только один раз, после чего ответ сохраняется в таблице. 
Это позволяет избежать одних и тех же повторных вычислений каждый раз, когда 
встречается данная, уже решенная ранее, подзадача.
 Динамическое программирование, как правило, применяется к задачам оп
 тимизации (optimization problems). Такая задача может иметь много возможных 
решений. С каждым вариантом решения можно сопоставить какое-то значение, 
и нам нужно найти среди них решение с оптимальным (минимальным или макси
 мальным) значением. Назовем такое решение одним из возможных оптимальных 
решений. В силу того, что таких решений с оптимальным значением может быть 
несколько, следует отличать их от единственного оптимального решения.1
 Процесс разработки алгоритмов динамического программирования можно раз
 бить на четыре перечисленных ниже этапа.
 1. Описание структуры оптимального решения.
 2. Определение значения, соответствующего оптимальному решению, с исполь
 зованием рекурсии.
 3. Вычисление значения, соответствующего оптимальному решению, обычно 
с помощью метода восходящего анализа.
 4. Составление оптимального решения на основе информации, полученной на 
предыдущих этапах.
 1В оригинале использованы различные артикли и говорится об “an optimal solution” и “the optimal 
solution” — Примеч. пер.
"лава 15. Динамическое программирование
 Длина i 1 2 3 4 5 6 7 8 9 10
 Цена pi 1 5 8 9 10 17 17 20 24 30
 393
 Рис. 15.1. Пример таблицы цен отрезков стержня. Каждый отрезок длиной i приносит компании 
прибыль рг.
 Этапы 1-3 составляют основу метода динамического программирования для ре
 шения задач. Этап 4 может быть опущен, если требуется узнать только значе
 ние, соответствующее оптимальному решению. На этапе 4 иногда используется 
дополнительная информация, полученная на этапе 3, что облегчает процесс кон
 струирования оптимального решения.
 В последующих разделах метод динамического программирования использу
 ется для решения некоторых задач оптимизации. В разделе 15.1 исследуется за
 дача разрезания стержня на меньшие стержни таким образом, чтобы получить 
за них максимальную прибыль. В разделе 15.2 исследуется вопрос о том, в ка
 ком порядке следует выполнять перемножение нескольких матриц, чтобы свести 
к минимуму общее количество операций перемножения скаляров. На этих двух 
примерах в разделе 15.3 рассматриваются две основные характеристики, кото
 рыми должны обладать задачи, для которых подходит метод динамического про
 граммирования. Далее, в разделе 15.4, показано, как найти самую длинную об
 щую подпоследовательность двух последовательностей. Наконец в разделе 15.5 
с помощью динамического программирования конструируется дерево бинарного 
поиска, оптимальное для заданного распределения ключей, по которым ведется 
поиск.
 15.1. Разрезание стержня
 В нашем первом примере динамическое программирование применяется для 
решения простой задачи о том, как лучше разрезать стальные стержни. Компания 
“Навар лимитед” покупает длинные стальные стержни, режет их на куски и про
 дает. Сама порезка стержней не стоит компании ни копейки. Руководство “Навар 
лимитед” хочет знать, как лучше всего разрезать стержни на части.
 Предположим, что нам известны цены pi (г = 1,2,...), по которым компания 
продает куски длиной г. Длины кусков всегда представляют собой целые числа. 
На рис. 15.1 показан пример таблицы цен.
 Задача разрезания стержня формулируется следующим образом. Имеются 
стержень длиной п и таблица цен pi для i = 1,2,..., п. Необходимо найти мак
 симальную прибыль гп, получаемую при разрезании стержня и продаже полу
 ченных кусков. Заметим, что если цена рп стержня длиной п достаточно велика, 
оптимальное решение может состоять в продаже стержня целиком, без разрезов.
 Рассмотрим случай п = 4. На рис. 15.2 показаны все способы разрезания 
стержня длиной 4, включая вариант оставить его нетронутым. Как видно из ри
 сунка, оптимальным является разрезание стержня длиной 4 на два куска длиной 2, 
ЧТО приводит К прибыли Р2+Р2 = 5 + 5= 10.
394
 I ) ' )
 (а)
 1 
1 
(д)
 5
 ’ )
 Часть IV. Усовершенствованные методы разработки и анализа
 9
 1 
8
 (ГГ) ; - )
 (б)
 1 
5 
1
 5 
5
 8 
raim о~ т о
 (В)
 5 
(Г)
 1 
1
 1
 1 1 1 1
 шпп 0ZDQD+) fDISfDfD
 (е)
 (ж)
 (3)
 Рис. 15.2. Восемь возможных способов разрезания стержня длиной 4. Над каждым фрагментом 
стержня указана его цена в соответствии с таблицей на рис. 15.1. Оптимальная стратегия показана 
в части (в): она заключается в том, чтобы разрезать стержень на две части длиной 2 каждая с общей 
ценой 10.
 Стержень длиной п можно разрезать 2П-1 разными способами, поскольку мы 
можем независимо выбирать, резать его или нет на расстоянии г от левого конца, 
где г = 1,2,..., п — I.2 Мы будем записывать разбиение на части в виде обычного 
сложения, так что запись 7 = 2 + 2 + 3 означает, что стержень длиной 7 разрезан 
на три части: две длиной 2 и одну длиной 3. Если оптимальное решение состоит 
в разрезании стержня на к частей, для некоторого 1 < к < п, то оптимальное 
разбиение
 п = h + гг Н---------1-ik
 стержня на части длиной i\, гг, ...» ik дает соответствующую максимальную 
прибыль
 r n = Ph + Pi2 Н------+ Pik •
 В случае нашей конкретной задачи максимальные прибыли г*, г = 1,2,..., 10, 
получаются с помощью следующих разбиений:
 П = 1 из решения 1 = 1 (без разрезов) ,
 гг = 5 из решения 2 = 2 (без разрезов) ,
 гз = 8 из решения 3 = 3 (без разрезов) ,
 7*4 = 10 из решения 4 = 2 + 2,
 Г5 = 13 из решения 5 = 2 + 3,
 Гб = 17 из решения 6 = 6 (без разрезов) ,
 77 = 18 из решения 7= 1 + 6 или 7 = 2 + 2 + 3 ,
 7*8 = 22 из решения 8 = 2 + 6 ,
 7*9 = 25 из решения 9 = 3 + 6 ,
 7*10 = 30 из решения 10 = 10 (без разрезов) .
 2 Если потребовать, чтобы отрезаемые части располагались в неубывающем порядке, то придется рассмот
 реть меньшее количество вариантов разрезания. При п = 4 следует рассмотреть только 5 таких способов: части 
(а), (б), (в), (д) и (з) на рис. 15.2. Количество способов разрезания именуется функцией разбиения (partition
 function); оно приблизительно равно еп\/2п/ 3/ 4пл/3. Эта величина меньше, чем 2П-1, но все равно больше 
любого полинома от п. Однако мы не будем подробно исследовать этот вопрос.
Глава 15. Динамическое программирование
 395
 В общем случае можно записать значения гп для п > 1 через оптимальные 
прибыли от более коротких стержней:
 rn = max(pn,ri +г„_i,r2 +гп_2, ■ ■ • ,гп_1 +п) . 
(15.1)
 Первый аргумент, рп, соответствует продаже стержня длиной п как есть, без раз
 резов. Прочие п — 1 аргументов функции шах соответствуют максимальным до
 ходам, получаемым при первоначальном разрезании стержня на две части раз
 мерами i и п — г, для каждого г = 1,2,...,п — 1, с последующим оптимальным 
разрезанием второй части (при этом от полученных частей мы получаем доходы 
rj и rn-i). Поскольку заранее неизвестно, какое значение г оптимизирует при
 быль, придется рассмотреть все возможные значения г и выбрать из них то, кото
 рое максимизирует доход. Кроме того, возможно, следует не выбирать ни одного 
значения i вообще, а предпочесть продавать стержни неразрезанными.
 Заметим, что для решения исходной задачи размером п мы решаем меньшие 
задачи того же вида. Как только мы сделали первый разрез, мы можем рассмат
 ривать две части стержня как независимые экземпляры задачи разрезания стерж
 ня. Общее оптимальное решение включает оптимальные решения двух связанных 
подзадач, максимизирующих доходы от каждой из двух частей стержня. Мы гово
 рим, что задача разрезания стержня демонстрирует оптимальную подструктуру: 
оптимальное решение задачи включает оптимальные решения подзадач, которые 
могут быть решены независимо.
 В связанном, но немного более простом, способе организации рекурсивной 
структуры задачи разрезания стержня мы рассматриваем разрезание стержня как 
состоящее из первой части длиной i и остатка длиной п — г. Первая часть далее не 
разрезается; резать можно только остаток. Таким образом, мы можем рассматри
 вать любое разрезание стержня длиной п как первую часть и некоторое разделе
 ние на части остатка стержня без первой части. При этом допускается и решение 
без разрезов, если первая часть имеет размер г = п и дает прибыль рп, а оста
 ток длиной 0 дает нулевой доход. В итоге мы получаем более простую версию 
уравнения (15.1):
 тп — max (pi + rn-i) . 
1<г<п
 (15.2)
 В такой формулировке оптимальное решение включает решение только одной 
связанной подзадачи — разрезания остатка — вместо двух, как это было ранее.
 Рекурсивная нисходящая реализация
 Приведенная далее процедура реализует вычисления, неявно заключенные 
в уравнении (15.2), простым нисходящим рекурсивным способом.
396
 Cut-Rod (р, п)
 1 if п == О
 2 
return О
 3 q = —ос
 4 
for г = 1 to п
 5 
Часть IV. Усовершенствованные методы разработки и анализа
 q — таx(q,p[i] + CUT-ROD(p, п — г))
 6 return q
 Процедура CUT-ROD получает в качестве входных данных массив цен р[ 1.. п] 
и целое число п и возвращает максимально возможную прибыль для стерж
 ня длиной п. Если п = 0, прибыль невозможна, так что процедура CUT-ROD 
возвращает 0 в строке 2. Строка 3 инициализирует максимальную прибыль q 
значением — оо, так что цикл for в строках 4 и 5 корректно вычисляет q = 
maxi<i<n(pi + CUT-ROD(p, п — г)); затем строка 6 возвращает вычисленное значе
 ние. Простая индукция по п с использованием уравнения (15.2) доказывает, что 
этот ответ равен искомому значению гп.
 Если вы закодируете процедуру CUT-ROD на своем любимом языке програм
 мирования, то обнаружите, что, когда входные размеры становятся умеренно 
большими, программа начинает работать весьма медленно. При п — 40 програм
 ма на вашем компьютере будет работать как минимум несколько минут, а скорее 
всего — больше часа. Вы можете заметить, что при увеличении п на 1 время 
работы вашей программы примерно удваивается.
 Почему же процедура CUT-ROD столь неэффективна? Дело в том, что она 
рекурсивно вызывает сама себя вновь и вновь с одними и теми же значениями 
параметров; она многократно решает одни и те же подзадачи. На рис. 15.3 пока
 зано, что происходит при п = 4: CUT-ROD (р, п) вызывает CUT-ROD (р, п — i) для 
г = 1,2,..., п; или, что то же самое, CUT-ROD(p, п) вызывает Cut-Rod(p,j) для 
каждого j = 0,1,..., п — 1. Когда этот процесс рекурсивно разворачивается, рост 
количества выполняемой работы как функции от п носит взрывной характер.
 Чтобы проанализировать время работы процедуры CUT-ROD, обозначим через 
Т(п) общее количество вызовов CUT-ROD со вторым параметром, равным п. Это 
выражение равно числу узлов в поддереве с корнем с меткой п в дереве рекурсии. 
Это число включает и начальный вызов в корне. Таким образом, Г(0) = 1 и
 71— 1
 з=о
 (15.3)
 Начальная единица соответствует вызову в корне, а член T (j) учитывает коли
 чество вызовов (включая рекурсивные), связанных с вызовом CUT-ROD(р, п — г), 
где j = п — г. В упр. 15.1.1 требуется показать, что
 Т(п) = 2п
 (15.4)
 так что время работы процедуры CUT-ROD экспоненциально зависит от п.
Глава 15. Динамическое программирование
 397
 Рис. 15.3. Дерево рекурсии показывает рекурсивные вызовы, являющиеся результатом вызова 
Cut-Rod(p , п) для п = 4. Каждая метка узла указывает размер п соответствующей подзадачи, так 
что ребро от родительского узла с меткой я к дочернему узлу с меткой t соответствует отрезанию 
от стержня части размером я — t и решение подзадачи для оставшейся части размером t. Путь 
от корня к листу соответствует одному из 2n_1 способов разрезания стержня длиной п. В общем 
случае это дерево рекурсии имеет 2П узлов и 2n_1 листьев.
 В ретроспективе в этом экспоненциальном времени нет ничего удивительного. 
Процедура Cut-Rod явным образом рассматривает все 2n_1 возможных способа 
разрезания стержня длиной п. Дерево рекурсивных вызовов имеет 2П-1 листьев, 
по одному для каждого возможного разрезания стержня. Метки на простом пу
 ти от корня к листу указывают размеры правой части стержня перед каждым 
разрезанием. Иначе говоря, метки указывают соответствующие точки разрезов, 
отмеренные от правого конца стержня.
 Применение динамического программирования для оптимального 
разрезания стержня
 Теперь мы покажем, как превратить процедуру Cut-Rod в эффективный ал
 горитм, воспользовавшись динамическим программированием.
 Метод динамического программирования работает следующим образом. За
 метив, что имеющееся рекурсивное решение неэффективно из-за того, что мно
 гократно решаются одни и те же подзадачи, мы будем сохранять их решения, 
тем самым добиваясь только однократного решения подзадач. Если позже нам 
вновь придется решать такую подзадачу, мы просто найдем ее ответ, не решая 
ее заново. Таким образом, динамическое программирование использует дополни
 тельную память для экономии времени вычисления; это один из примеров про
 странственно-временного компромисса. Экономия времени работы может быть 
очень большой: решение с экспоненциальным временем работы можно превра
 тить в решение с полиномиальным временем. Подход с применением динамиче
 ского программирования решает поставленную задачу за полиномиальное время, 
если количество различных подзадач полиномиально зависит от размера входных 
данных, и мы можем решить каждую из них за полиномиальное время.
 Обычно имеется два эквивалентных способа реализации подхода динамиче
 ского программирования. Мы проиллюстрируем оба на примере задачи о разре
 зании стержня.
398
 Часть IV. Усовершенствованные методы разработки и анализа
 Первый подход — нисходящий с запоминанием (memoization3). При таком 
подходе мы пишем процедуру рекурсивно, как обычно, но модифицируем ее та
 ким образом, чтобы она запоминала решение каждой подзадачи (обычно в масси
 ве или хеш-таблице). Теперь процедура первым делом проверяет, не была ли эта 
задача решена ранее. Если была, то возвращается сохраненное значение (и эко
 номятся вычисления на данном уровне). Если же подзадача еще не решалась, 
процедура вычисляет возвращаемое значение, как обычно. Мы говорим, что дан
 ная рекурсивная процедура с запоминанием — она “запоминает” вычисленный 
ею результат.
 Второй подход — восходящий. Обычно он зависит от некоторого естествен
 ного понятия “размера” подзадачи, такого, что решение любой конкретной под
 задачи зависит только от решения “меньших” подзадач. Мы сортируем подзада
 чи по размерам в возрастающем порядке. При решении определенной подзадачи 
необходимо решить все меньшие подзадачи, от которых она зависит, и сохранить 
полученные решения. Каждую подзадачу мы решаем только один раз, и к мо
 менту, когда мы впервые с ней сталкиваемся, все необходимые для ее решения 
подзадачи уже решены.
 Эти два подхода приводят к алгоритмам с одним и тем же асимптотическим 
временем работы, за исключением редких ситуаций, когда нисходящий подход 
в действительности не выполняет рекурсивное изучение всех возможных подза
 дач. Зачастую восходящий подход обладает лучшими константными множителя
 ми, поскольку при его применении оказываются меньшими накладные расходы, 
связанные с вызовами функций.
 Вот как выглядит псевдокод нисходящей процедуры CUT-ROD с добавленным 
запоминанием.
 Memoized-Cut-Rod (р, п)
 1 г [0.. п] — новый массив
 2 for i — 0 to п
 3 
г[г] = — оо
 4 return Memoized-Cut-Rod-Aux (р, п, г)
 Memoized-Cut-Rod-Aux (р, п , г )
 1 if г[п\ > О
 2 
return г[п]
 3 if п == О
 4 
5 
6 
7 
q = О
 else q — —оо
 for г = 1 to гг
 return q
 q = max(g, p[i\ + MEMOIZED-CUT-ROD-AUX (p, n - i, r))
 8 r[n] = q
 9 
3B данном случае это не опечатка, по-английски этот термин пишется именно так. Как поясняют в приме
 чании авторы книги, смысл не просто в том, чтобы запомнить информацию (memorize), а в том, чтобы вскоре 
ею воспользоваться, как памяткой (memo). — Примеч. пер.
Глава 15. Динамическое программирование
 399
 Здесь основная процедура M emoized-Cut-Rod инициализирует новый вспо
 могательный массив г[0.. п] значением — оо, которое представляет собой удоб
 ный выбор для обозначения “неизвестно”. (Известные значения прибыли всегда 
неотрицательны.) Затем она вызывает вспомогательную процедуру MEMOIZED- 
Cut-Rod-Aux.
 Процедура Memoized-Cut-Rod-Aux представляет собой версию с запоми
 нанием предыдущей процедуры Cut-Rod. Сначала в строке 1 она проверяет, 
не известно ли уже искомое значение, и, если известно, возвращает его в стро
 ке 2. В противном случае в строках 3-7 процедура вычисляет искомое значение q 
обычным способом, в строке 8 сохраняет его в г[п], а в строке 9 возвращает это 
значение вызвавшему коду.
 Восходящая версия еще проще.
 Bottom-Up-Cut-Rod (р, п)
 1 г [0.. п\ — новый массив
 2 г[0] = О
 3 for j = 1 to п
 4 
q = —оо
 5 
6 
7 
for г = 1 to j
 q = max(g,p[i] -I- r\j - г])
 r\j\ = q
 8 return r[n]
 При восходящем подходе динамического программирования процедура 
Bottom-U p-Cut-Rod использует естественное упорядочение подзадач: подза
 дача размером i “меньше” подзадачи размером j, если г < j. Таким образом, 
процедура решает подзадачи размером j = 0,1,..., п в указанном порядке.
 В строке 1 процедуры Bottom-U p-Cut-Rod создается новый массив г[0.. п], 
в котором хранятся решения подзадач, а в строке 2 элемент г[0] инициализиру
 ется значением 0, поскольку стержень длиной 0 не приносит никакой прибыли. 
В строках 3-6 решается каждая подзадача размером j для j = 1,2,..., п в поряд
 ке возрастания. Подход, используемый для решения задачи определенного раз
 мера j, тот же, что и применяемый в процедуре Cut-Rod, с тем отличием, что 
в строке 6 выполняется непосредственное обращение к элементу массива r\j — г] 
вместо рекурсивного вызова для решения подзадачи размером j — i. В строке 7 
выполняется сохранение в r\j\ решения подзадачи размером j. Наконец в строке 8 
выполняется возврат г[п], оптимального значения гп.
 Восходящая и нисходящая версии имеют одно и то же асимптотическое время 
работы. Из-за вложенной структуры циклов время работы процедуры Воттом- 
Up-Cut-Rod составляет 0 (п 2). Количества итераций внутреннего цикла for 
в строках 5 и 6 образуют арифметическую прогрессию. Время работы нисхо
 дящего двойника, процедуры Memoized-Cut-Rod, также равно 0 (п 2), хотя это 
время может быть не столь очевидным. Поскольку рекурсивный вызов для ре
 шения ранее решенных задач немедленно возвращается, процедура MEMOIZED- 
Cut-Rod решает каждую подзадачу только один раз. Она решает подзадачи раз
400
 Часть IV. Усовершенствованные методы разработки и анализа
 мером 0,1,..., п. Для решения подзадачи размером п цикл for в строках 6 и 7 
выполняет п итераций. Таким образом, общее количество итераций этого цикла 
for по всем рекурсивным вызовам Memoized-Cut-Rod образует арифметиче
 скую прогрессию, что приводит к общему количеству итераций, равному @(п2), 
как и в случае внутреннего цикла for процедуры Bottom-Up-Cut-Rod. (В дей
 ствительности нами использована разновидность группового анализа, который 
будет подробно рассматриваться в разделе 17.1.)
 Графы подзадач
 При рассмотрении задачи динамического программирования следует найти 
множество решаемых подзадач и понять, как подзадачи зависят одна от другой.
 Граф подзадач для задачи динамического программирования содержит инте
 ресующую нас информацию. На рис. 15.4 показан граф подзадач для задачи разре
 зания стержня при п = 4. Это ориентированный граф, содержащий по одной вер
 шине для каждой из различных подзадач. Граф подзадач содержит дугу, идущую 
от вершины подзадачи х к вершине подзадачи у, если определение оптимально
 го решения подзадачи х непосредственно включает поиск оптимального решения 
для подзадачи у. Например, граф подзадач содержит дугу, идущую от х к у, ес
 ли нисходящая рекурсивная процедура для решения х непосредственно вызывает 
саму себя для решения у. Граф подзадач можно рассматривать как “уменьшен
 ную” или “сжатую” версию дерева рекурсии нисходящего рекурсивного метода, 
в которой мы сливаем все узлы для одной и той же подзадачи в единую вершину 
и направляем все дуги от родительских узлов к дочерним.
 Восходящий метод динамического программирования рассматривает верши
 ны графа подзадач в том порядке, в котором решаются сами подзадачи, т.е. все 
подзадачи у, смежные данной подзадаче х, решаются до того, как мы присту
 пим к решению подзадачи х. (Вспомним из раздела Б.4, что отношение смежно
 сти не обязано быть симметричным.) Используя терминологию главы 22, в вос
 ходящем алгоритме динамического программирования вершины графа подзадач
 Рис. 15.4. Граф подзадач для задачи разрезания стержня при п = 4. Метки вершин указывают 
размеры соответствующих подзадач. Ориентированное ребро (х,у) указывает, что при решении 
подзадачи х необходимо решить подзадачу у. Этот граф представляет собой уменьшенную версию 
дерева на рис. 15.3, в которой все узлы на одном уровне слиты в единую вершину, а все ребра 
превращены в дуги, идущие от родительского узла к дочернему.
Глава 15. Динамическое программирование
 401
 рассматриваются в порядке “обратной топологической сортировки”, или “тополо
 гической сортировки транспозиции” (см. раздел 22.4) графа подзадач. Другими 
словами, никакая подзадача не рассматривается до тех пор, пока не будут ре
 шены все подзадачи, от которых она зависит. Аналогично, используя понятия 
из той же главы, мы можем рассматривать нисходящий метод (с запоминанием) 
динамического программирования как “поиск в глубину” в графе подзадач (см. 
раздел 22.3).
 Размер графа подзадач G = (V, Е) может помочь в определении времени ра
 боты алгоритма динамического программирования. Поскольку каждая подзадача 
решается однократно, время работы алгоритма представляет собой сумму времен, 
необходимых для решения каждой подзадачи. Обычно время решения подзадачи 
пропорционально степени (количеству исходящих ребер) соответствующей вер
 шины в графе подзадач, а количество подзадач равно числу вершин в графе под
 задач. В этом распространенном случае время работы алгоритма динамического 
программирования линейно зависит от числа вершин и ребер.
 Восстановление решения
 Наше решение задачи разрезания стержня путем динамического программиро
 вания возвращает значение оптимального решения, но не само решение, которое 
должно иметь вид списка размеров частей. Можно расширить подход динамиче
 ского программирования и записывать не только вычисленное оптимальное зна
 чение каждой подзадачи, но и выбор, который приводит к этому оптимальному 
значению. При наличии этой информации мы можем легко вывести оптимальное 
решение.
 Вот как выглядит расширенная версия процедуры Bottom-Up-Cut-Rod, ко
 торая для каждого размера стержня j вычисляет не только максимальную при
 быль rj, но и оптимальный размер первой отрезаемой части Sj.
 Extended-Bottom-Up-Cut-Rod (р, п)
 1 г [0.. п] и s[0.. п\ — новые массивы
 2 г[0] = О
 3 for j = 1 to п
 4 
q = —оо
 5 
6 
7 
8 
9 
for г = 1 to j
 if q < p[i] + r\j — i]
 q = p[i] +r[j - i]
 s\j] = i
 r\j] = q 
10 return г и s
 Эта процедура аналогична процедуре BOTTOM-UP-CUT-ROD, с тем отличием, что 
она создает массив s в строке 1 и обновляет sfj] в строке 8, сохраняя оптимальный 
размер i первой отрезаемой части при решении подзадачи размером j.
 Приведенная далее процедура получает таблицу цен р и размер стержня п 
и вызывает процедуру E X T E N D E D-B O TTO M-U P-C U T-R O D для вычисления масси
402
 Часть IV. Усовершенствованные методы разработки и анализа
 ва s[l.. п] оптимальных размеров первых частей, а затем выводит полный список 
размеров частей в оптимальном разрезании стержня длиной п.
 Print-Cut-Rod-Solution (р, п)
 1 (г, s) = Extended-Bottom-Up-Cut-Rod (р,п)
 2 while п > О
 3 
print s[n]
 4 
п = п — s[n]
 В нашем примере вызов Extended-Bottom-Up-Cut-Rod (р, 10) вернет следу
 ющие массивы.
 г 0 1 2 3 4 5 6 7 8 9 10
 г[г] 0 1 5 8 10 13 17 18 22 25 30
 s[i] 0 1 2 3 2 2 6 1 2 3 10
 Вызов Print-Cut-Rod-Solution (р, 10) выведет единственную часть длиной 10, 
но для п = 7 будут выведены размеры частей 1 и 6, соответствующие первому 
оптимальному разрезанию для 7*7, приведенному ранее.
 Упражнения
 15.1.1
 Покажите, что уравнение (15.4) следует из уравнения (15.3) и начального усло
 вия Т( 0) = 1.
 15.1.2
 Покажите с помощью контрпримера, что описанная далее жадная стратегия не 
всегда определяет оптимальный способ разрезания стержня. Определим плот
 ность стержня длиной г как рг/г, т.е. как стоимость единицы его длины. Жадная 
стратегия для стержня длиной п отрезает от стержня первую часть длиной г, где 
1 < г < п, имеющую максимальную плотность. Затем та же жадная стратегия 
применяется к оставшейся части длиной п — г.
 15.1.3
 Рассмотрим модификацию задачи разрезания стержня, в которой в дополнение 
к цене pi каждого стержня добавляется фиксированная цена разреза с. Теперь 
прибыль, связанная с решением, представляет собой сумму цен частей стержня 
минус стоимость разрезов. Разработайте алгоритм динамического программиро
 вания для этой модифицированной задачи.
 15.1.4
 Модифицируйте процедуру Memoized-Cut-Rod таким образом, чтобы она воз
 вращала не только значение, но и фактическое решение задачи.
Глава 15. Динамическое программирование
 15.1.5
 403
 Числа Фибоначчи определяются рекуррентным соотношением (3.22). Разрабо
 тайте алгоритм динамического программирования со временем работы 0{п) для 
вычисления п-го числа Фибоначчи. Изобразите граф подзадач. Сколько вершин 
и ребер имеет этот граф?
 15.2. Перемножение цепочки матриц
 Очередной пример применения динамического программирования — алго
 ритм, позволяющий решить задачу о перемножении цепочки матриц. Пусть име
 ется последовательность (цепочка) (Ai, Л2, ..., Ап), состоящая из п матриц, 
и нужно вычислить их произведение
 AiAi'-An. 
(15.5)
 Выражение (15.5) можно вычислить, используя в качестве подпрограммы стан
 дартный алгоритм перемножения пар матриц. Однако сначала нужно расставить 
скобки, чтобы устранить все неоднозначности в порядке перемножения. Опера
 ция умножения матриц ассоциативна, так что любая расстановка скобок даст один 
и тот же результат. Порядок произведения матриц полностью определен скобка
 ми (fully parenthesized), если произведение является либо отдельной матрицей, 
либо взятым в скобки произведением двух подпоследовательностей матриц, в ко
 тором порядок перемножения полностью определен скобками. Например, если 
задана последовательность матриц (Ai, А2, A3 
, А4
 ), то способ вычисления их 
произведения А 1
 А2
 А3
 А4
 можно полностью определить с помощью скобок пя
 тью разными способами:
 (^1(А2(АзА4))) ,
 (^l((^2^3)^4)) ,
 ((AiA2)(A3A4)) ,
 ((А!(А2А3))А4),
 (((Л1Л2)Л3)А4) •
 От того, как расставлены скобки при перемножении последовательности мат
 риц, может сильно зависеть время, затраченное на вычисление произведения. 
Сначала рассмотрим, как определить стоимость произведения двух матриц. Ни
 же приводится псевдокод стандартного алгоритма, который обобщает процедуру 
Square-M atrix-M ultiply из раздела 4.2. Атрибуты rows и columns означают 
количество строк и столбцов матрицы.
404
 Matrix-M ultiply(A, В)
 1 if Л. columns 7^ В. rows
 2
 Часть IV. Усовершенствованные методы разработки и анализа
 error “несовместимые размеры матриц”
 3 else С — новая матрица размером A. rows х В. columns
 4 
5
 6
 7
 8 
9
 for i = 1 to A. rows
 for j = 1 to B. columns
 Cij — 0
 for k = 1 to A. columns
 Cij = C{j -|- Ицc • bfcj
 return C
 Матрицы А и В можно перемножать, только если они совместимы: количество 
столбцов матрицы А должно совпадать с количеством строк матрицы В. Если 
А — это матрица размером р х q, а В — матрица размером q х г, то в результате 
их перемножения получится матрица С размером р х г. Время вычисления матри
 цы С преимущественно определяется количеством произведений скаляров (далее 
в главе для краткости будем называть эту операцию скалярным умножением. — 
Примеч. пер.), которое выполняется в строке 8. Это количество равно pqr. Итак, 
стоимость умножения матриц будет выражаться в терминах количества умноже
 ний скалярных величин.
 Чтобы проиллюстрировать, как расстановка скобок при перемножении не
 скольких матриц влияет на количество выполняемых операций, рассмотрим при
 мер, в котором перемножаются три матрицы — (Ai, Ач, А?). Предположим, что 
размеры этих матриц равны 10 х 100, 100 х 5 и 5 х 50 соответственно. Пере
 множая матрицы в порядке, заданном выражением ((Ai А2) Аз), необходимо вы
 полнить 10 • 100 • 5 = 5000 скалярных умножений, чтобы найти результат про
 изведения А\Ач (при этом получится матрица размером 10 х 5), а затем — еще 
10 • 5 • 50 = 2500 скалярных умножений, чтобы умножить эту матрицу на матри
 цу As. Всего получается 7500 скалярных умножений. Если вычислять результат 
в порядке, заданном выражением (А^АгАз)), то сначала понадобится выполнить 
100 • 5 • 50 = 25 000 скалярных умножений (при этом будет найдена матрица Ач Аз 
размером 100 х 50), а затем еще 10 -100 -50 = 50000 скалярных умножений, чтобы 
умножить А\ на эту матрицу. Всего получается 75 000 скалярных умножений. Та
 ким образом, для вычисления результата первым способом понадобится в 10 раз 
меньше времени.
 Задачу о перемножении последовательности матриц (matrix-chain multipli
 cation problem) можно сформулировать следующим образом: для заданной после
 довательности п матриц (Ai, Ач, ..., Ап), в которой матрица А*, г = 1, 2,.... гг 
имеет размер pi-\ х pi, с помощью скобок следует полностью определить поря
 док умножений в матричном произведении А\ Ач • • • Ап, при котором количество 
скалярных умножений сведется к минимуму.
 Обратите внимание, что само перемножение матриц в задачу не входит. Наша 
цель — определить оптимальный порядок перемножения. Обычно время, затра
 ченное на нахождение оптимального способа перемножения матриц, с лихвой 
окупается, когда выполняется само перемножение (как это было в рассмотрен
Глава 15. Динамическое программирование
 405
 ном примере, когда удалось обойтись всего 7500 скалярными умножениями вме
 сто 75 000).
 Подсчет количества способов расстановки скобок
 Прежде чем приступить к решению задачи об умножении последовательности 
матриц методами динамического программирования, заметим, что исчерпываю
 щая проверка всех возможных вариантов расстановки скобок не является эффек
 тивным алгоритмом ее решения. Обозначим через Р(п) количество различных 
способов расстановки скобок в последовательности, состоящей из п матриц. Ес
 ли п = 1, то матрица всего одна, поэтому скобки в матричном произведении 
можно расставить всего одним способом. Если п > 2, то произведение после
 довательности матриц, в котором порядок перемножения полностью определен 
скобками, является произведением двух таких произведений подпоследователь
 ностей матриц, в которых порядок перемножения также полностью определен 
скобками. Разбиение на подпоследовательности может производиться на грани
 це к- и (к + 1)-й матриц для любого к = 1,2,..., п — 1. В результате получаем 
рекуррентное соотношение
 1 , 
Р(п)
 если п = 1 ,
 < 71-1 
Р(к)Р(п — к) 1 , если п > 2 .
 >■к=1
 В задаче 12.4 предлагается показать, что решением аналогичного рекуррентно
 го соотношения является последовательность чисел Каталано (Catalan numbers), 
возрастающая как 0(4n/n 3/2). Более простое упражнение (упр. 15.2.3) заключа
 ется в том, чтобы показать, что решение рекуррентного соотношения (15.6) ведет 
себя, как 0(2П). Таким образом, количество вариантов расстановки скобок экспо
 ненциально увеличивается с ростом п, и метод прямого перебора всех вариантов 
не подходит для определения оптимальной стратегии расстановки скобок в мат
 ричном произведении.
 (15.6)
 Применение динамического программирования
 Для вычисления оптимальной расстановки скобок при перемножении после
 довательности матриц мы применим динамическое программирование. Для этого 
мы должны следовать последовательности из четырех этапов, описанной в начале 
данной главы.
 1. Описание структуры оптимального решения.
 2. Определение значения, соответствующего оптимальному решению, с исполь
 зованием рекурсии.
 3. Вычисление значения, соответствующего оптимальному решению, обычно 
с помощью метода восходящего анализа.
406
 Часть IV Усовершенствованные методы разработки и анализа
 4. Составление оптимального решения на основе информации, полученной на
 предыдущих этапах.
 Мы последовательно пройдем все эти этапы, ясно демонстрируя их применение 
к данной задаче.
 Этап 1. Структура оптимальной расстановки скобок
 Первый этап применения парадигмы динамического программирования — най
 ти оптимальную вспомогательную подструктуру, а затем с ее помощью сконстру
 ировать оптимальное решение задачи по оптимальным решениям подзадач. В рас
 сматриваемой задаче этот этап можно осуществить следующим образом. Обозна
 чим для удобства результат перемножения матриц АгА{+\ • • • Aj через 
где 
г < j. Заметим, что если задача нетривиальна, т.е. г < j, то любой способ расста
 новки скобок в произведении AiAi+\ • • • Aj разбивает это произведение между 
матрицами Ak и Ak+i, где к — целое, удовлетворяющее условию г < к < j. 
Таким образом, при некотором к сначала выполняется вычисление матриц 
д. 
и Ak+i..j, а затем они умножаются друг на друга, в результате чего получается 
произведение Aimm j. Стоимость, соответствующая этому способу расстановки ско
 бок, равна сумме стоимости вычисления матрицы 
стоимости вычисления 
матрицы Ak+i „j и стоимости вычисления их произведения.
 Ниже описывается оптимальная вспомогательная подструктура для данной за
 дачи. Предположим, что в результате оптимальной расстановки скобок последова
 тельность AiAi+ 1 ■ • • Aj разбивается на подпоследовательности между матрица
 ми Ak и Аь+1. Тогда расстановка скобок в “префиксной” подпоследовательности 
AiAi+ 1 • • • Ak также должна быть оптимальной. Почему? Если бы существовал 
более экономный способ расстановки скобок в последовательности A{Ai+i • • • Ak, 
то его применение позволило бы перемножить матрицы AiAi+i ■ ■ ■ Aj еще эф
 фективнее, что противоречит предположению об оптимальности первоначальной 
расстановки скобок. Аналогично можно прийти к выводу, что расстановка ско
 бок в подпоследовательности матриц Ak+i Ak+2 • • ■ Aj, возникающей в результа
 те оптимальной расстановки скобок в последовательности AiA{+ 1 • • • Aj, также 
должна быть оптимальной.
 Теперь с помощью нашей оптимальной вспомогательной подструктуры пока
 жем, что оптимальное решение задачи можно составить из оптимальных решений 
подзадач. Мы уже убедились, что для решения любой нетривиальной задачи об 
оптимальном произведении последовательности матриц всю последовательность 
необходимо разбить на подпоследовательности и что каждое оптимальное реше
 ние содержит в себе оптимальные решения подзадач. Другими словами, решение 
полной задачи об оптимальном перемножении последовательности матриц можно 
построить путем разбиения этой задачи на две подзадачи — оптимальную расста
 новку скобок в подпоследовательностях AiA{+1 • • • Ak и Ak+iAk+2 • • • Aj. После 
этого находятся оптимальные решения подзадач, из которых затем составляется 
оптимальное решение полной задачи. Необходимо убедиться, что при поиске спо
 соба перемножения матриц учитываются все возможные варианты разбиения —
Глава 15. Динамическое программирование
 407
 только в этом случае можно быть уверенным, что найденное решение будет гло
 бально оптимальным.
 Этап 2. Рекурсивное решение
 Далее рекурсивно определим стоимость оптимального решения в терминах 
оптимальных решений подзадач. В задаче о перемножении последовательности 
матриц в качестве подзадачи выбирается задача об оптимальной расстановке ско
 бок в подпоследовательности AiAi+\ • • • Aj при 1 < г < j < п. Путь m[i,j] — 
минимальное количество скалярных умножений, необходимых для вычисления 
матрицы Ai__j. Тогда в полной задаче минимальная стоимость матрицы А\„п рав
 на т [1,п].
 Рекурсивно определить величину m[i,j] можно следующим образом. Если 
i = j, то задача становится тривиальной: последовательность состоит всего из 
одной матрицы 
= Л*, и для вычисления произведения матриц не нужно вы
 полнять никаких скалярных умножений. Таким образом, при i = 1,2,... ,п имеем 
m[i,i] = 0. Чтобы вычислить m[i,j] при г < j, воспользуемся свойством под
 структуры оптимального решения, исследованным на этапе 1. Предположим, что 
в результате оптимальной расстановки скобок последовательность Л^Л^+ 1 • • • Aj 
разбивается между матрицами Лк и А^+ ь где i < k < j. Тогда величина m[i,j] 
равна минимальной стоимости вычисления частных произведений Л^.^ и Ak+i..j 
плюс стоимость умножения этих матриц друг на друга. Если вспомнить, что каж
 дая матрица А{ имеет размеры pi_i х рг, то нетрудно понять, что для вычисления 
произведения матриц A i^ A k + iпонадобится Pi-iPkPj скалярных умножений. 
Таким образом, получаем
 m[i,j] = m[i,k] + т[к + 1 ,j] + Pi-iPkPj ■
 В этом рекурсивном уравнении предполагается, что значение к известно, но 
на самом деле это не так. Для выбора этого значения всего имеется j — г возмож
 ностей, а именно — к = i,i + 1,... ,j — 1. Поскольку в оптимальной расстановке 
скобок необходимо использовать одно из этих значений к, все, что нужно сде
 лать, — проверить все возможности и выбрать среди них лучшую. Таким обра
 зом, рекурсивное определение оптимальной расстановки скобок в произведении 
ЛгЛг+i • • • Aj принимает вид
 0 , 
m[i,j]
 если г = j ,
 min {m[i, /г] + т[к + 1 ,j] + Pi-iPkPj} , если г < j .
 i<k<j
 (15.7)
 Величины m[i,j] равны стоимостям оптимальных решений подзадач. Чтобы 
легче было проследить за процессом построения оптимального решения, обозна
 чим через s[i,j] значение к, в котором последовательность АгАг+\ ■ ■ ■ Aj разби
 вается на две подпоследовательности в процессе оптимальной расстановки ско
 бок. Таким образом, величина s[z,j] равна значению к, такому, что m[i,j] = 
m[i, к] + т[к + 1 ,j] +p{-ipkpj.
408
 Часть IV Усовершенствованные методы разработки и анализа
 Этап 3. Вычисление оптимальных стоимостей
 На данном этапе не составляет труда написать на основе рекуррентного соот
 ношения (15.7) рекурсивный алгоритм для вычисления минимальной стоимости 
т[1,п] для произведения А\ А2 ■ ■ • Ап. Однако в разделе 15.3 мы сможем убедить
 ся, что время работы этого алгоритма экспоненциально зависит от п, что ничем 
не лучше метода прямого перебора, при котором проверяется каждый способ рас
 становки скобок в произведении.
 Важное наблюдение, которое можно сделать на данном этапе, заключается 
в том, что у нас относительно мало различных подзадач: по одной для каждого 
выбора величин г и j, удовлетворяющих неравенству 1 < г < j < п, т.е. всего 
(2) + п = 0(п2). В рекурсивном алгоритме каждая подзадача может неодно
 кратно встречаться в разных ветвях рекурсивного дерева. Такое свойство пере
 крытия подзадач — вторая отличительная черта применимости метода динами
 ческого программирования (первая отличительная черта — наличие оптимальной 
подструктуры).
 Вместо того чтобы рекурсивно решать рекуррентное соотношение (15.12), вы
 полним этап 3 парадигмы динамического программирования и вычислим оп
 тимальную стоимость путем построения таблицы в восходящем направлении. 
В описанной ниже процедуре предполагается, что размеры матриц А{ равны 
Pi- 1 х pi (г = 1, 2,..., п). Входные данные представляют собой последователь
 ность р = {po,pi,... ,Рп); длина данной последовательности равна length\p\ = 
п + 1. В процедуре используется вспомогательная таблица ra [ l . .n , 
1..гг] для хра
 нения стоимостей m[i,j] и вспомогательная таблица s [ l . .n , l . .n ] , 
в которую за
 носятся индексы к, при которых достигаются оптимальные стоимости 
Таблица s будет использоваться при построении оптимального решения.
 Вместо рекурсивного вычисления рекуррентного соотношения (15.7) мы вы
 числяем оптимальную стоимость с помощью табличного восходящего подхода. 
(Соответствующий нисходящий подход с запоминанием будет представлен в раз
 деле 15.3.)
 Мы реализуем табличный восходящий подход в процедуре Matrix-Chain- 
Order, приведенной ниже. В этой процедуре предполагается, что матрица Ai 
имеет размер pi-\ х pi для г = 1,2,..., п. Ее входными данными является после
 довательность р = (ро,р\,..., рп), где р. length = п + 1. Процедура использует 
вспомогательную таблицу т[ 1.. n , 
1.. п\ для хранения стоимостей m[i,j] и дру
 гую вспомогательную таблицу, s [ l . . n 
— 1,2.. п], в которую записывается, для 
какого индекса к достигается оптимальная стоимость при вычислении m[i,j}. 
Таблица s будет использоваться при построении оптимального решения.
 Чтобы корректно реализовать восходящий подход, необходимо определить, 
с помощью каких записей таблицы будут вычисляться величины m[i,j]. Из урав
 нения (15.7) видно, что стоимость m[i,j] вычисления произведения последова
 тельности j — i + 1 матриц зависит только от стоимости вычисления после
 довательностей матриц, содержащих менее j — i + 1 матриц. Другими слова
 ми, при к = г, г + 1,..., j — 1 матрица 
представляет собой произведение 
к — i + 1 < j — г + 1 матриц, а матрица Ak+i..j — произведение j — к < j — г + 1 
матриц. Таким образом, в ходе выполнения алгоритма следует организовать за
Глава 15. Динамическое программирование
 409
 полнение таблицы га в порядке, соответствующем решению задачи о расстановке 
скобок в последовательностях матриц возрастающей длины. В случае подзада
 чи оптимальной расстановки скобок в цепочке AiAi+ 1 • ■ • Aj мы рассматриваем 
размер подзадачи как равный длине j — i + 1 цепочки.
 Matrix-Chain-Order (р)
 1 п = р. length — 1
 2 т[ 1.. n, 1.. п] и s[l.. п — 1,2.. п] — новые таблицы
 3 for г = 1 to п
 4 
га[г,г] = О
 5 for I = 2 to п 
6 
7
 8
 9
 10 
11 
12 
13
 for г = 1 to п — I + 1
 И l — длина цепочки
 j = i + 1-l
 m[i,j] - оо 
for к = г to j — 1
 q = m[i, fc] + m[k + 1, j] + Pi-\pkPj
 if q< m[i,j} 
m[i,j} = q 
s[i,j] = к
 14 return га и s
 Сначала в этом алгоритме (строки 3 и 4) выполняется инициализация m[i,i] =
 0 для г = 1,2, ...,п (минимальные стоимости для последовательностей еди
 ничной длины). Затем в первой итерации цикла for в строках 5-13 с помо
 щью рекуррентного соотношения (15.7) вычисляются величины га[г,г + 1] при 
г = 1,2, ...,п — 1 (минимальные стоимости для последовательностей длиной
 1= 2). При втором проходе этого цикла вычисляются величины га[г, г + 2] при 
г = 1,2, ...,п — 2 (минимальные стоимости для последовательностей длиной 
/ = 3) и т.д. На каждом этапе вычисляемые в строках 10-13 величины га[г, j] 
зависят только от уже вычисленных и занесенных в таблицу значений т[г, к] 
и т[к + 1, j].
 На рис. 15.5 описанный выше процесс проиллюстрирован для цепочки, состо
 ящей из п = 6 матриц. Поскольку величины т[г, j] определены только для г < j, 
используется только часть таблицы т , расположенная над ее главной диагональю. 
Таблица на рисунке повернута так, чтобы ее главная диагональ была расположе
 на горизонтально. В нижней части рисунка приведен список матриц, входящих 
в последовательность. На этой схеме легко найти минимальную стоимость m[i,j] 
перемножения подцепочки матриц A{Ai+\ • • • Aj. Она находится на пересечении 
линий, идущих от матрицы А{ вправо и вверх и от матрицы Aj — влево и вверх. 
В каждой горизонтальной строке таблицы содержатся стоимости перемножения 
подцепочек, состоящих из одинакового количества матриц. В процедуре M A TR IX- 
Chain-Order строки вычисляются снизу вверх, а элементы в каждой строке — 
слева направо. Величина m[i,j\ вычисляется с помощью произведений Pi-iPkPj 
для к = i,i + 1,... ,j — I и всех величин внизу слева и внизу справа от т[г, j].
 Несложный анализ структуры вложенных циклов в процедуре Matrix- 
Chain-Order показывает, что время ее работы составляет 0(п3). Глубина вло
410
 Часть IV. Усовершенствованные методы разработки и анализа
 т
 s
 ^2 
Aj 
А5
 Рис. 15.5. Таблицы т и s, вычисляемые процедурой Matrix-Chain-Order для п = 6 и следу
 ющих размерностей матриц.
 Матрица
 Л 2
 А з
 а 4
 Аъ
 Аб
 Размерность 30 х 35 35 х 15 15 х 5 5 х 10 10 х 20 20 х 25
 Таблицы повернуты таким образом, чтобы главная диагональ располагалась горизонтально. В таб
 лице тп используются только главная диагональ и верхний треугольник, а в таблице s — только 
верхний треугольник, без главной диагонали. Минимальное количество скалярных умножений для 
вычисления произведений шести матриц равно т[1,6] = 15 125. Более темным цветом выделены 
пары, совместно используемые в строке 10 при вычислении
 1
 тп[2,5] = min <
 = 7125 .
 m[2,2] + m [3, 5] + Р1Р2Р5 = 0 + 2500 + 35-15-20 = 13 000
 m[2,3] + m [4,5] + pipzps = 2625 + 1000 + 35 • 5 • 20 = 7125 , 
m[2,4] + m[5,5] + р\р4ръ = 4375 + 0 + 35-10-20 = 11 375
 жения циклов равна трем, а индексы в каждом из них (I, ink) принимают не 
более п — 1 значений. В упр. 15.2.5 предлагается показать, что время работы этого 
алгоритма фактически равно Q(n3). Для хранения таблиц га и s требуется объем, 
равный ©(п2). Таким образом, процедура Matrix-Chain-Order намного эф
 фективнее, чем метод перебора и проверки всевозможных способов расстановки 
скобок, время работы которого экспоненциально зависит от количества перемно
 жаемых матриц.
 Этап 4. Построение оптимального решения
 Несмотря на то что в процедуре Matrix-Chain-Order определяется оп
 тимальное количество скалярных произведений, необходимых для вычисления 
произведения последовательности матриц, в нем не показано, как именно пере
 множаются матрицы. Оптимальное решение несложно построить с помощью ин
 формации, хранящейся в таблице s[l.. п — 1,2.. п]. В каждом элементе 
хранится значение индекса к, где при оптимальной расстановке скобок в по
 следовательности AiAi+i Aj выполняется разбиение. Таким образом, нам из
 вестно, что оптимальное вычисление произведения матриц А\..п выглядит как 
^i..s[i,n]^s[i,n]+i..n- Все предшествующие произведения матриц можно вычислить 
рекурсивно, поскольку элемент s i, s[l,n]] определяет матричное умножение, вы
Глава 15. Динамическое программирование
 411
 полняемое последним при вычислении ..s[1)Tl], a s[s[l,n] + 1,п] — последнее 
умножение при вычислении -As[i,n]+i..n- Приведенная ниже рекурсивная процеду
 ра выводит оптимальный способ расстановки скобок в последовательности мат
 риц (Ai, Ai+1, . . . ,Aj ) по таблице s, полученной в результате работы процедуры 
Matrix-Chain-Order, и по индексам г и j . Первоначальный вызов процедуры 
Print-Optimal-Parens (s, 1,п) выводит оптимальную расстановку скобок в по
 следовательности {А\ ,А2 , . . . ,Ап).
 Print-Optimal-Parens (s , г, j )
 1 if г == j
 2 
print “Л”г
 3 else print “(”
 4 
5 
6 
Print-Optimal-Parens (s, i, s[i, j ])
 Print-Optimal-Parens (s,s[i , j] + 1 , j )
 print “)”
 В примере, проиллюстрированном на рис. 15.5, вызов процедуры Print- 
Optimal-Parens^, 1,6) дает строку ((Л1(Л2Лз))((Л4Л5)Лб)).
 Упражнения
 15.2.1
 Найдите оптимальную расстановку скобок в произведении последовательности 
матриц, размерности которых равны (5,10,3,12,5,50,6).
 15.2.2
 Разработайте рекурсивный алгоритм Matrix-Chain-M ultiply(.A, $,г, j), в ко
 тором оптимальным образом вычисляется произведение заданной последователь
 ности матриц (j4i, А2 , ..., А п). На вход этого алгоритма, кроме того, поступают 
индексы г и j, а также таблица s, вычисленная с помощью процедуры MATRIX- 
Chain-ORDER. (Начальный вызов этой процедуры выглядит следующим обра
 зом: Matrix-Chain-Multiply(i4, s, l,n ).)
 15.2.3
 Покажите с помощью метода подстановок, что решением рекуррентного соотно
 шения (15.6) является П(2П).
 15.2.4
 Опишите граф подзадач для перемножения цепочки матриц для входной цепочки 
длиной п. Сколько вершин в этом графе? Сколько в нем ребер, и что они собой 
представляют?
 15.2.5
 Пусть R(i,j) — количество обращений к элементу матрицы 
которые
 выполняются в ходе вычисления других элементов этой матрицы в процедуре 
Matrix-Chain-Order. Покажите, что полное количество обращений ко всем
412
 элементам равно
 Часть IV. Усовершенствованные методы разработки и анализа
 г=1 j=i
 П3 — П
 3
 {Указание: для решения может оказаться полезным уравнение (А.З).)
 15.2.6
 Покажите, что в полной расстановке скобок в n-элементном выражении исполь
 зуется ровно п — 1 пар скобок.
 15.3. Элементы динамического программирования
 Несмотря на рассмотренные в предыдущем разделе два примера, в которых 
применялся метод динамического программирования, возможно, вам все еще не 
совсем понятно, когда применим этот метод. В каких случаях задачу можно ре
 шать с помощью динамического программирования? В данном разделе рассмат
 риваются два ключевых ингредиента, которые должны быть присущи задаче оп
 тимизации, чтобы к ней можно было применить метод динамического програм
 мирования: наличие оптимальной подструктуры и перекрывающихся подзадач. 
Мы также более полно рассмотрим метод запоминания (memoization) и изучим, 
каким образом он позволяет воспользоваться преимуществами перекрывающихся 
подзадач при нисходящем рекурсивном подходе.
 Оптимальная подструктура
 Первый шаг решения задачи оптимизации методом динамического программи
 рования состоит в том, чтобы охарактеризовать структуру оптимального решения. 
Напомним, что оптимальная подструктура проявляется в задаче в том случае, 
если в ее оптимальном решении содержатся оптимальные решения подзадач. Ес
 ли в задаче выявлена оптимальная подструктура, это служит веским аргументом 
в пользу того, что к ней может быть применим метод динамического программи
 рования. (Однако наличие этого свойства может также свидетельствовать о при
 менимости жадных алгоритмов; см. главу 16.) В динамическом программирова
 нии оптимальное решение задачи строится из оптимальных решений подзадач. 
Следовательно, необходимо убедиться в том, что в число рассматриваемых под
 задач входят те, которые используются в оптимальном решении.
 Оптимальная подструктура была обнаружена в обеих задачах, которые до это
 го были исследованы в настоящей главе. В разделе 15.1 было установлено, что 
оптимальное разрезание стержня длиной п (если разрезание вообще имеет место) 
включает оптимальные разрезания частей, появившихся в результате первого раз
 реза. В разделе 15.2 было продемонстрировано, что в оптимальную расстановку 
скобок, в результате которой последовательность матриц АгАг+\ • • • Aj разбива
 ется на подпоследовательности между матрицами А^ и А^+ь входят оптималь
Глава 15. Динамическое программирование
 413
 ные решения задач о расстановке скобок в подпоследовательностях Ai A{+i ■ ■ ■ А^ 
и Ak+iAk+2 • ■ ■ Aj.
 Можно видеть, что поиск оптимальной подструктуры происходит по общему 
образцу.
 1. На этапе 1 следует показать, что в процессе решения задачи приходится делать 
выбор. В рассмотренных примерах это был выбор начального разреза стерж
 ня или выбор индекса, при котором разбивается последовательность матриц. 
После выбора остается решить одну или несколько подзадач.
 2. На этом этапе мы исходим из того, что для поставленной задачи делается 
выбор, ведущий к оптимальному решению. Пока что не рассматривается, как 
именно следует делать выбор, а просто предполагается, что он найден.
 3. Исходя из заданного выбора определяется, какие подзадачи получаются и как 
лучше охарактеризовать получающееся в результате пространство подзадач.
 4. Показывается, что решения подзадач, возникающих в ходе оптимального ре
 шения задачи, сами должны быть оптимальными. Это делается методом “от 
противного”: предполагая, что решение каждой подзадачи не оптимально, при
 ходим к противоречию. В частности, путем “вырезания” неоптимального ре
 шения подзадачи и “вставки” оптимального демонстрируется, что можно по
 лучить лучшее решение исходной задачи, а это противоречит предположению 
о том, что уже имеется оптимальное решение. Если подзадач несколько, они 
обычно настолько похожи, что описанный выше способ рассуждения, приме
 ненный к одной из подзадач, легко модифицируется для остальных.
 Характеризуя пространство подзадач, постарайтесь придерживаться такого 
практического правила: попытайтесь сделать так, чтобы это пространство было 
как можно проще, а затем расширьте его до необходимых пределов. Например, 
пространство в подзадачах, возникающих в задаче о разрезании стержня, бы
 ло образовано задачами оптимального разрезания стержня длиной г для каждого 
размера г. Это подпространство оказалось вполне подходящим, и не возникло 
необходимости его расширять.
 Теперь предположим, что в задаче о перемножении цепочки матриц пред
 принимается попытка ограничить пространство подзадач произведениями вида 
А\А2 • • • Aj. Как и ранее, оптимальная расстановка скобок должна разбивать про
 изведение между матрицами Аь и А^+1 для некоторого индекса 1 < k < j. 
Если к не всегда равно j — 1, мы обнаружим, что возникают подзадачи вида 
А\ А2 ■ ■ ■ Ak и Ак+\Ак+2 • • • Aj и что последняя подзадача не является подзадачей 
вида А1А2 ■ ■ ■ Aj. В этой задаче необходима возможность изменения обоих кон
 цов последовательности, т.е. чтобы в подзадаче AjAi+i ■ • • Aj могли меняться оба 
индекса - иг, и j.
 Оптимальная подструктура изменяется в области определения задачи в двух 
аспектах.
 1. Количество подзадач, которые используются при оптимальном решении ис
 ходной задачи.
414
 Часть IV. Усовершенствованные методы разработки и анализа
 2. Количество выборов, возникающих при определении того, какая подзадача
 (подзадачи) используется в оптимальном решении.
 В оптимальном решении задачи о разрезании стержня длиной п используется 
только одна подзадача размером п — г, но для поиска оптимального решения 
необходимо рассмотрение п вариантов значения г. Перемножение подцепочки 
матриц АгА{+\ ■ • • Aj служит примером с двумя подзадачами и j — г варианта
 ми выбора. Если задана матрица Ак, у которой происходит разбиение произведе
 ния, то возникают две подзадачи — расстановка скобок в подпоследовательностях 
А{А{+1 • • • Ак и Ak+iAk+2 ■ ■ • Aj, причем для каждой из них необходимо найти 
оптимальное решение. Как только оптимальные решения подзадач найдены, вы
 бирается один из j — г вариантов индекса к.
 Если говорить неформально, время работы алгоритма динамического програм
 мирования зависит от произведения двух множителей: общего количества подза
 дач и количества вариантов выбора, возникающих в каждой подзадаче. При раз
 резании стержня всего у нас возникало 0(п) подзадач и не более п вариантов 
выбора, что дает время работы 0(п2). При перемножении матриц всего возни
 кало 0(п2) подзадач, и в каждой из них — не более п — 1 вариантов выбора, 
поэтому время работы в этом случае равно 0(п3) (на самом деле — 0(п3) соглас
 но упр. 15.2.5).
 Обычно граф подзадач представляет собой альтернативный путь выполнения 
этого анализа. Каждая вершина соответствует подзадаче, а варианты выбора для 
каждой подзадачи представлены ребрами, входящими в соответствующую верши
 ну. Вспомним, что в задаче о разрезании стержня граф имел п вершин и не более 
п ребер на одну вершину, что дает время работы 0(п2). Если изобразить граф 
подзадач для перемножения цепочки матриц, то он будет иметь 0(п2) вершин, 
а каждая вершина — степень не выше п— 1, что всего дает 0(п3) вершин и ребер.
 Оптимальная подструктура часто используется в динамическом программи
 ровании в восходящем направлении. Другими словами, сначала находятся опти
 мальные решения подзадач, после чего определяется оптимальное решение по
 ставленной задачи. Поиск оптимального решения задачи влечет за собой необ
 ходимость выбора одной из подзадач, которые будут использоваться в реше
 нии полной задачи. Стоимость решения задачи обычно определяется как сумма 
стоимостей решений подзадач и стоимости, которая затрачивается на определе
 ние правильного выбора. Например, в задаче о разрезании стержня мы снача
 ла решали подзадачи оптимальных способов разрезания стержней длиной г для 
г = 0,1,..., п— 1, а затем определяли, какая подзадача дает оптимальное решение 
для стержня длиной п, используя уравнение (15.2). Стоимость, которая относится 
к самому выбору, представляет собой член pi в уравнении (15.2). В задаче о пе
 ремножении цепочки матриц сначала был определен оптимальный способ рас
 становки скобок в подцепочках AiAi+\ ■ • ■ Aj, а затем была выбрана матрица Ак, 
у которой выполняется разбиение произведения. Стоимость, которая относится 
к самому выбору, выражается членом pi-\PkPj.
 В главе 16 рассматриваются жадные алгоритму имеющие много общего с ди
 намическим программированием. В частности, задачи, к которым применимы 
жадные алгоритмы, обладают оптимальной подструктурой. Одно из характер
Глава 15. Динамическое программирование
 415
 ных различий между жадными алгоритмами и динамическим программирова
 нием заключается в том, что в жадных алгоритмах оптимальная подструктура 
используется в нисходящем направлении. Вместо того чтобы находить оптималь
 ные решения подзадач с последующим выбором одного из возможных вариантов, 
в жадных алгоритмах сначала делается выбор, который выглядит наилучшим на 
текущий момент, а затем решается возникшая в результате подзадача. При этом 
мы не беспокоимся о решении всех возможных меньших связанных подзадач. 
Удивительно, но в некоторых случаях данная стратегия работает!
 Некоторые тонкости
 Следует быть особенно внимательным в отношении вопроса о применимости 
оптимальной подструктуры, когда она отсутствует в задаче. Рассмотрим две зада
 чи, в которых имеются ориентированный граф G = (V, Е) и вершины и, v £ V .
 Задача о кратчайшем невзвешенном пути.4 Нужно найти простой путь от вер
 шины и к вершине v, состоящий из минимального количества ребер. Этот путь 
обязан быть простым, поскольку в результате удаления из него цикла получа
 ется путь, состоящий из меньшего количества ребер.
 Задача о длиннейшем невзвешенном пути. Нужно найти простой путь от вер
 шины и к вершине v, состоящий из максимального количества ребер. Требова
 ние простоты весьма важно, поскольку в противном случае можно проходить 
по одному и тому же циклу сколько угодно раз, получая в результате путь, 
состоящий из произвольно большого количества ребер.
 В задаче о кратчайшем пути возникает оптимальная подструктура. Это мож
 но показать с помощью таких рассуждений. Предположим, что и ф v, так что 
задача является нетривиальной. В этом случае любой путь р от и к v должен 
содержать промежуточную вершину, скажем, w. (Заметим, что вершина w может
 р
 совпадать с вершиной и или v.) Поэтому путь 
v можно разложить на подпу
 ти и Q w & v. Очевидно, что количество ребер, входящих в путь р, равно сумме 
числа ребер в путях р\ и р2. Мы утверждаем, что если путь р от вершины и к вер
 шине v оптимальный (т.е. кратчайший), то р\ должен быть кратчайшим путем от 
вершины и к вершине w. Почему? Аргумент такой: если бы существовал другой 
путь, соединяющий вершины и и v и состоящий из меньшего количества ребер, 
чем р\ (скажем, р[), то можно было бы вырезать путь р\ и вставить путь р[, в pe
 зультате чего получился бы путь 
w v, состоящий из меньшего количества 
ребер, чем путь р. А это противоречит предположению об оптимальности пути р. 
Аналогично р2 должен быть кратчайшим путем от вершины w к вершине v. Та
 ким образом, кратчайший путь от вершины и к вершине v можно найти, рассмот
 рев все промежуточные вершины w, найдя кратчайший путь от вершины и к вер
4Термин “невзвешенный” используется, чтобы отличать эту задачу от той, в ходе решения которой нахо
 дится кратчайший путь на взвешенных ребрах и с которой мы ознакомимся в плавах 24 и 25. Для решения 
задачи о невзвешенном пути можно использовать метод поиска в ширину, описанный в главе 22.
416
 Часть IV Усовершенствованные методы разработки и анализа
 Рис. 15.6. Ориентированный граф, демонстрирующий, что задача поиска длиннейшего простого 
пути в невзвешенном ориентированном графе не имеет оптимальной подструктуры. Путь q —> г —> 
t является наидлиннейшим простым путем от q к t, но ни подпуть q —> г не является длиннейшим 
простым путем от q к г, ни подпуть г —> t не является длиннейшим простым путем от г к t.
 шине w и кратчайший путь от вершины w к вершине v и выбрав промежуточную 
вершину w, через которую весь путь окажется кратчайшим. В разделе 25.2 один 
из вариантов этой оптимальной подструктуры используется для поиска кратчай
 шего пути между всеми парами вершин во взвешенном ориентированном графе.
 Напрашивается предположение о том, что в задаче поиска самого длинно
 го простого невзвешенного пути также проявляется оптимальная подструктура. 
В конце концов, если разложить самый длинный простой путь и ^ v на подпути 
и Q w v, то разве не должен путь р\ быть самым длинным простым путем от 
вершины и к вершине w, а путь р2 — самым длинным простым путем от вершины 
w к вершине vl Оказывается, нет! Пример такой ситуации приведен на рис. 15.6. 
Рассмотрим путь q —»■ г —»■ t, который является самым длинным простым путем 
от вершины q к вершине t. Является ли путь q —»• г самым длинным путем от 
вершины q к вершине г? Нет, поскольку простой путь q —У s —У t —У г длиннее. 
Является ли путь г —»■ t самым длинным путем от вершины г к вершине tl Снова 
нет, поскольку простой путь г —»■ q —> s —> t длиннее.
 Этот пример демонстрирует, что в задаче о самых длинных простых путях не 
только отсутствует оптимальная подструктура, но и не всегда удается составить 
“законное” решение задачи из решений подзадач. Если сложить самые длинные 
простые пути g— >£—
 >гиг—
 >£, то получится путь q —»• s —»■ 
t ^ r ^ q ^ s ^ t , который не является простым. Итак, на деле оказывается, 
что в задаче о поиске самого длинного невзвешенного пути не возникает ника
 ких оптимальных подструктур. Для этой задачи до сих пор не найдено ни одного 
эффективного алгоритма, работающего по принципу динамического программи
 рования. Фактически это NP-полная задача, что означает — как будет показано 
в главе 34, — что вряд ли ее можно решить в течение полиномиального времени.
 Почему подструктура самого длинного простого пути так отличается от под
 структуры самого короткого пути? Несмотря на то что в решениях задач о поиске 
и самого короткого, и самого длинного пути возникают две подзадачи, эти под
 задачи при определении самого длинного пути не являются независимыми, в то 
время как в задаче о кратчайшем пути они независимы. Что подразумевается под 
независимостью подзадач? Подразумевается, что решение одной подзадачи не 
влияет на решение другой подзадачи, возникающей в той же задаче. В примере, 
проиллюстрированном на рис. 15.6, рассматривается задача о поиске самого длин
 ного простого пути между вершинами q и t, в которой возникают две подзадачи: 
определение самых длинных простых путей между вершинами q и г и между
Глава 15. Динамическое программирование
 вершинами г 
417
 и t. 
Для первой из этих подзадач выбирается путь q —у s —у t —у г, 
в котором используются вершины s 
и t. 
Во второй подзадаче мы не сможем боль
 ше использовать эти вершины, поскольку в процессе комбинирования решений 
этих двух подзадач получился бы путь, который не является простым. Если во 
второй задаче нельзя использовать вершину t, то ее вообще невозможно решить, 
поскольку эта вершина должна быть в найденном пути, и это не та вершина, 
в которой “соединяются” решения подзадач (такой вершиной является г). Ис
 пользование вершин s 
и t 
в решении одной подзадачи приводит к невозможности 
их применения в решении другой подзадачи. Однако для ее решения необходимо 
использовать хотя бы одну из них, а в оптимальное решение данной подзада
 чи входят обе эти вершины. Поэтому эти подзадачи не являются независимыми. 
Другими словами, использование ресурсов в решении одной подзадачи (в каче
 стве ресурсов выступают вершины) делает их недоступными в другой подзадаче.
 Почему же подзадачи остаются независимыми при поиске самого короткого 
пути? Ответ такой: по самой природе поставленной задачи возникающие в ней 
подзадачи не используют одни и те же ресурсы. Утверждается, что если вершина 
w находится на кратчайшем пути р от вершины и к вершине v, то можно соеди
 нить любой кратчайший путь и & w с любым кратчайшим путем w v, получив 
в результате самый короткий путь от вершины и к вершине v. Мы уверены в том, 
что пути pi и р2 не содержат ни одной общей вершины, кроме w. Почему? Пред
 положим, что имеется некоторая вершина х ф w, принадлежащая путям р\ и р2,
 __ 
Рих 
pxv
 так что путь р\ можно разложить как и ^ х ^ w9 а путь р2 — как w ^ х ^ v. 
В силу оптимальной подструктуры этой задачи количество ребер в пути р равно 
сумме количеств ребер в путях р\ и р2. Предположим, что путь р содержит е ре
 бер. Теперь построим путь р' = и 
х 
v от вершины и к вершине v. В этом 
пути содержится не более е — 2 вершин, что противоречит предположению о том, 
что путь р — кратчайший. Таким образом, мы убедились, что подзадачи, возника
 ющие в задаче поиска кратчайшего пути, являются независимыми.
 Подзадачи, возникающие в задачах, которые рассматриваются в разделах 15.1 
и 15.2, являются независимыми. При перемножении цепочки матриц подзадачи 
заключались в перемножении подцепочек A{Ai+i • • • А^ и 
2■ ■ ■ Aj. Это
 непересекающиеся подцепочки, которые не могут содержать общих матриц. При 
определении наилучшего способа разрезания стержня длиной п мы ищем наи
 лучшие пути разрезания стержня длиной г при г = 0,1,... ,п — 1. Поскольку 
оптимальное решение для длины п включает только одно из решений этих подза
 дач (после отрезания первой части), независимость подзадач не вызывает никаких 
сомнений.
 Перекрытие подзадач
 Вторая составляющая, необходимая для применения динамического програм
 мирования, заключается в том, что пространство подзадач должно быть “неболь
 шим” в том смысле, что в результате выполнения рекурсивного алгоритма одни 
и те же подзадачи решаются снова и снова, а новые подзадачи не возникают. 
Обычно полное количество различающихся подзадач выражается как полиноми
14 3ак. 3726
418
 Часть IV. Усовершенствованные методы разработки и анализа
 альная функция от объема входных данных. Когда рекурсивный алгоритм снова 
и снова обращается к одной и той же задаче, говорят, что задача оптимизации 
содержит перекрывающиеся подзадачи (overlapping subproblems)5. В отличие от 
описанной выше ситуации, в задачах, решаемых с помощью алгоритма разбиения, 
на каждом шаге рекурсии обычно возникают полностью новые задачи. В алгорит
 мах динамического программирования обычно используется преимущество, за
 ключающееся в наличии перекрывающихся подзадач. Это достигается путем од
 нократного решения каждой подзадачи с последующим сохранением результатов 
в таблице, где при необходимости их можно будет найти за фиксированное время.
 В разделе 15.1 мы видели, что рекурсивное решение задачи о разрезании 
стержня выполняло экспоненциальное количество вызовов для поиска решений 
меньших подзадач. Наше решение методом динамического программирования 
превращало экспоненциальный алгоритм в квадратичный.
 Чтобы подробнее проиллюстрировать свойство перекрывания подзадач, еще 
раз обратимся к задаче о перемножении цепочки матриц. Возвратимся к рис. 15.5. 
Обратите внимание, что процедура Matrix-Chain-Order в процессе решения 
подзадач в более высоких строках постоянно обращается к решениям подзадач 
в более низких строках. Например, к элементу тп[3,4] осуществляется четыре об
 ращения: при вычислении элементов тп[2,4], тп[ 1,4], т[3 ,5] и т[3 ,6]. Если бы 
элемент т[3 ,4] каждый раз приходилось вычислять заново, а не просто находить 
в таблице, это привело бы к значительному увеличению времени работы. Чтобы 
продемонстрировать это, рассмотрим приведенную ниже (неэффективную) ре
 курсивную процедуру, в которой определяется величина m[i,j], т.е. минимальное 
количество скалярных умножений, необходимых для вычисления произведения 
цепочки матриц A*. j = AiAi+i • • • Aj. Эта процедура основана непосредственно 
на рекуррентном соотношении (15.7).
 Recursive-Matrix-Chain (р, i,j)
 1 if г == j
 2 
r e tu rn О
 3 m[i,j] = оо
 4 for k = i to j — 1
 5 
q = Recursive-Matrix-Chain (p, i, k)
 + Recursive-Matrix-Chain (p, k + 1 ,j)
 + Pi-iPkPj
 6 
7 
i f q<m[i,j]
 m[i,j] = q
 8 return m[г, j]
 5Может показаться странным, что подзадачи, используемые в динамическом программировании, являются 
и независимыми, и перекрывающимися. Хотя эти требования и могут показаться противоречащими друг другу, 
на самом деле это не так, поскольку они относятся к разным понятиям. Две подзадачи одной и той же задачи 
независимы, если в них не используются общие ресурсы. Две подзадачи перекрываются, если на самом деле 
речь идет об одной и той же подзадаче, возникающей в разных задачах.
Глава 15. Динамическое программирование
 419
 Рис. 15.7. Дерево рекурсии для вычисления Recursive-Matrix-Chain(p, 1,4). Каждый узел 
содержит значения параметров г и j. Вычисления, выполняемые в заштрихованных поддеревьях, 
заменяются в процедуре Memoized-Matrix-Chain единственным поиском в таблице.
 На рис. 15.7 показано дерево рекурсии, полученное в результате вызова про
 цедуры Recursive-Matrix-Chain(р, 1,4). Каждый его узел обозначен величи
 нами параметров г и j. Обратите внимание, что некоторые пары значений встре
 чаются много раз.
 Можно показать, что время вычисления величины m[l,n] этой рекурсивной 
процедурой как минимум экспоненциально зависит от п. Обозначим через Т(п) 
время, которое требуется процедуре Recursive-Matrix-Chain для вычисления 
оптимального способа расстановки скобок в цепочке, состоящей из п матриц. 
Если считать, что выполнение каждой из строк 1 и 2, 6 и 7 требует как минимум 
единичного интервала времени, как и умножение в строке 5, то мы получим такое 
рекуррентное соотношение:
 Т(1) > 1 ,
 П— 1
 Т(п) > 1 + ^(Г(Л ) + Т(п -k) + 1) для п > 1 . 
к=1
 Если заметить, что при г = 1,2, ...,n — 1 каждое слагаемое Т{г) один раз появ
 ляется как Т(к) и один раз как Т(п — к), и просуммировать п — 1 единиц с той, 
которая находится слева от суммы, то рекуррентное соотношение можно перепи
 сать в виде
 П— 1
 Т(п) > 2 ^ Т{г) + п . 
г=1
 (15.8)
 Докажем с помощью метода подстановок, что Т(п) = П(2п). В частности, 
покажем, что для всех п > 1 справедливо соотношение Т(п) > 2п~1. Очевидно, 
что базисное соотношение индукции выполняется, поскольку Т(1) > 1 = 2°.
420
 Часть IV Усовершенствованные методы разработки и анализа
 Далее, по методу математической индукции для п > 2 имеем
 п—1
 Т(п) > 2 ^ 2 i_1 + п
 i= 1 
п—2
 = 2 2* + п
 г=0
 = 2(2n_1 — 1) + п 
(согласно (А.5))
 = 2П - 2 + п 
> 2п~1 ,
 что и завершает доказательство. Таким образом, полное количество вычис
 лений, которые выполняются при вызове процедуры Recursive-Matrix- 
Chain (р, 1, п), как минимум экспоненциально зависит от п.
 Сравним этот нисходящий рекурсивный алгоритм (без запоминания) с восхо
 дящим алгоритмом, построенным по принципу динамического программирова
 ния. Последний работает эффективнее, поскольку в нем используется свойство 
перекрывающихся подзадач. Всего в задаче о перемножении цепочки матриц воз
 никает 0(п2) различных подзадач, и в алгоритме, основанном на принципах ди
 намического программирования, каждая из них решается ровно по одному разу. 
В рекурсивном же алгоритме каждую подзадачу необходимо решать всякий раз, 
когда она возникает в рекурсивном дереве. Каждый раз, когда рекурсивное де
 рево для обычного рекурсивного решения задачи несколько раз включает в себя 
одну и ту же подзадачу, а общее количество подзадач невелико, следует задумать
 ся о возможности применить динамическое программирование, которое может 
повысить эффективность решения такой задачи, причем зачастую — повысить 
кардинально.
 Построение оптимального решения
 На практике мы часто сохраняем в таблице информацию о том, какой выбор 
был сделан в каждой подзадаче, так что впоследствии нам не нужно дополни
 тельно решать задачу восстановления этой информации.
 В задаче перемножения цепочки матриц таблица s[z,j] экономит нам массу ра
 боты при построении оптимального решения. Предположим, что мы не поддер
 живаем таблицу 
j], заполняя только лишь таблицу m[i,j] стоимостями опти
 мальных решений подзадач. В таком случае при построении оптимального реше
 ния нам придется осуществлять выбор среди j — i вариантов, чтобы определить, 
какая из подзадач используется в оптимальном решении задачи о расстановке 
скобок в цепочке AiAi+i • • • Aj, a j — г не является константой. Следовательно, 
время, требуемое для определения выбранной для подзадачи с оптимальным ре
 шением, составляет 0(j — г) — ы(1). В случае хранения индекса матрицы для 
оптимального разбиения цепочки AiAi+i • • • Aj каждый выбор восстанавливает
 ся за время 0(1).
Гчава 15. Динамическое программирование
 421
 Запоминание
 Как мы видели в задаче о разрезании стержня, имеется альтернативный под
 ход динамического программирования, который зачастую обеспечивает эффек
 тивность восходящего подхода при применении нисходящей стратегии. Идея за
 ключается в оснащении естественного, но неэффективного алгоритма запомина
 нием. Как и при восходящем подходе, мы поддерживаем таблицу с решениями 
подзадач, но управляющая структура для заполнения таблицы больше похожа на 
рекурсивный алгоритм.
 В рекурсивном алгоритме с запоминанием для решения каждой подзадачи 
поддерживается соответствующий элемент таблицы. Изначально в каждом та
 ком элементе таблицы содержится специальное значение, указывающее на то, 
что данный элемент еще не заполнен. Если в процессе выполнения рекурсивного 
алгоритма подзадача встречается впервые, ее решение вычисляется и заносится 
в таблицу. Каждый раз, когда эта подзадача будет встречаться снова, будет выпол
 няться поиск ее решения в таблице6.
 Ниже приведена версия процедуры Recursive-Matrix-Chain с запомина
 нием. Обратите внимание на сходство этой процедуры с нисходящим методом 
с запоминанием, примененным для решения задачи о разрезании стержня.
 Memoized-Matrix-Chain (р)
 1 п = р. length — 1
 2 т[ 1 .. n, 1 .. п] — новая таблица
 3 for г = 1 to п
 4 
for j = i to n
 5 
га[г, j] = oo
 6 return Lookup-Chain (m, p, 1, n)
 Lookup-Chain (m, p, i, j )
 1 if m[i,j] < oo
 2 
return m[i,j]
 3 if i== j
 4 
m[i,j] = 0
 5 else for k = i to j — 1
 6 
q = Lookup-Chain (т,р,г,/г)
 + Lookup-Chain (m, p, k + l,j) +Pi-\PkPj
 7 
8 
if q<m[i,j]
 rn[ij] = q
 9 return m[i,j\
 В процедуре Memoized-Matrix-Chain, как и в процедуре Matrix-Chain- 
Order, поддерживается таблица т[ 1.. n, 1.. п], состоящая из вычисленных зна
6В этом подходе предполагается, что известен набор параметров всех возможных подзадач и установле
 но соответствие между ячейками таблицы и подзадачами. Другой подход состоит в том, чтобы организовать 
запоминание с помощью хеширования, в котором в качестве ключей выступают параметры подзадач.
422
 Часть IV. Усовершенствованные методы разработки и анализа
 чений т[г, j\, которые представляют собой минимальное количество скалярных 
умножений, необходимых для вычисления матрицы Ai„j. Изначально каждый эле
 мент таблицы содержит значение оо, указывающее на то, что данный элемент еще 
должен быть заполнен. Если при вызове процедуры Lookup-Chain(m,p, г, j) 
в строке 1 выполняется условие т[г, j] < оо, то эта процедура в строке 2 про
 сто возвращает ранее вычисленную стоимость m[i,j]. В противном случае эта 
стоимость вычисляется так же, как и в процедуре Recursive-Matrix-Chain, 
сохраняется в элементе 
после чего возвращается. Таким образом, проце
 дура Lookup-Chain(m,p,i,j) всегда возвращает значение 
но оно вы
 числяется лишь в том случае, если это первый вызов данной процедуры с этими 
параметрами г и j.
 На рис. 15.7 показано, насколько эффективнее процедура Memoized-Matrix- 
Chain расходует время по сравнению с процедурой Recursive-Matrix-Chain. 
Затененные поддеревья представляют значения, которые вычисляются только 
один раз. При возникновении повторной потребности в этих значениях вместо 
их вычисления осуществляется поиск в хранилище.
 Время работы процедуры Memoized-Matrix-Chain, как и время выполне
 ния алгоритма Matrix-Chain-Order, построенного по принципу динамическо
 го программирования, равно 0(п3). Строка 5 процедуры Memoized-Matrix- 
Chain выполняется О(п2) раз. Все вызовы процедуры Lookup-Chain можно 
разбить на два типа:
 1 . вызовы, в которых выполняется условие га[г, j] = оо, так что выполняются
 строки 3-9;
 2. вызовы, в которых выполняется условие m[i,j] < оо, так что процедура
 Lookup-Chain просто выполняет возврат в строке 2.
 Всего вызовов первого типа насчитывается 0(п2), по одному на каждый элемент 
таблицы. Все вызовы второго типа осуществляются как рекурсивные обраще
 ния из вызовов первого типа. Всякий раз, когда в некотором вызове процеду
 ры Lookup-Chain выполняются рекурсивные обращения, общее их количество 
равно 0(п). Поэтому в общем итоге производится 0(п3) вызовов второго типа, 
причем на каждый из них расходуется время 0(1). На каждый вызов первого 
типа требуется время О(п) плюс время, затраченное на рекурсивные обращения 
в данном вызове первого типа. Поэтому общее время равно 0(п3). Таким об
 разом, запоминание преобразует алгоритм, время работы которого равно П(2П), 
в алгоритм со временем работы 0 (п3).
 В итоге получается, что задачу об оптимальном способе перемножения це
 почки матриц можно решить либо с помощью алгоритма с запоминанием, рабо
 тающего в нисходящем направлении, либо с помощью динамического програм
 мирования в восходящем направлении. При этом в обоих случаях потребуется 
время, равное 0(п3). Оба метода используют преимущество, возникающее бла
 годаря перекрытию подзадач. Всего возникает только @(п2) различных подзадач, 
и в каждом из описанных выше методов решение каждой из них вычисляется 
один раз. Если не применять запоминание, то время работы обычного рекур
Глава 15. Динамическое программирование
 423
 сивного алгоритма станет экспоненциальным, поскольку уже решенные задачи 
придется неоднократно решать заново.
 В общем случае, если все подзадачи необходимо решить хотя бы по одному 
разу, восходящий алгоритм, построенный по принципу динамического програм
 мирования, обычно работает быстрее, чем нисходящий алгоритм с запоминани
 ем. Причины — отсутствие непроизводительных накладных расходов на рекурсию 
и их сокращение при поддержке таблицы. Более того, в некоторых задачах после 
определенных исследований удается сократить время доступа к таблице или за
 нимаемый ею объем. Если же можно обойтись без решения некоторых подзадач, 
содержащихся в пространстве подзадач данной задачи, запоминание результатов 
решений обладает тем преимуществом, что решаются только действительно необ
 ходимые подзадачи.
 Упражнения
 15.3.1
 Как эффективнее определить оптимальное количество скалярных умножений 
в задаче о перемножении цепочки матриц: перечислить все способы расстановки 
скобок в произведении матриц и вычислить количество скалярных умножений 
в каждом из них или запустить процедуру Recursive-Matrix-Chain? Обос
 нуйте ответ.
 15.3.2
 Изобразите рекурсивное дерево для процедуры Merge-Sort, описанной в раз
 деле 2.3.1 и работающей с массивом из 16 элементов. Объясните, почему для по
 вышения производительности работы хорошего алгоритма “разделяй и властвуй”, 
такого как Merge-Sort, использование запоминания не даст никакого улучше
 ния производительности.
 15.3.3
 Рассмотрим разновидность задачи о перемножении цепочки матриц, цель кото
 рой — так расставить скобки в последовательности матриц, чтобы количество 
скалярных умножений стало не минимальным, а максимальным. Проявляется ли 
в этой задаче оптимальная подструктура?
 15.3.4
 Как говорилось выше, в динамическом программировании сначала решаются под
 задачи, а затем выбираются те из них, которые будут использованы в оптималь
 ном решении задачи. Профессор утверждает, что не всегда необходимо решать 
все подзадачи, чтобы найти оптимальное решение. Он выдвигает предположение 
о том, что оптимальное решение задачи о перемножении цепочки матриц можно 
найти, всегда выбирая матрицу Ak, после которой следует разбивать произве
 дение AiAi+i ■ • • Aj (индекс к выбирается так, чтобы минимизировать величину 
Pi-iPkPj) перед решением подзадач. Приведите пример задачи о перемножении 
цепочки матриц, в котором такой жадный подход приводит к решению, отлично
 му от оптимального.
424
 15.3.5
 Часть IV. Усовершенствованные методы разработки и анализа
 Предположим, что в задаче о разрезании стержня из раздела 15.1 имеется пре
 дельное значение U количества частей длиной г (г = 1 , 2 , . . . , п) , которое можно 
получить при разрезании одного стержня. Покажите, что свойство оптимальной 
подструктуры из раздела 15.1 в этом случае не выполняется.
 15.3.6
 Представим, что вы хотите обменять одну валюту на другую. Вы надеетесь на то, 
что если вместо непосредственного обмена выполнить несколько промежуточных 
обменов на другие валюты, то обмен получится более выгодным. Предположим, 
что можно выполнять обмен п различных валют, пронумерованных 1,2, ...,п, 
причем вы начинаете с валюты 1 и хотите закончить валютой п. Для каждой па
 ры валют г и j у вас имеется обменный курс г^, означающий, что если у вас 
есть d единиц валюты г, то вы можете получить за них drij единиц валюты j. 
Последовательность обменов может вызывать комиссионные сборы, зависящие 
от количества произведенных обменов. Пусть Q. — комиссионный сбор, кото
 рый вы должны заплатить за к обменов. Покажите, что, если сд, = 0 для всех 
к = 1,2,... ,п, то задача поиска наилучшей последовательности обменов валю
 ты 1 на валюту п демонстрирует оптимальную подструктуру. Затем покажите, что 
если комиссионные сборы сд, имеют произвольные значения, то эта задача поиска 
наилучшей последовательности обменов валюты 1 на валюту п такой оптималь
 ной подструктурой может и не обладать.
 15.4. 
Наидлиннейшая общая подпоследовательность
 В биологических приложениях часто возникает необходимость сравнить ДНК 
двух (или более) различных организмов. Стандартная ДНК состоит из после
 довательности молекул, которые называются основаниями (bases). К этим мо
 лекулам относятся: аденин (adenine), гуанин (guanine), цитозин (cytosine) и ти
 мин (thymine). Если обозначить каждое из перечисленных оснований его на
 чальной буквой латинского алфавита, то стандартную ДНК можно представить 
в виде строки, состоящей из конечного множества элементов {А, С, G, Т}. (Опре
 деление строки см. в приложении В.) Например, ДНК одного организма мо
 жет иметь вид S\ = ACCGGTCGAGTGCGCGGAAGCCGGCCGAA, а ДНК другого — 
5 2 = GTCGTTCGGAATGCCGTTGCTCTGTAAA Одна из целей сравнения двух ДНК 
состоит в том, чтобы выяснить степень их сходства. Это один из показателей то
 го, насколько тесно связаны между собой два организма. Степень подобия можно 
определить многими способами. Например, можно сказать, что два кода ДНК по
 добны, если один из них является подстрокой другого. (Алгоритмы, с помощью 
которых решается эта задача, исследуются в главе 32.) В нашем примере ни Si, 
ни 5г не является подстрокой другой ДНК. В этом случае можно сказать, что 
две цепочки молекул подобны, если для преобразования одной из них в другую 
потребовались бы только небольшие изменения. (Такой подход рассматривается
Глава 15. Динамическое программирование
 425
 в задаче 15.5.) Еще один способ определения степени подобия последовательно
 стей S\ и 
заключается в поиске третьей последовательности S3, основания 
которой имеются как в Si, так и в S2; при этом они следуют в одном и том 
же порядке, но не обязательно одно за другим. Чем длиннее последовательность 
S3, тем более схожи последовательности Si и S2. В рассматриваемом примере 
наидлиннейшая последовательность S3 имеет вид GTCGTCGGAAGCCGGCCGAA.
 Последнее из упомянутых выше понятий подобия формализуется в виде за
 дачи о наидлиннейшей общей подпоследовательности. Подпоследовательность 
данной последовательности — это просто данная последовательность, из кото
 рой удалили нуль или более элементов. Формально последовательность Z = 
(z\, 22, , Zk) является подпоследовательностью (subsequence) последователь
 ности X = (xi, Х2, ..., хт ), если существует строго возрастающая последова
 тельность (ii, гг,..., ik) индексов X , такая, что для всех j = 1,2,..., к выпол
 няется соотношение х^ = zj. Например, Z = {B,C,D, В) представляет собой 
подпоследовательность последовательности X = (А, В , С, В, D, А, В), причем 
соответствующая ей последовательность индексов имеет вид (2,3,5,7).
 Говорят, что последовательность Z является общей подпоследовательностью 
(common subsequence) последовательностей X и Y, если Z является подпосле
 довательностью как X, так и Y. Например, если X — (А, В, С, В, D, А, В) 
и Y = (В, £>, С, А, В, А), то последовательность (В , С, А) является общей 
подпоследовательностью X и Y. Однако последовательность (В, С, А) — не на
 идлиннейшая общая подпоследовательность X и Y, поскольку ее длина равна 3, 
а длина последовательности (В , С, В , А), которая также является общей подпо
 следовательностью X и Y, равна 4. Последовательность (В , С, В, А) — наид
 линнейшая общая подпоследовательность (longest common subsequence — LCS) 
последовательностей X и Y, как и последовательность (В, D, А, В), поскольку 
не существует общей подпоследовательности длиной 5 элементов или более.
 В задаче о наидлиннейшей общей подпоследовательности задаются две по
 следовательности, X = (xi, Х2,..., хт) и Y = (у\, у2,..., уп), и требуется найти 
общую подпоследовательность X и Y максимальной длины. В данном разделе 
показано, что эта задача эффективно решается методом динамического програм
 мирования.
 Этап 1. Характеристика наидлиннейшей общей подпоследовательности
 Решение задачи поиска наидлиннейшей общей подпоследовательности “в лоб” 
заключается в том, чтобы перечислить все подпоследовательности последователь
 ности X и проверить, являются ли они также подпоследовательностями Y, пы
 таясь отыскать при этом наидлиннейшую из них. Каждая подпоследовательность 
последовательности X соответствует подмножеству индексов {1,2, ...,т} по
 следовательности X. Всего имеется 2т подпоследовательностей последователь
 ности X, поэтому время работы алгоритма, основанного на этом подходе, будет 
экспоненциально зависеть от размера задачи, и для длинных последовательностей 
он становится непригодным.
 Однако задача поиска наидлиннейшей общей подпоследовательности обладает 
оптимальной подструктурой. Этот факт доказывается в сформулированной ниже
426
 Часть IV. Усовершенствованные методы разработки и анализа
 теореме. Как мы увидим, естественно возникающие классы подзадач соответству
 ют парам “префиксов” двух входных последовательностей. Дадим точное опре
 деление этого понятия: г-м префиксом последовательности X = (xi, Х2,..., х т ) 
для г = 1,2,..., т является подпоследовательность Xi = (х\, Х2,..., х^). Напри
 мер, если X = (Л, В , С, В , D, А, Б), то Х± = (Л, 5, С, 5), а Хо представляет 
собой пустую последовательность.
 Теорема 15.1 (Оптимальная подструктура LCS)
 Пусть имеются последовательности X = (xi, хг,..., хш) и У — (у\, уъ,..., ?/n) 
и пусть Z = (zi, 22,..., Zk) — наидлиннейшая общая подпоследовательность X 
и Y.
 1. Если хш = т/п, то 
= хш = уп и Zk-1 — LCS последовательностей Xm_i
 и У„_1.
 2. Если хш ф уп, то из Zfc ф хт вытекает, что Z представляет собой LCS после
 довательностей Хт- 1 и Y.
 3. Если хт ф уп, то из Zk ф Уп вытекает, что Z представляет собой LCS после
 довательностей X и Yn- 1.
 Доказательство. (1) Если бы выполнялось соотношение Zk ф хт , то к по
 следовательности Z можно было бы добавить элемент хт = уп, в результате 
чего получилась бы общая подпоследовательность последовательностей X и Y 
длиной к + 1, а это противоречит предположению о том, что Z — наидлшней- 
шая общая подпоследовательность последовательностей X и Y. Таким образом, 
должно выполняться соотношение Zk = хт = уп. Итак, префикс Zk-i — общая 
подпоследовательность последовательностей Хт_\ и Yn-\ длиной к — 1. Нужно 
показать, что это наидлиннейшая общая подпоследовательность. Проведем дока
 зательство методом от противного. Предположим, что имеется общая подпосле
 довательность W последовательностей Х т-\ и Yn- 1, длина которой превышает 
к — 1. Добавив к W элемент хш = уп, получим общую подпоследовательность 
последовательностей X и Y, длина которой превышает к, что приводит к проти
 воречию.
 (2) Если Zk ф хш, то Z — общая подпоследовательность последовательностей 
Xm-i и Y. Если бы существовала общая подпоследовательность W последова
 тельностей Xm_i и У, длина которой превышала бы к, то она была бы также 
общей подпоследовательностью последовательностей Х т и У, что противоречит 
предположению о том, что Z — наидлиннейшая общая подпоследовательность 
последовательностей X и У.
 (3) Доказательство симметрично (2). 
■
 Из теоремы 15.1 видно, что наидлиннейшая общая подпоследовательность 
двух последовательностей содержит в себе наидлиннейшую общую подпоследо
 вательность их префиксов. Таким образом, задача о наидлиннейшей общей под
 последовательности обладает оптимальной подструктурой. В рекурсивном реше
 нии этой задачи также возникают перекрывающиеся подзадачи, но об этом речь 
пойдет чуть позже.
Глава 15. Динамическое программирование
 427
 Этап 2. Рекурсивное решение
 Из теоремы 15.1 следует, что при нахождении наидлиннейшей общей под
 последовательности последовательностей X = (xi, £2, ■ • •, хт) и Y = {у\,у2, 
..., уп) возникает одна или две подзадачи. Если хт = уп, необходимо най
 ти наидлиннейшую общую подпоследовательность последовательностей Х т-\ 
и Yn- \. Добавив к ней элемент хт = уп, получим LCS последовательностей X 
и Y. Если хт ф Уп, необходимо решить две подзадачи: найти LCS последова
 тельностей Xm-i и У, а также последовательностей X и Yn-\. Какая из этих 
двух подпоследовательностей окажется длиннее, та и будет наидлиннейшей об
 щей подпоследовательностью последовательностей X и Y. Поскольку эти случаи 
исчерпывают все возможности, мы знаем, что одно из оптимальных решений под
 задач должно находиться в LCS X и Y.
 В задаче поиска наидлиннейшей общей подпоследовательности легко увидеть 
проявление свойства перекрывающихся подзадач. Чтобы найти LCS последо
 вательностей X и Y, может понадобиться найти LCS последовательностей X 
и Yn-\, а также последовательностей Х т-\ и Y . Однако в каждой из этих подза
 дач возникает подзадача поиска LCS последовательностей Х т-\ и Yn-\. Общие 
подзадачи возникают и во многих других случаях.
 Как и в задаче о перемножении цепочки матриц, в рекурсивном решении зада
 чи о наидлиннейшей общей подпоследовательности устанавливается рекуррент
 ное соотношение для значений, характеризующих оптимальное решение. Обо
 значим через c[i,j] длину наидлиннейшей общей подпоследовательности после
 довательностей Х{ и Yj. Если г = 0 или j = 0, длина одной из этих последо
 вательностей равна нулю, поэтому наидлиннейшая их общая подпоследователь
 ность имеет нулевую длину. Оптимальная вспомогательная подструктура задачи 
о наидлиннейшей общей подпоследовательности определяется рекурсивной фор
 мулой
 О , 
ф ,л
 < с[г — 1, j — 1] + 1 , 
если г = 0 или j = 0 ,
 если i,j > 0 и Х{ = yj ,
 k таx(c[i,j - 1 ],с[г - 1 ,j]) , если г, j > 0 и х{ ф yj .
 (15.9)
 Обратите внимание, что в этой рекурсивной формулировке условия задачи 
ограничивают круг рассматриваемых подзадач. Если Xi = yj, можно и нужно 
рассматривать подзадачу поиска наидлиннейшей общей подпоследовательности 
последовательностей Xi- 1 и Yj-1. В противном случае рассматриваются две под
 задачи поиска LCS последовательностей Xi и Yj-1, а также Xi- 1 и Yj. В рассмот
 ренных ранее алгоритмах, основанных на принципах динамического программи
 рования (для задач о разрезании стержня и о перемножении цепочки матриц), вы
 бор подзадач не зависел от условий задачи. Задача поиска LCS не единственная, 
в которой вид возникающих подзадач определяется условиями задачи. В качестве 
другого подобного примера можно привести задачу о расстоянии редактирования 
(см. задачу 15.5).
428
 Часть IV. Усовершенствованные методы разработки и анализа
 Этап 3. Вычисление длины наидлиннейшей общей подпоследовательности
 На основе уравнения (15.9) легко написать рекурсивный алгоритм с экспонен
 циальным временем работы, предназначенный для вычисления длины LCS двух 
последовательностей. Однако благодаря наличию всего лишь О (тп) различных 
подзадач можно воспользоваться динамическим программированием для вычис
 ления решения в восходящем направлении.
 В процедуре LCS-Length в роли входных данных выступают две последова
 тельности X = (х\,Х2, ■ ■ ■, хт) и Y = (у\, у2,.. •, Уп)■ Величины c[i,j] хранятся 
в таблице с[0.. тп, 0.. п], элементы которой вычисляются построчно (т.е. снача
 ла слева направо заполняется первая строка, затем — вторая и т.д.). В процеду
 ре также поддерживается таблица Ь[1.. тп, 1.. п\, благодаря которой упрощается 
процесс построения оптимального решения. Наглядный смысл элементов b[i,j] 
состоит в том, что каждый из них указывает на элемент таблицы, соответству
 ющий оптимальному решению подзадачи, выбранной при вычислении элемента 
c[i,j]. Процедура возвращает таблицы 6 и с; в элементе с[тп,п] хранится длина 
LCS последовательностей X и Y.
 LCS-Length (X,Y)
 1 тп = X. length
 2 п = Y. length
 3 b[l.. m, 1.. п] и с[0.. m, 0.. n] — новые таблицы
 4 for г = 1 to тп
 5
 с[г, 0] = 0
 6 for j — 0 to п
 7
 с[0, j\ = 0
 8 for г = 1 to тп
 9
 for j = 1 to n
 10
 И
 if Xi 
yj
 Ф,7'] = c[i - 1, j - 1] + 1
 12
 13
 14
 15
 16
 17
 b[i,j] =
 elseif c[i — 1 ,j] > c[i,j — 1]
 II
 b[i,j} =
 Ф - 1,7]
 else c[i,j\ = Ф,7 - 1]
 b[i,j] = 44^_1)
 18 return с и b
 На рис. 15.8 показаны таблицы, полученные в результате работы процедуры LCS- 
Length с последовательностями X = (А, В, С, В, D,A,B)uY = (В, D, С, А, В, 
А). Время работы процедуры равно 0(тп), поскольку каждый элемент таблицы 
вычисляется за время 0(1).
 Этап 4. Построение наидлиннейшей общей подпоследовательности
 С помощью таблицы 6, которая возвращается процедурой LCS-LENGTH, мож
 но быстро построить самую длинную общую подпоследовательность последо
Глава 15. Динамическое программирование
 j 
/
 0
 1
 2
 3
 4
 5
 6 
7
 0 
у} 
1 
В D С А В А
 429
 2 
3 
4 
5 
6
 Рис. 15.8. Таблицы с и 6, полученные в результате работы процедуры L C S-L E N G TH с последова
 тельностями X = (А, В, С, В, D,A,B)hY — (В, D, С, А, В, А). Квадрат на пересечении строки 
г и столбца j содержит значение c[i,j] и стрелку в качестве значения элемента b[i,j]. Значение 4 
в квадрате с[7,6] — нижнем правом углу таблицы — представляет собой длину LCS (В, С, В, А) 
последовательностей X и Y. При i,j > 0 элемент с [г, j] зависит только от того, выполняется ли 
равенство я, = yj, и от значений в элементах с[г — 1, j\, c[i, j — 1] и c[i — 1 ,j — 1], которые вычисля
 ются до вычисления с[г, j]. Чтобы восстановить элементы, входящие в LCS, следуем по стрелкам 
b[i,j] из нижнего правого угла таблицы; на рисунке эта последовательность заштрихована. Каждая 
стрелка “\ ” в этой последовательности соответствует элементу, для которого Xi = yj является 
членом LCS.
 вательностей X = (xi, Х2, - хт ) и Y = (у\, У2, 
Уп)• Мы просто на
 чинаем с элемента Ь[тп,п] и проходим таблицу по стрелкам. Если значением 
элемента Ь[г, j] является 
то элемент х* = yj принадлежит наидлиннейшей 
общей подпоследовательности. Элементы LCS, восстановленные этим методом, 
следуют в обратном порядке. Приведенная ниже рекурсивная процедура выво
 дит элементы самой длинной общей подпоследовательности последовательно
 стей X и У в прямом порядке. Начальный вызов этой процедуры выглядит как 
PRINT-LCS (6, X, X. length, У. length).
 PRINT-LCS(6, X,i,j)
 1 if i == 0 or j == 0
 2 
return
 3 if b[i,j\ == “V
 4 
Print-LCS(6, Jf, г — l,j — 1)
 5 
print X{
 6 elseif b[i,j] == “t ”
 7 
Print-LCS(6,X ,г- l,j)
 8 else Print-LCS (6, X , г, j - 1)
 Для таблицы b, изображенной на рис. 15.8, эта процедура выводит последова
 тельность “ВСВА”. Время работы процедуры равно 0(т + п), поскольку хотя 
бы один из индексов г или j уменьшается при каждом рекурсивном вызове.
430
 Улучшение кода
 Часть IV. Усовершенствованные методы разработки и анализа
 После разработки алгоритма часто оказывается, что можно улучшить время 
его работы или объем требуемой им памяти. Одни изменения могут упростить 
код и уменьшить постоянный множитель, но при этом не приводят к повышению 
производительности в асимптотическом пределе. Другие же могут вызвать суще
 ственную асимптотическую экономию времени работы и используемой памяти.
 Например, в алгоритме поиска LCS можно обойтись без таблицы Ь. Каж
 дый элемент c[i,j] зависит только от трех других элементов этой же таблицы: 
с[г — 1 ,j — 1], с [г — 1 ,j] и с[г, j — 1]. Для данного элемента c[i,j] в течение вре
 мени 0(1) можно определить, какое из этих трех значений было использовано 
для вычисления c[i,j\, не прибегая к таблице Ъ. Таким образом, самую длинную 
общую подпоследовательность можно восстановить в течение времени 0 ( т + п). 
Для этого понадобится процедура, подобная процедуре Print-LCS (такую про
 цедуру предлагается составить в упр. 15.4.2). Несмотря на то что в этом методе 
экономится объем памяти, равный 0(тп), асимптотически количество памяти, 
необходимой для вычисления самой длинной общей подпоследовательности, не 
изменяется. Это объясняется тем, что таблица с все равно требует 0 (тп ) памяти.
 Однако можно уменьшить асимптотический объем памяти, необходимой для 
работы процедуры Print-LCS, поскольку одновременно нужны лишь две стро
 ки таблицы с: вычисляемая и предыдущая. (Фактически для вычисления длины 
самой длинной общей подпоследовательности можно обойтись пространством, 
лишь немного превышающим объем, необходимый для одной строки матрицы с; 
см. упр. 15.4.4.) Это усовершенствование работает лишь в том случае, когда нуж
 но знать только длину самой длинной общей подпоследовательности. Если же 
необходимо воссоздать элементы этой подпоследовательности, такая “урезанная” 
таблица содержит недостаточно информации для того, чтобы проследить обрат
 ные шаги за время 0(т + п).
 Упражнения
 15.4.1
 Определите LCS последовательностей (1,0,0,1,0,1,0,1) и (0,1,0,1,1,0,1,1,0).
 15.4.2
 Напишите псевдокод для воссоздания наидлиннейшей общей подпоследователь
 ности из заполненной таблицы с и исходных последовательностей X = (xi, £2, 
..., хт) u Y = (t/i, У2,..., уп) за время 0(т + п), не используя таблицу Ъ.
 15.4.3
 Приведите версию процедуры LCS-Length с запоминанием, время работы ко
 торой равно О (ran).
 15.4.4
 Покажите, как вычислить длину наидлиннейшей общей подпоследовательности, 
используя при этом только 2 • min(ra,n) элементов таблицы с плюс 0(1) допол
Глава 15. Динамическое программирование
 431
 нительной памяти. Затем покажите, как то же самое можно сделать с помощью 
min(т,п) элементов таблицы и 0(1) дополнительной памяти.
 15.4.5
 Разработайте алгоритм, предназначенный для вычисления наидлиннейшей моно
 тонно неубывающей подпоследовательности данной последовательности, состо
 ящей из п чисел. Время работы алгоритма должно быть равно 0(п2).
 15.4.6 ★
 Разработайте алгоритм, предназначенный для вычисления наидлиннейшей моно
 тонно неубывающей подпоследовательности данной последовательности, состо
 ящей из п чисел. Время работы алгоритма должно быть равно O(nlgn). (Указа
 ние: обратите внимание, что последний элемент кандидата в искомую подпосле
 довательность длиной г по величине не меньше последнего элемента кандидата 
длиной г — 1.)
 15.5. 
Оптимальные бинарные деревья поиска
 Предположим, что разрабатывается программа, предназначенная для перевода 
текстов с русского языка на украинский. Для каждого русского слова необходимо 
найти украинский эквивалент. Один из возможных путей поиска — построение 
бинарного дерева поиска с п русскими словами, выступающими в роли клю
 чей, и украинскими эквивалентами, играющими роль сопутствующих данных. 
Поскольку поиск с помощью этого дерева будет производиться для каждого от
 дельного слова из текста, полное затраченное на него время должно быть как 
можно меньше. С помощью красно-черного дерева или любого другого сбалан
 сированного бинарного дерева поиска можно добиться того, что время каждого 
отдельного поиска будет равным O(lgn). Однако слова встречаются с разной ча
 стотой, и может получиться так, что какое-нибудь часто употребляемое слово 
(например, предлог или союз) находится далеко от корня, а такое редкое сло
 во, как контрвстреча, — возле корня. Подобный способ организации привел бы 
к замедлению перевода, поскольку количество узлов, просмотренных в процессе 
поиска ключа в бинарном дереве, равно увеличенной на единицу глубине узла, 
содержащего данный ключ. Нужно сделать так, чтобы слова, которые встречают
 ся в тексте часто, были размещены поближе к корню.7 Кроме того, в исходном 
тексте могут встречаться слова, для которых перевод отсутствует. Таких слов мо
 жет вообще не оказаться в бинарном дереве поиска. Как организовать бинарное 
дерево поиска, чтобы свести к минимуму количество посещенных в процессе 
поиска узлов, если известно, с какой частотой встречаются слова?
 То, что мы хотим получить, называется оптимальное бинарное дерево поис
 ка (optimal binary search tree). Приведем формальное описание задачи. Имеется
 7Впрочем, одни и те же слова в текстах разной тематики могут встречаться с разной частотой.
432
 Часть IV. Усовершенствованные методы разработки
 Рис. 15.9. Два бинарных дерева поиска для множества из п — 5 ключей со следующими вероят
 ностями.
 i
 0
 Pi
 Qi
 0.05
 1
 0.15
 2
 3
 4
 5
 0.10 0.05 0.10 0.20
 0.10 0.05 0.05 0.05 0.10
 (а) Бинарное дерево поиска с ожидаемой стоимостью поиска 2.80. (б) Бинарное дерево поиска 
с ожидаемой стоимостью поиска 2.75. Это дерево — оптимальное.
 заданная последовательность К = {к\, &2, ..., кп), состоящая из п различных 
ключей, которые расположены в отсортированном порядке (так что ki < &2 < 
• • ■ < кп). Из этих ключей нужно составить бинарное дерево поиска. Для каждо
 го ключа ki задана вероятность pi поиска этого ключа. Кроме того, может выпол
 няться поиск значений, отсутствующих в последовательности К, поэтому следу
 ет предусмотреть п +1 фиктивных ключей do, d\, di,..., dn, представляющих эти 
значения. В частности, do представляет все значения, меньшие к\, a dn — все зна
 чения, превышающие кп. Фиктивный ключ di (г = 1,2,... ,71 — 1) представляет 
все значения, которые находятся между к{ и ki+\. Для каждого фиктивного ключа 
d{ задана соответствующая ей вероятность <^. На рис. 15.9 показаны два бинар
 ных дерева поиска для множества, состоящего из п — 5 ключей. Каждый ключ ki 
представлен внутренним узлом, а каждый фиктивный ключ di является листом. 
Поиск может быть либо успешным (найден какой-то ключ ki), либо неудачным 
(возвращается какой-то фиктивный ключ di), поэтому справедливо соотношение
 71 
71
 У > + У > = 1. 
г = 1 
г=0
 (15.10)
 Поскольку вероятность поиска каждого обычного и фиктивного ключа извест
 на, можно определить математическое ожидание стоимости поиска по заданному 
бинарному дереву поиска Т. Предположим, что фактическая стоимость поиска 
определяется количеством проверенных узлов, т.е. увеличенной на единицу глу
 биной узла на дереве Т, в котором находится искомый ключ. Тогда математиче
Глава 15. Динамическое программирование
 ское ожидание стоимости поиска в дереве Т равно
 П 
Е [стоимость поиска вГ] = ^ (d ep th T(fc*) + 1) ■ pi 
i—\ 
n 
433
 П
 г=0
 (depthr (dj) + 1) • qi
 n
 = 1 +У^ depthT(kj) pi +y^depthT(dj) • , (15.11)
 г=1 
г=0
 где величина depthT обозначает глубину узла в дереве Т. Последнее равенство 
следует из уравнения (15.10). Используя приведенную на рис. 15.9 таблицу ве
 роятностей, можно вычислить математическое ожидание стоимости поиска для 
бинарного дерева, изображенного в части (а) рисунка.
 Узел Глубина Вероятность Вклад
 1
 к\
 к2
 кз
 к5
 do
 d\
 d2
 do
 d4
 do
 Всего 
0.15
 0
 2
 1
 2
 2
 2
 3
 3
 3
 3
 0.10
 0.05
 0.10
 0.20
 0.05
 0.10
 0.05
 0.05
 0.05
 0.10
 0.30
 0.10
 0.15
 0.20
 0.60
 0.15
 0.30
 0.20
 0.20
 0.20
 0.40
 2.80
 Наша цель — построить для данного набора вероятностей бинарное дерево 
поиска, математическое ожидание стоимости поиска для которого будет мини
 мальным. Такое дерево называется оптимальным бинарным деревом поиска. 
На рис. 15.9, (б) показано оптимальное бинарное дерево поиска для вероятностей, 
указанных в таблице в подписи к рисунку. Математическое ожидание стоимости 
поиска в этом дереве равно 2.75. Этот пример демонстрирует, что оптимальное 
бинарное дерево поиска — это не обязательно дерево минимальной высоты. Кро
 ме того, в оптимальном дереве ключ, которому соответствует максимальная веро
 ятность, не всегда находится в корне. В данном случае вероятность имеет самую 
большую величину для ключа ко, хотя в корне оптимального бинарного дерева 
расположен ключ к2. (Минимальная величина математического ожидания сто
 имости поиска для всевозможных бинарных деревьев поиска, в корне которых 
находится ключ ко, равна 2.85.)
 Как и в задаче о перемножении цепочки матриц, последовательный пере
 бор всех возможных деревьев в данном случае оказывается неэффективным. 
Чтобы сконструировать бинарное дерево поиска, можно обозначить ключами 
к\, к2, • ■ • ,кп узлы бинарного дерева с п узлами, а затем добавить листья для фик
 тивных ключей. В задаче 12.4 было показано, что количество бинарных деревьев 
с п узлами равно Q(4n /п3/2), так что количество бинарных деревьев, которые 
нужно проверять при полном переборе, растет экспоненциально с ростом п. Не
434
 Часть IV Усовершенствованные методы разработки и анализа
 удивительно, что эта задача будет решаться методом динамического программи
 рования.
 Этап 1. Структура оптимального бинарного дерева поиска
 Чтобы охарактеризовать оптимальную подструктуру оптимального бинарного 
дерева поиска, исследуем его поддеревья. Рассмотрим произвольное поддерево 
бинарного дерева поиска. Оно должно содержать ключи в непрерывном интерва
 ле hi,... ,kj для некоторых 1 < г < j < п. Кроме того, поддерево, содержащее 
ключи ki,... ,kj, должно также содержать в качестве листьев фиктивные ключи 
di—1, , dj.
 Теперь можно сформулировать оптимальную подструктуру: если в состав оп
 тимального бинарного дерева поиска Т входит поддерево Т', содержащее ключи 
ki,...,kj, это поддерево также должно быть оптимальным для подзадачи с клю
 чами кг,... ,kj и фиктивными ключами di-1,... ,dj. Для доказательства этого 
утверждения применяется обычный метод вырезания и вставки. Если бы суще
 ствовало поддерево Т", математическое ожидание поиска в котором ниже, чем 
математическое ожидание поиска в поддереве Т', то из дерева Т можно было 
бы вырезать поддерево Т1 и подставить вместо него поддерево Т". В результате 
получилось бы дерево, математическое ожидание времени поиска в котором ока
 залось бы меньше, что противоречит утверждению об оптимальности дерева Т.
 Покажем с помощью описанной выше оптимальной подструктуры, что опти
 мальное решение задачи можно воссоздать из оптимальных решений подзадач. 
Если имеется поддерево, содержащее ключи ki,... ,kj, то один из этих ключей, 
скажем, кг (г < г < j) будет корнем этого оптимального поддерева. Поддере
 во, которое находится слева от корня кг, будет содержать ключи к{,...,кг-\ 
(и фиктивные ключи di-1,..., dr-\), а правое поддерево — ключи кг+\,... ,kj 
(и фиктивные ключи dr,... ,dj). Как только будут проверены все ключи кг (где 
г < г < j), которые являются кандидатами на роль корня, и найдены оптималь
 ные бинарные деревья поиска, содержащие элементы ki,..., кг-\ и kr+1,... ,kj, 
мы гарантированно построим оптимальное бинарное дерево поиска.
 Стоит сделать одно замечание по поводу “пустых” поддеревьев. Предполо
 жим, что в поддереве с ключами ki,...,kj в качестве корня выбран ключ ki. 
Согласно приведенным выше рассуждениям, поддерево, которое находится слева 
от корня ki, содержит ключи ki,..., ki-1. Естественно интерпретировать эту по
 следовательность как такую, в которой не содержится ни одного ключа. Однако 
следует иметь в виду, что поддеревья содержат, помимо реальных, и фиктивные 
ключи. Примем соглашение, согласно которому поддерево, состоящее из ключей 
ki,..., ki-1, не содержит обычных ключей, но содержит один фиктивный ключ 
di-1. Аналогично, если в качестве корня выбран ключ kj, то правое поддерево не 
содержит обычных ключей, но содержит один фиктивный ключ dj.
 Этап 2. Рекурсивное решение
 Теперь все готово для рекурсивного определения оптимального решения. В ка
 честве подзадачи выберем задачу поиска оптимального бинарного дерева поиска, 
содержащего ключи ki,..., kj, где г>1, j<nnj>i—1 (если j = г—1, то факта
Глава 15. Динамическое программирование
 435
 ческих ключей не существует, имеется только фиктивный ключ di-\). Определим 
величину e[i,j] как математическое ожидание стоимости поиска в оптимальном 
бинарном дереве поиска с ключами ki,... ,kj. В конечном итоге нужно вычислить 
величину е[1, п].
 Если j = г — 1, то все просто. В этом случае имеется всего один фиктивный 
ключ di-1, и математическое ожидание стоимости поиска равно е[г, г — 1] = qi-\.
 Если j > г, то среди ключей ki,... ,kj нужно выбрать корень кГ, а затем из 
ключей hi,..., kr-i составить левое оптимальное бинарное дерево поиска, а из 
ключей кг+1,... ,kj — правое оптимальное бинарное дерево поиска. Что проис
 ходит с математическим ожиданием стоимости поиска в поддереве, когда оно 
становится поддеревом какого-то узла? Глубина каждого узла в поддереве воз
 растает на единицу. Согласно уравнению (15.11) математическое ожидание стои
 мости поиска в этом поддереве возрастает на величину суммы по всем вероятно
 стям поддерева. Обозначим эту сумму вероятностей, вычисленную для поддерева 
с ключами fcj,..., fcj, как
 3 
w{i,j) = J 2 pi + 
l=i 
3
 l=i— 1
 qi ' 
(15.12)
 Таким образом, если kr — корень оптимального поддерева, содержащего ключи 
ki,..., kj, то выполняется соотношение
 e[i, j] =рг + (е[г,г - 1] + w(i,r - 1)) + (е[г + 1, j] + w(r + 1, j)) .
 Заметив, что
 w(i,j) = w(i, г — 1 )+pr + w(r + 1, j) , 
перепишем e[i, j] как
 e[i,j\ = e[i, r — 1] + e[r + l,j) +w(i,j) . 
(15.13)
 Рекурсивное соотношение (15.13) предполагает, что нам известно, какой узел 
кг используется в качестве корня. На эту роль выбирается ключ, который при
 водит к минимальному значению математического ожидания стоимости поиска. 
С учетом этого получаем окончательную рекурсивную формулу:
 Qi- 1 , 
е М
 если j = i — 1 ,
 min {e[i, г — 1] + e[r + l,j] + w(i, j)} , если i < j .
 i<r<j
 (15.14)
 Величины e[i,j] представляют собой математическое ожидание стоимостей 
поиска в оптимальных бинарных деревьях поиска. Чтобы было легче следить 
за структурой оптимального бинарного дерева поиска, обозначим через root[i,j] 
(где 1 < i < j < п) индекс г узла кг, который является корнем оптимального 
бинарного дерева поиска, содержащего ключи ki,...,kj. Хотя вскоре мы узна
 ем, как вычисляются величины root[i,j], способ восстановления из этих величин 
оптимального бинарного дерева поиска отложим до упр. 15.5.1.
436
 Часть IV. Усовершенствованные методы разработки и анализа
 Этап 3. Вычисление математического ожидания стоимости поиска 
в оптимальном бинарном дереве поиска
 На данном этапе можно заметить некоторое сходство между характеристика
 ми задач об оптимальных бинарных деревьях поиска и о перемножении цепочки 
матриц. Во вспомогательных задачах обеих задач индексы элементов изменяются 
последовательно. Прямая рекурсивная реализация уравнения (15.14) может ока
 заться такой же неэффективной, как и прямая рекурсивная реализация алгоритма 
в задаче о перемножении цепочки матриц. Вместо этого будем сохранять зна
 чения e[i,j] в таблице е[1..п 4- 1,0.. гг]. Первый индекс должен пробегать не 
п, а п + 1 значений. Это объясняется тем, что для получения поддерева, в ко
 торое входит только фиктивный ключ dn, понадобится вычислить и сохранить 
значение е[п + 1, п]. Второй индекс должен начинаться с нуля, поскольку для по
 лучения поддерева, содержащего лишь фиктивный ключ do, нужно вычислить 
и сохранить значение е[1,0]. Мы будем использовать только те элементы e[i,j\, 
для которых j > i — 1. Кроме того, будет использована таблица root [г, j], в ко
 торую будут заноситься корни поддеревьев, содержащих ключи ki,..., kj. В этой 
таблице задействованы только те записи, для которых 1 < г < j < п.
 Для повышения эффективности понадобится еще одна таблица. Вместо того 
чтобы каждый раз при вычислении e[i,j] вычислять значения w(i,j) “с нуля”, 
для чего потребуется ©(j — г) операций сложения, будем сохранять эти значения 
в таблице w[\ .. п+1,0.. п\. В базовом случае вычисляются величины w[i, г — 1] = 
1для 1 < г < п 4-1. Для j > г вычисляются величины
 w[i,j] = w[i,j - 1] +Pj+qj . 
(15.15)
 Таким образом, каждое из 0(п 2) значений матрицы w[i,j] можно вычислить за 
время 0(1).
 Ниже приведен псевдокод, который принимает в качестве входных данных 
вероятности pi,... ,рп и qo,..., qn и размер п и возвращает таблицы е и root.
 OPTIMAL-BST (р, q, п)
 1 е[1.. п + 1,0 .. п], w[ 1.. п + 1,0 .. п]
 и root[l.. п, 1.. п] — новые таблицы
 2 for г = 1 to п + 1
 3 
e\i, г — 1] = 
4 
5 for / = 1 to n
 6 
q{-i
 w[i,i- 1] = q{-i
 for i = 1 tO 72 — / + 1
 7 
8 
9 
10 
11 
12 
13 
14 
j = i + l — 1
 e[i,j\ = oo
 w[i, j] = w[i,j - 1] +pj + qj
 for r — i to j
 t = e[i,r - 1] + e[r + 1, j] + w[i, j]
 if t < e[i,j]
 e[i, j] = t
 root[i, j] = r
 15 return e и root
Глава 15. Динамическое программирование
 root
 5 41
 Рис. 15.10. Таблицы 
437
 w[i,j\ и root[i,j], вычисленные процедурой OPT1MAL-BST для рас
 пределения ключей, показанного на рис. 15.9. Таблицы повернуты таким образом, чтобы диагонали 
располагались по горизонтали.
 Благодаря приведенному выше описанию и схожести с процедурой M atrix- 
Chain-Order из раздела 15.2, работа представленной выше процедуры долж
 на быть понятной. Цикл for в строках 2-4 инициализирует значения e[i,i — 1] 
и w[i,i — 1]. Затем в цикле for в строках 5-14 с помощью рекуррентных соот
 ношений (15.14) и (15.15) вычисляются элементы матриц e[i,j] и w[i,j\ для всех 
индексов 1 < г < j < п. В первой итерации, когда I — 1, в этом цикле вычис
 ляются элементы е[г,г] и w[i, г] для г = 1,2, ...,п. Во второй итерации, когда 
I = 2, вычисляются элементы е[г,г + 1] и w[i,г + 1] для г = l,2,...,n — 1 и т.д. 
Во внутреннем цикле for (строки 10-14) каждый индекс г апробируется на роль 
индекса корневого элемента kr оптимального бинарного дерева поиска с ключами 
ki,... ,kj. В этом цикле элементу root[i,j] присваивается то значение индекса г, 
которое подходит лучше всего.
 На рис. 15.10 показаны таблицы e[i,j\, w[i,j] и root[i,j], вычисленные с по
 мощью процедуры OPTIMAL-BST для распределения ключей, показанного на 
рис. 15.9. Как и в примере с перемножением цепочки матриц на рис. 15.5, табли
 цы повернуты так, чтобы диагонали располагались горизонтально. В процедуре 
Optimal-BST строки вычисляются снизу вверх, а в каждой строке заполнение 
элементов выполняется слева направо.
 Время работы процедуры Optimal-BST, как и время работы процедуры 
Matrix-Chain-Order, равно 0(п3). Легко увидеть, что время работы состав
 ляет 0(п3), поскольку циклы for этой процедуры трижды вложены друг в друга, 
и индекс каждого цикла принимает не более п значений. Далее, индексы цик
 лов в процедуре Optimal-BST изменяются не в тех же пределах, что и индексы
438
 Часть IV. Усовершенствованные методы разработки и анализа
 циклов в процедуре Matrix-Chain-Order, но во всех направлениях они прини
 мают по крайней мере одно значение. Таким образом, процедура Optimal-BST, 
как и процедура Matrix-Chain-Order, выполняется в течение времени Q(n3).
 Упражнения
 15.5.1
 Напишите псевдокод процедуры Construct-Optimal-BST (root), которая по за
 данной таблице root выводит структуру оптимального бинарного дерева поиска. 
Для примера, приведенного на рис. 15.10, процедура должна выводить структу
 ру, соответствующую оптимальному бинарному дереву поиска, показанному на 
рис. 15.9, (б).
 &2 является корнем 
к\ является левым дочерним узлом /сг 
do является левым дочерним узлом к\ 
d\ является правым дочерним узлом к\ 
ко является правым дочерним узлом &2 
&4 является левым дочерним узлом ко 
ко является левым дочерним узлом к± 
d2 является левым дочерним узлом ко 
do является правым дочерним узлом ко 
d± является правым дочерним узлом к± 
do является правым дочерним узлом ко
 15.5.2
 Определите стоимость и структуру оптимального бинарного дерева поиска для 
множества, состоящего из гг = 7 ключей, которым соответствуют следующие 
вероятности.
 г
 0
 1
 2
 3
 4
 5
 7
 0.04 0.06 0.08 0.02 0.10 0.12 0.14
 6
 Pi
 Qi
 0.06 0.06 0.06 0.06 0.05 0.05 0.05 0.05
 15.5.3
 Предположим, что вместо того, чтобы поддерживать таблицу w[i,j\, значение 
w(i,j) вычисляется в строке 9 процедуры Optimal-BST непосредственно из 
уравнения (15.12) и используется в строке 11. Как это изменение повлияет на 
асимптотическое поведение времени выполнения этой процедуры?
 15.5.4 ★
 Кнут [211] показал, что всегда существуют корни оптимальных поддеревьев, та
 кие, что root[i,j — 1] < root[i,j] < root[i + 1,j] для всех 1 < i < j < n. 
Используйте этот факт для модификации процедуры Optimal-BST, при которой 
время ее работы станет равным О (гг2).
Глава 15. Динамическое программирование
 Задачи
 439
 15.1. Наидлиннейший простой путь в ориентированном ациклическом графе
 Предположим, что имеется ориентированный ациклический граф G = (У,Е) 
с действительными весами ребер и двумя различными вершинами s и t. Опишите 
подход динамического программирования для поиска наидлиннейшего взвешен
 ного простого пути от s к t. Как выглядит граф подзадач? Какова эффективность 
разработанного вами алгоритма?
 15.2. Наидлиннейшая палиндромная подпоследовательность
 Палиндром представляет собой непустую строку на некотором алфавите, ко
 торая одинаково читается в прямом и обратном направлениях. Примерами палин
 дромов могут служить все строки длиной 1, потоп, топот, заказ и др.
 Разработайте эффективный алгоритм поиска наидлиннейшего палиндрома, 
являющегося подпоследовательностью данной входной строки. Например, для 
строки математика ваш алгоритм должен выводить атата. Каково время ра
 боты вашего алгоритма?
 15.3. Битоническая евклидова задача о коммивояжере
 В битонической евклидовой задаче о коммивояжере на плоскости задано 
множество из п точек, и необходимо найти кратчайший замкнутый путь, соеди
 няющий все эти точки. На рис. 15.11, (а) показано решение задачи, в которой име
 ется семь точек. В общем случае задача является NP-полной, поэтому считается, 
что для ее решения требуется время, превышающее полиномиальное (см. гла
 ву 34).
 И.Л. Бентли (J.L. Bentley) предположил, что задача упрощается благодаря огра
 ничению интересующих нас маршрутов битоническими (bitonic tour), т.е. таки
 ми, которые начинаются в крайней слева точке, проходят слева направо, а затем — 
справа налево, возвращаясь прямо к исходной точке. На рис. 15.11,(6) показан 
кратчайший битонический маршрут, проходящий через те же семь точек. В этом
 (а) 
(б)
 Рис. 15.11. Семь точек на плоскости, наложенные на единичную сетку, (а) Кратчайший замкнутый 
путь длиной около 24.89. Этот путь не является битоническим. (б) Кратчайший битонический 
замкнутый путь для того же множества точек. Его длина — около 25.58.
440
 Часть IV. Усовершенствованные методы разработки и анализа
 случае возможна разработка алгоритма, время работы которого является полино
 миальным.
 Разработайте алгоритм для определения оптимального битонического марш
 рута, время работы которого будет равным О (гг2). Предполагается, что не суще
 ствует двух точек, координаты х которых совпадают. (Указание: перебор вариан
 тов следует организовать слева направо, поддерживая оптимальные возможности 
для двух частей, из которых состоит маршрут.)
 15.4. Вывод на печать с форматированием
 Рассмотрим задачу о форматировании параграфа текста, предназначенного для 
вывода на печать. Входной текст представляет собой последовательность, состоя
 щую из п слов, длины которых равны h,h, • • • Jn (длина слов измеряется в сим
 волах). При выводе на печать параграф должен быть аккуратно отформатирован 
и размещен в несколько строк, в каждой из которых помещается по М симво
 лов. Сформулируем критерий “аккуратного” форматирования следующим обра
 зом. Если данная строка содержит слова от г-го до j-ro, где г < j, и мы оставляем 
между словами ровно по одному пробелу, количество оставшихся пробелов в кон
 це строки, равное М — j + г — Ylk=i должно быть неотрицательным, чтобы все 
слова поместились в строке. Мы хотим минимизировать сумму возведенных в куб 
остатков по всем строкам, кроме последней. Сформулируйте алгоритм, основан
 ный на принципах динамического программирования, который аккуратно выво
 дит на принтер параграф, состоящий из п слов. Проанализируйте время работы 
этого алгоритма и требуемое для его работы количество памяти.
 15.5. Расстояние редактирования
 Для того чтобы преобразовать исходную строку текста х[1..т] в конечную 
строку у[1.. п\, можно воспользоваться различными операциями преобразования. 
Наша цель заключается в том, чтобы для данных строк х и у определить последо
 вательность преобразований, превращающих х в у. Для хранения промежуточных 
результатов используется массив 2 (предполагается, что он достаточно велик для 
хранения необходимых промежуточных результатов). Изначально массив г пуст, 
а в конце работы z[j] = y[j] для всех j = 1,2,..., п. Поддерживаются текущий 
индекс г массива х и индекс j массива г, ив ходе выполнения операций преоб
 разования разрешено изменять элементы массива г и эти индексы. Изначально 
г = j = 1. В процессе преобразования необходимо проверить каждый символ 
массива х. Это означает, что в конце выполнения последовательности операций 
значение г должно быть равно га + 1.
 Всего имеется шесть перечисленных ниже операций преобразования.
 Копирование символа из массива х в массив г путем присвоения z\j\ — х[г] 
с последующим увеличением индексов г и j. В этой операции проверяется 
элемент ж [г].
 Замена символа из массива х другим символом с путем присвоения z\j\ = с 
с последующим увеличением индексов i и j. В этой операции проверяется 
элемент х[г\.
Глава 15. Динамическое программирование
 441
 Удаление символа из массива ж путем увеличения на единицу индекса г и сохра
 нения индекса j прежним. В этой операции проверяется элемент ж [г].
 Вставка символа с в массив г путем присвоения z[j] = си увеличения на еди
 ницу индекса j при сохранении индекса г прежним. В этой операции не про
 веряется ни один элемент массива х.
 Перестановка двух следующих символов путем их копирования из массива х 
в массив г в обратном порядке. Это делается путем присваиваний z\j\ = 
ж [г 4- 1] и z\j + 1] = ж [г] с последующим изменением значений индексов 
г = г 4- 2 и j = j + 2. В этой операции проверяются элементы ж [г] и ж [г 4 1].
 Удаление остатка массива ж путем присвоения г = т 4- 1. В этой операции 
проверяются все элементы массива ж, которые не были проверены до сих пор. 
Если эта операция выполняется, то она должна быть последней.
 В качестве примера приведем один из способов преобразования исходной 
строки alg orith m в конечную строку altruistic. В ходе этого преобразо
 вания выполняется перечисленная ниже последовательность операций, в которых 
подчеркнутые символы представляют собой элементы ж [г] и z[j\ после выполне
 ния очередной операции.
 Операция
 Начальные строки
 Копирование
 Копирование
 Замена на t
 Удаление
 Копирование
 Вставка и
 Вставка i
 Вставка s
 Перестановка
 Вставка с
 ж
 a lg orith m
 a lg orith m
 algorithm
 a lg orith m
 algorithm
 a lg orith m
 a lg orithm
 a lg orithm
 a lg orithm
 algorithm
 algorithm
 algorithm_
 z
 a_
 al_
 alt_
 alt_
 altr_
 altru_
 altrui_
 altruis_
 altruisti_
 altruistic
 altruistic
 Удаление остатка
 Заметим, что существует ряд других последовательностей операций, позволяю
 щих преобразовать строку algorithm в строку altruistic.
 С каждой операцией преобразования связана своя стоимость, которая зави
 сит от конкретного приложения. Однако мы предположим, что стоимость каж
 дой операции — известная константа. Кроме того, предполагается, что стоимо
 сти отдельно взятых операций копирования и замены меньше суммарной сто
 имости операций удаления и вставки, иначе применять эти операции было бы 
нерационально. Стоимость некоторой последовательности операций преобразо
 вания представляет собой сумму стоимостей отдельных операций последователь
 ности. Стоимость приведенной выше последовательности преобразований строки 
algorithm в строку altruistic равна сумме трех стоимостей копирования, 
стоимости замены, стоимости удаления, четырем стоимостям вставки, стоимости 
перестановки и удаления остатка.
442
 Часть IV. Усовершенствованные методы разработки и анализа
 а. Пусть имеются две последовательности, х[1..т\ и у[1..п], а также мно
 жество, элементами которого являются стоимости операций преобразования. 
Расстоянием редактирования (edit distance) между х и у называется мини
 мальная стоимость последовательности операций преобразования х в у. Опи
 шите основанный на принципах динамического программирования алгоритм, 
в котором определяется расстояние редактирования от х[1.. га] до у[1.. п] 
и выводится оптимальная последовательность операций редактирования. Про
 анализируйте время работы этого алгоритма и требуемую для него память.
 Задача о расстоянии редактирования — это обобщение задачи об анализе двух 
ДНК (см., например, книгу Сетубала (Setubal) и Мейданиса (Meidanis) [308, раз
 дел 3.2]). Имеется несколько методов, позволяющих оценить подобие двух ДНК 
путем их выравнивания. Один такой способ выравнивания двух последователь
 ностей х и у заключается в том, чтобы вставлять пробелы в произвольных местах 
этих двух последовательностей (включая позиции в концах). Получившиеся в ре
 зультате последовательности х' и у' должны иметь одинаковую длину, однако они 
не могут содержать пробелы в одинаковых позициях (т.е. не существует такого 
индекса j, чтобы и x'[j], и y'[j] были пробелами). Затем каждой позиции присва
 ивается определенное количество баллов в соответствии со сформулированными 
ниже правилами:
 • +1, если x'\j] = y'\j] и ни один из этих элементов не является пробелом;
 • —1, если x'\j\ ^ y'[j] и ни один из этих элементов не является пробелом;
 • —2, если либо x'\j\, либо y'\j\ является пробелом.
 Стоимость выравнивания определяется как сумма баллов, полученных при срав
 нении отдельных позиций. Например, если заданы последовательности х = 
GATCGGCAT и у = CAATGTGAATC, то одно из возможных выравниваний име
 ет следующий вид.
 G ATCG GCAT 
СААТ GTGAATC 
—*++*+*+—++*
 Символ + под позицией указывает на то, что ей присваивается балл +1, символ - 
означает балл —1, а символ * — балл —2. Таким образом, полная стоимость равна 
б . 1 _ 2 • 1 - 4 • 2 = -4.
 б. Объясните, как свести задачу о поиске оптимального выравнивания к задаче 
о поиске расстояния редактирования с помощью подмножества операций пре
 образования, состоящего из копирования, замены, удаления элемента, вставки, 
перестановки и удаления остатка.
 15.6. Вечеринка на фирме
 Профессор Тамада является консультантом президента корпорации по вопро
 сам проведения вечеринок компании. Взаимоотношения между сотрудниками 
компании описываются иерархической структурой. Это означает, что отношение
Глава 15. Динамическое программирование
 443
 “начальник-подчиненный” образует дерево, во главе (в корне) которого находится 
президент. В отделе кадров каждому служащему присвоили рейтинг дружелюбия, 
представленный действительным числом. Чтобы на вечеринке все чувствовали 
себя раскованно, президент выдвинул требование, согласно которому ее не долж
 ны одновременно посещать сотрудник и его непосредственный начальник.
 Профессору Тамаде предоставили дерево, описывающее структуру корпора
 ции в представлении с левым дочерним и правым сестринским узлами, описан
 ном в разделе 10.4. Каждый узел дерева, кроме указателей, содержит имя со
 трудника и его рейтинг дружелюбия. Опишите алгоритм, предназначенный для 
составления списка гостей, который бы давал максимальное значение суммы рей
 тингов дружелюбия гостей. Проанализируйте время работы этого алгоритма.
 15.7. Алгоритм Витерби
 Динамическое программирование можно использовать в ориентированном 
графе G = (V,E) для распознавания речи. Каждое ребро (и, v) е Е графа по
 мечено звуком cr(u,v), который является членом конечного множества звуков Е. 
Граф с метками представляет собой формальную модель речи человека, который 
разговаривает на языке, состоящем из ограниченного множества звуков. Все пути 
в графе, которые начинаются в выделенной вершине 
£ V, соответствуют воз
 можной последовательности звуков, допустимых в данной модели. Метка направ
 ленного пути по определению является конкатенацией меток, соответствующих 
ребрам, из которых состоит путь.
 а. Разработайте эффективный алгоритм, который для заданного графа G с поме
 ченными ребрами и выделенной вершиной но и для последовательности зву
 ков s = (<7i, <72,..., (Jk) из множества Е возвращал бы путь в графе G, который 
начинается в вершине но и имеет метку s (если таковой существует). В про
 тивном случае алгоритм должен возвращать строку NO-SUCH-PATH (нет такого 
пути). Проанализируйте время работы алгоритма. (Указание: могут оказаться 
полезными концепции, изложенные в главе 22.)
 Теперь предположим, что каждому ребру (и, v) £ Е также сопоставляется неот
 рицательная вероятность р(и, v) перехода по этому ребру из вершины и. При этом 
издается соответствующий звук. Сумма вероятностей по всем ребрам, исходящим 
из произвольной вершины, равна 1. По определению вероятность пути равна про
 изведению вероятностей составляющих его ребер. Вероятность пути, берущего 
начало в вершине vo, можно рассматривать как вероятность “случайного блуж
 дания”, которое начинается в этой вершине и продолжается по случайному пути. 
Выбор каждого ребра на этом пути в вершине и производится в соответствии 
с вероятностями ребер, исходящих из этой вершины.
 б. Обобщите сформулированный в п. (а) ответ так, чтобы возвращаемый путь 
(если он существует) был наиболее вероятным из всех путей, начинающих
 ся в вершине г>о и имеющих метку s. Проанализируйте время работы этого 
алгоритма.
444
 Часть IV Усовершенствованные методы разработки и анализа
 15.8. Масштабирование изображения
 У нас имеется цветное изображение, состоящее из т х тг-массива 
А[1.. га, 1.. п] пикселей, где каждый пиксель определяется тройкой интенсив
 ностей красного, зеленого и синего цветов (RGB). Предположим, что мы хотим 
немного сжать это изображение, а именно — удалить по одному пикселю из каж
 дой из га строк, чтобы изображение стало на один пиксель уже. Во избежание 
визуальных искажений мы требуем, чтобы пиксели, удаляемые в смежных стро
 ках, находились в одном и том же или в смежных столбцах; удаленные пиксели 
формируют “шов” от верхней до нижней строки, в котором последовательные 
пиксели шва смежны по вертикали или диагонали.
 а. Покажите, что количество таких возможных швов растет как минимум экспо
 ненциально с ростом т , в предположении п > 1.
 б. Предположим теперь, что для каждого пикселя A[i,j] мы вычисляем действи
 тельную меру искажений d[i,j], указывающую, насколько важен тот или иной 
пиксель A[i,j] в плане удаления. Интуитивно понятно, что чем меньше эта 
мера для данного пикселя, тем больше он похож на соседние с ним. Затем 
предположим, что мы определяем меру искажений шва как сумму мер иска
 жений составляющих его пикселей.
 Разработайте алгоритм поиска шва с наименьшей мерой искажений. Насколько 
эффективен ваш алгоритм?
 15.9. Разбиение строки
 Некоторые языки, ориентированные на работу со строками, позволяют про
 граммисту разбивать строки на две части. Поскольку эта операция копирует стро
 ки, ее стоимость составляет п единиц времени для разбиения строки из п сим
 волов на две части. Предположим, что программист хочет разбить строку на 
несколько частей. Порядок разбиения может влиять на требуемое для него время. 
Предположим, например, что программист желает разбить 20-символьную строку 
после символов с номерами 2, 8 и 10 (используется нумерация в возрастающем 
порядке слева направо, начиная с 1). Если разбиения выполняются слева напра
 во, то первое стоит 20 единиц времени, второе — 18 (строка от символа 3 до 
символа 20 разбивается после символа 8), а третье — 12 единиц, т.е. общая стои
 мость равна 50. Если же разбиения выполняются справа налево, то их стоимости 
соответственно равны 20, 10 и 8 единиц времени, так что общая стоимость рав
 на 38 единиц времени. При еще одном порядке можно сначала разбить строку 
после символа 8 (стоимость 20), а затем разбить полученные части после симво
 ла 2 (стоимость 8) и символа 10 (стоимость 12) с общей стоимостью разбиения, 
равной 40.
 Разработайте алгоритм, который для данных номеров символов, после кото
 рых выполняется разбиение, определяет последовательность разбиений с мини
 мальной общей стоимостью. Более формализованно — для заданной строки S 
длиной п и массива L[1.. га] с точками разбиений вычислить наименьшую стой
Глава 15. Динамическое программирование
 445
 мость последовательности разбиений, а также саму последовательность, при ко
 торой достигается эта стоимость.
 15.10. Планирование стратегии капиталовложений
 Ваши знания алгоритмов помогли вам получить потрясающую работу в компа
 нии “КрупноТвердь” с единовременным пособием в 10000 долларов. Вы решили 
вложить эти деньги так, чтобы получить за 10 лет как можно больший доход, 
и обратились для этого в компанию “МЖ инвест”, которая предлагает следующие 
правила. Компания предлагает вам п различных вариантов капиталовложений, 
пронумерованных от 1 до гг. В год j капиталовложение г обеспечивает доход rxj . 
Другими словами, если вы вложите d долларов в г в год j, то в конце года j 
будете иметь 
долларов. Компания гарантирует, что в течение 10 лет ее пре
 зидент не сбежит, прихватив кассу, и она будет гарантированно выплачивать ваш 
доход. Принимать решения о том, куда вложить деньги, вы можете один раз в год. 
В конце каждого года вы можете либо оставить все деньги там же, где они были 
в предыдущем году, либо перераспределить их между другими вложениями. Если 
вы не трогаете свои деньги по окончании года, то платите сбор f\ долларов; если 
переносите их — то платите сбор /2 > /i .
 а. Как указано, вы можете вкладывать деньги в несколько предприятий ежегод
 но. Докажите, что существует оптимальная стратегия, и заключается она в том, 
чтобы каждый год вкладывать все деньги в одно предприятие. (Напомним, что 
оптимальная стратегия должна максимизировать количество денег по проше
 ствии 10 лет и не рассматривает никакие иные цели, такие, как, например, 
минимизация рисков.)
 б. Докажите, что задача планирования оптимальной стратегии капиталовложе
 ний демонстрирует оптимальную подструктуру.
 в. Разработайте алгоритм выработки оптимальной стратегии. Каково время ра
 боты вашего алгоритма?
 г. Предположим, что “МЖ инвест” добавляет ограничение, заключающееся 
в том, что в одно предприятие не может быть вложено более 15 000 долла
 ров. Покажите, что при этом ограничении задача максимизации прибыли по 
истечении 10 лет не обладает оптимальной подструктурой.
 15.11. Разработка производственного плана
 Компания “Эх, прокачу” изготовляет сани. Естественно, что спрос на эту про
 дукцию колеблется от месяца к месяцу, так что компании требуется разрабо
 тать стратегию производства с учетом колеблющегося, но предсказуемого спроса. 
Компании нужен план на следующие п месяцев. Для каждого месяца г известен 
спрос di, т.е. количество саней, которые будут проданы. Пусть D = ^ " =1 ~
 общий спрос саней на все п месяцев. Постоянный штат работников позволяет 
производить до т саней в месяц. Если требуется произвести большее количе
 ство саней, можно нанять временных работников, оплата которых составляет с
446
 Часть IV. Усовершенствованные методы разработки и анализа
 долларов за сани. Кроме того, если в конце месяца остаются нераспроданные 
сани, приходится платить за их хранение. Стоимость хранения j саней представ
 ляет собой функцию h(j) для j = 1,2, ...,Z), где h(j) > 0 для 1 < j < D 
и h(j) < h(j + 1) для 1 < j < D — 1.
 Разработайте алгоритм для расчета производственного плана компании, мини
 мизирующего затраты при выполнении всех ограничений. Время работы алгорит
 ма должно полиномиально зависеть от п и D.
 Заключительные замечания
 Р. Веллман (R. Bellman) приступил к систематическому изучению динамиче
 ского программирования в 1955 году. Как в названии “динамическое программи
 рование”, так и в термине “линейное программирование” слово “программирова
 ние” относится к методу табличного решения. Методы оптимизации, включаю
 щие в себя элементы динамического программирования, были известны и рань
 ше, однако именно Веллман дал строгое математическое обоснование этой обла
 сти [36].
 Галил (Galil) и Парк (Park) [124] классифицировали алгоритмы динамического 
программирования в соответствии с размером таблиц и количеством записей, от 
которых зависит каждый элемент таблицы. Они называют алгоритм динамическо
 го программирования tD/eD, если размер его таблицы равен 0(пг), а каждый ее 
элемент зависит от 0(пе) других элементов. Например, алгоритм перемножения 
цепочки матриц из раздела 15.2 является алгоритмом 2D/ID, а алгоритм поиска 
наидлиннейшей подпоследовательности из раздела 15.4 — алгоритмом 2D/0D.
 Ху (Ни) и Шинг (Shing) [181,182] разработали алгоритм, позволяющий решить 
задачу о перемножении матриц в течение времени O(nlgn).
 По-видимому, алгоритм решения задачи о наидлиннейшей общей подпосле
 довательности, время работы которого равно 0(тп), — плод “народного творче
 ства” Кнут (Knuth) [69] поставил вопрос о том, существует ли алгоритм решения 
этой задачи, время работы которого возрастало бы медленнее, чем квадрат раз
 мера. Масек (Masek) и Патерсон (Paterson) [242] ответили на этот вопрос утвер
 дительно, разработав алгоритм, время работы которого равно 0(тп/ lgn), где 
п < га, а последовательности составлены из элементов множества ограниченно
 го размера. Шимански (Szimanski) [324] показал, что в частном случае, когда ни 
один элемент не появляется во входной последовательности более одного раза, 
эту задачу можно решить за время 0((п + га) lg(n + га)). Многие из этих ре
 зультатов были обобщены для задачи о вычислении расстояния редактирования 
(задача 15.5).
 Ранняя работа Гильберта (Gilbert) и Мура (Moore) [132], посвященная бинар
 ному кодированию переменной длины, нашла применение при конструировании 
оптимального бинарного дерева поиска для случая, когда все вероятности pt рав
 ны 0. В этой работе приведен алгоритм, время работы которого равно О (гг3). 
Ахо (Aho), Хопкрофт (Hopcrofit) и Ульман (Ullman) [5] представили алгоритм,
Глава 15. Динамическое программирование
 447
 описанный в разделе 15.5. Упр. 15.5.4 предложено Кнутом [211]. Ху и Такер 
(Tucker) [183] разработали алгоритм для случая, когда все вероятности pi рав
 ны 0; время работы этого алгоритма равно 0(п2), а количество необходимой для 
него памяти — 0(п). Впоследствии Кнуту [210] удалось уменьшить это время до 
величины O(nlgn).
 Задача 15.8 принадлежит Авидану (Avidan) и Шамиру (Shamir) [26], ко
 торые разместили в вебе чудесную видеоиллюстрацию этого метода сжатия 
изображений.
Глава 16. Жадные алгоритмы
 Алгоритмы, предназначенные для решения задач оптимизации, обычно пред
 ставляют собой последовательность шагов, на каждом из которых предоставляет
 ся некоторое множество выборов. Определение наилучшего выбора с помощью 
принципов динамического программирования во многих задачах оптимизации на
 поминает стрельбу из пушки по воробьям; другими словами, для этих задач луч
 ше подходят более простые и эффективные алгоритмы. В жадном алгоритме 
(greedy algorithm) всегда делается выбор, который кажется самым лучшим в дан
 ный момент, т.е. проводится локально оптимальный выбор в надежде, что он 
приведет к оптимальному решению глобальной задачи. В этой главе рассматри
 ваются задачи оптимизации, для которых жадные алгоритмы приводят к опти
 мальным решениям. Прежде чем приступить к изучению главы, следует ознако
 миться с динамическим программированием, изложенным в главе 15, в частности 
с разделом 15.3.
 Жадные алгоритмы не всегда приводят к оптимальным решениям, но во мно
 гих задачах дают нужный результат. В разделе 16.1 рассматривается простая, но 
нетривиальная задача о выборе процессов, эффективное решение которой мож
 но найти с помощью жадного алгоритма. Чтобы прийти к жадному алгоритму, 
сначала будет рассмотрено решение, основанное на подходе динамического про
 граммирования, после чего будет показано, что оптимальное решение можно по
 лучить, исходя из принципов жадных алгоритмов. В разделе 16.2 представлен 
обзор основных элементов подхода, в соответствии с которым разрабатываются 
жадные алгоритмы. Это позволяет упростить доказательство корректности жад
 ных алгоритмов. В разделе 16.3 приводится важное приложение методов жадного 
программирования: разработка кодов Хаффмана (Huffman) для сжатия данных. 
В разделе 16.4 исследуются теоретические положения, на которых основаны ком
 бинаторные структуры, известные под названием “матроиды”, для которых жад
 ный алгоритм всегда дает оптимальное решение. Наконец в разделе 16.5 матрои
 ды применяются для решения задачи о составлении расписания заданий равной 
длительности с крайним сроком выполнения и штрафами.
 Жадный метод обладает достаточной мощью и хорошо подходит для довольно 
широкого класса задач. В последующих главах представлены многие алгоритмы, 
которые можно рассматривать как применение жадного метода, включая алгорит
 мы поиска минимальных остовных деревьев (minimum-spanning-tree) (глава 23), 
алгоритм Дейкстры (Dijkstra) для определения кратчайших путей из одного ис















































































































































































































































































































752
 Часть VI. Алгоритмы для работы с графами
 pa (s, Si) с пропускной способностью c(s, Si) = оо для каждого г = 1,2,..., т. 
Точно так же создается фиктивный сток (supresink) t и добавляются ориенти
 рованные ребра (U,t) с c(U,t) = оо для каждого г = 1 , 2 Интуитивно 
понятно, что любой поток в сети на рис. 26.3, (а) соответствует потоку в сети на 
рис. 26.3, (б), и наоборот. Единственный исток s просто обеспечивает поток лю
 бой требуемой величины к истокам si, а единственный сток t аналогичным об
 разом потребляет поток любой желаемой величины от множественных стоков t{. 
В упр. 26.1.2 предлагается формально доказать эквивалентность этих двух задач.
 Упражнения
 26.1.1
 Покажите, что разделение ребра в транспортной сети дает эквивалентную сеть. 
Говоря более формально, предположим, что транспортная сеть G содержит реб
 ро (и, v), и мы создаем транспортную сеть G' путем добавления новой вершины х 
и замены (и, v) новыми ребрами (и, х) и (х, v), такими, что с{и, х) = с(х, v) = 
с(и, v). Покажите, что максимальный поток в G' имеет ту же величину, что и в G.
 26.1.2
 Распространите свойства потока и определения на задачу с несколькими истоками 
и стоками. Покажите, что любой поток в сети с несколькими истоками и стоками 
соответствует потоку той же величины в сети с единственным истоком и стоком, 
получаемой путем добавления фиктивных истока и стока, и наоборот.
 26.1.3
 Предположим, что транспортная сеть G = (V, Е) нарушает предположение о том, 
что в сети имеются пути s ^ v ^ t для всех вершин v е V. Пусть и представляет 
собой вершину, для которой такого пути s 
и 
t нет. Покажите, что в G 
должен существовать максимальный поток /, такой, что f(u,v) = f(v,u) = О 
для всех вершин v G V.
 26.1.4
 Пусть / является потоком в сети, и пусть а — действительное число. Скаляр
 ным произведением потока (scalar flow product), обозначаемым как af, является 
функция, отображающая V х V на R и определенная следующим образом:
 (af)(u,v) = а ■ f{u,v) .
 Докажите, что потоки в сети образуют выпуклое множество, т.е. покажите, что 
если f\ и /2 являются потоками, то потоком является и a fi + (1 — a )f2 для всех 
а из диапазона 0 < а < 1.
 26.1.5
 Сформулируйте задачу о максимальном потоке в виде задачи линейного програм
 мирования.
Глава 26. Задача о максимальном потоке
 26.1.6
 753
 У профессора двое детей, которые, к сожалению, терпеть не могут друг друга. 
Проблема настолько серьезна, что они не только не хотят вместе ходить в школу, 
но даже отказываются заходить в квартал, в котором в этот день побывал другой. 
При этом они допускают, что их пути могут пересекаться на углу того или иного 
квартала. К счастью, и дом профессора, и школа расположены на углах кварталов, 
однако профессор не уверен, возможно ли отправить обоих детей в одну школу. 
У профессора есть карта города. Покажите, как сформулировать задачу о воз
 можности отправить детей в одну и ту же школу в виде задачи о максимальном 
потоке.
 26.1.7
 Предположим, что в дополнение к пропускным способностям ребер транспорт
 ная сеть имеет пропускные способности вершин, т.е. каждая вершина v имеет 
предел l(v), определяющий, какой величины поток может через нее проходить. 
Покажите, как преобразовать транспортную сеть G = (У, Е) с пропускными спо
 собностями вершин в эквивалентную транспортную сеть G' = (V7, Е') без про
 пускных способностей вершин, такую, что максимальный поток в G' имеет ту же 
величину, что и максимальный поток в G. Сколько ребер и вершин входят в G'l
 26.2. Метод Форда-Фалкерсона
 В данном разделе представлен метод Форда-Фалкерсона для решения задачи 
о максимальном потоке. Мы называем его методом, а не алгоритмом, поскольку 
он допускает несколько реализаций с различным временем выполнения. Метод 
Форда-Фалкерсона базируется на трех важных идеях, которые выходят за рам
 ки данного метода и применяются во многих потоковых алгоритмах и задачах. 
Это — остаточные сети, увеличивающие пути и разрезы. Данные концепции ле
 жат в основе важной теоремы о максимальном потоке и минимальном разрезе 
(теорема 26.6), которая определяет значение максимального потока через разрезы 
транспортной сети. В заключение данного раздела мы предложим одну конкрет
 ную реализацию метода Форда-Фалкерсона и проанализируем время ее выпол
 нения.
 Метод Форда-Фалкерсона итеративно увеличивает значение потока. Вначале 
поток обнуляется: /(u,v) — 0 для всех u,v е V. На каждой итерации величина 
потока в G увеличивается посредством поиска “увеличивающего пути” в связан
 ной “остаточной сети” Gf. Зная ребра увеличивающего пути в G/, мы можем 
легко идентифицировать конкретные ребра в G, для которых можно изменить по
 ток таким образом, что его величина увеличится. Хотя каждая итерация метода 
Форда-Фалкерсона увеличивает величину потока, мы увидим, что поток через 
конкретное ребро G может возрастать или уменьшаться; уменьшение потока че
 рез некоторые ребра может быть необходимым для того, чтобы позволить алго
 ритму переслать больший поток от истока к стоку. Мы многократно увеличиваем
754
 Часть VI. Алгоритмы для работы с графами
 поток до тех пор, пока остаточная сеть не будет иметь ни одного увеличивающего 
пути. В теореме о максимальном потоке и минимальном разрезе будет показано, 
что по завершении данного процесса получается максимальный поток.
 Ford-Fulkerson-M ethod (G, s, t)
 1 Инициализация потока / нулевым значением
 2 while существует увеличивающий путь р в остаточной сети Gу
 3 
увеличиваем поток / вдоль пути р
 4 return /
 Чтобы реализовать и проанализировать метод Форда-Фалкерсона, необходимо 
ввести несколько дополнительных концепций.
 Остаточные сети
 Интуитивно понятно, что если заданы некоторая транспортная сеть G и по
 ток /, то остаточная сеть Gf — это сеть, состоящая из ребер с пропускными 
способностями, указывающими, как могут меняться потоки через ребра G. Ребро 
транспортной сети может пропустить дополнительный поток, равный пропускной 
способности ребра минус поток, проходящий через это ребро. Если это значение 
положительно, мы помещаем такое ребро в Gf с “остаточной пропускной спо
 собностью” су (u, v) = c(u, v) — f(u, v). Дополнительный поток могут пропустить 
только те ребра в G, которые входят в Gy; ребра (и, v), поток через которые равен 
их пропускной способности, имеют Cf(u,v) = 0 и не входят в Gy.
 Однако остаточная сеть Gy может также включать ребра, не входящие в G. 
Когда алгоритм работает с потоком с целью его увеличения, ему может потре
 боваться уменьшить поток в некотором конкретном ребре. Чтобы представить 
возможное уменьшение положительного потока f(u, v) в ребре в G, мы помеща
 ем ребро (v,u) в Gy с остаточной пропускной способностью Cf(v,u) = /(u, v), 
т.е. ребро, которое может пропустить поток в направлении, обратном к (u, v), не 
больше потока, идущего по ребру (u,v). Эти обратные ребра в остаточной сети 
позволяют алгоритму пересылать обратно поток, уже переданный по ребру. Пере
 сылка в обратном направлении эквивалентна уменьшению потока в ребре, которое 
во многих алгоритмах является необходимой операцией.
 Говоря более формально, предположим, что у нас есть транспортная сеть G = 
(V, Е) с истоком s и стоком t. Пусть в G имеется поток /, и рассмотрим пару 
вершин u,v G V. Определим остаточную пропускную способность Cf(u,v) как
 cf{u,v) = <
 с(и, v) — f(u, v) , если (и, v) е Е , 
f{v,u) , 
если (v,u) € Е , 
О 
в противном случае .
 (26.2)
 В силу нашего предположения о том, что из (и, v) € Е вытекает (у, и) £ Е, 
к каждой упорядоченной паре вершин применим только один случай из (26.2).
 В качестве примера (26.2), если c(u,v) = 16 и f(u,v) = 11, мы можем уве
 личить f(u,v) на величину, не превышающую Cf(u,v) = 5 единиц, прежде чем
Глава 26. Задача о максимальном потоке
 755
 Рис. 26.4. (а) Транспортная сеть G и поток /, показанные на рис. 26.1, (б), (б) Остаточная сеть G/ 
с выделенным штриховкой увеличивающим путем р\ его остаточная пропускная способность рав
 на Cf(p) = c/(v2,г>з) = 4. Ребра с остаточной пропускной способностью, равной 0, такие 
как (in,из), не показаны (соглашение, которому мы будем следовать в оставшейся части этого 
раздела), (в) Поток в G, полученный в результате увеличения вдоль пути р на его остаточную 
пропускную способность 4. Ребра, не несущие поток, такие как (^3,^2), помечены только про
 пускной способностью (еще одно соглашение, которому мы будем следовать), (г) Остаточная сеть, 
порожденная потоком в (в).
 превысим ограничение пропускной способности ребра (и,г>). Мы также хотим 
позволить алгоритму возвращать до 11 единиц потока назад от v к и, и следова
 тельно, Cf(v,U) = 11.
 Для заданной транспортной сети G — (V, Е) и потока / остаточная сеть 
(residual network) G, порожденная потоком /, представляет собой граф Gj = 
(V,Ef), где
 Ef = {(u,u) €V xV : cf (u,v) > 0} . 
(26.3)
 Иначе говоря, как и отмечалось выше, по каждому ребру остаточной сети, или 
остаточному ребру, можно направить поток, больший 0. На рис. 26.4, (а) воспро
 изведены транспортная сеть G и поток /, представленные на рис. 26.1, (б), а на 
рис. 26.4, (б) показана соответствующая остаточная сеть Gf. Ребра в Ef являются 
либо ребрами из Е, либо обратные им, и, таким образом,
 \Е/\ <2\Е\ .
 Заметим, что остаточная сеть Gf подобна транспортной сети с пропускны
 ми способностями, задаваемыми с/. Она не удовлетворяет нашему определению 
транспортной сети, так как может содержать одновременно и ребро (и, и), и об
 ратное ему ребро (v,u). Помимо этого различия, остаточная сеть обладает всеми 
свойствами транспортной сети, и мы можем определить поток в остаточной се
756
 способностям с / 
Часть VI. Алгоритмы для работы с графами
 ти как удовлетворяющий определению потока, но по отношению к пропускным 
сети Gf.
 Поток в остаточной сети предоставляет указания по добавлению потока к ис
 ходной транспортной сети. Если / представляет собой поток в G, а /' представ
 ляет собой поток в соответствующей остаточной сети Gf, определим увеличение 
(augmentation) / 1 f потока / на /' как функцию, отображающую V х V на R, 
определенную следующим образом:
 f(u, v) + f'(u, v) - f'(v, и) , если (и, v) G E
 (/T/')(«.«) = { о
 в противном случае .
 (26.4)
 Интуитивно понятно, что это определение следует из определения остаточ
 ной сети. Мы увеличиваем поток в ребре (u,v) на f'(u,v), но уменьшаем его 
на f'(v, и), поскольку пропускание потока по обратным ребрам в остаточной сети 
означает уменьшение потока в исходной сети. Пропускание потока по обратному 
ребру в остаточной сети известно также как сокращение (cancellation). Например, 
если мы пересылаем 5 ящиков с хоккейными шайбами из и в v, а 2 ящика — из v 
в и, то это эквивалентно (конечно, с точки зрения окончательного результата, а не 
оплаты перевозок) пересылке 3 ящиков из и в и, и ничего — из v в и. Сокраще
 ния такого вида являются ключевым моментом любого алгоритма максимального 
потока.
 Лемма 26.1
 Пусть G = (V,E) является транспортной сетью с истоком s и стоком t и пусть 
/ представляет собой поток в G. Пусть Gf — остаточная сеть G, порожденная /, 
и пусть /' — поток в Gf. Тогда функция f'lf', определенная в уравнении (26.4), 
представляет собой поток в G с величиной |/Т f'\ = 1/1 + |/'|.
 Доказательство. Сначала убедимся, что / 1 f подчиняется ограничению про
 пускной способности для каждого ребра в Е в сохранению потока в каждой вер
 шине в V — {s, t}.
 В случае ограничения пропускной способности сначала заметим, что ес
 ли (u,v) G Е, то Cf(v,u) = f(u,v). Таким образом, мы имеем f'(v,u) < 
Cf(v, и) = f(u, v), а следовательно
 {f 'l f'){u,v) — f(u,v) -f f'(u,v) — f'(v,u) (согласно уравнению (26.4))
 > f(u, V) + f'(u, V) - f(u, v) (поскольку f(v, и) < f(u, V)) 
= f'(u,v)
 > 0 .
Глава 26. Задача о максимальном потоке
 Кроме того,
 = /(u, v) 4- f(u,v) — f'(v,u) (согласно уравнению (26.4))
 < f(u, v) + f \u, v) 
< f(u,v) + Cf(u,v) 
= f(u, v) + с(и, v) — f(u, v) (определение cf)-- c(u, v) .
 757
 (так как потоки неотрицательны)
 (ограничение пропускной способности)
 В случае сохранения потока, поскольку и /, и /' подчиняются свойству сохра
 нения потока, для всех и G V — {s, t} имеем
 $^(/17')(u>u) = ^2 
v&V 
v&V
 + f'fav) - f'(v,u))
 = 51 f (u'v) + 51 /'fa, v)-^ 2 / ,(u’w)
 v£V 
u€V 
vGV
 = 51 f (v'u) + 51 /'к w) - 51 /'fa*
 v€V 
v&V 
v&V
 = 51 (/K u) + /'(u>u) - /'K v))
 vev
 vev
 где третья строка следует из второй согласно сохранению потока.
 Наконец вычислим величину 
Вспомним, что антипараллельные ребра
 в G (но не в Gf) запрещены, а следовательно, для каждой вершины v G V мы 
знаем, что может иметься либо ребро (s,v), либо ребро (v,s), но не оба одно
 временно. Определим Vi = {и : (s,u) G Е} как множество вершин с ребрами 
из s, a V2 = {v : (v, s) G Е} как множество вершин с ребрами в s. Мы имеем 
Vi U Vi С V и, поскольку антипараллельные ребра запрещены, Vi П Vi = 0. 
Теперь вычислим
 l /t/'l = Е (Л Л (»■«) - Е (Л Л (».«)
 u€V 
v£V
 = Е (/1Л (а.«) - Е (/1 /') (»■«) , 
u€Vi 
u€V2
 (26.5)
 где вторая строка следует из того, что (f 'l f')(w,x) равно 0, если (w,x) £ Е. 
Теперь применим к уравнению (26.5) определение / | f , а затем переупорядочим
758
 и сгруппируем члены, чтобы получить
 l/t/'l
 = 51 v)+ 
Часть VI. Алгоритмы для работы с графами
 _ /'кs))_ 5Z (/(^s)+/'(^s)_ 
v£Vi 
= 51 
v£V\ 
= 51 /(S’V) “ 51 /K S)
 u £ V i 
v£V2
 + 51 
v£V\ 
_ 51 f'(vis)
 v£Vi- ^2 /к s) - 5Z ^ s)+ 5Z л®»
 u €V2 
v£V2 
u €V2
 v£V2
 v))
 + 51 /'(s’v) + 5Z /'(s’v) - 51 №>«) - 51 /'(v’s)
 uGVi 
v£V2 
v£V\ 
= ^22 f(s,v) - ^22 f(v,s) + ^2 /'(s^)- 5Z 
uGVi 
VGV2 
UGV1UV2 
v£V2
 uG V1UV2
 ■ (26-6)
 В уравнении (26.6) можно распространить все четыре суммы на суммирование по 
всему множеству V, поскольку все дополнительные члены в этом случае имеют 
значения 0 (в упр. 26.2.1 это требуется строго доказать). Таким образом, мы имеем
 I/1 л = 51 ^ (s’v) - 51 /(^s) + 51 ^ v) - 5Z s) 
u G V 
= l/l + l/'l
u G V 
v£V 
v£V
 (26-7)
 Увеличивающие пути
 Для заданных транспортной сети G = (У,Е) и потока / увеличивающим пу
 тем (augmenting path) р является простой путь из s в t в остаточной сети Gf. Со
 гласно определению остаточной сети мы можем увеличить поток в ребре (u, v) 
увеличивающего пути до Cf{u,v) без нарушения ограничения пропускной спо
 собности соответствующего ребра в исходной сети.
 Выделенный путь на рис. 26.4, (б) является увеличивающим путем. Рассмат
 ривая представленную на рисунке остаточную сеть G/ как некоторую транспорт
 ную сеть, можно увеличивать поток вдоль каждого ребра данного пути вплоть 
до четырех единиц, не нарушая ограничений пропускной способности, посколь
 ку наименьшая остаточная пропускная способность на данном пути составля
 ет Cf{v2, г?з) = 4. Максимальная величина, на которую можно увеличить поток 
в каждом ребре увеличивающего пути р, называется остаточной пропускной 
способностью (residual capacity) пути р и задается формулой
 с/(р) = min{c/(u, v) : (u,v) принадлежит р} .
 Следующая лемма, доказательство которой предлагается провести в качестве 
упр. 26.2.7, более строго формулирует приведенные выше рассуждения.
Глава 26. Задача о максимальном потоке
 Лемма 26.2
 759
 Пусть G = (V", Е) является транспортной сетью, а / представляет собой поток 
в G, и пусть р является увеличивающим путем в Gf. Определим функцию /р :
 V х V ->• М как
 p\u,v) = < '
 Cf(p) , если (u,v) принадлежит р
 (О 
в противном случае .
 Тогда /р является потоком в Gf с величиной |/Р| = с/(р) > 0.
 (26.8)
 Вытекающее из данной леммы следствие показывает, что если увеличить / на 
/ р, то можно получить новый поток в G, величина которого ближе к максималь
 ной. На рис. 26.4, (в) показан результат увеличения потока /, представленного на 
рис. 26.4, (а), на поток /р, показанный на рис. 26.4, (б), а на рис. 26.4, (г) показана 
полученная остаточная сеть.
 Следствие 26.3
 Пусть G = (V, Е) представляет собой транспортную сеть, а / является потоком 
в G, и пусть р представляет собой увеличивающий путь в Gf. Пусть также /р 
определен, как в уравнении (26.8), и предположим, что мы увеличиваем / на /р. 
Тогда функция / t/p является потоком bG c величиной |/t/pl — \ f\ + \fp\ > \f\
Доказательство. Непосредственно вытекает из лемм 26.1 и 26.2. 
■
 Разрезы транспортных сетей
 В методе Форда-Фалкерсона проводится многократное увеличение потока 
вдоль увеличивающих путей до тех пор, пока не будет найден максимальный 
поток. Откуда нам известно, что по завершении алгоритма мы действительно 
найдем максимальный поток? В теореме о максимальном потоке и минимальном 
разрезе, которую мы вскоре докажем, утверждается, что поток является макси
 мальным тогда и только тогда, когда его остаточная сеть не содержит увеличи
 вающих путей. Однако для доказательства данной теоремы необходимо ввести 
понятие разреза транспортной сети.
 Разрезом (cut) (5, Т) транспортной сети G = (V, Е) называется разбиение 
множества вершин V на множества S и Т = V — S, такие, что s е S, a t е Т. 
(Это определение аналогично определению разреза, которое использовалось при
 менительно к минимальным остовным деревьям в главе 23, однако здесь речь 
идет о разрезе в ориентированном графе, а не в неориентированном, и мы требу
 ем, чтобы s е 5, a t е Г.) Если / — поток, то чистый поток (net flow) /(5, Т) 
через разрез (5, Т) определяется как
 /(^ т) = 
Ки'v) “ 
u£Sv£T
 •
 (26.9)
 u£Sv£T
760
 Часть VI. Алгоритмы для работы с графами
 ■<— S Т
 Рис. 26.5. Разрез (S,T) в транспортной сети, показанной на рис.26.1,(6), где S = {s,vi,V2}, 
а Т — {v3,v4, t}. Вершины в S показаны черными, а вершины в Т — белыми. Чистый поток через 
разрез (5, Т) равен f(S, Т) = 19, а пропускная способность составляет с(5, Т) = 26.
 Пропускной способностью (capacity) разреза (5, Т) является
 u£S v£T
 (26.10)
 Минимальным разрезом (minimum cut) сети является разрез, пропускная способ
 ность которого среди всех разрезов сети минимальна.
 Асимметрия между определениями потока и пропускной способности разреза 
является преднамеренной и существенной. В случае пропускной способности мы 
учитываем только пропускные способности ребер, идущих из S в Т, игнорируя 
ребра, идущие в обратном направлении. Что касается потока, то мы рассматри
 ваем поток из S в Т минус поток, идущий в обратном направлении, из Т в S. 
Причина этой разницы в определениях станет ясной позже в этом разделе.
 На рис. 26.5 показан разрез ({s,ui,U2} , {vs,v^,t}) транспортной сети, пред
 ставленной на рис. 26.1, (б). Чистый поток через данный разрез равен
 f{v 1,из) + f(v2,u4) - f(y3,v2) = 12 + 11-4
 = 19,
 а пропускная способность данного разреза составляет
 c{vi,v3) + c(v2,v4) = 12 + 14 
= 26.
 Следующая лемма показывает, что для заданного потока / чистый поток через 
любой разрез одинаков и равен величине потока |/|.
 Лемма 26.4
 Пусть / представляет собой поток в транспортной сети G со стоком s и истоком t 
и пусть (5, Т) — произвольный разрез G. Тогда чистый поток через разрез (S, Т)
 равен / (-S', Т) = |/|.
Глава 26. Задача о максимальном потоке
 761
 Доказательство. Условие сохранения потока для любого узла и Е V — {s,t} 
можно переписать как
 $ ^ /к ^) - 
v£V 
= ° • 
v£V
 (26.li)
 С учетом определения |/| из уравнения (26.1), добавляя равную 0 левую часть 
уравнения (26.11), и суммируя по всем вершинам в S — {s}, получим
 i/i = 
+ S 
v€V 
v£V 
u£S— {s} \и€У 
(^2f(u^v)-^2^v'un •
 v£V 
Расширение правой суммы и перегруппировка членов дает
 i/i = ^2f(s,v) - ^ /(v ,s) + 
v€V 
v£V 
u£S—{s} v£V 
S 
u£S— {s} v£V
 /
 ] C /(u’u)
 = ^2 /(s’v)+ H /(u^) - ^2 /(v’s)+ S /0^))
 v£V у 
uG5—{s} 
J 
= Y , S /(“-") - Z! Y , /(">“) •
 v&V u&S 
v£V u&S
 v£V у 
uGS—{s} 
J
 Поскольку V = SUT и SC\T = 0, мы можем разбить каждое суммирование по V 
на суммы по 5 и Т и получить
 i/i = ХШ 
v£S u£S 
/(w’ v) - 
v£T u£S 
= Е Е Л “’")“ £ £ /(«-«)
 V(zT U(zS 
\v(zS u£S 
V(zT U(zS
 v£S u£S 
/(v’w) - 
v£S u£S 
)
 /(^w)
 v£T u£S
 Две суммы в скобках на самом деле одинаковы, поскольку для всех вершин х, у Е 
Sчлен f(x,y) в каждую сумму входит по одному разу. Следовательно, эти суммы 
сокращаются, и мы имеем
 i/i = J2 ^2 /fa»v) - 2 S /(и>
 ueSveT 
= f(S,T). 
ueSveT
 .
 Следствие леммы 26.4 показывает, как пропускные способности разрезов мож
 но использовать для определения границы величины потока.
762
 Следствие 26.5
 Часть VI. Алгоритмы для работы с графами
 Величина любого потока / в транспортной сети G ограничена сверху пропускной 
способностью произвольного разреза G.
 Доказательство. Пусть (5, Г) представляет собой произвольный разрез G 
и пусть / является произвольным потоком. Согласно лемме 26.4 и ограничению 
пропускной способности
 1/1 = ns, Т)
 uES veT 
uES vET 
uES veT
 = c(S,T) .
 E E /(">“)
 uESvET
 Непосредственно из следствия 26.5 вытекает, что величина максимального по
 тока в сети ограничена сверху пропускной способностью минимального разреза. 
Сейчас мы сформулируем и докажем важную теорему о максимальном потоке 
и минимальном разрезе, в которой утверждается, что значение максимального 
потока равно пропускной способности минимального разреза.
 Теорема 26.6 (О максимальном потоке и минимальном разрезе)
 Если / представляет собой поток в транспортной сети G = (V,E) с истоком s 
и стоком t, то следующие утверждения эквивалентны.
 1. / является максимальным потоком в G.
 2. Остаточная сеть Gf не содержит увеличивающих путей.
 3. |/| = c(S,T) для некоторого разреза (5, Т) транспортной сети G.
 Доказательство. (1) => (2): предположим противное: пусть / является макси
 мальным потоком в G, но G/ содержит увеличивающий путь р. Тогда, соглас
 но следствию 26.3, поток, полученный путем увеличения потока / на поток /р, 
где /р задается уравнением (26.8), представляет собой поток в G с величиной, 
строго большей, чем |/|, что противоречит предположению о том, что / является 
максимальным потоком.
 (2) => (3): предположим, что G/ не содержит увеличивающего пути, т.е. что 
в Gf нет пути из s в t. Определим
 S = {v £V : в Gf имеется путь из s в v }
 и Т = V — S. Разбиение (5, Т) является разрезом: s 6 5 выполняется тривиально, 
a t £ S, поскольку в Gf нет пути из s в t. Теперь рассмотрим пару вершин и G 5 
и v G Т. Если (и, v) Е Е, должно выполняться f(u,v) = c(u,v), поскольку
Глава 26. Задача о максимальном потоке
 763
 в противном случае (u,v) 6 Ef, что помещало бы вершину v в множество S. 
Если (v,u) G Е, должно выполняться f(v,u) = 0, поскольку в противном случае 
значение Cf(u,v) = f(v,u) должно было бы быть положительным и мы должны 
были бы иметь (u,v) € Ef, так что v должно было бы находиться в 5. Конечно, 
если ни (u, v), ни (v, и) не находятся в Е, то f(u, v) = f(v, и) = 0. Таким образом, 
имеем
 /(s, т) = 
_ 
ueSveT 
veTues
 = S S c(“’,,)_ S S 0
 uGS dGT 
= c(S,T) .
 u€T u€5
 u)
 Следовательно, согласно лемме 26.4 |/| = f(S,T) = c(S,T).
 (3) => (1): согласно следствию 26.5 |/| < c(S,T) для всех разрезов (5, Т). 
Таким образом, из условия |/| = c(S,T) вытекает, что поток / является макси
 мальным потоком. 
■
 Базовый алгоритм Форда-Фалкерсона
 При выполнении каждой итерации метода Форда-Фалкерсона мы находим 
некоторый увеличивающий путь р и используем р для того, чтобы изменять по
 ток /. Как предлагается леммой 26.2 и следствием 26.3, мы заменяем / на / t /р» 
получая новый поток, величина которого равна |/| + |/р|. Приведенная далее 
реализация данного метода вычисляет максимальный поток в транспортной се
 ти G = (V, Е) путем обновления атрибута потока (u, v).f каждого ребра (и, v) G 
Е1. Е сли (и, v) £ Е, неявно предполагается, что (u,v).f = 0. Мы также счита
 ем, что вместе с транспортной сетью задаются пропускные способности с(и, v) 
и что c(u,v) = 0, если (u,v) ^ Е. Остаточная пропускная способность Cf(u,v) 
вычисляется по формуле (26.2). Выражение cj{p) в коде процедуры является про
 сто временной переменной, в которой хранится остаточная пропускная способ
 ность пути р.
 Ford-Fulkerson(<3, s , t)
 1 for каждого ребра (u, v) е G.E
 2
 (u,v).f = 0
 3 while существует путь p из s в t в остаточной сети G/
 4 
5
 6
 7 
8 
cf{p) = min {cf(u, v) : (u, v) содержится ър}
 for каждого ребра (и, v) в р
 if (и, v) е Е
 (u,v).f = (u,v).f + cf(p)
 else (v, u).f = (v, u).f - cf(p)
 1 Вспомним из раздела 22.1, что мы представляем атрибут / для ребра (u,v) с помощью того же стиля 
обозначений — (u, v).f, — что и в случае атрибутов любого другого объекта.
764
 Часть VI. Алгоритмы для работы с графами
 Рис. 26.6. Работа базового алгоритма Форда-Фалкерсона. (а)-(д) Последовательные итерации 
цикла while. Слева в каждой части показана остаточная сеть G/ из строки 3 с выделенным увели
 чивающим путем р. Справа показан новый поток /, который является результатом увеличения / 
на / р. Остаточная сеть в (а) представляет собой входную сеть G.
 Процедура Ford-Fulkerson является расширением приведенного ранее псев
 докода Ford-Fulkerson-M ethod. На рис. 26.6 показаны результаты каждой 
итерации при тестовом выполнении. Строки 1 и 2 инициализируют поток / зна
 чением 0. В цикле while в строках 3-8 выполняется неоднократный поиск уве
 личивающего пути р в Gf и увеличение потока / вдоль пути р увеличивается на 
остаточную пропускную способность Cf(p). 
Каждое остаточное ребро в пути р 
является либо ребром исходной сети, либо обратным к ребру в исходной сети. 
В строках 6-8 выполняется обновление потока, соответствующее каждому слу
 чаю, путем добавления потока, если остаточное ребро является ребром исходной 
сети, и вычитания в противном случае. Когда увеличивающих путей больше нет, 
поток / является максимальным.
 Анализ метода Форда-Фалкерсона
 Время выполнения процедуры Ford-Fulkerson зависит от того, как именно 
выполняется поиск увеличивающего пути р в строке 3. При неудачном выбо
 ре метода поиска алгоритм может даже не завершиться: величина потока будет 
последовательно увеличиваться, но она не обязательно будет сходиться к макси
Глава 26. Задача о максимальном потоке
 765
 (е)
 Рис. 26.6 (продолжение), (е) Остаточная сеть при последней проверке цикла while. В ней нет 
увеличивающих путей, так что поток /, показанный в части (д), является максимальным. Величина 
найденного максимального потока равна 23.
 FULKERSON ц и кл 
мальному значению потока2. Если увеличивающий путь выбирается с использо
 ванием поиска в ширину (который мы рассматривали в разделе 22.2), алгоритм 
выполняется за полиномиальное время. Прежде чем доказать этот результат, по
 лучим простую границу времени выполнения для случая, когда увеличивающий 
путь выбирается произвольным образом, а все значения пропускных способно
 стей являются целыми числами.
 На практике задача поиска максимального потока часто возникает в цело
 численной постановке. Если пропускные способности являются рациональными 
числами, можно использовать соответствующее масштабирование, которое сде
 лает их целыми. Если обозначить максимальный поток в такой трансформиро
 ванной сети как /*, то в случае непосредственной реализации процедуры FORD- 
while в строках 3-8 выполняется не более |/*| раз, поскольку 
величина потока за каждую итерацию увеличивается по крайней мере на одну 
единицу.
 Цикл while будет выполняться эффективно, если реализовать транспортную 
сеть G = (V, Е) с помощью правильно выбранной структуры данных и искать 
увеличивающий путь с помощью алгоритма с линейным временем работы. Пред
 положим, что мы поддерживаем структуру данных, соответствующую ориентиро
 ванному графу G' = (V,E'), где Е' = {(гг., v) : (u,v) G Е или (v,u) 6 Е}. Ребра
 2Метод Форда-Фалкерсона может работать бесконечно, только если значения пропускной способности 
ребер являются иррациональными числами.
766
 Часть VI. Алгоритмы для работы с графами
 Рис. 26.7. (а) Транспортная сеть, для обработки которой алгоритму Ford-Fulkerson может по
 требоваться время Q(E |/*|), где /* представляет собой максимальный поток, который в данном 
случае имеет величину |/*| = 2000000. Штриховкой выделен увеличивающий путь с остаточ
 ной пропускной способностью 1. (б) Полученная остаточная сеть с другим увеличивающим путем 
с остаточной пропускной способностью 1. (в) Полученная в результате остаточная сеть.
 сети G являются также ребрами графа G', поэтому в такой структуре данных 
можно довольно легко хранить пропускные способности и потоки. Для данного 
потока / в G ребра остаточной сети G/ состоят из всех ребер (и, v) графа G', 
таких, что Cf(u,v) > 0, где с/ удовлетворяет уравнению (26.2). Следователь
 но, время поиска пути в остаточной сети составляет 0(V + Е') = О(Е), если 
используется либо поиск в глубину, либо поиск в ширину. Таким образом, каж
 дая итерация цикла while занимает время О(Е), что вместе с инициализацией 
в строках 1 и 2 делает общее время выполнения алгоритма Ford-Fulkerson 
равным 0{Е |/*|).
 Когда значения пропускных способностей являются целыми числами и оп
 тимальное значение потока |/*| невелико, время выполнения алгоритма Форда- 
Фалкерсона достаточно неплохое. Но на рис. 26.7, (а) показан пример того, что 
может произойти в простой транспортной сети с большим значением |/*|. Вели
 чина максимального потока в данной сети равна 2 000 000: 1 000 000 единиц по
 тока идет по пути s и t, а другие 1 000 000 единиц идут по пути s v t. 
Если первым увеличивающим путем, найденным процедурой Ford-Fulkerson, 
является путь s 
и—> v —> t, как показано на рис. 26.7, (а), поток после первой 
итерации имеет значение 1. Полученная остаточная сеть показана на рис. 26.7, (б). 
Если в ходе выполнения второй итерации будет найден увеличивающий путь s —>• 
v—у и —у t, как показано на рис. 26.7, (б), поток станет равным 2. На рис. 26.7, (в) 
показана соответствующая остаточная сеть. Можно продолжать процедуру, выби
 рая увеличивающий путь s —> и —> v —> tB нечетных итерациях и s v и —¥ t 
в четных. В таком случае нам придется выполнить 2000 000 увеличений, при 
этом величина потока на каждом шаге увеличивается всего на 1.
 Алгоритм Эдмондса-Карпа
 Можно улучшить временную границу алгоритма Ford-Fulkerson, если ре
 ализовать вычисление увеличивающего пути р в строке 3 как поиск в ширину, 
т.е. если в качестве увеличивающего пути выбрать кратчайший путь из s в / 
в остаточной сети, где каждое ребро имеет единичную длину (вес). Такая ре
 ализация метода Форда-Фалкерсона называется алгоритмом Эдмондса-Карпа
Глава 26. Задача о максимальном потоке
 767
 (Edmonds-Кагр algorithm). Докажем, что время выполнения алгоритма Эдмондса- 
Карпа составляет 0(VE2).
 Анализ зависит от расстояний между вершинами остаточной сети Gf. В сле
 дующей лемме длина кратчайшего пути из вершины и в г; в остаточной сети G/, 
где каждое ребро имеет единичную длину, обозначена как £/(u, v).
 Лемма 26.7
 ти 6 /( s , г;) 
Если применить алгоритм Эдмондса-Карпа к транспортной сети G = (V, Е) с ис
 током s и стоком t, то для всех вершин v 6 V — {s, £} длина кратчайшего пу
 в остаточной сети Gf монотонно увеличивается с каждым увеличени
 ем потока.
 Доказательство. Предположим, что для некоторой вершины v 6 V - {s,t} су
 ществует такое увеличение потока, которое приводит к уменьшению длины крат
 чайшего пути из s в v, и покажем, что это предположение приведет нас к про
 тиворечию. Пусть / — поток, который был непосредственно перед первым уве
 личением, приведшим к уменьшению длины некоего кратчайшего пути, a f — 
поток сразу после этого увеличения. Пусть v — вершина с минимальной длиной 
кратчайшего пути 6f/(s, v), которая уменьшилась в результате увеличения потока, 
так что 6f>(s,v) < 6f(s,v). Пусть p = s ' ^u—>v — кратчайший путь из s в v 
в Gf, такой, что (u,v) 6 Ер и
 6f>(s,u) = 6fi(s,v) — 1. 
(26.12)
 Исходя из того, как мы выбирали v, можно утверждать, что длина пути до вер
 шины и из истока s не уменьшилась, т.е.
 6f>(s, и) > 6f(s, и) . 
(26.13)
 Мы утверждаем, что (u,v) ^ Ef. Почему? Если мы имели (и, v) е Ej, то должны 
были также выполняться соотношения
 <5/(s, v) < 6f(s, и) + 1 
< 6f>(s,u) + 1 
= 6f>(s,v) 
(лемма 24.10, неравенство треугольника)
 (согласно неравенству (26.13))
 (согласно уравнению (26.12)) ,
 что противоречит нашему предположению о том, что 6f(s,v) < 6/(s,v).
 Как же может получиться (u, v) ^ Ef и (u,v) е Е^1 Увеличение должно 
привести к возрастанию потока из v в и. Алгоритм Эдмондса-Карпа всегда уве
 личивает поток вдоль кратчайших путей, поэтому последним ребром кратчайшего 
пути из s в и в Gf является ребро (v, и). Следовательно,
 6f(s,v) = 6f(s,u) - 1
 < 6f>(s,u) — 1 
= 6ft(s,v) — 2 
(согласно неравенству (26.13))
 (согласно уравнению (26.12)) ,
768
 Часть VI. Алгоритмы для работы с графами
 что противоречит нашему предположению о том, что 6p(s,v) < 6f(s,v). 
Мы заключаем, что наше предположение о существовании такой вершины v 
неверное. 
■
 В следующей теореме устанавливается верхний предел количества итераций 
алгоритма Эдмондса-Карпа.
 Теорема 26.8
 Если алгоритм Эдмондса-Карпа выполняется для некоторой транспортной се
 ти G = (V, Е) с истоком s и стоком t, то общее число увеличений потока, выпол
 няемых данным алгоритмом, составляет 0(VE).
 Доказательство. Назовем ребро (u,v) остаточной сети Gj критическим 
(critical) для увеличивающего пути р, если остаточная пропускная способность р 
равна остаточной пропускной способности ребра (и, v), т.е. если с/ (р) = Cf(u, v). 
После увеличения потока вдоль увеличивающего пути все критические ребра это
 го пути исчезают из остаточной сети. Кроме того, по крайней мере одно ребро 
любого увеличивающего пути должно быть критическим. Теперь покажем, что 
каждое из \Е\ ребер может становиться критическим не более \V\ /2 раз.
 Пусть и и v являются вершинами из множества вершин V, соединенными 
некоторым ребром из множества Е. Поскольку увеличивающие пути являются 
кратчайшими путями, то, когда ребро (u,v) становится критическим в первый 
раз, справедливо равенство
 6f(s,V) = 6f(s,U) + 1 .
 После того как поток увеличен, ребро (и, v) исчезает из остаточной сети. Оно не 
может появиться в другом увеличивающем пути, пока не будет уменьшен поток 
из и в v, а это может произойти только в том случае, если на некотором уве
 личивающем пути встретится ребро (v,u). Если в этот момент в сети G поток 
представляет собой /', то справедливо следующее равенство
 6f'(s,U) = 6f>(s,v) + 1 .
 Поскольку Sf(s, v) < 6f>(s, v), согласно лемме 26.7, мы имеем
 6f'(s,U) = 6p(s,v) + 1 
> 6f(s,v) + 1 
= 8/(s, и) + 2 .
 Следовательно, за время, прошедшее с момента, когда ребро (и, v) стало кри
 тическим, до момента, когда оно станет критическим в следующий раз, расстоя
 ние до и от истока увеличивается не менее чем на 2. Расстояние до и от истока 
в начальный момент было не меньше 0. Среди промежуточных вершин на крат
 чайшем пути из s в и не могут находиться s, и или t (поскольку наличие реб
 ра (и, г;) в увеличивающем пути влечет за собой и ф t). Следовательно, к тому
Глава 26. Задача о максимальном потоке
 769
 моменту, когда вершина и станет недостижимой из истока (если такое произой
 дет), расстояние до нее будет не более |У| — 2. Таким образом, ребро (и, v) может 
стать критическим не более чем еще (|У| — 2)/2 = |У| /2 — 1 раз, т.е. всего не бо
 лее \V \/2 раз. Поскольку в остаточном графе имеется 0(Е) пар вершин, которые 
могут быть соединены ребрами в остаточной сети, общее количество критических 
ребер в ходе выполнения алгоритма Эдмондса-Карпа равно 0(VE). Каждый уве
 личивающий путь содержит по крайней мере одно критическое ребро, а значит, 
теорема доказана. 
■
 Поскольку, если использовать поиск в ширину, можно выполнять каждую ите
 рацию процедуры FORD-FULKERSON за время О(Е), общее время работы алго
 ритма Эдмондса-Карпа оказывается равным 0(VE2). Мы покажем, что алгорит
 мы проталкивания предпотока позволяют достичь еще лучших результатов. На 
основе алгоритма из раздела 26.4 построен метод, который позволяет достичь 
времени выполнения 0(V2E); этот метод является основой алгоритма со време
 нем выполнения 0(V3), рассматриваемого в разделе 26.5.
 Упражнения
 26.2.1
 Докажите, что сумма в уравнении (26.6) равна сумме в уравнении (26.7).
 26.2.2
 Чему равен поток через разрез ({s, V2, u*} , {г>1, г>з, £}) на рис. 26.1, (б)? Какова 
пропускная способность этого разреза?
 26.2.3
 Продемонстрируйте выполнение алгоритма Эдмондса-Карпа на примере транс
 портной сети, представленной на рис. 26.1, (а).
 26.2.4
 Укажите на рис. 26.6 минимальный разрез, соответствующий показанному макси
 мальному потоку. Какой из показанных в примере увеличивающих путей приво
 дит к сокращению потока?
 26.2.5
 Вспомним предложенную в разделе 26.1 конструкцию, которая преобразует 
транспортную сеть с несколькими истоками и несколькими стоками в сеть с од
 ним истоком и одним стоком путем добавления ребер с бесконечной пропускной 
способностью. Докажите, что любой поток в полученной сети имеет конечную 
величину, если ребра исходной сети с множественными истоками и стоками име
 ют конечную пропускную способность.
 26.2.6
 Предположим, что каждый исток s* в задаче с множественными истоками и стока
 ми производит ровно pi единиц потока, так что J2vev f(si>v) = Pi- Предположим 
также, что каждый сток tj потребляет ровно qj единиц, так что J2vev fiv-> tj) = 4j->
 25 Зак. 3726
770
 Часть VI. Алгоритмы для работы с графами
 гДе YhiPi = Yhj 4j• Покажите, как преобразовать данную задачу поиска потока /, 
удовлетворяющего указанным дополнительным ограничениям, в задачу поиска 
максимального потока в транспортной сети с одним истоком и одним стоком.
 26.2.7
 Докажите лемму 26.2.
 26.2.8
 Предположим, что мы переопределили остаточную сеть, запретив ребра, входя
 щие в s. Докажите, что процедура Ford-Fulkerson все равно будет корректно 
вычислять максимальный поток.
 26.2.9
 Предположим, что и /, и f являются потоками в сети G и что мы вычисля
 ем поток / 1 f- Будет ли увеличенный поток удовлетворять свойству сохранения 
потока? А ограничению пропускной способности?
 26.2.10
 Покажите, как найти максимальный поток в сети G = (V,E) путем последова
 тельности не более чем из |£7| увеличивающих путей. (Указание: определите пути 
после нахождения максимального потока.)
 26.2.11
 Реберной связностью (edge connectivity) неориентированного графа называется 
минимальное число ребер к, которые необходимо удалить, чтобы разъединить 
граф. Например, реберная связность дерева равна 1, а реберная связность цик
 лической цепи вершин равна 2. Покажите, как определить реберную связность 
неориентированного графа G = {V,E) с помощью алгоритма максимального по
 тока не более чем для \ V\ транспортных сетей, каждая из которых содержит 0(V) 
вершин и О(Е) ребер.
 26.2.12
 Предположим, что имеется транспортная сеть G и что в G имеются ребра, входя
 щие в исток s. Пусть / представляет собой поток в G, в котором одно из входящих 
в исток ребер (г;, s) имеет f(v, s) = 1. Докажите, что должен существовать другой 
поток /' с f'(v,s) = 0, такой, что |/| = |/'|. Разработайте алгоритм со временем 
работы О(Е), который вычисляет /' по данному /, в предположении, что все 
пропускные способности ребер являются целыми числами.
 26.2.13
 Предположим, что вам требуется найти среди всех минимальных разрезов транс
 портной сети G с целочисленными пропускными способностями тот, который 
содержит наименьшее количество ребер. Покажите, как изменить пропускные 
способности G, чтобы создать новую транспортная сеть G’, в которой любой 
минимальный разрез в G' является минимальным разрезом с наименьшим коли
 чеством ребер в G.
Глава 26. Задача о максимальном потоке
 26.3. Максимальное паросочетание
 771
 Некоторые комбинаторные задачи можно легко свести к задачам поиска мак
 симального потока. Одной из таких задач является задача определения макси
 мального потока в сети с несколькими истоками и стоками, описанная в разде
 ле 26.1. Существуют другие комбинаторные задачи, которые, на первый взгляд, 
имеют мало общего с транспортными сетями, однако могут быть сведены к за
 дачам поиска максимального потока. В данном разделе рассматривается одна из 
подобных задач: поиск максимального паросочетания в двудольном графе. Что
 бы решить данную задачу, воспользуемся свойством полноты, обеспечиваемым 
методом Форда-Фалкерсона. Мы также покажем, что с помощью метода Форда- 
Фалкерсона можно решить задачу поиска максимального паросочетания в дву
 дольном графе G = (V, Е ) за время 0(VE).
 Задача поиска максимального паросочетания в двудольном графе
 Пусть дан неориентированный граф G = (V,E). Паросочетанием (matching) 
называется подмножество ребер MCE , такое, что для всех вершин v 6 V 
в М содержится не более одного ребра, инцидентного v. Мы говорим, что вер
 шина v е V является связанной (matched) паросочетанием М, если в М есть 
ребро, инцидентное v; в противном случае вершина v называется открытой 
(unmatched). Максимальным паросочетанием называется паросочетание мак
 симальной мощности, т.е. такое паросочетание М , что для любого паросочета
 ния М' справедливо соотношение \М\ > \М'\. В данном разделе мы ограни
 чимся рассмотрением задачи поиска максимальных паросочетаний в двудольных 
графах, т.е. в графах, множество вершин которых можно разбить на два подмно
 жества V = L U R, где L и R не пересекаются и все ребра в Е проходят между L 
и R. Далее мы предполагаем, что каждая вершина в V имеет по крайней мере од
 но инцидентное ребро. Понятие паросочетания проиллюстрировано на рис. 26.8.
 Задача поиска максимального паросочетания в двудольном графе имеет мно
 жество практических приложений. В качестве примера можно рассмотреть паро
 сочетание множества машин L и множества задач R, которые должны выполнять
 ся одновременно. Наличие в Е ребра (u,v) означает, что машина и 6 L может 
выполнять задачу v 6 R. Максимальное паросочетание обеспечивает максималь
 ную загрузку машин.
 Поиск максимального паросочетания в двудольном графе
 С помощью метода Форда-Фалкерсона можно найти максимальное паросоче
 тание в неориентированном двудольном графе G = (V, Е) за время, полиноми
 ально зависящее от |V| и \Е\. Фокус заключается в том, чтобы построить транс
 портную сеть, потоки в которой соответствуют паросочетаниям, как показано на 
рис. 26.8, (в). Определим для заданного двудольного графа G соответствующую 
транспортную сеть G' = {V , Е') следующим образом. Возьмем в качестве ис
 тока s и стока t новые вершины, не входящие в V, и положим V' = V U {s,£}.
772
 L 
R
 (а) 
Часть VI. Алгоритмы для работы с графами
 L 
R
 (6) 
L 
R
 (в)
 Рис. 26.8. Двудольный граф G = (V, Е) с разбиением вершин V = L U R. (а) Паросочетание 
с мощностью 2 (ребра выделены штриховкой), (б) Максимальное паросочетание с мощностью 3. 
(в) Соответствующая транспортная сеть G' с показанным максимальным потоком. Каждое ребро 
имеет единичную пропускную способность. Через заштрихованные ребра идет поток величиной 1, 
во всех остальных ребрах потока нет. Заштрихованные ребра из L в R соответствуют заштрихо
 ванным ребрам в максимальном паросочетании в части (б).
 Если разбиение вершин в графе G представляет собой V = L U R, ориентирован
 ными ребрами G' являются ребра Е, направленные из L в R, а также \V\ новых 
ориентированных ребер
 Е' = {(s, и) : и G L} U {(и, v) : {и, v) G Е} U {(г;, t) : v G R} .
 Чтобы завершить построение, присвоим каждому ребру Е' единичную пропуск
 ную способность. Поскольку каждая вершина из множества вершин V имеет по 
крайней мере одно инцидентное ребро, |.Е| > \V\ /2. Таким образом, \Е\ < \Е'\ = 
\Е\ + \V\ < 3 \Е\, так что \Е'\ = в(Е).
 Следующая лемма показывает, что паросочетание в G непосредственно со
 ответствует потоку в соответствующей транспортной сети G'. Поток / в транс
 портной сети G = (V, Е) называется целочисленным (integer-valued), если значе
 ния f(u, v) целые для всех (и, v) е V х V.
 Лемма 26.9
 Пусть G = (V, Е) является двудольным графом с разбиением вершин V = L U R 
и пусть G' = i y \ Е') представляет собой соответствующую ему транспортную 
сеть. Если М является паросочетанием в G, то существует целочисленный по
 ток / в G1, величина которого — |/| = \М\. Справедливо и обратное утвержде
 ние: если / представляет собой целочисленный поток в G', то в G существует 
паросочетание М с мощностью \М\ = |/|.
 Доказательство. Покажем сначала, что паросочетанию М в графе G соответ
 ствует некоторый целочисленный поток / в сети G'. Определим / следующим 
образом. Если (u,v) е М, то f(s,u) = f(u,v) = f(v,t) = 1. Для всех остальных
Глава 26. Задача о максимальном потоке
 773
 ребер (u, v) е Е' определим f(u, v) = 0. Нетрудно убедиться, что / удовлетворя
 ет ограничению пропускной способности и сохранению потока.
 Интуитивно понятно, что каждое ребро (и, v) е М соответствует единице по
 тока в G', проходящего по пути s 
и 
v 
t. Кроме того, пути, порожденные 
ребрами из М, представляют собой непересекающиеся множества вершин, не 
считая s и t.
 Чистый поток через разрез (L U {s} , R U {£}) равен \М\; следовательно, со
 гласно лемме 26.4 величина потока равна |/| = \М\.
 Чтобы доказать обратное, предположим, что / — некоторый целочисленный 
поток в G', и пусть
 М = {(и, у) : и € L, v € R, и f(u, v) > 0} .
 Каждая вершина и е L имеет только одно входящее ребро, а именно — (s, и), 
и его пропускная способность равна 1. Следовательно, в каждую вершину и е L 
входит не более одной единицы положительного потока, и если она действитель
 но входит, то из нее должна также выходить одна единица положительного потока 
согласно свойству сохранения потока. Более того, поскольку / — целочисленный 
поток, для каждой вершины и е L одна единица потока может входить не более 
чем по одному ребру и выходить не более чем по одному ребру. Таким образом, 
одна единица положительного потока входит в и тогда и только тогда, когда су
 ществует в точности одна вершина v е R, такая, что f(u,v) = 1, и из каждой 
вершины и е L выходит не более одного ребра, несущего положительный поток. 
Симметричные рассуждения применимы для каждой вершины и е й. Следова
 тельно, М является паросочетанием.
 Чтобы показать, что \М\ = |/|, заметим, что f(s, и) = 1 для каждой связанной 
вершины и 6 L, и для каждого ребра (и, v) е Е — М мы имеем f{u, v) = 0. 
Следовательно, f(LL){s} , R\J {£}), чистый поток через разрез (LU {s} , R\J {£}), 
равен \М\. Применив лемму 26.4, получаем, что |/| = /(LU{s} , Яи{£}) = \М\. я
 На основании леммы 26.9 можно сделать вывод о том, что максимальное паро- 
сочетание в двудольном графе G соответствует максимальному потоку в соответ
 ствующей ему транспортной сети G1, следовательно, можно находить максималь
 ное паросочетание в G с помощью алгоритма поиска максимального потока в G'. 
Единственной проблемой в данных рассуждениях является то, что алгоритм по
 иска максимального потока может вернуть такой поток в G', в котором некоторое 
значение f(u,v) оказывается нецелым, несмотря на то что величина |/| долж
 на быть целой. В следующей теореме показано, что при использовании метода 
Форда-Фалкерсона такая проблема возникнуть не может.
 Теорема 26.10 (Теорема о целочисленности)
 Если функция пропускной способности с принимает только целые значения, то 
максимальный поток /, полученный с помощью метода Форда-Фалкерсона, об
 ладает тем свойством, что значение потока |/| является целочисленным. Более 
того, для всех вершин u n v величина f(u, v) является целой.
774
 Часть VI. Алгоритмы для работы с графами
 Доказательство. Доказательство проводится индукцией по числу итераций. 
Его предлагается выполнить в качестве упр. 26.3.2. 
■
 Теперь мы можем доказать следствие из леммы 26.9.
 Следствие 26.11
 Мощность максимального паросочетания М в двудольном графе G равна вели
 чине максимального потока / в соответствующей транспортной сети G'.
 Доказательство. Воспользуемся терминологией леммы 26.9. Предположим, 
что М представляет собой максимальное паросочетание в G, но соответству
 ющий ему поток / в G' не максимален. Тогда в G' существует максимальный 
поток /', такой, что |/'| > |/|. Поскольку пропускные способности в G' являют
 ся целочисленными, теорема 26.10 позволяет считать поток /' целочисленным. 
Таким образом, /' соответствует некоторому паросочетанию М' в G мощно
 стью \М'\ = |/'| > |/| = \М\, что противоречит нашему предположению о том, 
что М является максимальным паросочетанием. Аналогично можно показать, что 
если / — максимальный поток в G', то соответствующее ему паросочетание яв
 ляется максимальным паросочетанием в G. 
ш
 Таким образом, для заданного неориентированного двудольного графа G мож
 но найти максимальное паросочетание путем создания транспортной сети G', 
применения метода Форда-Фалкерсона и непосредственного получения макси
 мального паросочетания М по найденному максимальному целочисленному по
 току /. Поскольку любое паросочетание в двудольном графе имеет мощность не 
более min(L, R) = 0(V), величина максимального потока в G' составляет 0(V). 
Поэтому максимальное паросочетание в двудольном графе можно найти за вре
 мя 0(VE') — 0(VE), поскольку \Е'\ = @{Е).
 Упражнения
 26.3.1
 Примените алгоритм Форда-Фалкерсона для транспортной сети на рис. 26.8, (в) 
и покажите остаточную сеть после каждого увеличения потока. Вершины из мно
 жества L пронумеруйте сверху вниз от 1 до 5, а вершины множества R — от 6 
до 9. Для каждой итерации укажите лексикографически наименьший увеличива
 ющий путь.
 26.3.2
 Докажите теорему 26.10.
 26.3.3
 Пусть G = (У, Е) представляет собой двудольный граф с разбиением вер
 шин V = L U R, a G' — соответствующая ему транспортная сеть. Найдите верх
 нюю границу длины любого увеличивающего пути, найденного в G' в процессе 
выполнения процедуры Ford-Fulkerson.
Глава 26. Задача о максимальном потоке
 775
 26.3.4 ★
 Идеальное паросочетание (perfect matching) представляет собой паросочетание, 
в котором каждая вершина является связанной. Пусть G = (V,E) является неори
 ентированным двудольным графом с разбиением вершин V = LUR, где \Ь\ = |Я|. 
Для любого X С V определим окрестность (neighborhood) X как
 N(X) = {у е V : (х, у) G Е для некоторого хеХ} ,
 т.е. это множество вершин, смежных с какой-либо из вершин X. Докажите теоре
 му Холла (Hall’s theorem): идеальное паросочетание в G существует тогда и толь
 ко тогда, когда |А| < |TV(vl) | для каждого подмножества А С L.
 26.3.5 ★
 Двудольный граф G = (V, Е), где V = L U R, называется d-регулярным (d- 
regular), если каждая вершина и еУ имеет степень, в точности равную d. В каж
 дом d-регулярном двудольном графе выполняется соотношение \L\ = |Д|. Дока
 жите, что в каждом d-регулярном двудольном графе имеется паросочетание мощ
 ности \Ь\, показав, что минимальный разрез соответствующей транспортной сети 
имеет пропускную способность \L\.
 ★ 
26.4. Алгоритмы проталкивания предпотока
 В данном разделе будет рассмотрен подход к вычислению максимальных по
 токов, основанный на “проталкивании предпотока’! В настоящее время многие 
асимптотически наиболее быстрые алгоритмы поиска максимального потока при
 надлежат данному классу, и на этом методе основаны реальные реализации алго
 ритмов поиска максимального потока. С помощью методов проталкивания пред
 потока можно решать и другие связанные с потоками задачи, например задачу 
поиска потока с минимальной стоимостью. В данном разделе приводится раз
 работанный Голдбергом (Goldberg) “обобщенный” алгоритм поиска максималь
 ного потока, для которого существует простая реализация с временем выполне
 ния 0(V2E), что лучше времени работы алгоритма Эдмондса-Карпа 0(VE2). 
В разделе 26.5 данный обобщенный алгоритм будет усовершенствован, что поз
 волит получить алгоритм проталкивания предпотока, время выполнения которого 
составляет 0(V3).
 Алгоритмы проталкивания предпотока работают способом, более локальным, 
чем метод Форда-Фалкерсона. Вместо того чтобы для поиска увеличивающего 
пути анализировать всю остаточную сеть, алгоритмы проталкивания предпотока 
обрабатывают вершины по одной, рассматривая только соседей данной вершины 
в остаточной сети. Кроме того, в отличие от метода Форда-Фалкерсона, алгорит
 мы проталкивания предпотока не обеспечивают поддержание в процессе работы 
свойства сохранения потока. При этом, однако, они поддерживают предпоток 
(preflow), который представляет собой функцию / : V х V —> Ш, удовлетво
776
 Часть VI. Алгоритмы для работы с графами
 ряющую ограничениям пропускной способности и следующему ослабленному 
условию сохранения потока:
 ^T, f{v,u) - £ / ( « , „ ) > О
 vEV 
v£V
 для всех вершин и е V — {s}. Будем называть величину
 е{и) = ^2f{v,u) - ^2f(u,v) 
v£V 
v£V
 (26.14)
 избыточным потоком (excess flow), входящим в вершину и. Избыток в вершине 
представляет собой величину, на которую входящий поток превышает исходя
 щий. Мы говорим, что вершина и е V — {5, t} переполненная (overflowing), 
если е(и) > 0.
 Мы начнем данный раздел с описания интуитивных соображений, приводя
 щих к методу проталкивания предпотока. Затем рассмотрим две применяемые 
в данном методе операции: “проталкивание” предпотока и подъем (перемарки- 
ровка — relabeling) некоторой вершины. Наконец, мы представим обобщенный 
алгоритм проталкивания предпотока и проанализируем его корректность и время 
выполнения.
 Интуитивные соображения
 Интуитивные соображения, лежащие в основе метода проталкивания предпо
 тока, лучше всего проиллюстрировать на примере потоков жидкости: пусть транс
 портная сеть G = (V, Е) представляет собой систему труб с заданными пропуск
 ными способностями. Применив данную аналогию, о методе Форда-Фалкерсона 
можно сказать, что каждый увеличивающий путь в сети вызывает дополнитель
 ный поток жидкости без точек ветвления, который течет от истока к стоку. Метод 
Форда-Фалкерсона многократно добавляет дополнительные потоки до тех пор, 
пока дальнейшее добавление станет невозможным.
 В основе обобщенного алгоритма проталкивания предпотока лежат другие ин
 туитивные соображения. Пусть, как и ранее, ориентированные ребра соответству
 ют трубам. Вершины, в которых трубы пересекаются, обладают двумя интерес
 ными свойствами. Во-первых, чтобы принять избыточный поток, каждая вершина 
снабжена выходящей трубой, ведущей в произвольно большой резервуар, способ
 ный накапливать жидкость. Во-вторых, каждая вершина, ее резервуар и все труб
 ные соединения находятся на платформе, высота которой увеличивается по мере 
работы алгоритма.
 Высота вершины определяет, как проталкивается поток: поток может протал
 киваться только вниз, т.е. от более высокой вершины к более низкой. Поток может 
быть направлен и от нижестоящей вершины к вышестоящей, но операции про
 талкивания потока проталкивают его только вниз. Высота истока является фикси
 рованной и составляет \V\, а фиксированная высота стока равна 0. Высота всех 
других вершин сначала равна 0 и увеличивается со временем. Алгоритм сначала
Глава 26. Задача о максимальном потоке
 777
 посылает максимально возможный поток вниз от истока к стоку. Посылается ко
 личество, в точности достаточное для заполнения всех выходящих из истока труб 
до достижения их пропускной способности; таким образом посылается поток, 
равный пропускной способности разреза (s, V — {s}). Когда поток впервые вхо
 дит в некоторую транзитную вершину, он накапливается в ее резервуаре. Отсюда 
он со временем проталкивается вниз.
 Может случиться так, что все трубы, выходящие из вершины и и еще не за
 полненные потоком, ведут к вершинам, которые лежат на одном уровне с и или 
находятся выше нее. В этом случае, чтобы избавить переполненную вершину и 
от избыточного потока, необходимо увеличить ее высоту — провести операцию 
подъема (relabeling) вершины и. Ее высота увеличивается и становится на еди
 ницу больше, чем высота самой низкой из смежных с ней вершин, к которым 
ведут незаполненные трубы. Следовательно, после подъема вершины существует 
по крайней мере одна выходящая труба, по которой можно протолкнуть дополни
 тельный поток.
 В конечном итоге весь поток, который может пройти к стоку, оказывается там. 
Больше пройти не может, поскольку трубы подчиняются ограничениям пропуск
 ной способности; количество потока через любой разрез ограничено его про
 пускной способностью. Чтобы сделать предпоток “нормальным” потоком, алго
 ритм после этого посылает избытки, содержащиеся в резервуарах переполненных 
вершин, обратно к истоку, продолжая менять метки вершин, чтобы их высота 
превышала фиксированную высоту истока \V\. Как будет показано, после того 
как резервуары окажутся пустыми, предпоток станет не только нормальным, но 
и максимальным потоком.
 Основные операции
 Как следует из предыдущих рассуждений, в алгоритме проталкивания пред- 
потока выполняются две основные операции: проталкивание избытка потока от 
вершины к одной из соседних с ней вершин и подъем вершины. Применение 
этих операций зависит от высот вершин, которым мы сейчас дадим более точные 
определения.
 Пусть G = (V,E) представляет собой транспортную сеть с истоком s и сто
 ком t, а / является некоторым предпотоком в G. Функция h : V —у N является 
функцией высоты (height function)3, h(s) = |V|, h(t) = 0 и
 h(u) < h(v) + 1
 для каждого остаточного ребра (u,v) е Ef. Сразу же можно сформулировать 
следующую лемму.
 3В литературе функция высоты обычно называется функцией расстояния (distance function), а высота вер
 шины называется меткой расстояния (distance label). Мы используем термин “высота”, поскольку он лучше 
согласуется с интуитивным обоснованием алгоритма. Высота вершины связана с ее расстоянием от стока £, 
которое можно найти с помощью поиска в ширину в GT.
778
 Лемма 26.12
 Часть VI. Алгоритмы для работы с графами
 Пусть G = (V, Е) представляет собой транспортную сеть, а / является некоторым 
предпотоком в G, и пусть h — функция высоты, заданная на множестве V. Для 
любых двух вершин u,v € V справедливо следующее утверждение: если h(u) > 
h(v) + 1, то (и, v) не является ребром остаточной сети. 
■
 Операция проталкивания
 Основная операция Push(u,v) может применяться тогда, когда и является пе
 реполненной вершиной, Cf(u,v) > 0 и h(u) = h(v) + 1. Представленный ниже 
псевдокод обновляет предпоток / и избыточный поток для и иг;. Предполагает
 ся, что остаточные пропускные способности Cf(u,v) при заданных / и с можно 
вычислить за фиксированное время. Излишний поток в вершине и поддержива
 ется в виде атрибута и. е, а высота вершины и — в виде атрибута u.h. Выра
 жение Af(u,v) представляет собой временную переменную, в которой хранится 
количество потока, которое можно протолкнуть из и в v.
 Push (u,v)
 1 // Применяется при: вершина и переполнена,
 // 
Cf(u, v) > 0 и и. h = v. h + 1.
 2 //Действие: 
// 
проталкивает A/(w, v) = min(w. е, Cf(u, г;))
 единиц потока из и в и.
 3 Af(u,v) = min (u.e,Cf(u,v))
 4 if (и, v) E E
 5 
6
 (и, v).f = (и, v).f + Af(u, v)
 else (v,u).f = (v,u).f - Af(u,v)
 7 u. e = u. e — Af(u,v)
 8 v.e = v.e + A f(u,v)
 Процедура Push работает следующим образом. Поскольку вершина и имеет по
 ложительный избыток и.е и остаточная пропускная способность ребра (u,v) 
положительна, можно увеличить поток из и в v на величину Af(u,v) = 
min(u.e,cf(u,v)), при этом избыток и.е не становится отрицательным и не бу
 дет превышена пропускная способность c(u,v). В строке 3 вычисляется значе
 ние A f(u, v), после чего в строках 4-6 обновляется /. В строке 5 увеличивается 
поток в ребре (u,v), поскольку мы проталкиваем поток через остаточное ребро, 
которое также является и исходным ребром. В строке 6 уменьшается поток в реб
 ре (v,u), поскольку остаточное ребро в действительности обратно ребру в исход
 ной сети. Наконец в строках 7 и 8 обновляются избыточные потоки в вершины и 
и v. Таким образом, если / являлся предпотоком перед вызовом процедуры Push. 
он останется предпотоком и после ее выполнения.
 Обратите внимание, что в коде процедуры Push ничто не зависит от высот 
вершин и и v; тем не менее мы запретили вызов процедуры, если не выполнено 
условие u.h = v.h + 1. Таким образом, избыточный поток проталкивается вниз 
только при разности высот, равной 1. Согласно лемме 26.12 между двумя вер
 шинами, высоты которых отличаются более чем на 1, не существует остаточных
Глава 26. Задача о максимальном потоке
 779
 ребер, а значит, поскольку атрибут h является функцией высоты, мы ничего не до
 бьемся, разрешив проталкивать вниз поток при разности высот, превышающей 1.
 Процедура P u sh (u , v) называется проталкиванием (push) из и в и. Если опе
 рация проталкивания применяется к некоторому ребру (и, v), выходящему из вер
 шины и, будем говорить, что операция проталкивания применяется к и. Если 
в результате ребро (и, v) становится насыщенным (saturated) (после проталкива
 ния Cf (и, v) = 0), то это насыщающее проталкивание (saturating push), в против
 ном случае это ненасыщающее проталкивание (nonsaturating push). Если ребро 
становится насыщенным, оно исчезает из остаточной сети. Один из результатов 
ненасыщающего проталкивания характеризует следующая лемма.
 Лемма 26.13
 После ненасыщающего проталкивания из и в v вершина и более не является 
переполненной.
 Доказательство. Поскольку проталкивание ненасыщающее, фактическое коли
 чество посланного потока Af(u,v) должно быть равно величине и.е непосред
 ственно перед проталкиванием. Поскольку избыток и. е уменьшается на эту ве
 личину, после проталкивания он становится равным 0. 
■
 Операция подъема
 Основная операция R ela b el (u ) применяется, если вершина и переполнена 
и если u.h < v.h для всех ребер (u,v) е Ef. Иными словами, переполненную 
вершину и можно подвергнуть подъему, если все вершины v, для которых имеет
 ся остаточная пропускная способность от и к v, расположены не ниже и, так что 
протолкнуть поток из и нельзя. (Напомним, что по определению ни исток s, ни 
сток t не могут быть переполнены; следовательно, ни s, ни t нельзя подвергать 
подъему.)
 R e l a b el (и)
 1 // Применяется при: вершина и переполнена, и для всех v е V, таких,
 // 
что (u,v) е Ef, имеем u.h < v.h.
 2 // Действие: 
увеличивает высоту и.
 3 u.h = 1 + min {г;.h : (и, v) G Ef}
 Когда вызывается операция R elab el (и), мы говорим, что вершина и подверга
 ется подъему (relabeled). Заметим, что когда выполняется подъем и, Ef должно 
содержать хотя бы одно ребро, выходящее из и, чтобы минимизация в коде опе
 рации осуществлялась по непустому множеству. Это свойство вытекает из пред
 положения о том, что вершина и переполнена, что, в свою очередь, говорит нам, 
что
 U. е = ^2 f(v, и) - ^2 f(u, v) > 0 .
 v£V 
v£V
 Поскольку все потоки неотрицательны, должна быть по крайней мере одна вер
 шина v, такая, что (v,u).f > 0. Но тогда Cf(u,v) > 0, откуда вытекает, что
780
 Часть VI. Алгоритмы для работы с графами
 (u,v) Е Ef. Таким образом, операция Relabel(w) назначает и наибольшую вы
 соту, допускаемую наложенными на функцию высоты ограничениями.
 Обобщенный алгоритм
 Обобщенный алгоритм проталкивания предпотока использует следующую 
подпрограмму для создания начального предпотока в транспортной сети.
 Initialize-Preflow(G, s)
 1 for каждой вершины v Е G. V
 2 
v.h = 0
 3 
5 
v. e = 0
 4 for каждого ребра (и, v) E G.E
 (u, v).f — 0
 6 s.h = \G.V\
 7 for каждой вершины v E s.Adj
 8 
{s,v).f = c{s,v)
 9 
10 
v.e = c(s,v)
 s.e = s.e — c(s, v)
 Initialize-Preflow создает начальный предпоток f, определяемый как
 { с(и, v) , если и = s ,
 0 
в противном случае .
 (26.15)
 Иначе говоря, каждое ребро, выходящее из истока s, заполняется до его пропуск
 ной способности, а все остальные ребра не несут потока. Для каждой вершины v, 
смежной с истоком, изначально мы имеем v.e = c(s,v) и инициализируем s.e 
суммой этих значений с обратным знаком. Обобщенный алгоритм начинает рабо
 ту с начальной функцией высоты h, задаваемой следующим образом:
 {|У| , если и = s ,
 0 
в противном случае .
 (26.16)
 Уравнение (26.16) определяет функцию высоты, поскольку единственными реб
 рами (и, v), для которых u.h > v.h + 1, являются те, для которых и = s, и эти 
ребра заполнены, а это означает, что их нет в остаточной сети.
 Инициализация, за которой следует ряд операций проталкивания и подъема, 
выполняемых без определенного порядка, образует алгоритм Generic-Push- 
Relabel.
 Generic-Push-Relabel (G)
 1 Initialize-Preflow (G,s)
 3
 2 while существует применимая операция 
проталкивания или подъема
 выбрать и выполнить операцию проталкивания или подъема
Глава 26. Задача о максимальном потоке
 781
 В следующей лемме утверждается, что до тех пор, пока существует хотя бы одна 
переполненная вершина, применима хотя бы одна из этих операций.
 Лемма 26.14 (Для переполненной вершины можно выполнить либо 
проталкивание, либо подъем)
 Пусть G = (V, Е) представляет собой транспортную сеть с истоком s и стоком t, 
а / является предпотоком, и пусть h является произвольной функцией веса для /. 
Если и представляет собой произвольную переполненную вершину, то к ней при
 менимо либо проталкивание, либо подъем.
 Доказательство. Для любого остаточного ребра (и, v) выполняется соотноше
 ние h(u) < h(v) + 1, поскольку h представляет собой функцию высоты. Если 
к переполненной вершине и не применима операция проталкивания, то для всех 
остаточных ребер (и, v) должно выполняться условие h(u) < h(v) +1, откуда сле
 дует, что h(u) < h(v). В таком случае к и можно применить операцию подъема. ■
 Корректность метода проталкивания предпотока
 Чтобы показать, что обобщенный алгоритм проталкивания предпотока поз
 воляет решить задачу максимального потока, сначала докажем, что если он за
 вершается, то предпоток / является максимальным потоком. Затем докажем, что 
алгоритм завершается. Начнем с рассмотрения некоторых свойств функции вы
 соты h.
 Лемма 26.15 (Высота вершины никогда не уменьшается)
 При выполнении процедуры Generic-Push-Relabel над транспортной се
 тью G = (V, Е) для любой вершины и € V ее высота и. h никогда не уменьшает
 ся. Более того, всякий раз, когда к вершине и применяется операция подъема, ее 
высота u.h увеличивается как минимум на 1.
 Доказательство. Поскольку высота вершины меняется только при выполне
 нии операции подъема, достаточно доказать второе утверждение леммы. Ес
 ли вершина и должна подвергнуться подъему, то для всех вершин v, та
 ких, что (и, v) е Ef, выполняется условие u.h < v.h. Таким образом, 
u.h < 1 + min {v. h : (и, v) € Ef}, и операция должна увеличить значение и. h. и
 Лемма 26.16
 Пусть G — (V Е ) представляет собой транспортную сеть с истоком s и стоком 
t. Во время выполнения процедуры Generic-Push-Relabel над сетью G атри
 бут h сохраняет свойства функции высоты.
 Доказательство. Доказательство проводится индукцией по числу выполнен
 ных основных операций. Изначально, как уже отмечалось, h является функцией 
высоты.
 Мы утверждаем, что если h является функцией высоты, то опера
 ция Relabel (п) оставляет h функцией высоты. Если рассмотреть остаточное 
ребро (и, v) 6 E f, которое выходит из и, то операция Relabel (и) гарантирует,
782
 Часть VI. Алгоритмы для работы с графами
 что после нее будет выполняться соотношение и. h < v. h + 1. Теперь рассмотрим 
остаточное ребро (w,u), входящее в и. Согласно лемме 26.15 из w.h < u.h + 1 
перед выполнением операции Relabel(w) вытекает w.h < u.h + 1 после нее. 
Таким образом, операция Relabel(ц) оставляет h функцией высоты.
 Теперь рассмотрим операцию Push(w, г>). Эта операция может добавить реб
 ро (v, и) к Ef, и может удалить ребро (и, у) из Ef. В первом случае име
 ем у.h = u.h — 1 < u.h + 1, так что h остается функцией высоты. Во втором 
случае удаление ребра (и, у) из остаточной сети приводит к удалению соответ
 ствующего ограничения, так что h по-прежнему остается функцией высоты. ■
 Следующая лемма характеризует важное свойство функций высоты.
 Лемма 26.17
 Пусть G = (V, Е) представляет собой транспортную сеть с истоком s и стоком t, 
/ является предпотоком в G, a h — функцией высоты, определенной на множе
 стве V. Тогда в остаточной сети Gf не существует пути из истока s в сток t.
 Доказательство. Предположим, что в Gf имеется некоторый путь р = (г>о, у\,
 ..., Vk) из s в t, где «о = s, a Ufc = t, и покажем, что это приводит к противоречию. 
Без потери общности можно считать, что р — простой путь, так что k < \V\. Для 
г = О,1,..., /г — 1 ребра (у{, Vj+i) € Ef. Поскольку h является функцией высоты, 
для г = 0,1,..., к — 1 справедливы соотношения h(vi) < h(vi+i) + 1. Объеди
 нив эти неравенства вдоль пути р, получаем, что h(s) < h(t) + к. Но поскольку 
h(t) = 0, получаем h(s) < к < \V\, что противоречит требованию h(s) = \V\ 
к функции высоты. 
■
 Теперь мы готовы показать, что после завершения обобщенного алгоритма 
проталкивания предпотока вычисленный алгоритмом предпоток является макси
 мальным потоком.
 Теорема 26.18 (Корректность обобщенного алгоритма проталкивания 
предпотока)
 Если алгоритм Generic-Push-Relabel, выполняемый над транспортной се
 тью G = (V, Е) с истоком s и стоком t, завершается, то вычисленный им предпо
 ток / является максимальным потоком в G.
 Доказательство. Воспользуемся следующим инвариантом цикла.
 Всякий раз, когда в строке 2 процедуры Generic-Push-Relabel выпол
 няется проверка условия цикла while, / является предпотоком.
 Инициализация. Initialize-Preflow делает / предпотоком.
 Сохранение. Внутри цикла while в строках 2 и 3 выполняются только операции 
проталкивания и подъема. Операции подъема влияют только на атрибуты вы
 соты, но не на величины потока, следовательно, от них не зависит, будет ли / 
предпотоком. Анализируя работу процедуры Push, мы доказали (с. 778), что
Глава 26. Задача о максимальном потоке
 783
 если / является предпотоком перед выполнением операции проталкивания, он 
остается предпотоком и после ее выполнения.
 Завершение. По завершении процедуры каждая вершина из множества V — {s, t} 
должна иметь нулевой избыток, поскольку из леммы 26.14 и инварианта, что / 
всегда остается предпотоком, вытекает, что переполненных вершин нет. Сле
 довательно, / является потоком. Лемма 26.16 показывает, что при заверше
 нии h является функцией высоты; таким образом, согласно лемме 26.17 в оста
 точной сети Gf не существует пути из s в t. Согласно теореме о максималь
 ном потоке и минимальном разрезе (теорема 26.6) / является максимальным 
потоком. 
■
 Анализ метода проталкивания предпотока
 Чтобы показать, что обобщенный алгоритм проталкивания предпотока дей
 ствительно завершается, найдем границу количества выполняемых им операций. 
Для каждого вида операций (подъем, насыщающее проталкивание и ненасыщаю
 щее проталкивание) имеется своя граница. Зная эти границы, несложно постро
 ить алгоритм, время работы которого — О (V2E). Однако, прежде чем проводить 
анализ, докажем важную лемму. Вспомним, что мы разрешаем ребрам входить 
в исток в остаточной сети.
 Лемма 26.19
 Пусть G = (V,E) представляет собой транспортную сеть с истоком s и стоком t, 
а / является предпотоком в G. Тогда в остаточной сети Gf для любой перепол
 ненной вершины х существует простой путь из х в s.
 Доказательство. Для переполненной вершины х введем U = {v : существует 
простой путь из х в v в G/}. Теперь предположим, что s £ U, и покажем, что это 
приводит к противоречию. Обозначим U = V — U.
 Возьмем определение избытка из уравнения (26.14), выполним суммирование 
по всем вершинам в U и заметим, что V = U U U. Это даст
 52 е(и)
 иеи
 £/(«,«) + ^2f(u>v)
 v£U
 v£U 
V£U
 v£U
 E E г»* u) + EEf(v>u) E E r u’v)~E E f (u'v)
 u£U v£U
 u£U v£U
 u£U v£U
 E E f<-v>u) - E E v) ■
 u£U v£U
 u£U v£U
 u£U v£U
784
 Часть VI. Алгоритмы для работы с графами
 Мы знаем, что величина J2ueu е(и) Должна быть положительной, поскольку 
е(х) > 0, х G U, что все вершины, отличные от s, имеют неотрицательный 
избыток и что согласно нашему предположению s £U. Таким образом, имеем
 f{u,v)> 0. 
uEU vEU 
uEU vEU
 (26.17)
 Все потоки ребер неотрицательны, так что, чтобы выполнялось уравнение (26.17), 
необходимо иметь J2ueu ^Zveu f(viu) > 0- Следовательно, должна существовать 
как минимум одна пара вершин и1 е U и v' € U, обладающих тем свойством, 
что f{v',u') > 0. Но если f(v',u') > 0, должно существовать остаточное реб
 ро (и v'), а это означает, что имеется простой путь из х в г/ (путь х 
и' 
что противоречит определению U. 
г/), 
ш
 В следующей лемме устанавливаются границы высот вершин, а в вытекающем 
из нее следствии устанавливается предел общего числа выполненных операций 
подъема.
 Лемма 26.20
 Пусть G = (V,E) представляет собой транспортную сеть с истоком s и стоком t. 
В любой момент в процессе выполнения процедуры Generic-Push-Relabel 
над сетью G для всех вершин и € V выполняется соотношение u.h < 2 |V| — 1.
 Доказательство. Высоты истока s и стока t никогда не изменяются, поскольку 
эти вершины по определению не переполняются. Таким образом, всегда s.h = \V\ 
и t.h = 0, причем оба значения не превышают 2\V\ — 1.
 Рассмотрим теперь произвольную вершину и G V — {s,t}. Изначально u.h =
 0 < 2 |V| — 1. Покажем, что после каждого подъема неравенство u.h < 2 |V| — 1 
остается справедливым. При подъеме вершины и она является переполненной, 
и согласно лемме 26.19 имеется простой путь р из и в s в G/. Пусть р — (г?о, 
vi, • • •, Vk), где vo = и, Vk = s и k < |V| — 1, поскольку p — простой путь. 
Для г = 0,1,..., к — 1 имеем (i?i,i?i+i) е Ef, а следовательно, V{.h < Vi+\.h +
 1 согласно лемме 26.16. Расписав неравенства для всех составляющих пути р,
 получаем u.h = vo-h < Vk-h + к < s.h + (|V| — 1) = 2 |V| — 1. 
■
 Следствие 26.21 (Верхний предел числа подъемов)
 Пусть G = (V,E) представляет собой транспортную сеть с истоком s и стоком t. 
Тогда в процессе выполнения процедуры Generic-Push-Relabel над G чис
 ло подъемов не превышает 2\V\ — 1 на вершину, а их общее количество — не 
более (2 | V| — 1)(| У| — 2) <2\V\2.
 Доказательство. В множестве V — {s, t] могут быть подняты только |V| — 2 
вершин. Пусть и G V — {s,t}. Операция Relabel(w) увеличивает высоту u.h. 
Значение u.h изначально равно 0 и согласно лемме 26.20 возрастает не более 
чем до 2\V\ — 1. Таким образом, каждая вершина и € V — {s,t} подвергается
Глава 26. Задача о максимальном потоке
 785
 подъему не более 2\V\ — 1 раз, а общее число выполненных подъемов не превы
 шает (2 | V| - 1)(| V| - 2) < 2 | V|2. 
■
 Лемма 26.20 помогает также определить границу количества насыщающих 
проталкиваний.
 Лемма 26.22 (Граница количества насыщающих проталкиваний)
 В процессе выполнения алгоритма Generic-Push-Relabel над любой транс
 портной сетью G = (V,E) число насыщающих проталкиваний меньше, чем 
2|V||E|.
 Доказательство. Для любой пары вершин u,v е V рассмотрим насыщающие 
проталкивания отикг;иоп;ки(в обе стороны) и назовем их насыщающими 
проталкиваниями между и и v. Если есть хотя бы одно такое проталкивание, то 
хотя бы одно из ребер (u, v) и (v, и) является ребром из Е. Теперь предположим, 
что произошло насыщающее проталкивание из и в v. В этот момент v.h = u.h—1. 
Чтобы позднее могло произойти еще одно проталкивание из и в v, алгоритм сна
 чала должен протолкнуть поток из v ъ и, что невозможно до тех пор, пока не 
будет выполнено условие v.h = u.h + 1. Поскольку u.h никогда не уменьшает
 ся, для того чтобы выполнялось условие v.h = u.h + 1, значение v.h должно 
увеличиться по меньшей мере на 2. Аналогично и. h должно увеличиться между 
последовательными насыщающими проталкиваниями из v ъ и как минимум на 2. 
Высота изначально принимает значение 0 и согласно лемме 26.20 никогда не пре
 вышает 2 | V| — 1, откуда следует, что количество раз, когда высота вершины может 
увеличиться на 2, меньше |У|. Поскольку между двумя насыщающими проталки
 ваниями между и и v хотя бы одна из высот u.h и v.h должна увеличиться на 2, 
всего имеется меньше 2\V\ насыщающих проталкиваний между и и v.
 Умножив это число на число ребер, получим, что общее число насыщающих 
проталкиваний меньше, чем 2 \ V\ \Е\. 
и
 Очередная лемма устанавливает границу числа ненасыщающих проталкива
 ний в обобщенном алгоритме проталкивания предпотока.
 Лемма 26.23 (Граница количества ненасыщающих проталкиваний)
 В процессе выполнения алгоритма Generic-Push-Relabel над любой транс
 портной сетью G = (У, Е) число ненасыщающих проталкиваний меньше 
4\V\2 (|Г| + |£|).
 Доказательство. Определим функцию потенциала следующим образом: Ф = 
J2v-e(v)>o v-h- Изначально Ф = 0, и значение Ф может изменяться после каждого 
подъема, насыщающего и ненасыщающего проталкивания. Найдем предел вели
 чины, на которую насыщающие проталкивания и подъемы могут увеличивать Ф. 
Затем покажем, что каждое ненасыщающее проталкивание должно уменьшать Ф 
как минимум на 1 и используем эти оценки для определения верхней границы 
числа ненасыщающих проталкиваний.
786
 Часть VI. Алгоритмы для работы с графами
 Рассмотрим два пути увеличения Ф. Во-первых, подъем вершины и увеличива
 ет Ф менее чем на 2 |V|, поскольку множество, для которого вычисляется сумма, 
остается прежним, а подъем не может увеличить высоту вершины и больше, чем 
ее максимально возможная высота, которая составляет не более 2 | V| — 1 согласно 
лемме 26.20. Во-вторых, насыщающее проталкивание из вершины и в вершину v 
увеличивает Ф менее чем на 2 \ V\, поскольку никаких изменений высот при этом 
не происходит, и только вершина v, высота которой не более 2\V\ — 1, может 
стать переполненной.
 Теперь покажем, что ненасыщающее проталкивание из и в v уменьшает Ф не 
менее чем на 1. Почему? Перед ненасыщающим проталкиванием вершина и была 
переполненной, a v могла быть переполненной или непереполненной. Согласно 
лемме 26.13 после этого проталкивания и больше не является переполненной. 
Кроме того, если только v не является истоком, она может быть как переполнен
 ной, так и не быть таковой после проталкивания. Следовательно, потенциальная 
функция Ф уменьшилась ровно на и. h, а увеличилась на 0 или на v.h. Посколь
 ку и. h — v. h = 1, в итоге потенциальная функция уменьшается как минимум на 1.
 Итак, в ходе выполнения алгоритма увеличение Ф происходит благодаря 
подъемам и насыщающим проталкиваниям; согласно следствию 26.21 и лем
 ме 26.22 это увеличение ограничено и составляет менее (2 |F|)(2 |F|2) + 
(2 |К|)(2\V\ \Е\) = 4|V'|2(|y| + |£’|). Поскольку Ф > 0, суммарная величина 
уменьшения и, следовательно, общее число ненасыщающих проталкиваний мень
 ше, чем 4\V\2 (|V^| + |£’|). 
■
 Определив границу числа подъемов, насыщающего проталкивания и ненасы
 щающего проталкивания, мы заложили основу дальнейшего анализа процедуры 
Generic-Push-Relabel, а следовательно, любых других алгоритмов, основан
 ных на методе проталкивания предпотока.
 Теорема 26.24
 При выполнении процедуры Generic-Push-Relabel над любой транспортной 
сетью G = (V, Е ) число основных операций составляет 0(V2E).
 Доказательство. Непосредственно вытекает из следствия 26.21 и лемм 26.22 
и 26.23. 
■
 Таким образом, алгоритм завершается после 0(V2E) операций. Итак, оста
 лось предложить эффективные методы реализации каждой операции и выбора 
подходящей выполняемой операции.
 Следствие 26.25
 Существует реализация обобщенного алгоритма проталкивания предпотока, ко
 торая для любой транспортной сети G = (V, Е) выполняется за время 0(V2E).
 Доказательство. В упр. 26.4.2 предлагается показать, как реализовать обоб
 щенный алгоритм, в котором на каждый подъем затрачивается время 0(V), а на 
каждое проталкивание — 0(1). Там же предлагается разработать структуру дан
Глава 26. Задача о максимальном потоке
 787
 ных, которая позволит выбирать применимую операцию за время 0(1). Тем са
 мым следствие будет доказано. 
■
 Упражнения
 26.4.1
 Докажите, что после завершения процедуры Initialize-Preflow(G, s) мы име
 ем s. е < — |/*|, где /* представляет собой максимальный поток в G.
 26.4.2
 Покажите, как реализовать обобщенный алгоритм проталкивания предпотока, 
в котором на каждый подъем затрачивается время 0(V), на каждое проталки
 вание — 0(1), и то же время 0(1) требуется для выбора применимой операции; 
суммарное время выполнения при этом составляет 0(V2E).
 26.4.3
 Докажите, что время, затрачиваемое в целом на выполнение всех 0(V2) подъемов 
в обобщенном алгоритме проталкивания предпотока, составляет только 0(VE).
 26.4.4
 Предположим, что с помощью алгоритма проталкивания предпотока найден мак
 симальный поток для транспортной сети G = (V ,E ). Разработайте быстрый ал
 горитм поиска минимального разреза в G.
 26.4.5
 Разработайте эффективный алгоритм проталкивания предпотока для поиска мак
 симального паросочетания в двудольном графе. Проанализируйте время его ра
 боты.
 26.4.6
 Предположим, что все пропускные способности ребер транспортной сети G = 
(V, Е) принадлежат множеству {1,2 ,
 ..., к}. 
Проанализируйте время выполнения 
обобщенного алгоритма проталкивания предпотока, выразив его через |У|, \Е\ 
и к. (Указание: сколько ненасыщающих проталкиваний можно применить к каж
 дому ребру, прежде чем оно станет насыщенным?)
 26.4.7
 Покажите, что можно заменить строку 6 процедуры Initialize-Preflow стро
 кой
 6 s.h = \G.V\-2
 без влияния на корректность или асимптотическую производительность обобщен
 ного алгоритма проталкивания предпотока.
 26.4.8
 Пусть 6f(u, v) представляет собой расстояние (количество ребер) от и до v в оста
 точной сети Gf. Покажите, что в процессе работы процедуры Generic-Push
788
 Часть VI. Алгоритмы для работы с графами
 Relabel выполняются следующие свойства: из и. h < \V\ вытекает u.h <
 5f(u,t), а из u.h > \V\ следует u.h — \V\ < 6f(u,s).
 26.4.9 ★
 Пусть, как и в предыдущем упражнении, 6f(u,v) представляет собой расстояние 
от и до v в остаточной сети Gf. Покажите, как можно модифицировать обобщен
 ный алгоритм проталкивания предпотока, чтобы в процессе работы процедуры 
поддерживались следующие свойства: из u.h < \V\ вытекает u.h = 6f(u,t), 
а из u.h > \V\ следует u.h — \V\ = 6f(u,s) . Суммарное время, затраченное на 
обеспечение выполнения данного свойства, должно составлять 0(VE).
 26.4.10
 Покажите, что количество ненасыщающих проталкиваний, выполняемых проце
 дурой Generic-Push-Relabel в транспортной сети G = (V,E) для |V| > 4 не 
превышает 4 \V\2 \Е\.
 ★ 
26.5. Алгоритм “поднять-в-начало”
 Метод проталкивания предпотока позволяет применять основные операции 
в произвольном порядке. Однако путем тщательного выбора порядка их выпол
 нения и при эффективном управлении структурой сетевых данных можно решить 
задачу поиска максимального потока быстрее, чем за предельное время 0(V2E), 
определенное следствием 26.25. Далее мы рассмотрим алгоритм “поднять-в-нача- 
ло” (relabel-to-front), основанный на методе проталкивания предпотока, время вы
 полнения которого составляет 0(V3), что асимптотически не хуже, чем 0(V2E), 
а для плотных сетей даже лучше.
 Алгоритм “поднять-в-начало” поддерживает список вершин сети. Алгоритм 
многократно сканирует список с самого начала, выбирает некоторую переполнен
 ную вершину и, а затем “разгружает” ее, т.е. выполняет операции проталкивания 
и подъема до тех пор, пока избыток в и не перестанет быть положительным. Ес
 ли выполнялось поднятие вершины, то она переносится в начало списка (отсюда 
и название алгоритма: “поднять-в-начало”), и алгоритм начинает сканирование 
списка заново.
 Для исследования корректности и временных характеристик данного алгорит
 ма используется понятие “допустимых” ребер: это ребра остаточной сети, через 
которые можно протолкнуть поток. Доказав некоторые свойства сети, состоящей 
из допустимых ребер, мы рассмотрим операцию разгрузки, а затем представим 
и проанализируем сам алгоритм “поднять-в-начало”
 Допустимые ребра и сети
 Если G = (V,E) представляет собой некоторую транспортную сеть с исто
 ком s и стоком t, f — предпоток в G, a h — функция высоты, то мы говорим, что 
ребро (и, и) является допустимым ребром (admissible edge), если Cf(u,v) > О
Глава 26. Задача о максимальном потоке
 789
 и h(u) = h(v) + 1. В противном случае ребро (u, v) называется недопусти
 мым (inadmissible). Допустимой сетью (admissible network) является сеть G
 = 
(К, Efth), где Efth — множество допустимых ребер.
 Допустимая сеть состоит из тех ребер, через которые можно протолкнуть по
 ток. Следующая лемма показывает, что такая сеть является ориентированным 
ациклическим графом.
 Лемма 26.26 (Допустимая сеть является ациклической)
 Если G = (V, Е) является транспортной сетью, / представляет собой предпоток 
в G, a h — функция высоты на G, то допустимая сеть G = (V, Ef^) ациклична.
 Доказательство. Проведем доказательство методом от противного. Предполо
 жим, что Gf^h содержит некоторый цикл р = (г>о, ui, ..., Vk), где vo — Vk 
и k > 0. Поскольку каждое ребро в р является допустимым, справедливо ра
 венство h(v{-1) = h(vi) + 1 для i = 1,2,..., А:. Просуммировав эти равенства 
вдоль циклического пути, получаем
 к 
к
 ^2h{vi-i) = ^2{h(vi) + 1) 
i= 1 
i=l
 к
 = ^2h(vi) + к . 
i— 1
 Поскольку каждая вершина цикла р встречается при суммировании по одному 
разу, приходим к выводу, что 0 = к, что противоречит первоначальному предпо
 ложению. 
■
 В двух следующих леммах показано, как операции проталкивания и подъема 
изменяют допустимую сеть.
 Лемма 26.27
 Пусть G = (V,E) представляет собой транспортную сеть, / — предпоток в G, 
и предположим, что атрибут h является функцией высоты. Если вершина и 
переполнена, а (и, v) является допустимым ребром, то применима процедура 
Push(u, ц). Эта операция не создает новых допустимых ребер, но может при
 вести к тому, что ребро (и, v) станет недопустимым.
 Доказательство. По определению допустимого ребра из и в v можно про
 толкнуть поток. Поскольку вершина и переполнена, применяется операция 
?USH(u,v). В результате проталкивания потока т и ъ v может быть создано 
только одно новое остаточное ребро (v, и). Поскольку v.h = u.h — 1, ребро (г», и) 
не может стать допустимым. Если примененная операция является насыщающим 
проталкиванием, то после ее выполнения Cf(u, v) = 0 и ребро (u,v) становится 
недопустимым. 
■
790
 Лемма 26.28
 Часть VI. Алгоритмы для работы с графами
 Пусть G = {V,E) представляет собой транспортную сеть, / является предпото- 
ком в G, и предположим, что атрибут h является функцией высоты. Если верши
 на и переполнена и не имеется допустимых ребер, выходящих из и, то приме
 няется операция Relabel(u). После подъема появляется по крайней мере одно 
допустимое ребро, выходящее из и, но нет допустимых ребер, входящих в и.
 Доказательство. Если вершина и переполнена, то согласно лемме 26.14 к ней 
применяется или операция проталкивания, или операция подъема. Если не су
 ществует допустимых ребер, выходящих из и, то протолкнуть поток из и невоз
 можно, следовательно, применяется операция Relabel(u). После данного подъ
 ема и. h = 1 + min {г>. h : (и, v) € Ef}. Таким образом, если v — вершина, в кото
 рой реализуется минимум указанного множества, ребро (u,v) становится допу
 стимым. Следовательно, после подъема имеется по крайней мере одно допусти
 мое ребро, выходящее из и.
 Чтобы показать, что после подъема не существует входящих в и допустимых 
ребер, предположим, что существует некоторая вершина v, такая, что ребро (г?, и) 
допустимо. Тогда после подъема v.h = u.h + 1, так что непосредственно перед 
подъемом v.h > u.h + 1. Но согласно лемме 26.12 не существует остаточных 
ребер между вершинами, высоты которых отличаются более чем на 1. Кроме то
 го, подъем вершины не меняет остаточную сеть. Таким образом, ребро (г?, и) не 
принадлежит остаточной сети, а следовательно, оно не может находиться в допу
 стимой сети. 
■
 Списки соседей
 Ребра в алгоритме “поднять-в-начало” объединены в так называемые “списки 
соседей’! В заданной транспортной сети G = (V, Е) списком соседей (neighbor 
list) и. N некоторой вершины и G V является односвязный список вершин, смеж
 ных cubG. Таким образом, вершина v оказывается в списке и. N, если (и, v) £ Е 
или (v,u) G Е. Список соседей u.N содержит только такие вершины v, для ко
 торых может существовать остаточное ребро (u,v). На первую вершину в спис
 ке u.N указывает указатель u.N. head. Указатель v. next-neighbor указывает на 
вершину, следующую в списке соседей за v; этот указатель имеет значение NIL, 
если v является последней вершиной в списке соседей.
 Алгоритм “поднять-в-начало” циклически обрабатывает каждый список сосе
 дей в произвольном порядке, который фиксируется в процессе выполнения алго
 ритма. Для каждой вершины и атрибут и. current указывает на текущую вершину 
списка и.N. Изначально и. current устанавливается равным u.N.head.
 Разгрузка переполненной вершины
 Переполненная вершина и разгружается (discharged) путем проталкивания 
всего ее избыточного потока через допустимые ребра в смежные вершины, при 
этом, если необходимо, выполняется подъем вершины и, чтобы ребра, выходящие
Глава 26. Задача о максимальном потоке
 791
 из вершины и, стали допустимыми. Псевдокод разгрузки выглядит следующим 
образом.
 Discharge(u)
 1 while и. е > О
 2 
3 
4 
5 
6 
7 
8 
v = и. current
 if v == NIL
 Relabel(u)
 и. current — и. N .head
 elseif Cf(u, v) > 0 и и. h == v. h + 1
 Push (u,v)
 else u. current = v. next-neighbor
 На рис. 26.9 показаны несколько итераций цикла while (строки 1-8), тело ко
 торого выполняется до тех пор, пока вершина и имеет положительный избыток. 
Каждая итерация выполняет одно из трех действий в зависимости от текущей 
вершины v из списка соседей и. N.
 1. Если v равно NIL, значит, мы дошли до конца списка и. N. Выполняется подъ
 ем вершины и (строка 4), а затем (строка 5) текущей соседней вершиной и 
делается первая вершина из списка u.N. (В лемме 26.29 утверждается, что 
в данной ситуации подъем применим.)
 2. 
Если v не равно NIL и ребро (u,v) является допустимым (что определяется 
с помощью проверки в строке 6), то (строка 7) выполняется проталкивание 
части (или всего) избытка из и в вершину v.
 3. Если v не равно NIL, но ребро (и, v) является недопустимым, то (строка 8) 
указатель и. current в списке и. N перемещается на одну позицию вперед.
 Заметим, что если процедура Discharge вызывается для некоторой перепол
 ненной вершины и, последним действием, выполняемым данной процедурой, 
должно быть проталкивание из и. Почему? Процедура завершается только то
 гда, когда избыток и. е становится равным нулю, и ни подъем, ни перемещение 
указателя и. current не влияют на значение и. е.
 Теперь необходимо убедиться, что когда процедура Discharge вызывает про
 цедуры Push или Relabel, эти операции применимы. В следующей лемме до
 казывается данный факт.
 Лемма 26.29
 Если процедура Discharge вызывает в строке 7 процедуру Push(u,v), то 
к (u,v) применима операция проталкивания. Если процедура Discharge вы
 зывает в строке 4 процедуру Relabel(u), к вершине и применим подъем.
 Доказательство. Проверки в строках 1 и 6 гарантируют, что операция протал
 кивания вызывается только тогда, когда она применима; таким образом, первое 
утверждение леммы доказано.
792
 Часть VI. Алгоритмы для работы с графами
 Рис. 26.9. Разгрузка вершины у. Она требует 15 итераций цикла while процедуры Discharge для 
того, чтобы протолкнуть весь избыточный поток из у. Показаны только соседи у и ребра транспорт
 ной сети, которые входят в вершину у или покидают ее. В каждой части рисунка число внутри вер
 шины представляет собой ее избыток в начале первой итерации, показанной в данной части; кроме 
того, в пределах части каждая вершина показана на своей высоте. Список соседей y.N в начале 
каждой итерации приведен в правой части; в первой строке указан номер итерации. Заштрихован
 ным соседом является у. current, (а) Изначально имеется 19 единиц избытка, которые должны быть 
протолкнуты из у, и у. current = s. Итерации 1-3 просто обновляют значение у. current, поскольку 
не имеется допустимых ребер, покидающих у. В итерации 4 у. current = NIL (указано штриховкой 
под списком соседей), так что у поднимается и у. current сбрасывается, получая в качестве значе
 ния заголовок списка соседей, (б) После подъема высота вершины у равна 1. В итерациях 5 и 6 
выясняется, что ребра (у, s) и (у, х) недопустимые, но в итерации 7 выполняется проталкивание 8 
единиц избыточного потока из у в z. Из-за проталкивания в этой итерации значение у. current 
не изменяется, (в) Поскольку проталкивание в итерации 7 насыщает ребро (у, z), в итерации 8 
обнаруживается его недопустимость. В итерации 9 у. current = NIL, так что вершина у снова 
поднимается, а у. current сбрасывается.
Глава 26. Задача о максимальном потоке
 (д)
 (е)
 (ж)
 793
 12
 s
 X
 Z
 15
 s
 X
 Z
 13
 S
 X
 Z
 14
 s
 X
 Z
 Рис. 26.9 (продолжение), (г) В итерации 10 ребро (у, s) недопустимо, но итерация 11 протал
 кивает 5 единиц избыточного потока из у в х. (д) Поскольку значение у. current не изменялось 
в итерации 11, в итерации 12 обнаруживается, что ребро (у, х) недопустимое. Итерация 13 находит 
недопустимость ребра (у, z), а итерация 14 поднимает вершину у и сбрасывает значение у. current. 
(е) Итерация 15 проталкивает 6 единиц избыточного потока из у в s. (ж) Вершина у теперь не имеет 
избыточного потока, и процедура Discharge завершается. В этом примере процедура Discharge 
и начинается, и завершается с текущим указателем на заголовок списка соседей, но в общем случае 
это не обязательно так.
794
 Часть VI. Алгоритмы для работы с графами
 Чтобы доказать второе утверждение, исходя из проверки в строке 1 и лем
 мы 26.28, необходимо только показать, что все ребра, выходящие из и, являются 
недопустимыми. Если вызов Discharge(w) начинается с указателем и. current 
на голову списка соседей, а по завершении он указывает за конец списка, то 
все выходящие из и ребра недопустимы, и применяется операция подъема. Воз
 можно, однако, что во время вызова Discharge (и) указатель и. current про
 ходит только по части списка перед возвратом из процедуры. После этого мо
 гут произойти вызовы процедуры Discharge с другими вершинами, но ука
 затель и. current будет перемещаться по списку в процессе следующего вызова 
Discharge (и). Рассмотрим теперь, что произойдет при полном проходе по спис
 ку, который начинается с заголовка u.N и заканчивается значением и. current = 
NIL. Когда и. current достигает конца списка, процедура поднимает и и начина
 ет новый проход. Чтобы в процессе прохода указатель и. current переместился 
за вершину v е u.N, ребро {u,v) должно быть признано недопустимым про
 веркой в строке 6. Таким образом, к моменту завершения прохода каждое ребро, 
покидающее и, определено как недопустимое в некоторый момент этого прохо
 да. Ключевым является тот факт, что к концу прохода все ребра, покидающие и, 
остаются недопустимыми. Почему? Согласно лемме 26.27 операции проталкива
 ния не могут приводить к созданию допустимых ребер, независимо от того, из 
какой вершины выполняется проталкивание. Таким образом, любое допустимое 
ребро должно быть создано операцией подъема. Но вершина и не подвергается 
подъему в процессе прохода, а любая другая вершина v, подвергшаяся подъему 
в процессе данного прохода (в результате вызова Discharge (v)), не имеет после 
подъема допустимых входящих ребер согласно лемме 26.28. Итак, в конце прохо
 да все ребра, выходящие из и, остаются недопустимыми, и лемма доказана. 
■
 Алгоритм “поднять-в-начало”
 В алгоритме “поднять-в-начало” поддерживается связанный список L, состоя
 щий из всех вершин множества V — {s,t}. Ключевым свойством данного списка 
является то, что вершины в нем топологически отсортированы в соответствии 
с допустимой сетью, как будет показано при рассмотрении инварианта цикла 
ниже. (Напомним, что согласно лемме 26.26 допустимая сеть является ориенти
 рованным ациклическим графом.)
 В приведенном ниже псевдокоде алгоритма “поднять-в-начало” предполага
 ется, что для каждой вершины и уже создан список соседей u.N. Кроме того, 
предполагается, что и. next указывает на вершину, следующую за и в списке L, 
и что, как обычно, если и — последняя вершина данного списка, то и. next = NIL.
Глава 26. Задача о максимальном потоке
 Relabel-To-Front(G, S, t)
 1 Initialize-Preflow(G, s)
 2 L = G. V — {s,t}, в произвольном порядке
 3 for каждой вершины и е G. V — {s,t}
 4 
и. current = u.N.head
 5 
и = L.head
 6 while и Ф NIL
 7 
old-height — и.h
 8 
9 
10 
11 
Discharge(u)
 ifu.h > old-height
 переместить и в начало списка L
 и = и. next
 795
 Алгоритм “поднять-в-начало” работает следующим образом. Строка 1 иници
 ализирует предпоток и высоты теми же значениями, что и обобщенный алгоритм 
проталкивания предпотока. Строка 2 инициализирует список L, который содер
 жит все потенциально переполненные вершины в произвольном порядке. Стро
 ки 3 и 4 инициализируют указатель current каждой вершины и таким образом, 
чтобы он указывал на первую вершину в списке соседей и.
 Как показано на рис. 26.10, цикл while (строки 6-11) проходит по списку L, 
разгружая вершины. Рассмотрение начинается с первой вершины списка L (стро
 ка 5). На каждой итерации цикла выполняется разгрузка вершины и (строка 8). 
Если процедура Discharge изменила высоту вершины и, строка 10 перемещает 
эту вершину в начало списка L. Чтобы определить, подверглась ли вершина и 
подъему, перед разгрузкой ее высота сохраняется в переменной old-height (стро
 ка 7), а затем это значение сравнивается со значением высоты после выполнения 
процедуры разгрузки (строка 9). Строка 11 обеспечивает выполнение очередной 
итерации цикла while для вершины, следующей за и в списке L. Если и была 
передвинута в начало списка в строке 10, рассматриваемая на следующей итера
 ции вершина представляет собой вершину, следующую за и в ее новой позиции 
в списке.
 Чтобы показать, что процедура Relabel-To-Front вычисляет максимальный 
поток, покажем, что она является реализацией обобщенного алгоритма протал
 кивания предпотока. Во-первых, заметим, что она выполняет операции протал
 кивания и подъема только тогда, когда они применимы, что гарантируется лем
 мой 26.29. Остается показать, что, когда процедура Relabel-To-Front завер
 шается, не применима ни одна основная операция. Дальнейшее доказательство 
корректности построено на следующем инварианте цикла:
 При каждом выполнении проверки в строке 6 процедуры Relabel-To- 
Front список L является топологическим упорядочением вершин допу
 стимой сети Gfth = (V, Efth), и ни одна вершина, стоящая в списке перед и, 
не имеет избыточного потока.
 Инициализация. Непосредственно после запуска процедуры Initialize- 
Preflow s.h = \V\ и v.h = 0 для всех v G V — {s}. Поскольку \V\ > 2
796
 Часть VI. Алгоритмы для работы с графами
 L: 
(а)
 х 
у 
z
 N: s s х
 у х у
 z 
z 
/
 t
 L: х у z
 N: s s х
 (б)
 у х у
 z 
t
 z 
t
 Рис. 26.10. Работа процедуры Relabel-To-Front. (а) Транспортная сеть непосредственно пе
 ред первой итерацией цикла while. Изначально источник s покидают 26 единиц потока. В правой 
части показан исходный список L = (х, у, z), где изначально и = х. Под каждой вершиной в спис
 ке L приведен ее список соседей, в котором выделен текущий сосед. Он поднимается до высоты 1, 
5 единиц избыточного потока проталкиваются в у, a 7 оставшихся единиц избытка проталкиваются 
в сток t. Поскольку х поднята, она перемещается в начало списка L, что в данном случае не приво
 дит к изменению структуры L. (б) После х следующей в L вершиной, подвергающейся разгрузке, 
является вершина у. На рис. 26.9 детально показан процесс разгрузки у в этой ситуации. Поскольку 
вершина у поднята, она перемещается в начало списка L. (в) Теперь вершина х следует в спис
 ке L за у, так что она вновь разгружается с проталкиванием всех 5 единиц избытка в t. Поскольку 
вершина х в этой операции разгрузки не поднимается, она остается на своем месте в списке L.
Глава 26. Задача о максимальном потоке
 797
 Рис. 26.10 (продолжение), (г) Поскольку в списке L за вершиной х следует вершина z, она 
подвергается разгрузке. Эта вершина поднимается до высоты 1, а все 8 единиц избытка потока 
проталкиваются в t. Поскольку z поднята, она перемещается в начало списка L. (д) Теперь за 
вершиной z в списке L следует вершина у, так что должна быть выполнена ее разгрузка. Но по
 скольку в вершине у избыток отсутствует, процедура DISCHARGE тут же выполняет возврат, и у 
остается в L на своем месте. Затем выполняется разгрузка вершины х. Поскольку она также не 
имеет избытка, процедура DISCHARGE вновь выполняет немедленный возврат, и х также остается 
на собственном месте в L. Процедура Relabel-To-Front достигает конца списка L и заверша
 ется. Переполненных вершин нет, и предпоток представляет собой максимальный поток.
 (так как V содержит как минимум исток s и сток t), ни одно ребро не яв
 ляется допустимым. Следовательно, Ef^ = 0, и любое упорядочение множе
 ства V — (s, t} является топологическим упорядочением G
 Поскольку изначально вершина и является заголовком списка L, перед ней нет 
вершин, следовательно, перед ней нет вершин с избытком потока.
 Сохранение. Чтобы убедиться в том, что данное топологическое упорядочение 
сохраняется при проведении итераций цикла while, прежде всего заметим, 
что к изменению допустимой сети приводят только операции проталкива
 ния и подъема. Согласно лемме 26.27 операции проталкивания не приводят 
к тому, что ребра становятся допустимыми. Поэтому допустимые ребра могут 
создаваться только подъемами. Однако после того как вершина и подверг
 лась подъему, согласно лемме 26.28 больше не существует допустимых ребер, 
входящих в и, но могут быть допустимые ребра, выходящие из нее. Таким 
образом, перемещая и в начало списка L, алгоритм гарантирует, что все до
 пустимые ребра, выходящие из и, удовлетворяют условию топологического 
упорядочения.
798
 Часть VI. Алгоритмы для работы с графами
 Чтобы убедиться в том, что ни одна вершина, предшествующая и в списке L, 
не имеет избытка потока, обозначим вершину, которая будет текущей верши
 ной и на следующей итерации, как и'. Среди вершин, которые будут предше
 ствовать и' на следующей итерации, находится текущая вершина и (согласно 
строке 11), и либо больше таких вершин нет (если и подвергалась подъему), 
либо там находятся те же вершины, что и ранее (если и не поднималась). 
Поскольку и подверглась разгрузке, она не содержит избытка потока. Следо
 вательно, если и подвергалась подъему в процессе разгрузки, то ни одна вер
 шина, предшествующая и', не содержит избытка потока. Если же и в процессе 
разгрузки не поднималась, ни одна вершина, стоящая в списке L перед ней, 
не получила избыток потока при этой разгрузке, поскольку список L остается 
топологически упорядоченным все время в процессе разгрузки (как уже от
 мечалось, допустимые ребра создаются только подъемами, а не операциями 
проталкивания), поэтому каждая операция проталкивания заставляет избыток 
потока двигаться только к вершинам, расположенным в списке дальше (или же 
к s или t). И вновь ни одна вершина, предшествующая и', не имеет избытка 
потока.
 Завершение. Когда цикл завершается, и оказывается за последним элементом 
списка L, поэтому инвариант цикла гарантирует, что избыток всех вершин 
равен 0. Следовательно, ни одна основная операция неприменима.
 Анализ
 Покажем теперь, что процедура Relabel-To-Front выполняется за вре
 мя 0(V3) для любой транспортной сети G = {V,E). Поскольку данный алго
 ритм является реализацией обобщенного алгоритма проталкивания предпотока, 
воспользуемся следствием 26.21, которое устанавливает границу 0(V) для числа 
подъемов, применяемых к одной вершине, и 0(V2) для общего числа подъемов. 
Кроме того, в упр. 26.4.3 устанавливается граница 0(VE) для суммарного вре
 мени, затраченного на выполнение подъемов, а лемма 26.22 устанавливает грани
 цу 0(VE) для суммарного числа операций насыщающих проталкиваний.
 Теорема 26.30
 Время выполнения процедуры Relabel-To-Front для любой транспортной се
 ти G — (V, Е) составляет 0(У 3).
 Доказательство. Будем считать “фазой” алгоритма “поднять-в-начало” время 
между двумя последовательными операциями подъема. Поскольку всего выпол
 няется 0(V2) подъемов, в алгоритме насчитывается 0(V2) фаз. Каждая фаза 
сдержит не более | V\ вызовов процедуры Discharge, что можно показать следу
 ющим образом. Если процедура Discharge не выполняет подъем, то следующий 
ее вызов происходит ниже по списку L, а длина L меньше | V|. Если же процедура 
Discharge выполняет подъем, то следующий ее вызов происходит уже в другой 
фазе алгоритма. Поскольку каждая фаза содержит не более \ V\ обращений к про
 цедуре Discharge, а всего в алгоритме насчитывается 0(V2) фаз, число вызовов 
данной процедуры в строке 8 процедуры Relabel-To-Front составляет 0(V3).
Глава 26. Задача о максимальном потоке
 799
 Таким образом, цикл while процедуры Relabel-To-Front выполняет работу 
(не учитывая работу, выполняемую внутри процедуры Discharge), не превыша
 ющую 0(V3).
 Теперь необходимо проанализировать работу процедуры Discharge в ходе 
выполнения данного алгоритма. Каждая итерация while в процедуре D ischarge 
заключается в выполнении одного из трех действий. Проанализируем объем ра
 боты при выполнении каждого из них.
 Начнем с подъемов (строки 4 и 5). В упр. 26.4.3 время выполнения всех 0(V2) 
подъемов ограничивается пределом 0(VE).
 Теперь предположим, что действие заключается в обновлении указате
 ля и. current в строке 8. Это действие выполняется 0(degree(n)) раз всякий 
раз, когда вершина и подвергается подъему, что в целом для вершины состав
 ляет 0(V ■ degree(u)) раз. Следовательно, для всех вершин общий объем работы 
по перемещению указателей в списках соседей составляет 0(VE) согласно лем
 ме о рукопожатиях (упр. Б.4.1).
 Третий тип действий, выполняемых процедурой Discharge, — операция про
 талкивания (строка 7). Мы уже знаем, что суммарное число насыщающих опера
 ций проталкивания составляет 0(VE). Заметим, что если выполняется ненасы
 щающее проталкивание, процедура D ischarge немедленно выполняет возврат, 
поскольку такое проталкивание уменьшает избыток до 0. Поэтому при каждом об
 ращении к процедуре Discharge может выполняться не более одного ненасыща
 ющего проталкивания. Как мы знаем, процедура Discharge вызывается 0(V3) 
раз, следовательно, общее время, затраченное на ненасыщающие проталкивания, 
составляет 0(V3).
 Таким образом, время выполнения процедуры Relabel-To-Front составля
 ет О(V3 + VE), что эквивалентно О{V3). 
■
 Упражнения
 26.5.1
 Проиллюстрируйте, используя в качестве образца рис. 26.10, выполнение 
процедуры Relabel-To-Front для транспортной сети, представленной на 
рис. 26.1, (а). Предполагается, что начальный порядок следования вершин в спис
 ке L — (v\,V2, v3, v4), а списки соседей имеют следующий вид:
 VI. N = (s,V2,V3) , 
V2.N = (s, V\, v3, v4) , 
v3.N = (vi,v2,v4,t) , 
V4.N = (v2,V3,t) .
 26.5.2 ★
 Необходимо реализовать алгоритм проталкивания предпотока, в котором поддер
 живается порядок обслуживания переполненных вершин “первым вошел, первым 
вышел” Данный алгоритм разгружает первую вершину в очереди и удаляет ее от
 туда, а все вершины, которые перед этой разгрузкой не были переполнены, но по
800
 Часть VI. Алгоритмы для работы с графами
 еле нее стали таковыми, помещаются в конец очереди. Когда очередь становится 
пустой, алгоритм завершается. Покажите, что можно построить реализацию дан
 ного алгоритма, которая вычисляет максимальный поток за время 0 (V 3).
 26.5.3
 Покажите, что обобщенный алгоритм будет работать, даже если процедура 
Relabel обновляет u.h, просто вычисляя u.h = u.h + 1. Как это повлияет 
на оценку времени выполнения процедуры Relabel-To-Front?
 26.5.4 ★
 Покажите, что если разгрузке всегда подвергается наивысшая переполненная вер
 шина, метод проталкивания предпотока можно реализовать так, чтобы он выпол
 нялся за время 0{V3).
 26.5.5
 Предположим, что в некоторой точке в процессе выполнения алгоритма протал
 кивания предпотока существует некоторое целое число 0 < к < \V\ — 1, для 
которого нет ни одной вершины с данной высотой, т.е. такой, у которой v.h = к. 
Покажите, что все вершины с v.h > к находятся в минимальном разрезе на сто
 роне истока. Если такое значение к существует, эвристика промежутка (gap 
heuristic) обновляет каждую вершину v G V — {s}, для которой v.h > к, уста
 навливая v.h = max(v.h, \V\ + 1). Покажите, что полученный таким образом 
атрибут h является функцией высоты. (Эвристика промежутка позволяет полу
 чить эффективные реализации метода проталкивания предпотока на практике.)
 Задачи
 26.1. Задача о выходе
 Решетка (grid) размером п х п представляет собой неориентированный граф, 
состоящий из п строк и п столбцов вершин, как показано на рис. 26.11. Обозна
 чим вершину, находящуюся в г-й строке и j-м столбце, как (г, j). Каждая верши
 на решетки имеет ровно по четыре соседа, за исключением граничных вершин, 
представляющих собой точки (г, j), для которых г = 1, г = п, j = 1 или j = п.
 Пусть в решетке задано т < п2 стартовых точек (xi,yi), (хч,уч),
 (im, Ут)- Задача о выходе (escape problem) заключается в том, чтобы определить, 
существует ли т путей, не имеющих общих вершин, из стартовых точек к лю
 бым т различным точкам границы. Например, решетка на рис. 26.11, (а) имеет 
выход, а решетка на рис. 26.11, (б) — не имеет.
 а. Рассмотрим транспортную сеть, в которой вершины, равно как и ребра, име
 ют пропускные способности, т.е. суммарный положительный поток, входящий 
в каждую заданную вершину, должен удовлетворять ограничению пропускной 
способности. Покажите, что задача определения максимального потока в та
 кой сети, где вершины и ребра имеют пропускные способности, может быть
Глава 26. Задача о максимальном потоке
 801
 (б)
 Рис. 26.11. Решетки для задачи о выходе. Стартовые точки — черные, прочие вершины решетки — 
белые, (а) Решетка с выходом, представленным заштрихованными путями, (б) Решетка без выхода.
 сведена к стандартной задаче о максимальном потоке для транспортной сети 
сопоставимого размера.
 б. 
Разработайте эффективный алгоритм решения задачи о выходе и проанализи
 руйте время его выполнения.
 26.2. Задача о минимальном покрытии путями
 Покрытие путями (path cover) ориентированного графа G = (V, Е) — это 
множество Р не имеющих общих вершин путей, таких, что каждая вершина 
из множества V принадлежит ровно одному пути из Р. Пути могут начинать
 ся и заканчиваться где угодно, а также иметь произвольную длину, включая 0. 
Минимальным покрытием путями (minimum path cover) графа G называется 
покрытие, содержащее наименьшее возможное количество путей.
 а. Предложите эффективный алгоритм поиска минимального покрытия путями 
ориентированного ациклического графа G = (V, Е ). (Указание: предположив, 
что V = {1,2,..., п}, постройте граф G' = (V7, Е'), где
 V = {т0, Х\ , . ..,Х„}и {уо,У1,- • • , Уп} ,
 Е' = {(z0, Яг) : г G V} U {(уиуо) : г <Е V} U {{x^yj) : (i,j) G Е } , 
и примените алгоритм поиска максимального потока.)
 б. Будет ли ваш алгоритм работать для ориентированного графа, содержащего 
циклы? Объясните свой ответ.
 26.3. Алгоритмическое консультирование
 Профессор решил открыть компанию, проводящую консультации по разным 
алгоритмам. Он разделил алгоритмы на п важных областей (грубо соответ
 ствующих различным частям этой книги), представленных множеством А = 
, А 2,..., Ап}. Для каждой подобласти Аь он может нанять эксперта по данной 
тематике за с*; долларов. У компании имеется множество J = {J\, J2,..., Jm} по
 тенциальных задач. Для выполнения задачи J{ компания должна нанять экспертов
 26 Зак. 3726
802
 Часть VI. Алгоритмы для работы с графами
 для подмножества Ri С А подобластей. Каждый эксперт может одновременно 
работать над несколькими задачами. Если компания решает взяться за задачу J*, 
она должна нанять экспертов во всех подобластях в Яг, и получит за выполнение 
задачи оплату в pi долларов.
 Профессору необходимо определить, для каких подобластей следует нанять 
экспертов и за какие задачи взяться, чтобы максимизировать чистую прибыль, 
равную плате за выполненные задачи минус оплата труда нанятых экспертов.
 Рассмотрим следующую транспортную сеть G. Она содержит исток s, верши
 ны А\, А2,..., Лп, вершины 
и сток t- Транспортная сеть содержит
 ребра (s, Ак) (к = 1,2 ... ,п) с пропускной способностью c(s, Ак) = Ск, и для 
г = 1,2,..., т транспортная сеть содержит ребра (J*, t) с пропускной способно
 стью c(Ji,t) = 
Если Ак G Яг (к = 1,2,..., п и г = 1,2,..., ш), то G содержит 
ребро (Ак, Ji) с пропускной способностью с(Ак, Jt) = 00.
 а. Покажите, что если Ji е Т для разреза (5, Т) с конечной пропускной способ
 ностью транспортной сети G, то Ак G Т для каждого Ак £ Ri
б. Покажите, как определить максимальную чистую прибыль из пропускной спо
 собности минимального разреза транспортной сети G и заданных значений pi.
 в. Разработайте эффективный алгоритм определения того, за какие задачи следу
 ет взяться и каких экспертов нанять. Найдите время работы своего алгоритма 
как функцию от т, п и г =
 26.4. Обновление максимального потока
 Пусть G = (У, Е) представляет собой транспортную сеть с истоком s и сто
 ком t и целочисленными пропускными способностями. Предположим, что изве
 стен максимальный поток в G.
 а. Предположим, что пропускная способность некоторого одного ребра (u, v) G 
Е увеличена на 1. Предложите алгоритм обновления максимального потока 
с временем выполнения 0 (V + Е).
 б. Предположим, что пропускная способность некоторого одного ребра (u, v) е 
Е уменьшена на 1. Предложите алгоритм обновления максимального потока 
с временем выполнения 0 (V + Е).
 26.5. Масштабирование
 Пусть G = (V, Е) представляет собой транспортную сеть с истоком s и сто
 ком t и целочисленными пропускными способностями c(u,v) каждого реб
 ра (ц, г;) G Е. Пусть С = max(U)i;)eE c(w>v)
а. Докажите, что минимальный разрез G имеет пропускную способность не бо
 лее С\Е\.
Глава 26. Задача о максимальном потоке
 803
 б. Для заданного числа К покажите, как за время О(Е) можно найти увели
 чивающий путь с пропускной способностью не менее К, если таковой путь 
существует.
 Для вычисления максимального потока в G можно использовать следующую мо
 дификацию процедуры Ford-Fulkerson-Method.
 Max-Flow-By-Scaling (G, s, t)
 1 C = max(UiV)G£; c(u, v)
 2 Инициализировать поток / значением О
 3 К = 2^CJ
 4 while К > 1
 5 
6
 7 
while существует увеличивающий путь р
 с пропускной способностью не менее К
 Увеличить поток / вдоль р
 К = К/ 2
 8 return /
 в. Докажите, что Max-Flow-By-Scaling возвращает максимальный поток.
 г. Покажите, что пропускная способность минимального разреза остаточной се
 ти Gf не превышает 2К \ Е\ при каждом выполнении строки 4.
 д. Докажите, что внутренний цикл while в строках 5 и 6 выполняется О(Е) раз 
для каждого значения К.
 е. Сделайте вывод о том, что процедуру Max-Flow-By-Scaling можно реали
 зовать таким образом, что она будет выполняться за время 0(Е2 lgC).
 26.6. Алгоритм Хопкрофта-Карпа поиска паросочетания в двудольном графе
 В данной задаче представлен более быстрый алгоритм поиска максимального 
паросочетания в двудольном графе, предложенный Хопкрофтом (Hopcroft) и Кар
 пом (Karp). Этот алгоритм выполняется за время 0(\/VE). Задан неориентиро
 ванный двудольный граф G = (V, Е), где V = L U R и у всех ребер ровно одна 
конечная точка находится в L. Пусть М — паросочетание в G. Мы говорим, что 
простой путь P bG является увеличивающим путем (augmenting path) по отно
 шению к М, если он начинается в некоторой свободной вершине множества L, 
заканчивается в некоторой свободной вершине R, а его ребра попеременно при
 надлежат М и Е — М. (Это определение увеличивающего пути связано с опре
 делением увеличивающего пути в транспортной сети, но несколько отличается 
от него.) В данной задаче путь трактуется как последовательность ребер, а не 
последовательность вершин. Кратчайший увеличивающий путь по отношению 
к паросочетанию М — это увеличивающий путь с минимальным числом ребер.
 Для заданных двух множеств А и В симметрическая разность (symmetric 
difference) А 0 В определяется как (А — В) U (В — А), т.е. это элементы, которые
804
 Часть VI. Алгоритмы для работы с графами
 а. Покажите, что если М представляет собой некоторое паросочетание, а Р — 
увеличивающий путь по отношению к М, то симметрическая разность мно
 жеств М 0 Р является паросочетанием, п \М (В Р\ = \М\ + 1. Покажите, что 
если Р\, Р2,..., Рк — увеличивающие пути по отношению к М, не имеющие 
общих вершин, то симметрическая разность М ф (Pi U Р2 U • • • U Рк) является 
паросочетанием с мощностью \М\ + к.
 Общая структура алгоритма имеет следующий вид.
 Hopcroft-Karp (G)
 1 М = 0
 2
 repeat
 3 
4 
6
 Пусть V = {Pi, Р2,..., Рк} — максимальное множество
 кратчайших увеличивающих путей по отношению 
к М, не имеющих общих вершин
 М = M0 (PiUP2U---UPfc)
 5 until V == 0
 return М
 Далее в этой задаче вам предлагается проанализировать число итераций данно
 го алгоритма (т.е. число итераций цикла repeat) и предложить реализацию стро
 ки 3.
 б. Для двух заданных паросочетаний М и М* в G покажите, что каждая вер
 шина графа G' = (V, М 0 М*) имеет степень не больше 2. Сделайте вывод, 
что G' является несвязным объединением простых путей или циклов. Дока
 жите, что ребра каждого такого простого пути или цикла по очереди принад
 лежат М и М*. Докажите, что если \М\ < |М*|, то М 0 М* содержит как 
минимум \М*\ — \М\ увеличивающих путей по отношению к М, не имеющих 
общих вершин.
 Пусть I обозначает длину кратчайшего увеличивающего пути по отношению к па- 
росочетанию М и пусть Pi, Р2,..., Рк представляет собой максимальное множе
 ство не имеющих общих вершин увеличивающих путей длиной I по отношению 
к М. Пусть М' = М ф (Pi U • ■ • U Рк), и предположим, что Р — кратчайший 
увеличивающий путь по отношению к М'.
 в. Покажите, что если Р не имеет общих вершин с Pi, Р2,..., Рк, то Р содержит 
более I ребер.
 г. Теперь предположим, что Р может иметь общие вершины с Pi, Р2,..., Рк- 
Пусть А — множество ребер (МфМ')фР. Покажите, что А — (Р\ U Р2 U • • • U 
Рк) © Р и что \А\ > (к + 1)1. Сделайте вывод о том, что Р содержит более I 
ребер.
 д. Докажите, что если кратчайший увеличивающий путь для М содержит I ребер, 
то размер максимального паросочетания составляет не более \М\ + \V\/(/ + 1).
Глава 26. Задача о максимальном потоке
 805
 е. Покажите, что число повторений цикла repeat в данном алгоритме не пре
 вышает 2у/Щ. (Указание: насколько сможет вырасти М после итерации но- 
мер v/JTf?)
 ж. Предложите алгоритм для поиска максимального множества не имеющих об
 щих вершин кратчайших увеличивающих путей Pi, Р2,..., Pk для заданного 
паросочетания М, время работы которого составляет О(Е). Заключите отсю
 да, что суммарное время выполнения процедуры Hopcroft-Karp составля
 ет O(VVE).
 Заключительные замечания
 Транспортные сети и связанные с ними алгоритмы рассматриваются в работах 
Ахуя (Ahuja), Магнанти (Magnanti) и Орлина (Orlin) [7], Ивена (Even) [102], Ло- 
улера (Lawler) [223], Пападимитриу (Papadimitriou) и Стейглица (Steiglitz) [269], 
Таржана (Taijan) [328]. Широкий обзор алгоритмов для задач поиска потоков 
в транспортных сетях можно найти также в книге Голдберга (Goldberg), Тар- 
доса (Tardos) и Таржана [138]. В работе Шрайвера (Schrijver) [302] предлагается 
интересный исторический обзор исследований в сфере транспортных сетей.
 Метод Форда-Фалкерсона представлен в работе Форда (Ford) и Фалкерсона 
(Fulkerson) [108], которые являются основоположниками формальных исследо
 ваний ряда задач в области транспортных сетей, включая задачи поиска макси
 мального потока и паросочетаний. Во многих ранних реализациях метода Форда- 
Фалкерсона поиск увеличивающих путей осуществляется с помощью поиска 
в ширину; Эдмондс (Edmonds) и Карп (Karp) [101] (и независимо от них Ди- 
ниц (Dinic) [88]) доказали, что такая стратегия дает полиномиальный по времени 
алгоритм. Диницу [88] также принадлежит идея использования “тупиковых пото
 ков” (blocking flows); предпотоки впервые предложил Карзанов (Karzanov) [201]. 
Метод проталкивания предпотока описан в работах Голдберга [135] и Голдбер
 га и Таржана [139]. Голдберг и Таржан приводят алгоритм со временем работы 
0 (V3), в котором для хранения множества переполненных вершин используется 
очередь, а также алгоритм на основе использования динамических деревьев, вре
 мя работы которого достигает 0(VE\g(V2/E + 2)). Некоторые другие исследо
 ватели разработали алгоритмы проталкивания предпотока для поиска максималь
 ного потока. В работах Ахуя и Орлина [9] и Ахуя, Орлина и Таржана [10] при
 водятся алгоритмы, использующие масштабирование. Чериян (Cheriyan) и Махе- 
швари (Maheshvari) [61] предложили проталкивать поток из переполненной вер
 шины с максимальной высотой. В работе Черияна и Хейджерапа (Hagerup) [60] 
предлагается использовать случайные перестановки списков соседей; другие ис
 следователи [14,203,274] развили данную идею, предложив искусные методы 
дерандомизации, что позволило получить ряд более быстрых алгоритмов. Алго
 ритм, предложенный Кингом (King), Pao (Rao) и Таржаном [203], является самым 
быстрым из них — время его работы составляет 0 (VElog^yigк) V).
806
 Часть VI. Алгоритмы для работы с графами
 Асимптотически самый быстрый из известных в настоящее время алгоритмов 
для задачи максимального потока разработан Голдбергом и Рао [137], время его 
работы равно 0(min(l/2/3, El/2)E\g(V2/Е + 2) lgC), где С = max(U)U)G£;c(w, v). 
Этот алгоритм не использует метод проталкивания предпотока, он основан на 
нахождении тупиковых потоков. Все предыдущие алгоритмы, включая рассмот
 ренные в данной главе, используют некоторое понятие расстояния (в алгоритмах 
проталкивания предпотока используется аналогичное понятие высоты), где каж
 дому ребру неявно присвоена длина 1. В этом же алгоритме используется дру
 гой подход: ребрам с высокой пропускной способностью присваивается длина О, 
а ребрам с низкой пропускной способностью — длина 1. Неформально при таком 
выборе длин кратчайшие пути от истока к стоку будут иметь высокую пропуск
 ную способность, следовательно, потребуется меньше итераций.
 На практике на сегодняшний день при решении задач поиска максимального 
потока алгоритмы проталкивания предпотока превосходят алгоритмы, основан
 ные на увеличивающих путях и линейном программировании. В исследованиях 
Черкасски (Cherkassky) и Голдберга [62] подчеркивается важность использования 
при реализации алгоритма проталкивания предпотока двух эвристик. Первая со
 стоит в том, что в остаточной сети периодически выполняется поиск в ширину, 
чтобы получить более точные значения высот. Вторая эвристика — это “эвристика 
промежутка” (gap heuristic), описанная в упр. 26.5.5. Авторы пришли к заключе
 нию, что наилучшим вариантом метода проталкивания предпотока является вари
 ант, в котором для разгрузки выбирается переполненная вершина с максимальной 
высотой.
 Наилучший известный к настоящему времени алгоритм поиска максимального 
паросочетания (описанный в задаче 26.6) был предложен Хопкрофтом (Hopcroft) 
и Карпом (Karp) [175]; время его работы составляет 0(y/VE). Задачи поиска 
паросочетаний подробно рассматриваются в книге Ловаса (Lovasz) и Пламмера 
(Plummer) [238].
VII Избранные темы
Введение
 В этой части содержатся избранные темы теории алгоритмов, расширяющие 
и дополняющие материал, изложенный в данной книге ранее. В одних главах 
вводятся новые вычислительные модели, такие как комбинационные схемы или 
параллельные вычислительные машины. Другие главы охватывают специализи
 рованные области знаний, такие как вычислительная геометрия или теория чисел. 
В двух последних главах обсуждаются некоторые известные ограничения, возни
 кающие при разработке эффективных алгоритмов, а также излагаются основы 
методов, позволяющих справиться с этими ограничениями.
 В главе 27 представлена алгоритмическая модель для параллельных вычис
 лений на основе динамической многопоточности. В этой главе сначала вводят
 ся основы указанной модели и демонстрируется, как количественно описать па
 раллелизм, а затем изучается несколько интересных многопоточных алгоритмов, 
включая алгоритмы умножения матриц и сортировки слиянием.
 В главе 28 изучаются эффективные алгоритмы, предназначенные для работы 
с матрицами. В ней представлены два общих метода — LU-разложение и LUP- 
разложение. Они предназначены для решения системы линейных уравнений по 
методу исключения Гаусса за время 0(п3). Здесь также показано, что перемно
 жение и обращение матриц можно выполнять с одинаковой скоростью. В заклю
 чительной части главы показано, как получить приближенное решение системы 
линейных уравнений методом наименьших квадратов, если эта система не имеет 
точного решения.
 В главе 29 исследуется линейное программирование, цель которого — мини
 мизировать или максимизировать целевую функцию при заданных ограниченных 
ресурсах и конкурирующих ограничениях. Линейное программирование приме
 няется в самых различных прикладных областях. В этой главе описывается по
 становка задач линейного программирования и их решение. В качестве метода 
решения предложен симплекс-алгоритм, который является одним из древнейших 
алгоритмов, используемых в линейном программировании. В отличие от многих
Часть VII. Избранные темы
 809
 других алгоритмов, о которых идет речь в этой книге, для симплекс-алгоритма 
время работы в наихудшем случае не выражается полиномиальной функцией, од
 нако он достаточно эффективен и широко применяется на практике.
 В главе 30 изучаются операции над полиномами. Здесь показано, как с помо
 щью такого известного метода обработки сигналов, как быстрое преобразование 
Фурье (Fast Fourier Transform — FFT), можно перемножить два полинома п-й сте
 пени за время O(nlgn). В этой главе также исследуются методы эффективной 
реализации FFT, включая параллельные вычисления.
 В главе 31 представлены теоретико-числовые алгоритмы. После обзора эле
 ментарной теории чисел здесь описан алгоритм Евклида, предназначенный для 
вычисления наибольшего общего делителя. Далее представлены алгоритмы для 
решения модульных линейных уравнений и для возведения числа в степень по 
модулю другого числа. Затем читатель сможет ознакомиться с важным прило
 жением теоретико-числовых алгоритмов: криптографической системой с откры
 тым ключом RSA. С ее помощью можно не только кодировать сообщения та
 ким образом, чтобы их не могли прочитать посторонние, но и создавать цифро
 вые подписи. Далее в главе представлен рандомизированный тест простоты чи
 сел Миллера-Рабина (Miller-Rabin), позволяющий выполнять эффективный по
 иск больших простых чисел, необходимый для реализации схемы RSA. В за
 ключительной части главы описан эвристический /9-метод Полларда (Pollard) для 
разбиения целых чисел на множители, а также обсуждаются успехи, достигнутые 
в области целочисленной факторизации.
 В главе 32 исследуется задача поиска всех вхождений заданной строки-образца 
в имеющуюся строку текста; эта задача часто возникает при написании программ, 
предназначенных для редактирования текста. После ознакомления с “наивным” 
подходом в этой главе представлен элегантный метод решения данной задачи, 
разработанный Рабином (Rabin) и Карпом (Karp). Затем, после демонстрации 
эффективного решения, основанного на теории конечных автоматов, вниманию 
читателя предложен алгоритм Кнута-Морриса-Пратта (Knuth-Morris-Pratt), поз
 воляющий достичь высокой эффективности за счет предварительной обработки 
образца.
 Тема главы 33 — некоторые задачи вычислительной геометрии. После обсуж
 дения основных примитивов этого раздела вычислительной математики в главе 
показано, как с помощью метода “обметания” можно эффективно определить, 
имеются ли пересечения в множестве прямолинейных отрезков. Два остроумных 
алгоритма, предназначенных для поиска выпуклой оболочки заданного множе
 ства точек — метод сканирования по Грэхему (Graham’s scan) и метод продвиже
 ния по Джарвису (Jarvis’s march), — также иллюстрируют мощь метода обмета
 ния. В заключение в главе описан эффективный алгоритм, предназначенный для 
поиска пары самых близких точек в заданном множестве точек на плоскости.
 Глава 34 посвящена NP-полным задачам. Многие интересные вычислитель
 ные задачи являются NP-полными, однако неизвестен ни один алгоритм решения 
какой бы то ни было из этих задач, время работы которого выражалось бы поли
 номиальной функцией. В данной главе представлены методы определения того, 
является ли задача NP-полной. Доказана NP-полнота для нескольких классичес
810
 Часть VII. Избранные темы
 ких задач: определение того, содержит ли граф цикл Гамильтона, выполнима ли 
заданная булева формула и содержит ли заданное множество чисел такое подмно
 жество, сумма элементов в котором была бы равна заданному значению. В этой 
главе, кроме того, доказано, что знаменитая задача о коммивояжере также явля
 ется NP-полной.
 В главе 35 показано, как эффективно находить приближенные решения NP- 
полных задач с помощью приближенных алгоритмов. Для одних NP-полных за
 дач не так уж сложно выразить приближенные решения, достаточно близкие к оп
 тимальным, в то время как для других задач даже самые лучшие из известных 
приближенных алгоритмов работают все хуже по мере увеличения размера зада
 чи. Есть также другой класс задач, для которых наблюдается возрастание времени 
вычисления с увеличением точности приближенных решений. Эти возможности 
проиллюстрированы на примере решения задачи о вершинном покрытии (пред
 ставлены невзвешенная и взвешенная версии), о коммивояжере и др.
Глава 27 Многопоточные алгоритмы
 Подавляющее большинство алгоритмов в этой книге — последовательные 
(serial), пригодные для выполнения на однопроцессорном компьютере, который 
в каждый момент времени выполняет только одну инструкцию. В этой главе мы 
расширим нашу алгоритмическую модель параллельными алгоритмами (parallel 
algorithms), которые могут выполняться на многопроцессорных компьютерах, до
 пускающих одновременное выполнение нескольких команд. В частности, мы рас
 смотрим элегантную модель динамических многопоточных алгоритмов, которые 
подчиняются общим принципам проектирования и анализа алгоритмов и при 
этом могут быть эффективно реализованы на практике.
 Параллельные компьютеры, т.е. компьютеры с несколькими устройствами об
 работки данных, становятся все более распространенными и охватывают широ
 кий диапазон цен и производительности. Относительно недорогие настольные 
и переносные компьютеры оснащены одним многоядерным процессором, в ко
 торый входят несколько “ядер”, которые сами по себе являются полноценными 
процессорами с доступом к общей памяти. В среднем диапазоне как по цене, 
так и по производительности находятся кластеры, составленные из отдельных 
компьютеров, зачастую относящихся к классу персональных, со связывающей их 
некоммутируемой сетью. К дорогостоящим относятся суперкомпьютеры, которые 
зачастую используют комбинацию специализированных архитектуры и сетей для 
достижения высочайшей производительности, выражаемой в количестве выпол
 няемых за секунду команд.
 В той или иной форме многопроцессорные компьютеры существуют уже де
 сятилетия. Но несмотря на то, что модель машины с произвольным доступом 
для последовательных вычислений появилась и была принята еще на ранней ста
 дии развития компьютерных наук, до сих пор ни одна модель для параллельных 
вычислений не получила широкого признания. Основная причина этого в том, 
что производители не договорились о единой архитектурной модели для парал
 лельных компьютеров. Например, одни параллельные компьютеры оснащены сов
 местно используемой памятью (shared memory), где каждый процессор может 
непосредственно обращаться к любой ячейке памяти. Другие параллельные ком
 пьютеры используют распределенную память (distributed memory), где каждый 
процессор имеет собственную память, и для доступа одного процессора к памя
 ти другого между процессорами должны передаваться явные сообщения. Однако 
с появлением многоядерных технологий каждый новый настольный или перенос
812
 Часть VII. Избранные темы
 ной компьютер в настоящее время представляет собой параллельный компьютер 
с совместно используемой памятью. Время покажет, правы ли мы в своем выборе, 
но в данной главе принята именно эта модель — многопроцессорности с совмест
 но используемой памятью.
 Распространенным методом программирования многоядерных и иных парал
 лельных компьютеров с совместно используемой памятью является применение 
статической многопоточности (static threading), предоставляющей программ
 ную абстракцию “виртуальных процессоров”, или потоков (threads), совместно 
использующих общую память. Каждый поток поддерживает связанный с ним 
счетчик команд и может выполнять код независимо от других потоков. Операци
 онная система загружает поток в процессор для выполнения и переключает пото
 ки, когда выполнения требует другой поток. Хотя операционная система и позво
 ляет программистам создавать и уничтожать потоки, эти операции относительно 
медленные. Таким образом, для большинства приложений потоки сохраняются на 
протяжении всего времени вычислений, почему они и получили название “стати
 ческие”
 К сожалению, непосредственное программирование параллельного компьюте
 ра с совместно используемой памятью с применением статических потоков — де
 ло сложное и чреватое ошибками. Одна из причин этого заключается в сложности 
равномерного динамического распределения работы между потоками. Для любо
 го (кроме самых простейших) приложения программист для сбалансированной 
загрузки потоков должен использовать сложные протоколы обмена информацией. 
Такое положение дел привело к созданию параллельных платформ (concurrency 
platforms), предоставляющих слой программного обеспечения, который коорди
 нирует ресурсы параллельных вычислений, планирует их и управляет ими. Одни 
из таких платформ имеют вид библиотек времени выполнения, другие же предо
 ставляют полноценные параллельные языки программирования с компиляторами 
и поддержкой времени выполнения.
 Динамическое многопоточное программирование
 Важным классом параллельных платформ является динамическая многопо
 точность (dynamic multithreading), которая представляет собой модель, исполь
 зуемую нами в данной главе. Динамическая многопоточность позволяет програм
 мисту указывать уровень параллелизма в приложении, не беспокоясь о комму
 никационных протоколах, сбалансированности загрузки и других неприятностях 
программирования со статическими потоками. Параллельная платформа содер
 жит планировщик, который автоматически обеспечивает баланс загрузки, тем са
 мым существенно упрощая работу программиста. Хотя функциональность сред 
с динамической многопоточностью продолжает развиваться, почти все они под
 держивают две возможности: вложенный параллелизм и параллельные циклы. 
Вложенный параллелизм обеспечивает параллельный запуск подпрограмм, поз
 воляя вызывающей программе продолжать работу, пока запущенная подпрограм
 ма выполняет свои вычисления. Параллельный цикл подобен обычному циклу 
for, с тем отличием, что его итерации могут выполняться одновременно.
Глава 27. Многопоточные алгоритмы
 813
 Эти две возможности образуют базис модели динамической многопоточности, 
которую мы изучим в данной главе. Ключевым моментом этой модели является 
то, что программист должен указывать только логическую параллельность вы
 числений, потоки параллельной платформы и распределение вычислений между 
ними. Мы будем изучать многопоточные алгоритмы, написанные для этой моде
 ли, и то, каким образом параллельная платформа может эффективно планировать 
выполняемые вычисления.
 Наша модель динамической многопоточности имеет несколько важных пре
 имуществ.
 • Она является простым расширением нашей последовательной модели. Мы мо
 жем описать многопоточный алгоритм, добавив в псевдокод только три клю
 чевых слова: parallel, spawn и sync. Кроме того, если мы удалим эти слова 
из многопоточного псевдокода, то получим текст последовательного псевдо
 кода для решения той же задачи, который мы будем называть сериализацией 
(serialization) многопоточного алгоритма.
 • Она обеспечивает теоретически ясный способ количественного описания па
 раллелизма на основе понятий работы (work) и интервала (span).
 • Многие многопоточные алгоритмы включают вложенный параллелизм, есте
 ственным образом вытекающий из парадигмы “разделяй и властвуй” Кроме 
того, многопоточные алгоритмы, как и последовательные, могут быть проана
 лизированы путем решения рекуррентных соотношений.
 • Модель соответствует развитию практики параллельных вычислений. Все 
большее количество параллельных платформ поддерживают тот или иной ва
 риант динамической многопоточности, включая Cilk [50, 117], Cilk++ [70], 
OpenMP [58], Task Parallel Library [229] и Threading Building Blocks [290].
 В разделе 27.1 введена модель динамической многопоточности и представлены 
метрики работы, интервала и параллелизма, которые будут использоваться нами 
для анализа многопоточных алгоритмов. В разделе 27.2 изучается многопоточ
 ное умножение матриц, а раздел 27.3 посвящен сложной задаче многопоточной 
сортировки слиянием.
 27.1. Основы динамической многопоточности
 Начнем изучение динамической многопоточности с примера рекурсивного вы
 числения чисел Фибоначчи. Вспомним, что числа Фибоначчи определены рекур
 рентным соотношением (3.22):
 *о = 0,
 *1 = 1,
 Ft = Fi_i + Fi_2 
для i > 2 .
814
 Часть VII. Избранные темы
 Рис. 27.1. Дерево экземпляров рекурсивной процедуры при вычислении Fib(6). Каждый экзем
 пляр FIB с одинаковым аргументом выполняет одинаковую работу и возвращает одинаковый ре
 зультат, так что этот способ вычисления чисел Фибоначчи очень неэффективен, но поучителен.
 Вот простой, рекурсивный последовательный алгоритм вычисления n-го числа 
Фибоначчи.
 FlB(n)
 2
 1 if n < 1
 return п
 3 else х = FiB(n — 1)
 4 
у = FlB(n — 2)
 5 
return x + у
 На практике вы не должны вычислять числа Фибоначчи таким способом, по
 скольку при таком вычислении имеется очень много повторяющейся работы. На 
рис. 27.1 показано дерево экземпляров рекурсивной процедуры, создаваемых при 
вычислении Fq. Например, вызов Fib(6) рекурсивно вызывает сначала Fib (5), 
а затем — Fib (4). Но вызов Fib (5) также вызывает Fib(4). Оба экземпляра Fib (4) 
возвращают один и тот же результат (F4 = 3). Поскольку процедура FlB не ис
 пользует технологию запоминания (memoization), второй вызов Fib(4) вновь вы
 полняет всю работу, уже выполненную первым вызовом.
 Обозначим через Т(п) время работы процедуры FlB(n). Поскольку FlB(n) со
 держит два рекурсивных вызова плюс константное количество дополнительной 
работы, мы получим рекуррентное соотношение
 Т(п) = Т(п - 1) + Т(п - 2) + 0(1) .
 Это рекуррентное соотношение имеет решение Т(п) = 0(Fn), что можно по
 казать с помощью метода подстановки. В качестве гипотезы индукции примем, 
что Т(п) < aFn — Ь, где а > 1 и b > 0 представляют собой константы. При
Глава 27. Многопоточные алгоритмы
 подстановке получим
 Т(п) < (aFn-i -Ь) + (aFn-2 - Ь) + 0(1)
 — a{Fn- 1 + Fn- 2) — 26 + 0(1)
 = aFn — b — (b — 0(1))
 < aFn - b ,
 815
 если выберем 6 достаточно большим для доминирования над константой в 0 (1). 
Затем мы можем выбрать а достаточно большим для удовлетворения начальному 
условию. Аналитическая граница
 Т(п) = 9(фп) , 
(27.1)
 где ф = (1 + л/5)/2 представляет собой золотое сечение, теперь следует из урав
 нения (3.25). Поскольку Fn растет с ростом п экспоненциально, эта процеду
 ра представляет собой очень медленный способ вычисления чисел Фибоначчи. 
(См. гораздо более быстрые способы в задаче 31.3.)
 Хотя процедура FIB — не лучший, если не худший способ вычисления чисел 
Фибоначчи, она представляет собой хороший пример для иллюстрации ключевых 
концепций анализа многопоточных алгоритмов. Заметим, что в FlB(n) два рекур
 сивных вызова, FlB(n — 1) и FlB(n — 2), в строках 3 и 4 являются независимыми 
один от другого: они могут быть вызваны в любом порядке, и вычисления од
 ной процедуры никак не влияют на вычисления другой. Таким образом, эти два 
рекурсивных вызова могут работать параллельно.
 Расширим используемый в книге псевдокод, добавив новые ключевые слова, 
а именно — spawn и sync. Вот как можно переписать процедуру FIB с использо
 ванием динамической многопоточности.
 2 
P-FlB(n)
 1 if n < 1
 return п
 3 else х = spawn P-FlB(n - 1)
 4 
у = P-FlB(n - 2)
 5 
6 
sync
 return x + y
 Обратите внимание, что если мы уберем ключевые слова spawn и sync из псев
 докода Р-FlB, то полученный в результате псевдокод будет идентичен Fib (не 
считая другого имени процедуры и двух рекурсивных вызовов). Определим се
 риализацию (serialization) многопоточного алгоритма как последовательный ал
 горитм, получаемый при удалении многопоточных ключевых слов spawn и sync 
(а когда мы изучим параллельные циклы, еще и parallel). Фактически наш псев
 докод обладает тем приятным свойством, что сериализация всегда представляет 
собой обычный последовательный код, решающий ту же самую задачу.
 Вложенный параллелизм осуществляется, когда ключевое слово spawn пред
 шествует вызову процедуры, как в строке 3. Семантика запуска (spawn) отличает
816
 Часть VII. Избранные темы
 ся от обычного вызова процедуры тем, что экземпляр процедуры, выполняющий 
запуск {родительская процедура), может продолжать работать параллельно с за
 пущенной дочерней подпрограммой, вместо того чтобы ожидать завершения ее 
работы, как это обычно делается при последовательном выполнении. В нашем 
случае, пока запущенная дочерняя подпрограмма вычисляет P-FlB(n — 1), ро
 дительская процедура может продолжать вычисление P-FlB(n — 2) в строке 4 
параллельно с запущенной дочерней подпрограммой. Поскольку процедура Р- 
FlB рекурсивна, эти два вызова сами создают вложенный параллелизм, как и их 
дочерние подпрограммы, тем самым создавая потенциально огромное дерево па
 раллельно выполняемых подвычислений.
 Однако ключевое слово spawn не требует от процедуры обязательного парал
 лельного с запущенной дочерней подпрограммой выполнения; оно лишь разре
 шает таковое. Ключевые слова для параллельных вычислений выражают логиче
 ский параллелизм (logical parallelism) вычислений, указывая, какие части вычис
 лений могут выполняться параллельно. Во время выполнения программы плани
 ровщик (scheduler) определяет, какие подвычисления в действительности могут 
выполняться параллельно, назначая их доступным процессорам. Немного позже 
мы рассмотрим теоретические основы работы планировщиков.
 Процедура не может безопасно использовать значения, возвращаемые запу
 щенными дочерними подпрограммами, кроме как после выполнения команды 
sync, как в строке 5. Ключевое слово sync указывает, что для того, чтобы перейти 
к следующей за sync команде, процедура должна дождаться окончания всех запу
 щенных дочерних подпрограмм. В процедуре Р-FlB ключевое слово sync необхо
 димо перед ключевым словом return в строке 6 для того, чтобы избежать некор
 ректного суммирования хиудо того, как будет вычислено значение х. В допол
 нение к явной синхронизации, обеспечиваемой ключевым словом sync, каждая 
процедура выполняет sync перед возвратом неявно, таким образом гарантируя, 
что все дочерние подпрограммы будут завершены до окончания родительской 
процедуры.
 Модель многопоточного выполнения
 Облегчить понимание многопоточного вычисления (multithreaded computa
 tion), которое является ни чем иным, как множеством команд, выполняемых про
 цессором от имени многопоточной программы, может его представление в виде 
ориентированного ациклического графа G = (V,E), именуемого графом вычис
 лений. В качестве примера на рис. 27.2 показан граф вычислений P-Fib(4). Кон
 цептуально вершинами в V являются команды, а ребра в Е представляют зави
 симости между командами, где (u,v) € Е означает, что команда и должна вы
 полняться до команды v. Для удобства, однако, если цепочка команд не содержит 
параллельных управляющих инструкций (spawn, sync или return, где последняя 
инструкция представляет собой возврат из запущенной подпрограммы — как яв
 ный, с применением ключевого слова return, так и неявный возврат по достиже
 нии конца процедуры), их можно группировать в единый фрагмент (strand), каж
 дый из которых представляет одну или несколько команд. Команды управления
Глава 27. Многопоточные алгоритмы
 817
 Рис. 27.2. Ориентированный ациклический граф, представляющий вычисление P-Fib(4). Каждый 
круг представляет один фрагмент вычисления, причем черные круги представляют либо базовый 
случай, либо часть процедуры (экземпляр) до запуска P-FlB(n — 1) в строке 3, серые круги пред
 ставляют часть процедуры, которая вызывает P-FlB(n — 2) в строке 4 перед ключевым словом 
sync в строке 5, где процедура приостанавливается в ожидании возврата запущенной процедуры 
P-FlB(n — 1), а белые круги представляют часть процедуры после ключевого слова sync, в которой 
выполняется сложение значения х и у перед точкой, в которой происходит возврат полученного 
результата. Каждая группа фрагментов, принадлежащих одной и той же процедуре, ограничена 
скругленным прямоугольником, слабо заштрихованным для запускаемых процедур и сильно — для 
вызываемых. Ребра запуска и вызова направлены вниз, продолжения выполнения — по горизонтали 
вправо, а ребра возврата — вверх. Полагая, что каждый фрагмент требует единицы времени, вся 
работа составляет 17 единиц, поскольку имеется 17 фрагментов, а интервал равен 8 единицам, по
 скольку критический путь (указанный выделенными штриховкой ребрами) содержит 8 фрагментов.
 параллельными вычислениями в фрагменты не входят, но представлены в струк
 туре ориентированного ациклического графа. Например, если фрагмент имеет два 
преемника, один из них должен быть запущен параллельно, а для предшественни
 ка указывают, что эти предшественники объединяются инструкцией sync. Таким, 
образом, в общем случае множество V образует множество фрагментов, а множе
 ство ориентированных ребер Е представляет зависимости между фрагментами, 
порожденными управлением параллельными вычислениями. Если в G имеется 
ориентированный путь от фрагмента и к фрагменту v, мы говорим, что эти два 
фрагмента (логически) последовательны. В противном случае фрагменты и и v 
(логически) параллельны.
 Многопоточное вычисление можно изобразить как ориентированный ацикли
 ческий граф фрагментов, встроенный в дерево экземпляров процедур. Напри
 мер, на рис. 27.1 показано дерево экземпляров процедур для вычисления P-FlB(6) 
(без детализированной структуры показанных фрагментов). На рис. 27.2 показана 
в увеличенном виде одна из частей этого дерева, с демонстрацией фрагментов, со
 ставляющих каждую процедуру. Все ориентированные ребра, соединяющие фраг
 менты, проходят либо в пределах процедуры, либо вдоль неориентированных ре
 бер дерева процедуры.
818
 Часть VII. Избранные темы
 Чтобы иметь возможность указывать различные зависимости между фрагмен
 тами, ребра ориентированного ациклического графа вычислений можно класси
 фицировать. Ребро продолжения (continuation edge) (и, и'), на рис. 27.2 направ
 ленное горизонтально, соединяет фрагмент и с его преемником и' в пределах 
одного и того же экземпляра процедуры. Когда фрагмент и запускает фрагмент v, 
ориентированный ациклический граф содержит ребро запуска (spawn edge) (и, г;), 
которое на рисунке направлено вниз. Ребра вызовов (call edges), представляя 
обычные вызовы процедур, также направлены вниз. Фрагмент и, запускающий 
фрагмент v, отличается от фрагмента и, вызывающего фрагмент v тем, что за
 пуск приводит к наличию горизонтального ребра продолжения от фрагмента и 
к фрагменту и', следующему в процедуре за и и указывающему, что и' можно вы
 полнять одновременно с г?, в то время как вызов не приводит к появлению такого 
ребра. Когда фрагмент и выполняет возврат в вызвавшую процедуру, а х пред
 ставляет собой фрагмент, непосредственно следующий за следующим sync в вы
 зывающей процедуре, ориентированный ациклический граф вычислений содер
 жит ребро возврата (return edge) (и, х), направленное вверх. Вычисление начи
 нается с одного начального фрагмента (initial strand) — черной вершины в про
 цедуре, помеченной как P-Fib(4) на рис. 27.2 — и заканчивается единственным 
конечным фрагментом (final strand) — белой вершиной в процедуре, помеченной 
как P-FlB(4).
 Мы будем изучать выполнение многопоточных алгоритмов на идеальном па
 раллельном компьютере (ideal parallel computer), состоящем из множества про
 цессоров и последовательно согласованной (sequentially consistent) совместно 
используемой памяти. Последовательная согласованность означает, что совмест
 но используемая память, в которую в действительности процессорами одновре
 менно может выполняться много как загрузок, так и чтений, дает одни и те же 
результаты, как и в случае, если на каждом шаге будет выполняться только одна 
команда одного процессора. Иначе говоря, память ведет себя так, как если бы ко
 манды выполнялись последовательно в некотором глобальном линейном порядке, 
сохраняющем индивидуальный порядок выполнения команд каждым процессо
 ром. В случае динамических многопоточных вычислений, автоматически распре
 деляемых по процессорам параллельной платформой, совместно используемая 
память ведет себя так, как если бы команды многопоточных вычислений чере
 довались таким образом, что образовывали бы линейный порядок, сохраняющий 
частичный порядок ориентированного ациклического графа вычислений. В зави
 симости от планировщика упорядочение может отличаться при разных запусках 
одной и той же программы, но поведение любого выполнения программы может 
быть понято в предположении, что команды выполняются в некотором линейном 
порядке, согласованном с ориентированным ациклическим графом вычислений.
 В дополнение к сделанным семантическим предположениям модель идеаль
 ного параллельного компьютера делает также некоторые предположения, связан
 ные с производительностью. В частности, предполагается, что каждый процес
 сор машины обладает одной и той же вычислительной мощностью, а стоимость 
планирования игнорируется. Хотя это последнее предположение может казаться 
слишком оптимистичным, оказывается, что для алгоритмов с достаточной степе
Глава 27. Многопоточные алгоритмы
 819
 нью “параллелизма” (термин, который вскоре будет точно определен) на практике 
накладные расходы планирования обычно минимальны.
 Меры производительности
 Измерять теоретическую эффективность многопоточного алгоритма можно 
с использованием двух метрик: “работы” (work) и “интервала” (span). Работа 
многопоточного вычисления представляет собой общее время выполнения всего 
вычисления на одном процессоре. Другими словами, работа представляет собой 
сумму времен, взятую по всем фрагментам. В ориентированном ациклическом 
графе вычислений, в котором каждый фрагмент требует единичного времени, ра
 бота равна просто количеству вершин ориентированного ациклического графа. 
Интервал представляет собой наибольшее время выполнения фрагментов вдоль 
произвольного пути в ориентированном ациклическом графе. Опять же, в слу
 чае ориентированного ациклического графа, в котором каждый фрагмент требу
 ет единичного времени, интервал равен количеству вершин на наидлиннейшем, 
или критическом, пути (critical path) в ориентированном ациклическом графе. 
(Вспомним из раздела 24.2, что критический путь в ориентированном ацикличе
 ском графе G = (V,E) можно найти за время 0(V" + Е).) Например, ориенти
 рованный ациклический граф вычислений на рис. 27.2 всего имеет 17 вершин, 
а в критическом пути у него 8 вершин, так что если каждый фрагмент тре
 бует единичного времени, то работа равна 17 единицам времени, а интервал — 
8 единицам.
 Фактическое время выполнения многопоточного вычисления зависит не толь
 ко от его работы и интервала, но и от количества доступных процессоров и от то
 го, как планировщик распределяет фрагменты по процессорам. Обозначая время 
выполнения многопоточного вычисления на Р процессорах, мы будем использо
 вать Р в качестве нижнего индекса. Например, время выполнения алгоритма на Р 
процессорах может быть обозначено как Тр. Работа представляет собой время 
выполнения алгоритма на одном процессоре, т.е. Т\. Интервал является временем 
работы при выполнении каждого фрагмента на своем собственном процессоре — 
другими словами, если у нас имеется неограниченное количество процессоров, — 
так что интервал мы обозначаем как Т^.
 Работа и интервал предоставляют нам нижнюю границу времени выполне
 ния Тр многопоточного вычисления на Р процессорах.
 • За один шаг идеальный параллельный компьютер с Р процессорами может 
выполнить не более Р единиц работы; таким образом, за время Гр он может 
выполнить работу, не превышающую РТр. Поскольку общая работа состав
 ляет Т\, имеем РТр > Т\. Деление на Р дает правило работы'.
 ТР > Т,/Р . 
(27.2)
 • Идеальный параллельный компьютер с Р процессорами не может работать 
быстрее машины с неограниченным количеством процессоров. Так что маши
 на с неограниченным количеством процессоров может эмулировать Р-процес- 
сорную машину, используя только Р из своих процессоров. Таким образом,
820
 Часть VII. Избранные темы
 можно сформулировать следующее правило интервалов- .
 ТР > Тое . 
(27.3)
 Определим ускорение (speedup) вычислений на Р процессорах как отноше
 ние Ti/Tp, говорящее о том, во сколько раз вычисления на Р процессорах быст
 рее, чем на 1 процессоре. Согласно правилу работы имеем Тр > Т\/Р, откуда 
вытекает, что Т\/Тр < Р. Таким образом, ускорение на Р процессорах не мо
 жет превышать Р. Когда ускорение линейно зависит от количества процессоров, 
т.е. когда Т\/Тр — @(Р), вычисления демонстрируют линейное ускорение, а ко
 гда Т\/Тр = Р, мы имеем идеальное линейное ускорение.
 Отношение Ti/T^ работы к интервалу дает параллелизм (parallelism) мно
 гопоточного вычисления. Параллелизм можно рассматривать с трех точек зре
 ния. Как отношение параллелизм определяет среднее количество работы, кото
 рая может быть выполнена параллельно на каждом шаге вдоль критического пу
 ти. Как верхняя граница параллелизм дает максимально возможное ускорение, 
которое может быть достигнуто с помощью произвольного количества процес
 соров. Наконец, что, вероятно, наиболее важно, параллелизм указывает предел 
возможности достичь идеального линейного ускорения. В частности, когда ко
 личество процессоров превышает уровень параллелизма, вычисления не могут 
достичь идеального линейного ускорения. Чтобы понять это утверждение, пред
 положим, что Р > Ti/Too, и в этом случае из правила интервалов вытекает, что 
ускорение удовлетворяет условию Т\/Тр < Ti/T^ < Р. Кроме того, если число 
процессоров Р в идеальном параллельном компьютере существенно превышает 
параллелизм — т.е. если Р 
Ti/T^, — то Т\/Тр -С Р, так что ускорение гораздо 
меньше, чем количество процессоров. Другими словами, чем больше процессоров 
мы используем сверх параллелизма, тем менее идеальным становится ускорение.
 В качестве примера рассмотрим вычисление P-Fib(4) на рис. 27.2 и будем 
считать, что каждый фрагмент требует единичного времени. Поскольку работа 
Т\ = 17, а интервал Т^ = 8, параллелизм равен Т\/Т,х = 17/8 - 2.125. Сле
 довательно, достигнуть более чем удвоенного ускорения невозможно, сколько бы 
процессоров не использовалось для проведения вычислений. Мы увидим, что 
в случае больших входных размеров P-FlB(n) демонстрирует существенную сте
 пень параллелизма.
 Определим зазор параллельности (parallel slackness) многопоточного вычис
 ления на идеальном параллельном компьютере с Р процессорами как отноше
 ние (Ti/Too)/P = Ti/iPToo), которое представляет собой множитель, на который 
параллелизм вычисления превосходит количество процессоров в машине. Таким 
образом, если зазор меньше 1, мы не можем надеяться достичь идеального ли
 нейного ускорения, поскольку Т\/{РТ0с) < 1 и из правила интервалов вытекает, 
что ускорение на Р процессорах удовлетворяет условию Т\/Тр < Ti/Too < Р. 
В действительности при уменьшении зазора от 1 до 0 ускорение вычисления от
 клоняется от идеального линейного ускорения все сильнее и сильнее. Однако, 
если зазор больше 1, ограничением является работа, приходящаяся на один про
Глава 27. Многопоточные алгоритмы
 821
 цессор. Как мы увидим, при росте зазора от 1 хороший планировщик может все 
больше и больше приближаться к идеальному линейному ускорению.
 Планирование
 Хорошая производительность зависит не только от минимизации работы и ин
 тервала. Должно также выполняться эффективное распределение фрагментов по 
процессорам параллельной машины. Наша модель многопоточного программиро
 вания не предоставляет возможности указать, какие фрагменты должны выпол
 няться тем или иным процессором. Вместо этого в вопросе распределения вычис
 лений по процессорам мы полагаемся на планировщик параллельной платфор
 мы. На практике планировщик распределяет фрагменты по статическим потокам, 
а операционная система распределяет потоки по процессорам, но этот дополни
 тельный уровень косвенности не является необходимым для нашего понимания 
процесса планирования. Мы можем просто представить, что планировщик парал
 лельной платформы распределяет фрагменты по процессорам непосредственно.
 Многопоточный планировщик должен выполнять планирование, не зная зара
 нее, когда фрагменты будут запущены или когда они завершатся — он должен 
работать в оперативном (on-line) режиме. Кроме того, хороший планировщик 
работает распределенно, с учетом баланса загруженности процессоров. Суще
 ствование хороших оперативных распределенных планировщиков доказано, но 
их анализ представляет собой сложную задачу.
 Поэтому для простоты мы будем рассматривать централизованный (centra
 lized) планировщик, которому в любой момент времени известно глобальное со
 стояние вычисления. В частности, мы проанализируем жадные планировщики, 
назначающие процессорам на каждом временном шаге максимально возможное 
количество фрагментов. Если на очередном шаге к выполнению готовы как ми
 нимум Р фрагментов, мы говорим, что этот шаг является полным, и жадный 
планировщик назначает любые Р готовых фрагментов процессорам. В против
 ном случае для выполнения готово менее Р фрагментов, и мы говорим, что шаг 
неполон, а планировщик назначает каждый готовый фрагмент своему процессору.
 Согласно правилу работы наилучшее время выполнения, на которое мы мо
 жем надеяться при наличии Р процессоров, составляет Тр = Т\/Р, а согласно 
правилу интервала лучшее, на что можно надеяться, — Тр = Тх . В приведенной 
далее теореме показано, что жадный планировщик доказанно хорош в том плане, 
что достигает в качестве верхней границы суммы этих двух нижних границ.
 Теорема 27.1
 На идеальном параллельном компьютере с Р процессорами жадный планиров
 щик выполняет многопоточное вычисление с работой Т\ и интервалом 
за 
время
 ТР < Т\/Р + Tqq . 
(27.4)
 Доказательство. Начнем с рассмотрения полных шагов. На каждом полном 
шаге Р процессоров вместе выполняют общее количество работы, равное Р. 
Предположим для доказательства от противного, что количество полных шагов
822
 Часть VII. Избранные темы
 строго больше, чем \Т\/Р\. Тогда общее количество работы на полных шагах 
составляет не менее
 P-([Ti/P\+l) = P[Ti/P\+P
 = T i- (Ti mod P) + P
 Ж
 (из уравнения (3.8))
 (из неравенства (3.9)) .
 Таким образом, мы получили противоречие, заключающееся в том, что Р про
 цессоров должны выполнить большую работу, чем требует вычисление, и это 
позволяет заключить, что количество полных шагов не превышает [Ti /Р \.
 Рассмотрим теперь неполный шаг. Пусть G является ориентированным ацик
 лическим графом, представляющим все вычисление в целом, и без потери общно
 сти предположим, что каждый фрагмент выполняется за единицу времени. (Мож
 но заменить каждый более длинный фрагмент цепочкой фрагментов единичной 
длины.) Пусть G' представляет собой подграф G, который все еще должен быть 
выполнен по состоянию на начало неполного шага, и пусть G" — подграф, ко
 торый останется невыполненным после этого неполного шага. Наидлиннейший 
путь в ориентированном ациклическом графе с необходимостью начинается в вер
 шине с нулевой входной степенью. Поскольку неполный шаг жадного планиров
 щика выполняет все фрагменты с нулевой входящей степенью в Gf, длина на
 идлиннейшего пути в G" должна быть на 1 меньше, чем длина наидлиннейшего 
пути в G'. Другими словами, неполный шаг уменьшает интервал невыполненного 
ориентированного ациклического графа на 1. Следовательно, количество непол
 ных шагов не превышает Too.
 Поскольку каждый шаг является либо полным, либо неполным, теорема дока
 зана. 
■
 Приведенное далее следствие из теоремы 27.1 показывает, что жадный плани
 ровщик всегда хорошо работает.
 Следствие 27.2
 Время выполнения Тр любого многопоточного вычисления при планировании 
выполнения жадным планировщиком на идеальном параллельном компьютере 
с Р процессорами отличается от оптимального не более чем в 2 раза.
 Доказательство. Обозначим через Тр время выполнения, получаемое путем 
оптимального планирования на машине с Р процессорами, и пусть Т\ и Too обо
 значают соответственно работу и интервал вычисления. Поскольку правила рабо
 ты и интервала — неравенства (27.2) и (27.3) — дают нам Тр > max(Ti/P, Too), 
из теоремы 27.1 вытекает, что
 Tp^T^P + Too
 < 2 ■ max(Ti/P,Too)
 < 2Tp .
Глава 27. Многопоточные алгоритмы
 823
 Очередное следствие показывает, что фактически жадный планировщик с ро
 стом зазора достигает близкого к идеальному линейного ускорения любого мно
 гопоточного вычисления.
 Следствие 27.3
 Пусть Тр обозначает время выполнения многопоточного вычисления, полученное 
жадным планировщиком на идеальном параллельном компьютере с Р процессо
 рами, и пусть Т\ и Too представляют собой соответственно работу и интервал 
вычисления. Тогда, если Р <С Ti/T», имеем Тр « Т\/Р, или, что эквивалентно, 
ускорение приблизительно равно Р.
 Доказательство. Если мы предположим, что Р «С Ti/Too, то мы также име
 ем Тх) 
Т\/Р, а следовательно, теорема 27.1 дает нам Тр < Т\/Р + Too « 
T\jP. Поскольку правило работы (27.2) гласит, что Тр > Т\/Р, мы заключаем, 
что Тр « Т\/Р, или, что эквивалентно, что ускорение равно Т\/Тр « Р. 
л
 Символ <С означает “гораздо меньше”, но насколько “гораздо”? На практике за
 зора, не меньшего 10 (т.е. когда параллелизм в 10 раз превышает количество про
 цессоров), в общем случае достаточно для достижения хорошего ускорения. При 
этом член, соответствующий интервалу, в жадной границе (27.4) составляет менее 
10% от члена, соответствующего работе, приходящейся на один процессор, что 
достаточно хорошо для большинства инженерных ситуаций. Например, если вы
 числение выполняется только на 10 или 100 процессорах, параллелизм, равный, 
скажем, 1000000, не имеет никакого преимущества над параллелизмом 10000, 
несмотря на разницу в 100 раз. Как показано в задаче 27.2, иногда снижение чрез
 вычайно высокого параллелизма дает возможность получить алгоритмы, лучшие 
с других точек зрения, но при этом в той же степени масштабируемые на разум
 ном количестве процессоров.
 Анализ многопоточных алгоритмов
 Теперь у нас есть все необходимые инструменты для проведения анализа мно
 гопоточных алгоритмов и получения точных границ времен их работы на различ
 ном количестве процессоров. Анализ работы достаточно прост и прямолинеен, 
поскольку ее подсчет — ни что иное, как анализ времени работы обычного после
 довательного алгоритма (а именно — сериализации многопоточного алгоритма), 
с которым вы уже должны быть хорошо знакомы, ведь именно этому вопросу 
посвящено большинство материала данной книги! Анализ интервала куда инте
 реснее, но, вообще говоря, не сложнее — стоит только немного в нем разобраться. 
Основные идеи мы изучим на примере программы P-FlB.
 Анализ работы Т\(п) алгоритма P-FlB(n) не представляет трудности, посколь
 ку мы уже его проводили. Исходная процедура Fib, по сути, является сериализа
 цией P-FlB, а следовательно, Т\{п) = Т(п) = @(фп) согласно уравнению (27.1).
 На рис. 27.3 показано, как выполняется анализ интервала. Если два подвычис
 ления соединены последовательно, интервал их объединения равен сумме их ин
 тервалов; если же они соединены параллельно, то интервал их объединения равен
824
 Интервал: 7’0О(/4 U В) = Т^А) + Т^В) 
(а) 
Часть VII. Избранные темы
 Работа: Т\ {A U В) = ТУ{А) + Т\(В) 
Работа: ТХ(А U В) = ТХ(А) + ТХ{В)
 Интервал: T^iA U В) = тах(Г0о(/1), Т^В))
 (б)
 Рис. 27.3. Работа и интервал составных подвычислений, (а) Когда два подвычисления соединены 
последовательно, работа их объединения равна сумме отдельных работ, а интервал — сумме от
 дельных интервалов, (б) Когда два подвычисления соединены параллельно, работа их объединения 
равна сумме отдельных работ, а интервал — максимальному из отдельных интервалов.
 максимальному из индивидуальных интервалов. В случае процедуры P-FlB(n) 
запускаемый вызов P-FlB(n — 1) в строке 3 выполняется параллельно с вызо
 вом P-FlB(n — 2) в строке 4. Следовательно, интервал P-FlB(n) можно записать 
в виде рекуррентного соотношения
 Тоо{п) = max(Too(n - 1), Т^п - 2)) + 0(1)
 = Тоо(п - 1) + 0(1) ,
 решением которого является Тос(п) = 0(п).
 Параллелизм процедуры P-FlB(n) равен Т\{п)/Т^п) = 0(0n/n)> т.е. быстро 
растет с ростом п. Таким образом, даже на очень больших параллельных компью
 терах средних значений п достаточно для достижения почти идеального линей
 ного ускорения для процедуры P-FlB(n), поскольку она обладает значительным 
зазором параллельности.
 Параллельные циклы
 Многие алгоритмы включают циклы, все итерации которых могут выполнять
 ся параллельно. Как мы увидим, такие циклы можно распараллелить с помощью 
ключевых слов spawn и sync, но гораздо удобнее явно указать, что итерации в та
 ких циклах могут выполняться одновременно. В нашем псевдокоде такая функ
 циональность обеспечивается ключевым словом parallel, предшествующим клю
 чевому слову for в соответствующем цикле.
 В качестве примера рассмотрим задачу умножения матрицы А = (а^) раз
 мером п х п на n-вектор х = (Xj). Полученный в результате n-вектор у = (уi) 
определяется как
 ТЬ
 У1 = ^ , aijXj 
3 = 1
 для г = 1,2__, п. Вычислить произведение матрицы на вектор можно путем
 параллельного вычисления всех элементов у следующим образом.
Глава 27. Многопоточные алгоритмы
 Mat-Ve с(А,х)
 1 п = A. rows
 2 у — вновь созданный вектор длиной п
 3 parallel for i = 1 to n
 4 
yi = 0
 5 parallel for i — 1 to n
 6 
for j — 1 to n
 7 
8 return у
 Hi = Hi 4” OijXj
 825
 В этом коде ключевые слова parallel for в строках 3 и 5 указывают, что ите
 рации соответствующих циклов могут выполняться одновременно. Компилятор 
может реализовать каждый цикл parallel for как подпрограмму с вложенным па
 раллелизмом. Например, цикл parallel for в строках 5-7 может быть реализо
 ван с помощью вызова Mat-Vec-Main-Loop (А, х, у, n, 1, п) в стиле “разделяй 
и властвуй”; при этом компилятор генерирует вспомогательную подпрограмму 
Mat-Vec-Main-Loop следующим образом.
 MAT-VEC-MAIN-LOOP (Л, х, у, п, г, г')
 1 if г == г'
 2 
for j = 1 to п
 Hi = yi “Ь CLjjXj
 3 
4 else mid = |_(г + i')/2j
 5 
spawn Mat-Vec-Main-Loop {A, x, y, n, i, mid)
 6 
7 
Mat-Vec-Main-Loop(v1, x, y, n, mid + 1, i')
 sync
 Этот код рекурсивно запускает первую половину итераций цикла параллельно со 
второй половиной, а затем выполняет команду sync, тем самым создавая бинарное 
дерево выполнения, листья которого представляют отдельные итерации цикла; 
как показано на рис. 27.4.
 Для вычисления работы 7\(п) процедуры Mat-Vec в случае матрицы разме
 ром п х п мы просто вычисляем время работы сериализации этого алгоритма, 
получаемой простой заменой циклов parallel for обычными циклами for. Таким 
образом, мы имеем Т\(п) = @(п2) из-за доминирующего квадратичного времени 
работы дважды вложенных циклов в строках 5-7. Этот анализ, однако, игнориру
 ет накладные расходы, связанные с рекурсивным запуском в реализации с парал
 лельными циклами. В действительности накладные расходы увеличивают работу 
параллельного цикла по сравнению с его сериализацией, но не асимптотически. 
Чтобы понять, почему это так, заметим, что поскольку дерево экземпляров рекур
 сивной процедуры является полным бинарным деревом, количество внутренних 
узлов на 1 меньше количества листьев (см. упр. Б.5.3). Каждый внутренний узел 
выполняет константную работу по разделению диапазона итераций, а каждый 
лист соответствует итерации цикла, которая требует как минимум константного 
времени (0(п) в данном случае). Таким образом, можно амортизировать наклад
826
 Часть VII. Избранные темы
 Рис. 27.4. Ориентированный ациклический граф, представляющий вычисление Mat-Vec-Main- 
LOOp(A, х, у, 8,1,8). Два числа внутри каждого скругленного прямоугольника указывают значе
 ния двух последних параметров (г и г в заголовке процедуры) при запуске или вызове процедуры. 
Черные круги представляют фрагменты, соответствующие либо базовому случаю, либо части про
 цедуры до запуска Mat-Vec-Main-Loop в строке 5; серые круги представляют фрагменты, соот
 ветствующие части процедуры, которая вызывает Mat-Vec-Main-Loop в строке 6 до ключевого 
слова sync в строке 7, где выполнение приостанавливается до тех пор, пока не будет осуществлен 
возврат подпрограммы, запущенной в строке 5; белые же круги представляют фрагменты, соответ
 ствующие (незначительной) части процедуры после ключевого слова sync и до точки возврата из 
процедуры.
 ные расходы рекурсивного запуска, получая вклад, соответствующий не более 
чем добавлению постоянного множителя к общей работе.
 С практической точки зрения динамически многопоточные параллельные 
платформы иногда огрубляют (coarsen) листья рекурсии, выполняя несколько 
итераций в пределах одного листа, либо автоматически, либо по команде програм
 миста, тем самым снижая накладные расходы рекурсивного запуска. Правда, это 
снижение достигается ценой уменьшения уровня параллелизма, но если вычис
 ление имеет достаточный зазор параллельности, близкое к идеальному линейное 
ускорение при этом в жертву не приносится.
 Мы также должны учесть накладные расходы на рекурсивные запуски в ходе 
анализа интервала конструкции параллельного цикла. Поскольку глубина рекур
 сивных вызовов логарифмически зависит от количества итераций, в случае парал
 лельного цикла с п итерациями, в котором г-я итерация имеет интервал iter^i), 
интервал цикла равен
 Тос{п) = @(lgn) + max г<еГоо(*) •
 1<г<п
 Например, для процедуры MAT-VEC в случае матрицы размером п х п парал
 лельный цикл инициализации в строках 3 и 4 имеет интервал 0(lgn), поскольку 
рекурсивный запуск доминирует над константной работой в каждой итерации. 
Интервал дважды вложенных циклов в строках 5-7 составляет @(п), посколь
 ку каждая итерация внешнего цикла parallel for содержит п итераций внутрен
Глава 27. Многопоточные алгоритмы
 827
 него (последовательного) цикла for. Интервал остального кода процедуры име
 ет константное значение, и, таким образом, доминирует интервал дважды вло
 женных циклов, что дает общий интервал всей процедуры 0(п). Поскольку ра
 бота равна 0 (п2), уровень параллелизма имеет значение 0 (п2)/0 (п) = 0 (п). 
(В упр. 27.1.6 предлагается построить реализацию с еще большим уровнем па
 раллелизма.)
 Условия гонки
 Многопоточный алгоритм является детерминированным (deterministic), если 
он всегда приводит к одним и тем же результатам при одних и тех же входных 
данных, независимо от того, как именно планируются команды в многоядерном 
компьютере. Алгоритм является недетерминированным, если его поведение мо
 жет меняться от выполнения к выполнению. Зачастую многопоточные алгоритмы, 
которые должны быть детерминированными, таковыми не являются, поскольку 
содержат “гонку детерминированности” (determinacy race).
 Гонка является проклятием параллельных вычислений. Среди знаменитых 
ошибок, связанных с ней, — прибор радиационной терапии Therac-25, убивший 
трех пациентов и серьезно навредивший еще нескольким, и североамериканское 
затмение 2003 года, когда без электричества остались более 50 миллионов че
 ловек. Эти пагубные ошибки очень трудно найти. Можно проводить различные 
многодневные тесты и так и не обнаружить спорадически проявляющиеся непо
 ладки.
 Гонка детерминированности осуществляется в том случае, когда две логи
 чески параллельные команды обращаются к одной и той же ячейке памяти и как 
минимум одна из них выполняет запись. Приведенная далее процедура иллю
 стрирует условие гонки.
 Race-Example ()
 х = 0
 1
 2 parallel for i = 1 to 2
 3 
x = x + 1
 4 print x
 После инициализации переменной х значением 0 в строке 1 процедура Race- 
Example создает два параллельных фрагмента, каждый из которых увеличива
 ет х в строке 3. Хотя, на первый взгляд, процедура Race-Example должна всегда 
выводить значение 2 (ее сериализация так и делает), может оказаться выведенным 
и значение 1. Давайте разберемся, как это может случиться.
 Когда процессор увеличивает значение переменной х, эта операция не являет
 ся неделимой, а состоит из последовательности команд.
 1. Чтение х из памяти в один из регистров процессора.
 2. Увеличение значения в регистре.
 3. Запись значения из регистра обратно в переменную х в памяти.
828
 Часть VII. Избранные темы
 (а)
 Шаг
 1
 2
 3
 4
 5
 6
 7
 X
 0
 0
 0
 0
 0
 1
 1
 г \
0
 1
 1
 1
 1
 1
 (б)
 г2--
0
 1
 I
 1
 Рис. 27.5. Иллюстрация гонки детерминированности в процедуре Race-Example, (а) Ориенти
 рованный ациклический граф вычисления указывает зависимости между отдельными командами. 
г\ и гг представляют собой регистры процессора. Команды, не относящиеся к гонке, такие как реа
 лизация управления циклом, опущены, (б) Последовательность выполнения, приводящая к ошибке, 
с указанием значения х в памяти и значений регистров т\ и гг для каждого шага последовательно
 сти выполнения.
 На рис. 27.5, (а) показан ориентированный ациклический граф вычисления, пред
 ставляющий выполнение Race-Example, с фрагментами, разбитыми на от
 дельные команды. Вспомним, что, поскольку идеальный параллельный компью
 тер поддерживает последовательную согласованность, параллельное выполнение 
многопоточного алгоритма можно рассматривать как чередование команд с уче
 том зависимостей в ориентированном ациклическом графе. В части (б) рисунка 
показаны значения при выполнении вычисления, вызывающем аномалию. Значе
 ние х хранится в памяти, а т\ и Г2 представляют собой регистры процессора. На 
первом шаге один из процессоров устанавливает значение х равным 0. На шагах 2 
и 3 процессор 1 считывает значение х из памяти в свой регистр т\ и увеличивает 
его, в результате чего в регистре т\ хранится значение, равное 1. В этот момент 
в игру вступает процессор 2, выполняющий команды 4-6. Процессор 2 считывает 
значение х из памяти в свой регистр гг и увеличивает его, в результате чего в ре
 гистре Г2 хранится значение, равное 1; затем он сохраняет полученное значение 
в переменной х, присваивая ей значение 1. Теперь процессор 1 продолжает рабо
 ту с шага 7, сохраняя значение 1 из регистра г\ в переменную х, что оставляет 
значение х неизменным. Следовательно, на шаге 8 выводится значение 1, а не 2, 
как в случае сериализованной процедуры.
 Мы видим, что получается. Если при параллельном выполнении процессор 1 
выполняет свои команды до процессора 2, выводится значение 2. Если при па
 раллельном выполнении, напротив, процессор 2 выполняет свои команды до про
 цессора 1, выводится то же значение 2. Если же команды двух процессоров вы
 полняются одновременно, то может случиться так, как в приведенном примере, 
когда одно из изменений значения х оказывается потерянным.
 Конечно, множество выполнений не приводит к ошибке. Например, если по
 рядок выполнения будет (1, 2,3, 7,4,5, 6,8) или (1,4, 5,6 , 2,3, 7,8), мы получим 
корректный результат. В этом и заключается основная проблема гонки детерми
Глава 27. Многопоточные алгоритмы
 829
 нированности. В общем случае большинство порядков выполнения дают коррект
 ный результат — как в нашем случае, когда команды слева выполняются до команд 
справа или наоборот. Но некоторые порядки выполнения чередующихся команд 
приводят к неверным результатам. Из-за этого гонки крайне трудно тестировать. 
Можно выполнять тесты сутки напролет и ни разу не столкнуться с ошибкой, 
а затем получить катастрофические последствия при эксплуатации готового про
 граммного обеспечения.
 Хотя справиться с проблемой гонки можно разными способами, включая при
 менение взаимоисключающих блокировок и иных методов синхронизации, для 
наших целей мы просто будем гарантировать, что параллельно выполняемые 
фрагменты независимы: между ними не может возникнуть гонка детерминиро
 ванности. Таким образом, в конструкции parallel for все итерации должны быть 
независимыми. Между spawn и соответствующим ему sync запускаемый дочер
 ний код должен быть независимым от кода родителя, включая код, выполняемый 
дополнительными запускаемыми или вызываемыми дочерними подпрограммами. 
Обратите внимание, что аргументы для запускаемой дочерней подпрограммы вы
 числяются родителем до того, как будет выполнен реальный запуск, так что вы
 числение этих аргументов происходит последовательно с любыми обращениями 
к ним после запуска.
 В качестве примера того, насколько просто сгенерировать код с гонкой, при
 ведем некорректную реализацию многопоточного умножения матрицы на вектор, 
интервал которой достигает значения @(lgn) путем распараллеливания внутрен
 него цикла for.
 Mat-Vec-Wrong(A ,x)
 1 п = A. rows
 2
 у — вновь созданный вектор длиной п
 3 parallel for i — 1 to n
 4 
6
 yi = 0
 5 parallel for i = 1 to n
 parallel for j = 1 to n
 7 
yi 
8
 return у
 yi Ч- atjXj
 К сожалению, эта процедура некорректна из-за гонки при обновлении yi в стро
 ке 7, выполняемой параллельно для всех п значений j. В упр. 27.1.6 предлагается 
разработать корректную реализацию алгоритма с интервалом @(lgn).
 Многопоточный алгоритм с гонкой иногда может оказаться корректным. На
 пример, два параллельных потока могут сохранять одно и то же значение в сов
 местно используемой переменной, и при этом не важно, какое значение будет 
сохранено первым. Однако в общем случае мы должны рассматривать код с гон
 кой как неверный.
830
 Урок шахмат
 Часть VII. Избранные темы
 Мы завершим этот раздел реальной историей, случившейся в процессе раз
 работки многопоточной шахматной программы мирового уровня ★ Socrates [79], 
хотя конкретные данные немного упрощены для ясности. Прототип программы 
отрабатывался на 32-процессорном компьютере, но окончательная работа пред
 полагалась на суперкомпьютере с 512 процессорами. В некотором месте разра
 ботчики применили оптимизацию, которая позволила снизить время работы при 
тестировании на 32-процессорной машине с Т32 = 65 до Т'Ъ2 = 40 секунд. Затем 
разработчики использовали измерения работы и интервала и заключили, что эта 
оптимизированная версия, работающая быстрее на 32 процессорах, на самом деле 
окажется медленнее исходной версии при работе на машине с 512 процессорами. 
В результате такая “оптимизация” была отвергнута.
 Вот как выглядел их анализ. Исходная версия программы имела работу Т\ = 
2048 секунд и интервал 
= 1 секунда. Если рассматривать неравенство (27.4) 
как равенство, Тр = Т\/Р + Т,'х , и использовать его как приближение вре
 мени работы на Р процессорах, то можно увидеть, что на самом деле Г32 = 
2048/32 + 1 = 65. При оптимизации работа становится равной Т[ = 1024 секун
 ды, а интервал — = 8 секунд. Вновь используя наше приближение, получаем
 ТЪ2 = 1024/32 + 8 = 40.
 Однако относительные скорости этих двух версий меняются, когда мы вы
 числяем время работы на 512 процессорах. В частности, мы имеем Т512 = 
2048/512 + 1 = 5 секунд, а Т§12 = 1024/512 + 8 = 10 секунд. Оптимизация, 
которая ускоряет программу при работе на 32 процессорах, делает ее в два раза 
более медленной на 512 процессорах! Оптимизированная версия интервала рав
 на 8, и недоминирующий член в формуле времени работы на 32 процессорах 
становится доминирующим в случае 512 процессоров, полностью сводя на нет 
преимущества использования большего количества процессоров.
 Мораль этой истории в том, что работа и интервал могут предоставить лучшее 
средство экстраполяции производительности, чем время работы.
 Упражнения
 27.1.1
 Предположим, что мы запускаем процедуру P-FlB(n — 2) в строке 4 процедуры 
P-FiB, а не вызываем ее, как это делается на самом деле. Как это повлияет на 
асимптотические работу, интервал и параллелизм?
 27.1.2
 Начертите ориентированный ациклический граф вычислений, получаемый при 
выполнении P-Fib(5). Считая, что каждый фрагмент вычисления выполняется за 
единичное время, вычислите работу, интервал и параллелизм данного вычисле
 ния. Покажите, как распределить полученный ориентированный ациклический 
граф по трем процессорам с использованием жадного планирования, пометив 
каждый фрагмент временным шагом, на котором он должен выполняться.
Глава 27. Многопоточные алгоритмы
 27.1.3
 831
 Докажите, что жадный планировщик обеспечивает следующую временную гра
 ницу, несколько более строгую, чем доказанная в теореме 27.1:
 Тр < Ъ ~ г °° +ТХ . 
27.1.4
 (27.5)
 Постройте ориентированный ациклический граф вычислений, для которого одно 
выполнение жадным планировщиком может потребовать почти в два раза больше 
времени, чем другое выполнение жадным планировщиком на том же количестве 
процессоров. Опишите работу этих двух разных выполнений вычисления.
 27.1.5
 Профессор выполняет измерения своего детерминированного многопоточного ал
 горитма на идеальном параллельном компьютере с жадным планировщиком на 4, 
10 и 64 процессорах. Он утверждает, что получил следующие величины: Т4 = 80 
секунд, Тю = 42 секунды и Т$4 = 10 секунд. Докажите, что профессор либо врет, 
либо некомпетентен. (Указание: воспользуйтесь правилом работы (27.2), прави
 лом интервала (27.3) и неравенством (27.5) из упр. 27.1.3.)
 27.1.6
 Разработайте многопоточный алгоритм для умножения матрицы размером п х п 
на n-вектор, который достигает уровня параллелизма 0 (n 2/ lg п) при работе 0 (п 2).
 27.1.7
 Рассмотрим следующий многопоточный псевдокод для транспонирования матри
 цы А размером п х п “на месте”, без привлечения дополнительной памяти.
 P-Transpose(A)
 1 п = A. rows
 2
 parallel for j = 2 to n
 3 
4 
parallel for i = 1 to j - 1
 обменять a,ij c aji
 Проанализируйте работу, интервал и уровень параллелизма этого алгоритма.
 27.1.8
 Предположим, что мы заменили цикл parallel for в строке 3 процедуры Р- 
Transpose (см. упр. 27.1.7) обычным циклом for. Проанализируйте работу, ин
 тервал и уровень параллелизма полученного алгоритма.
 27.1.9
 Для какого количества процессоров две версии описанной выше шахматной про
 граммы будут иметь одинаковую скорость работы в предположении, что Тр =
832
 27.2. Многопоточное умножение матриц
 Часть VII. Избранные темы
 В этом разделе рассматривается многопоточное умножение матриц, сериали
 зованное время работы которого изучалось в разделе 4.2. Мы изучим как много
 поточные алгоритмы, основанные на стандартном тройном вложенном цикле, так 
и алгоритмы “разделяй и властвуй”
 Многопоточное умножение матриц вложенными циклами
 Первый алгоритм, который мы рассмотрим, — простейший алгоритм, осно
 ванный на распараллеливании циклов процедуры Square-Matrix-Multiply, 
приведенной на с. 100.
 P-Square-M atrix-M ultiply (Л, В)
 1 п = A. rows
 2 С — вновь созданная матрица размером п х п
 3 parallel for i = 1 to n
 4 
parallel for j = 1 to n
 5 
6 
7 
8 return C
 Cij — 0
 for к = 1 to n
 C{j = Cij + 
• bfcj
 Для того чтобы проанализировать этот алгоритм, заметим, что поскольку его 
сериализацией является алгоритм Square-M atrix-M ultiply, работа данного 
алгоритма представляет собой просто Т\(п) = 0(п3) — время работы алгорит
 ма Square-Matrix-Multiply. Интервал Т^п) = 0(п), поскольку алгоритм 
следует вниз по пути в дереве рекурсии для цикла parallel for, начинающегося 
в строке 3, затем вниз по дереву рекурсии для цикла parallel for, начинающегося 
в строке 4, после чего выполняет все п итераций обычного цикла for, начина
 ющегося в строке 6, что в результате приводит к интервалу 0(lgn) + 0(lgn) + 
0(n) = 0(п). Таким образом, уровень параллелизма равен 0(n3)/0(n) = 0(п2). 
В упр. 27.2.3 предлагается распараллелить внутренний цикл для получения уров
 ня параллелизма, равного 0(n3/lgn), чего нельзя добиться простым использова
 нием parallel for, поскольку при этом создаются гонки.
 Многопоточный алгоритм “разделяй и властвуй” для умножения матриц
 Как мы знаем из раздела 4.2, матрицы размером пхп можно перемножить по
 следовательно за время 0(nlg7) = 0(п2-81), воспользовавшись стратегией “раз
 деляй и властвуй” Штрассена. Естественным образом возникает вопрос о много
 поточной версии этого алгоритма. Начнем, как и в разделе 4.2, с многопоточной 
версии более простого алгоритма “разделяй и властвуй”
 Вспомним (с. 102), что процедура Square-Matrix-Multiply-Recursive, 
которая умножает две матрицы, А и В, размером п х п и дает в результате мат
 рицу С того же размера, основывается на разбиении каждой из трех матриц на
Глава 27. Многопоточные алгоритмы
 четыре подматрицы размером п/2 х п /2:
 А = ( дп ^12 ) , В = ( в" в * 
V А 21 а 22 J 
V **21 £>22
 После этого мы можем переписать умножение матриц следующим образом:
 / 
\ 
С\\ 
С21 
С\2 \ _ ( М\ М2 \ ( Вц В\2 \
 С22 ) \ ^21 ^22 ) \ -®21 -®22 )
 _ ( М\В\\ АцВ\2 \ 
V М\В\\ А2\В\2 ) 
833
 С = С\\ С\2 
С21 С22
 ( А\2В2\ А12В22 \ 
\ А22В21 А22В22 )
 т (л
 Итак, для умножения двух матриц размером п х п мы выполняем восемь умно
 жений матриц размером п/2 х п/2 и одно сложение матриц размером п х п. 
Приведенный ниже псевдокод реализует эту стратегию “разделяй и властвуй” 
с использованием вложенного параллелизма. В отличие от процедуры Square- 
Matrix-Multiply-Recursive, на которой она основана, процедура P-Matrix- 
Multiply-Recursive получает выходную матрицу в качестве параметра, чтобы 
избежать излишнего выделения памяти для матриц.
 P-Matrix-Multiply-Recursive(C, А, В)
 1 п = A. rows
 2 if п == 1
 3 
сц = ацбц
 4 else пусть Т представляет собой новую матрицу размером п х п
 5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
Разбиение А, В, С и Т на подматрицы размером п/2 х п/2
 An, А\2, Л21, А22', Вц, В12, В21, В22', Сц, С\2, С21, С22; 
иТц,Т12,Т21,Т22; соответственно
 spawn P-Matrix-Multiply-Recursive(Ch , Аи,Вп)
 spawn P-Matrix-Multiply-Recursive(Ci2,^4h , Ви)
 spawn P-Matrix-Multiply-Recursive(C2i, A2\, Вц )
 spawn P-Matrix-Multiply-Recursive(C22, A2\, Bu)
 spawn P-Matrix-Multiply-Recursive(Th , Ai2, B21)
 spawn P-Matrix-Multiply-Recursive(Ti2, Ai2, B22)
 spawn P-Matrix-Multiply-Recursive (T21, Л22, B2\)
 P-Matrix-Multiply-Recursive (T22, Л22, B22)
 sync
 parallel for i = 1 to n
 parallel for j = 1 to n
 C-ij — C-ij 
tij
 В строке 3 обрабатывается базовый случай умножения матриц размером 1x1. 
Рекурсивный случай обрабатывается в строках 4-17. Память для временной мат
 рицы Т выделяется в строке 4, а в строке 5 выполняется разбиение каждой 
из матриц А, В, С и Т на подматрицы размером п/2 х п/2. (Как и в проце
 дуре Square-Matrix-Multiply-Recursive на с. 102, мы обошли молчанием
 27 Зак. 3726
834
 Часть VII. Избранные темы
 небольшой вопрос о том, как использовать вычисления индексов для представ
 ления подматричных частей исходной матрицы.) Рекурсивный вызов в строке 6 
присваивает подматрице Сц произведение подматриц А цВ ц, так что Сц стано
 вится равным первому из двух членов, образующих сумму в (27.6). Аналогично 
в строках 7-9 выполняется присваивание подматрицам Си, С21 и С22 первого из 
двух членов соответствующих сумм в (27.6). В строке 10 подматрице Тц присва
 ивается произведение подматриц А12В21, так что Тц становится равным второму 
члену в сумме для Сц. В строках 11-13 выполняется аналогичное присваивание 
вторых членов сумм для Си, С21 и С22 подматрицам Т\2, Т21 и Т22 соответствен
 но. Первые семь рекурсивных вызовов запускаются, а последний выполняется 
в основном фрагменте. Инструкция sync в строке 14 гарантирует, что все произ
 ведения подматриц в строках 6-13 будут полностью вычислены, после чего мы 
добавляем произведения из Т в С с использованием дважды вложенных циклов 
parallel for в строках 15-17.
 Сначала проанализируем работу М\ (п) процедуры P-Matrix-Multiply- 
Recursive, проводя анализ времени работы ее последовательного предшествен
 ника Square-Matrix-Multiply-Recursive. В рекурсивном случае разбиение 
выполняется за время 0(1), затем выполняется восемь рекурсивных умножений 
матриц размером п/2 х п/2, и наконец выполняется работа 0(п2) по сложению 
двух матриц размером п х п. Таким образом, рекуррентное соотношение для ра
 боты Mi (п) имеет вид
 Mi(n) = 8Mi(n/2) + 0(n2)
 = 0(п3)
 согласно случаю 1 основной теоремы. Другими словами, работа нашего много
 поточного алгоритма асимптотически та же, что и время выполнения процедуры 
Square-Matrix-Multiply с трижды вложенными циклами из раздела 4.2.
 Для определения интервала М ^п) процедуры P-Matrix-Multiply- 
Recursive сначала заметим, что интервал для разбиения равен 0(1) и над ним 
доминирует интервал 0 (lg п) дважды вложенных циклов parallel for в стро
 ках 15-17. Поскольку восемь параллельных рекурсивных вызовов работают с мат
 рицами одинакового размера, максимальным интервалом каждого рекурсивного 
вызова является интервал любого из них. Следовательно, рекуррентное соотно
 шение для интервала М ^п ) процедуры P-Matrix-Multiply-Recursive имеет 
вид
 MK,(n) = Moo(n/2) + 0(lgn). 
(27.7)
 Это рекуррентное соотношение не подпадает ни под один из случаев основной 
теоремы, но соответствует условию упр. 4.6.2. Согласно упр. 4.6.2 решением ре
 куррентного соотношения (27.7) является М ^ п ) = 0(lg2 п).
 Теперь, когда мы знаем работу и интервал процедуры P-Matrix-Multiply- 
Recursive, можно вычислить уровень ее параллелизма как М\ (п)/М ^ (п) = 
0(n3/lg 2 п) и увидеть, что он весьма высок.
Глава 27. Многопоточные алгоритмы
 Многопоточный метод Штрассена
 835
 В случае многопоточного алгоритма Штрассена мы следуем той же общей 
схеме, что и на с. 104, только с применением вложенного параллелизма.
 1. Разбиваем входные матрицы А и В и выходную матрицу С на подматрицы раз
 мером п /2 х п /2, как в (27.6). Работа и интервал этого шага составляют 0(1) 
при использовании пересчета индексов.
 2. Создаем 10 матриц Si, S2,..., S10, каждая из которых имеет размер п /2 х п /2 
и представляет собой сумму или разность двух матриц, созданных в п. 1. Все 
10 матриц создаются ценой работы 0(п2) и интервала 0(lgn) с помощью 
дважды вложенных циклов parallel for.
 3. Используя созданные в п. 1 подматрицы и 10 матриц, созданных в п. 2, рекур
 сивно запускаем вычисление семи произведений матриц P i, Р2,..., Р7 разме
 ром п /2 х п /2.
 4. Вычисляем искомые подматрицы Сц , С12, С21, С22 результирующей матри
 цы С путем сложения и вычитания различных комбинаций матриц Р{, вновь 
используя дважды вложенные циклы parallel for. Вычисление всех четырех 
подматриц имеет работу 0(п2) и интервал 0(lgn).
 Для анализа этого алгоритма сначала заметим, что, поскольку сериализация 
совпадает с исходным последовательным алгоритмом, работа нашего алгоритма 
равна времени работы сериализации, а именно — 0(nlg7). Как и в случае процеду
 ры P-Matrix-Multiply-Recursive для интервала можно записать рекуррент
 ное соотношение. В данном случае параллельно выполняются семь рекурсивных 
вызовов, но поскольку все они работают с матрицами одного и того же размера, 
мы получаем такое же рекуррентное соотношение (27.7), как и в случае про
 цедуры P-Matrix-Multiply-Recursive, решением которого является 0(lg2 п). 
Таким образом, уровень параллелизма многопоточного алгоритма Штрассена ра
 вен 0(nlg7/ lg2 п). Это высокий параллелизм, хотя и меньший, чем в случае про
 цедуры P-Matrix-Multiply-Recursive.
 Упражнения
 27.2.1
 Изобразите ориентированный ациклический граф для вычислений для процеду
 ры P-Square-Matrix-Multiply для матриц размером 2x2, помечая соответ
 ствие вершин на своей диаграмме фрагментам выполнения алгоритма. Исполь
 зуйте соглашение, согласно которому ребра, соответствующие запускам и вызо
 вам, направлены вниз, ребра продолжения направлены вправо, а ребра возвра
 тов — вверх. Считая, что каждый фрагмент выполняется за единичное время, 
проанализируйте работу, интервал и параллелизм этого вычисления.
 27.2.2
 Повторите упр. 27.2.1 для процедуры P-Matrix-Multiply-Recursive.
836
 27.2.3
 Часть VII. Избранные темы
 Запишите псевдокод многопоточного алгоритма, перемножающего две матрицы 
размером п х п с работой 0(n3), но с интервалом всего лишь 0(lg п). Проанали
 зируйте свой алгоритм.
 27.2.4
 Запишите псевдокод эффективного многопоточного алгоритма, умножающего 
матрицу размером р х q на матрицу размером q х г. Ваш алгоритм должен быть 
высокопараллельным, даже когда любые из значений р, q иг равны 1. Проанали
 зируйте свой алгоритм.
 27.2.5
 Запишите псевдокод эффективного многопоточного алгоритма транспонирования 
матрицы размером п х п “на месте”, без привлечения дополнительной памяти, 
с использованием для рекурсивного деления матрицы на четыре подматрицы раз
 мером п/ 2 х п/ 2 метода “разделяй и властвуй” без цикла parallel for. Проанали
 зируйте свой алгоритм.
 27.2.6
 Запишите псевдокод эффективной многопоточной реализации алгоритма (см. раз
 дел 25.2), который вычисляет кратчайшие пути между всеми парами вершин 
в графе со взвешенными ребрами. Проанализируйте свой алгоритм.
 27.3. Многопоточная сортировка слиянием
 Мы познакомились с сортировкой слиянием в разделе 2.3.1, а в разделе 2.3.2 
проанализировали время ее работы и показали, что оно составляет 0(nlgn). 
Поскольку сортировка слиянием сама по себе использует парадигму “разделяй 
и властвуй”, складывается впечатление, что она является прекрасным канди
 датом для многопоточности с применением вложенного параллелизма. Можно 
легко модифицировать псевдокод так, чтобы первый рекурсивный вызов был 
запускаемым.
 Merge-Sort' (А, р, г)
 1 if р < г
 2 
q = [(p + r)/2\
 3 
4 
5 
6 
spawn MERGE-SORT'(i4,p, q)
 Merge-Sort'(j4, q 1, r)
 sync
 MERGE(A,p,g,r)
 Подобно своему последовательному аналогу, Merge-Sort' сортирует подмас
 сив А\р..г\. После того как две рекурсивные подпрограммы в строках 3 и 4
Глава 27. Многопоточные алгоритмы
 Р\
 т ...
 9i
 X
 837
 г 1
 > X
 Рг
 < X
 92 
> г
 г2
 Рис. 27.6. Идея, лежащая в основе многопоточного слияния отсортированных подмасси
 вов T[pi..ri] и Т[р2 . .гг] в подмассив А[рз ..гз]. Пусть х = T[gi] представляет собой медиа
 ну T[pi.. ri], а дг — место в Т[рг ■ • гг], такое, что х попадает между Т[дг — 1] и Т^г]. Каждый 
элемент подмассивов T[pi.. 91 — 1] и Т[рг .. 92 — 1] (светлая штриховка) не превышает х, а каждый 
элемент подмассивов T[qi + 1.. п] и T[q2 -f 1.. r2] (темная штриховка) как минимум равен х. Для 
слияния мы вычисляем индекс 93, где х располагается в А\р$ ■ - гз], копируем х в Л[93], а затем 
рекурсивно выполняем слияния Т\р\ .. 91 — 1] с Т[рг .. 92 — 1] в Л[рз .. 93 — 1] и T[q\ + 1.. ri] 
с Т[92 .. г 2] в Л[93 -I- 1 . - г3].
 будут завершены, что обеспечивается инструкцией sync в строке 5, процедура 
Merge-Sort' вызывает такую же процедуру Merge, как и приведенная на с. 54.
 Давайте проанализируем процедуру Merge-Sort'. Для этого сначала проана
 лизируем процедуру Merge. В спомним, что в последовательном случае время ее 
работы по слиянию п элементов составляет 0(п). Поскольку процедура MERGE 
последовательная, и ее работа, и ее интервал равны 0(п). Таким образом, работа 
MS[(n) процедуры Merge-Sort' с п элементами характеризуется рекуррентным 
соотношением
 MS[(n) = 2MS'1(n/2) + 0(n)
 = ©(nlgn)
 и совпадает со временем работы последовательной сортировки слиянием. По
 скольку два рекурсивных вызова Merge-Sort' могут работать параллельно, ин
 тервал MS'qq определяется рекуррентным соотношением
 MS,00(n) = MS,00(n/2) + e(n)
 = 0(п) .
 Таким образом, уровень параллелизма процедуры Merge-Sort' стремится 
к M5,1(n)/M5'JX)(n) = 0(lgn), весьма невыразительной величине. Например, что
 бы отсортировать 10 миллионов элементов, линейного ускорения можно достичь 
на нескольких процессорах, но эффективно использовать сотни процессоров не 
удастся.
 Вероятно, вы уже догадались, в чем слабое место этой многопоточной реализа
 ции сортировки слиянием: в последовательной процедуре Merge. Хотя слияние 
изначально может казаться по своей сути последовательным, в действительности 
можно создать его многопоточную версию с использованием вложенного парал
 лелизма.
838
 Часть VII. Избранные темы
 Наша стратегия “разделяй и властвуй” для многопоточного слияния, проиллю
 стрированная на рис. 27.6, работает с подмассивами массива Т. Предположим, что 
мы сливаем два отсортированных подмассива — T[pi.. ri] длиной щ = г\ — р\ + 1 
И Т[р2 • • Гг] ДЛИНОЙ П2 = Г2 — Р2 + 1 — В ПОДМасСИВ Л[рз . . Гз] ДЛИНОЙ 713 =
 — Рз + 1 = Щ + 712- Без потери общности мы делаем упрощающее предполо
 жение О ТОМ, ЧТО 711 > П2.
 Сначала находим средний элемент х = T[qi] подмассива Т\р\..г\\, где 
ql = [(pi + 7'i)/2_|. Поскольку подмассив отсортирован, х является медиа
 ной T[pi.. гi]: любой элемент в Т\р\ .. q\ — 1] не превышает х, а любой элемент 
в T[qi +1.. ri] не меньше х. Затем мы используем бинарный поиск для того, что
 бы найти индекс q2 в подмассиве Т[р2 • .гг], такой, чтобы подмассив оставался 
отсортированным, если мы вставим х между T[q2 — 1] и T[q2\.
 Затем мы сливаем исходные подмассивы T[pi.. ri] и Т[рг • • гг] в Л[рз .. гз] 
следующим образом.
 1. Устанавливаем <73 = Рз + (qi — Pi) + (92 — Р2)
2. Копируем х в A[qz\.
 3. Рекурсивно сливаем T[pi.. q\ — 1] с Т[рг • • <72 — 1] и размещаем результат в под
 массиве А\рз .. дз — 1].
 4. Рекурсивно сливаем T[q\ + 1.. r\] с T[q2 .. Г2] и размещаем результат в под
 массиве A[qz + 1.. Г3].
 Когда мы вычисляем q3, величина q\ — р\ представляет собой количество эле
 ментов в подмассиве T[pi.. q\ — 1], а величина 92 — Р2 — количество элементов 
в подмассиве Т\р2 .. <72 — !]• Таким образом, их сумма равна количеству элементов, 
которые располагаются перед х в подмассиве Л[рз .. гз].
 Мы имеем дело с базовым случаем, когда 7ii = 712 = 0; при этом мы не долж
 ны выполнять никакой работы по слиянию двух пустых подмассивов. Поскольку 
мы предполагаем, что подмассив T[pi.. ri] имеет как минимум ту же длину, что 
и Т[р2 • • гг], т.е. 711 > 712, проверить базовый случай можно одной лишь провер
 кой 7ii = 0. Мы должны также убедиться, что рекурсия корректно обрабатывает 
случай, когда пуст только один из двух подмассивов, которым, в соответствии 
с нашим предположением о том, что 711 > 712, должен быть подмассив Т\р2 .. гг].
 Теперь превратим указанные идеи в псевдокод. Начнем с бинарного поиска, 
который выразим последовательно. Процедура Binary-Search(x, Г,р, г) полу
 чает ключ х и подмассив Т[р.. г] и возвращает одно из следующего списка.
 • Если Т\р.. г] пуст (г < р), то процедура возвращает индекс р.
 • Если х < Т\р\, а следовательно, не превышает все элементы Т[р.. г], то про
 цедура возвращает индекс р.
 • Если х > Т[р], то процедура возвращает наибольший индекс q в диапазоне р < 
q < г + 1, такой, что T[q — 1] < х.
 А вот и сам псевдокод.
Глава 27. Многопоточные алгоритмы
 Binary-Search (х, Т, р, г)
 1 low = р
 2
 3 
4 
5 
6 
7 
8 
high = max(p, г + 1)
 while low < high
 mid = [(low + high)/2J
 if x < T[mid\
 high = mid
 else low = mid + 1
 return high
 839
 Вызов Binary-Search(x, T,p, г) требует 0(lgn) последовательного времени 
в худшем случае (здесь п = г — р + 1 — размер подмассива, с которым работает 
процедура). (См. упр. 2.3.5.) Поскольку Binary-Search является последователь
 ной процедурой, в наихудшем случае ее работа и интервал равны 0(lgn).
 Теперь мы готовы написать псевдокод процедуры многопоточного слияния. 
Подобно процедуре Merge на с. 54, в процедуре P-Merge предполагается, что 
два сливаемых подмассива находятся в одном и том же массиве. Однако в от
 личие от процедуры Merge, в процедуре P-Merge не предполагается, что сли
 ваемые подмассивы граничат друг с другом, т.е. процедура P-Merge не тре
 бует выполнения равенства р2 = г\ + 1. Еще одно различие между Merge 
и P-Merge в том, что процедура P-Merge получает в качестве аргумента вы
 ходной подмассив А, в котором должны будут храниться слитые значения. Вы
 зов P-MERGE(T,pi,ri,p2?^2,-А,рз) сливает два отсортированных подмассива, 
T\pi.. ri] и Т[р2 • • г2\, В подмассив А\р3 .. г3], где r 3 = р3 + (п - р\ + 1) + 
(Г2 — Р2 + 1) ~ 1 = Рз + (ri — Pi) + (^2 — Р2) + 1 и не передается в качестве 
входного аргумента.
 P-Merge (Г, р\, г i, р2, г2, А, р3)
 1 П\ = Г\ - pi + 1
 2 п2 = г2 - р2 + 1
 3 if п\ < п2 
/ / Гарантируем, что п\ > п2
 4 
5 
6 
Обменять pi с р2
 Обменять г\ с г2
 Обменять п\ с п2
 7 if п\ == 0 
8 
return
 9 else q\ = |_(pi + ri)/2j
 10 
11 
12 
/ / Оба пусты?
 q2 = BINARY-SEARCH(T[9i],T,P2,^2)
 93 = рз + (qi -pi ) + (92 - P 2)
 А Ы = T[qi]
 13 
14 
15 
spawn P-Merge(T,pi,gi - 1,P2,92~ 1,Дрз)
 P-Merge (T, 91 + 1, n , 92, r2, A, q3 + 1)
 sync
 Процедура P-MERGE работает следующим образом. В строках 1 и 2 вы
 числяются длины п\ и п2 подмассивов Т\р\..г\\ и Т\р2..г2] соответственно.
840
 Часть VII. Избранные темы
 В строках 3-6 обеспечивается выполнение предположения о том, что щ > п2. 
В строке 7 выполняется проверка базового случая, когда подмассив Т\р\ .. г\] 
пуст (а следовательно, пуст и подмассив Т[р2 • • гг]), и в этом случае выполня
 ется простой возврат из процедуры. В строках 9-15 реализована стратегия “раз
 деляй и властвуй”. Строка 9 вычисляет среднюю точку подмассива T\pi.. ri], 
а строка 10 находит точку <72 в подмассиве Т[р2 .. гг], такую, что все элементы 
в Т[рг • • 92 — 1] меньше T[qi] (соответствующего х), а все элементы в T[q2 .. гг] 
не менее T[q\]. В строке 11 вычисляется индекс <73 элемента, который делит вы
 ходной подмассив А\рз .. гз] на А\р% .. q$ — 1] и A[q^ + 1 .. гз], а затем строка 12 
копирует T[qi] непосредственно в A[q%\.
 Затем выполняется рекурсия с применением вложенного параллелизма. Стро
 ка 13 запускает первую подзадачу, в то время как строка 14 параллельно вызывает 
вторую подзадачу. Инструкция sync в строке 15 гарантирует, что обе подзадачи 
будут завершены до возврата из процедуры. (Поскольку каждая процедура неявно 
выполняет sync перед возвратом, можно опустить инструкцию sync в строке 15, 
но явное включение этой инструкции является хорошим стилем кодирования.) 
Имеется определенная тонкость при кодировании, обеспечивающая корректность 
работы при пустом подмассиве Т[р2 • • г2]. Она заключается в том, что на каждом 
рекурсивном вызове медианный элемент подмассива Т\р\. .г \] помещается в вы
 ходной подмассив, пока сам Т \р\.. г\] не станет, наконец, пустым и тем самым 
осуществится базовый случай.
 Анализ многопоточного слияния
 Сначала выведем рекуррентное соотношение для интервала РМос(п) проце
 дуры P-Merge, где два подмассива содержат в сумме п = п\ + пг элементов. 
Поскольку запуск в строке 13 и вызов в строке 14 работают логически парал
 лельно, рассмотрим только более дорогостоящий из них. Ключевым моментом 
является понимание того, что в наихудшем случае максимальное число элемен
 тов любого из рекурсивных вызовов может быть не более Зп/4, что поясняется 
следующим образом. Поскольку строки 3-6 гарантируют, что пг < п\, отсюда 
вытекает, что пг = 2п2/2 < (п\ + пг)/2 = п/2. В наихудшем случае один из 
двух рекурсивных вызовов сливает \п\/2\ элементов подмассива Т \р\..г\] со 
всеми П2 элементами подмассива Т[рг • • гг], а следовательно, количество элемен
 тов, вовлеченных в вызов, составляет
 \п\/2\ +П2 < п\/2 + пг/2 + п2/2 
= (Hi + п2)/2 + п2/2
 < п/2 + п/4 
= Зп/4 .
 Добавив стоимость 0(lgn) вызова Binary-Search в строке 10, мы получим 
следующее рекуррентное соотношение для интервала в наихудшем случае:
 РМоо(п) = РМоо(Зп/4) + 0(lgn) .
 (27.8)




































































































































































































































































Глава 34. NP-полнота
 1101
 линомиальным временем работы. (Пока что мы не станем обременять себя раз
 мышлениями о том, как сформулировать такую задачу А.) Предположим также, 
что имеется преобразование, позволяющее в течение полиномиального времени 
преобразовать экземпляры задачи А в экземпляры задачи В. Теперь с помощью 
простого доказательства “от противного” можно показать, что для решения задачи 
В не существует алгоритмов с полиномиальным временем работы. Предположим 
обратное, т.е. что существует решение задачи В в виде алгоритма с полиномиаль
 ным временем работы. Тогда, воспользовавшись методом, проиллюстрированным 
на рис. 34.1, можно получить способ решения задачи А в течение полиномиаль
 ного времени, а это противоречит предположению о том, что таких алгоритмов 
для задачи А не существует.
 Если речь идет о NP-полноте, то здесь нельзя предположить, что для задачи А 
вообще не существует алгоритмов с полиномиальным временем работы. Однако 
методология аналогична в том отношении, что доказательство NP-полноты задачи 
В основывается на предположении об NP-полноте задачи А.
 Первая NP-полная задача
 Поскольку метод приведения основан на том, что для какой-то задачи заранее 
известна ее NP-полнота, то для доказательства NP-полноты различных задач по
 надобится “первая” NP-полная задача. В качестве таковой воспользуемся задачей, 
в которой задана булева комбинационная схема, состоящая из логических элемен
 тов И, ИЛИ и НЕ. В задаче спрашивается, существует ли для этой схемы такой 
набор входных булевых величин, для которого будет выдано значение 1. Доказа
 тельство NP-полноты этой первой задачи будет представлено в разделе 34.3.
 Краткое содержание главы
 В этой главе изучаются аспекты NP-полноты, которые непосредственно осно
 вываются на анализе алгоритмов. В разделе 34.1 формализуется понятие “задачи” 
и определяется класс сложности Р как класс задач принятия решения, разреши
 мых в течение полиномиального времени. Также станет ясно, как эти понятия 
укладываются в рамки теории формальных языков. В разделе 34.2 определяется 
класс NP, к которому относятся задачи принятия решения, правильность реше
 ния которых можно проверить в течение полиномиального времени. Здесь также 
формально ставится вопрос Р Ф NP.
 В разделе 34.3 показано, как с помощью приведения с полиномиальным вре
 менем работы изучаются взаимоотношения между задачами. Здесь дано опреде
 ление NP-полноты и представлен набросок доказательства того, что задача “о вы
 полнимости схемы” является NP-полной. Имея одну NP-полную задачу, в разде
 ле 34.4 мы увидим, как можно существенно проще доказать NP-полноту других 
задач с помощью приведения. Эта методология проиллюстрирована на приме
 ре двух задач на выполнимость формул, для которых доказывается NP-полнота. 
В разделе 34.5 NP-полнота демонстрируется для широкого круга других задач.
1102
 34.1. Полиномиальное время
 Часть VII. Избранные темы
 Начнем изучение NP-полноты с формализации понятия задач, разрешимых 
в течение полиномиального времени. Эти задачи считаются легко разрешимы
 ми, но не из математических, а из философских соображений. В поддержку этого 
мнения можно привести три аргумента.
 Во-первых, хотя и разумно считать трудноразрешимой задачу, для решения 
которой требуется время 0(п100), на практике крайне редко встречаются зада
 чи, время решения которых выражается полиномом такой высокой степени. Для 
практических задач, которые решаются за полиномиальное время, показатель сте
 пени обычно намного меньше. Опыт показывает, что если для задачи становится 
известен алгоритм с полиномиальным временем работы, то зачастую впослед
 ствии разрабатывается и более эффективный алгоритм. Даже если самый лучший 
из известных на сегодняшний день алгоритмов решения задачи характеризуется 
временем 0(п100), достаточно высока вероятность того, что вскоре будет разра
 ботан алгоритм с намного лучшим временем работы.
 Во-вторых, для многих приемлемых вычислительных моделей задача, которая 
решается в течение полиномиального времени в одной модели, может быть реше
 на в течение полиномиального времени и в другой. Например, в большей части 
книги рассматривается класс задач, разрешимых в течение полиномиального вре
 мени с помощью последовательных машин с произвольным доступом к памяти. 
Этот класс совпадает с классом задач, разрешимых в течение полиномиально
 го времени на абстрактных машинах Тьюринга1. Он также совпадает с классом 
задач, разрешимых в течение полиномиального времени на параллельных ком
 пьютерах, если зависимость количества процессоров от объема входных данных 
описывается полиномиальной функцией.
 В-третьих, класс задач, разрешимых в течение полиномиального времени, об
 ладает полезными свойствами замкнутости, поскольку множество полиномов за
 мкнуто относительно операций сложения, умножения и композиции. Например, 
если выход одного алгоритма с полиномиальным временем работы соединить 
со входом другой такой задачи, получится полиномиальный составной алгоритм. 
В упр. 34.1.5 требуется показать, что если алгоритм с полиномиальным временем 
работы фиксированное количество раз вызывает подпрограммы с полиномиаль
 ным временем работы и выполняет дополнительные действия также за полино
 миальное время, то и общее время работы такого составного алгоритма является 
полиномиальным.
 Абстрактные задачи
 Чтобы получить представление о классе задач, разрешимых за полиноми
 альное время, сначала необходимо формально описать само понятие “задача”
 Подробное рассмотрение модели Тьюринга можно найти в книгах Хопкрофта (Hopcroft) и Ульмана 
(Ullman) [179], а также Льюиса (Lewis) и Пападимитриу (Papadimitriou) [235].
Глава 34. NP-полнота
 1103
 Определим абстрактную задачу (abstract problem) Q как бинарное отноше
 ние между множеством экземпляров (instances) задач / и множеством реше
 ний (solutions) задач 5. Например, экземпляр задачи о поиске кратчайшего пути 
SHORTEST-PATH состоит из трех элементов: графа и двух вершин. Решени
 ем этой задачи является последовательность вершин графа; при этом пустая по
 следовательность может означать, что искомого пути не существует. Сама задача 
SHORTEST-PATH представляет собой отношение, сопоставляющее каждому эк
 земпляру графа и двум его вершинам кратчайший путь по графу, соединяющий 
эти две вершины. Поскольку кратчайший путь может быть не единственным, кон
 кретный экземпляр задачи может иметь несколько решений.
 Представленная выше формулировка абстрактной задачи носит более широкий 
характер, чем требуется для наших целей. Как мы уже видели, теория NP-полно- 
ты ограничивается рассмотрением задач принятия решения (decision problems), 
решения которых имеют вид “да/нет” В этом случае абстрактную задачу при
 нятия решения можно рассматривать как функцию, отображающую экземпляр 
множества / на множество решений {0,1}. Например, задача принятия реше
 ния, соответствующая задаче SHORTEST-PATH, — рассмотренная выше задача 
поиска пути PATH. Если г = (G, и, v, к) — экземпляр задачи принятия реше
 ния PATH, то равенство PATH (г) = 1 (да) выполняется, если количество ребер 
в кратчайшем пути из вершины и в вершину v не превышает к; в противном 
случае РАТН(г) = 0 (нет). Многие абстрактные задачи являются не задачами 
принятия решения, а задачами оптимизации (optimization problems), в которых 
некоторое значение подлежит минимизации или максимизации. Однако ранее мы 
убедились, что обычно не составляет труда сформулировать задачу оптимизации 
как задачу принятия решения, которая не сложнее исходной.
 Кодирование
 Если абстрактная задача решается с помощью компьютерной программы, эк
 земпляры задач необходимо представить в виде, понятном этой программе. Ко
 дирование (encoding) множества 5 абстрактных объектов — это отображение е 
множества 5 на множество бинарных строк2. Например, всем известно, что нату
 ральные числа N = {0,1,2,3,4,...} кодируются строками {0,1,10,11,100,...}. 
В этой кодировке е(17) = 10001. Каждый, кто интересовался, как в компьютере 
представляются символы клавиатуры, вероятно, знаком с кодами ASCII. В коди
 ровке ASCII представление символа А выглядит как 1000001. В виде бинарной 
строки можно закодировать даже составной объект. Для этого конструируется 
комбинация, состоящая из представлений элементов, которые содержит в себе 
этот объект. Многоугольники, графы, функции, ориентированные пары, програм
 мы — все это можно закодировать бинарными строками.
 Таким образом, компьютерный алгоритм, который “решает” некоторую аб
 страктную задачу принятия решения, фактически принимает в качестве вход
 2Область значений отображения е — это необязательно бинарные строки; подойдет любое множество строк, 
состоящих из символов конечного алфавита, содержащего не менее двух символов.
1104
 Часть VII. Избранные темы
 ных данных закодированный экземпляр задачи. Назовем задачу, множество эк
 земпляров которой является множеством бинарных строк, конкретной (concrete 
problem). Говорят, что алгоритм решает (solves) конкретную задачу в течение 
времени 0(Т(п)), если для заданного экземпляра задачи г длиной п = |г| с его 
помощью можно получить решение за время 0(Т(п))3. Поэтому конкретная за
 дача разрешима в течение полиномиального времени (polynomial-time solvable), 
если существует алгоритм, позволяющий решить ее за время 0 (пк) для некото
 рой константы к.
 Теперь можно формально определить класс сложности Р (complexity class 
Р) как множество конкретных задач принятия решения, разрешимых за полино
 миальное время.
 С помощью кодирования абстрактные задачи можно отображать на конкрет
 ные. Данную абстрактную задачу принятия решения Q, отображающую множе
 ство экземпляров / на множество {0,1}, с помощью кодирования е : / —> {0,1}* 
можно свести к связанной с ней конкретной задаче принятия решения, которая 
будет обозначаться как e(Q)4. Если Q(i) Е {0,1} — решение экземпляра аб
 страктной задачи г Е I, то оно же является и решением экземпляра конкретной 
задачи е(г) Е {0,1}*. Заметим, что некоторые бинарные строки могут не пред
 ставлять осмысленного экземпляра абстрактной задачи. Для удобства мы будем 
предполагать, что любая такая строка произвольным образом отображается на 0. 
Таким образом, конкретная задача имеет те же решения, что и абстрактная, если 
ее экземпляры в виде бинарных строк представляют закодированные экземпляры 
абстрактной задачи.
 Было бы неплохо расширить определение разрешимости в течение полиноми
 ального времени для конкретных задач на абстрактные задачи, воспользовавшись 
в качестве связующего звена кодами; однако хотелось бы, чтобы определение не 
зависело от вида кодировки. Другими словами, эффективность решения задачи не 
должна зависеть от того, как она кодируется. К сожалению, на самом деле суще
 ствует достаточно сильная зависимость от кодирования. Например, предположим, 
что в качестве входных данных алгоритма выступает только целое число к и что 
время работы этого алгоритма равно 0(/с). Если число к передается как унарное 
(unary), т.е. в виде строки, состоящей из к единиц, то время работы алгоритма для 
входных данных длины п равно 0 (п) (выражается полиномиальной функцией). 
Если же используется более естественное бинарное представление числа к, то 
длина входной строки равна п = |_lg к\ + 1. В этом случае время работы алгорит
 ма равно Q(k) = 0(2П), т.е. зависит от объема входных данных как показательная 
функция. Таким образом, в зависимости от способа кодирования алгоритм может 
как выполняться за полиномиальное время, так и иметь время работы, превосхо
 дящее полиномиальное.
 Предполагается, что выходные данные алгоритма отделены от его входных данных. Поскольку для по
 лучения каждого выходного бита требуется по крайней мере один элементарный временной интервал, а всего 
имеется 0(Т(п)) временных интервалов, объем выходных данных представляет собой 0(Т(п)).
 4Мы обозначаем через {0,1}* множество всех строк, составленных из символов множества {0,1}.
Глава 34. NP-палнота
 1105
 Поэтому кодирование абстрактной задачи — достаточно важный вопрос для 
нашего понимания полиномиального времени. Невозможно вести речь о реше
 нии абстрактной задачи, не представив подробного описания кодировки. Тем не 
менее, если отбросить такие “дорогостоящие” коды, как унарные, само кодирова
 ние задачи на практике будет мало влиять на то, разрешима ли задача в течение 
полиномиального времени. Например, если представить целые числа в троичной 
системе счисления, а не в двоичной, это не повлияет на то, разрешима ли задача 
в течение полиномиального времени, поскольку целое число в троичной системе 
счисления можно преобразовать в целое число в двоичной системе счисления за 
полиномиальное время.
 Говорят, что функция / : {0,1}* —> {0,1}* вычислима за полиномиальное 
время (polynomial-time computable), если существует алгоритм А с полиномиаль
 ным временем работы, который для произвольных входных данных х £ {0,1}* 
возвращает выходные данные f(x). Для некоторого множества / экземпляров за
 дач две кодировки, е\ и ег, называются полиномиально связанными (polynomially 
related), если существуют такие две вычислимые в течение полиномиального вре
 мени функции, fi2 и /21, что для любого экземпляра г £ / выполняются равен
 ства / 12(61(1)) = ег(г) и /21(62(0 ) = ei(г)5. Другими словами, закодированную 
величину ег(г) можно вычислить на основе закодированной величины ei (г) с по
 мощью алгоритма с полиномиальным временем работы и наоборот. Если две ко
 дировки, е\ и в2, абстрактной задачи полиномиально связаны, то, как следует из 
представленной ниже леммы, разрешимость задачи в течение полиномиального 
времени не зависит от используемой кодировки.
 Лемма 34.1
 Пусть Q — абстрактная задача принятия решения, определенная на множестве 
экземпляров I, а е\ и ег - полиномиально связанные кодировки множества I. 
В этом случае e\(Q) £ Р тогда и только тогда, когда ег((5) £ Р.
 Доказательство. Достаточно доказать только прямое утверждение, поскольку 
обратное утверждение симметрично по отношению к прямому. Поэтому пред
 положим, что задачу е\(Q) можно решить за время 0(пк), где к — некоторая 
константа. Далее, предположим, что для любого экземпляра г задачи кодирова
 ние е\(г) можно получить из кодирования ег(г) за время 0(пс), где с — некото
 рая константа, ап = |ег(г)|- Чтобы решить задачу ег((5) с входными данными 
ег(г), сначала вычисляется ei (г), после чего алгоритм запускается для решения 
задачи e\(Q) с входными данными e\(i). Сколько времени это займет? Для пре
 образования кодировки требуется время 0(пс), поэтому выполняется равенство 
| ei (г) | = 0(пс), поскольку объем выходных данных алгоритма на последователь
5Кроме того, накладывается техническое требование, чтобы функции /12 и /21 “отображали неэкземпляры 
в неэкземпляры” Неэкземпляр (noninstance) в кодировке е — это строка х £ {0,1}*, такая, что не существует 
экземпляра г, для которого е(г) = х. Потребуем, чтобы равенство /12(х) - у выполнялось для каждого 
неэкземпляра х в кодировке ei, где у — некоторый неэкземпляр в кодировке ег, а равенство /21 (х') — у' — 
для каждого неэкземпляра х' в кодировке ег, где у' — некоторый неэкземпляр в кодировке е\.
1106
 Часть VII. Избранные темы
 ном компьютере не может превосходить по величине время его работы. Решение 
задачи с входными данными ei(г) занимает время 0(|ei(i)|fc) = (Э(пск), которое 
является полиномиальным, поскольку и с, и к — константы. 
■
 Таким образом, то, как закодированы экземпляры абстрактной задачи — в дво
 ичной системе счисления или в троичной, — не влияет на ее “сложность”, т.е. на 
то, разрешима ли она в течение полиномиального времени. Однако, если эти эк
 земпляры имеют унарную кодировку, сложность задачи может измениться. Что
 бы иметь возможность осуществлять преобразование независимым от кодировки 
образом, в общем случае предполагается, что экземпляры задачи закодированы 
в произвольном рациональном и сжатом виде, если специально не оговаривается 
противное. Точнее говоря, предполагается, что кодирование целых чисел поли
 номиально связано с их бинарным представлением и что кодирование ограни
 ченного множества полиномиально связано с его кодированием в виде списка 
элементов, заключенных в скобки и разделенных запятыми. (Одна из таких схем 
кодирования — ASCII.) Располагая таким “стандартным” кодом, можно получить 
рациональный код других математических объектов, таких как кортежи, графы 
и формулы. Для обозначения стандартного кода объекта этот объект будет за
 ключаться в угловые скобки. Таким образом, (G) обозначает стандартный код 
графа G.
 До тех пор, пока неявно используется код, полиномиально связанный с таким 
стандартным кодом, можно прямо говорить об абстрактных задачах, не ссылаясь 
при этом на какой-то отдельный код, зная, что выбор кода не повлияет на раз
 решимость абстрактной задачи в течение полиномиального времени. С этого мо
 мента в общем случае предполагается, что все экземпляры задачи представляют 
собой бинарные строки, закодированные с помощью стандартного кодирования, 
если явно не оговаривается противное. Кроме того, в большинстве случаев мы 
будем пренебрегать различием между абстрактными и конкретными задачами. 
Однако на практике читателю следует остерегаться тех возникающих на практи
 ке задач, в которых стандартное кодирование не очевидно и выбор кодирования 
имеет значение.
 Структура формальных языков
 Один из аргументов в пользу удобства задач принятия решения заключает
 ся в том, что для них можно использовать алгоритмы из теории формальных 
языков. Здесь стоит привести некоторые определения из этой теории. Алфавит 
£ (alphabet £) представляет собой конечное множество символов. Языком L 
(language L), определенным над множеством £, является произвольное множе
 ство строк, состоящих из символов из множества £. Например, если £ = {0,1}, 
то множество L = {10,11,101,111,1011,1101,10001,...} является языком би
 нарного представления простых чисел. Обозначим пустую строку (empty string) 
как е, а пустой язык (empty language) — как 0. Язык всех строк, заданных 
над множеством £, обозначается как £*. Например, если £ = {0,1}, то £* = 
{s, 0,1,00,01,10,11,000,...} — множество всех бинарных строк. Любой язык L 
над множеством £ является подмножеством множества £*.
Глава 34. NP-полнота
 1107
 Над языками можно определить ряд операций. Наличие таких операций из 
теории множеств, как объединение (union) и пересечение (intersection), непосред
 ственно следует из теоретико-множественной природы определения языков. До
 полнение (complement) языка L определим с помощью соотношения L = £* — L. 
Конкатенацией (concatenation) языков Ь\ и L2 является язык
 L — {х\Х2 : х\ £ L\ и Х2 € L2} ■
 Замыканием (closure), или замыканием Клини (Kleene star), языка L называется 
язык
 V = {5} U L U L2 U L3 U • ■ • ,
 где Lk — язык, полученный в результате /с-кратной конкатенации языка L с самим 
собой.
 С точки зрения теории языков множество экземпляров любой задачи принятия 
решения Q — это просто множество £*, где £ = {0,1}. Поскольку множество 
Q полностью характеризуется теми экземплярами задачи, в которых выдается 
ответ 1 (да), это множество можно рассматривать как язык L над множеством 
£ = {0,1}, где
 L = {х £ £* : Q{x) = 1} .
 Например, задаче принятия решения PATH соответствует язык
 к > 0 
PATH = {(G, u,v,k) : G = (V, Е) — неориентированный граф,
 и, v £ V,
 — целое число, и 
в G имеется путь из и в v, состоящий 
не более чем из к ребер} .
 (Для удобства иногда одно и то же имя (в данном случае это имя PATH) будет 
употребляться и для задачи принятия решения, и для соответствующего ей языка.)
 Схема формальных языков позволяет в сжатом виде выразить взаимоотноше
 ние между задачами принятия решения и решающими их алгоритмами. Говорят, 
что алгоритм А принимает (accepts) строку х€ {0,1}*, если для заданных вход
 ных данных х выход алгоритма А(х) равен 1. Язык, принимаемый (accepted) ал
 горитмом А, представляет собой множество строк L = {х £ {0,1}* : А{х) = 1}, 
т.е. множество строк, принимаемых алгоритмом. Алгоритм А отвергает (rejects) 
строку х, если А{х) = 0.
 Даже если язык L принимается алгоритмом А, этот алгоритм необязательно 
отвергает строку х £ L, предоставляемую в качестве его входных данных. На
 пример, алгоритм может быть организован в виде бесконечного цикла. Язык L 
распознается (decided) алгоритмом А, если каждая бинарная строка этого языка 
принимается алгоритмом А, а каждая бинарная строка, которая не принадлежит 
языку L, отвергается этим алгоритмом. Язык L принимается за полиномиаль
 ное время (accepted in polynomial time) алгоритмом А, если он принимается ал
 горитмом А и, кроме того, если существует такая константа к, что для любой 71- 
символьной строки х £ L алгоритм А принимает строку х за время 0(пк). Язык
1108
 Часть VII. Избранные темы
 L распознается за полиномиальное время (decided in polynomial time) алгорит
 мом А, если существует такая константа к, что для любой n-символьной строки 
х G {0,1}* алгоритм за время 0(пк) правильно выясняет, принадлежит ли стро
 ка х языку L. Таким образом, чтобы принять язык, алгоритму нужно заботиться 
только о строках языка L, а чтобы распознать язык, он должен корректно принять 
или отвергнуть каждую строку из множества {0,1}*.
 Как пример, — язык PATH может быть принят в течение полиномиального 
времени. Один из принимающих алгоритмов с полиномиальным временем рабо
 ты проверяет, закодирован ли объект G как неориентированный граф, убеждает
 ся, что и и v — его вершины, с помощью поиска в ширину находит в графе G 
кратчайший путь из вершины и к вершине v, а затем сравнивает количество ре
 бер в полученном кратчайшем пути с числом к. Если в объекте G закодирован 
неориентированный граф и путь из вершины и к вершине v содержит не более 
к ребер, алгоритм выводит значение 1 и останавливается. В противном случае 
он работает бесконечно долго. Однако такой алгоритм не распознает язык PATH, 
поскольку он не выводит явно значение 0 для экземпляров, длина кратчайшего 
пути в которых превышает к ребер. Предназначенный для задачи PATH алго
 ритм распознавания должен явно отвергать бинарные строки, не принадлежащие 
языку PATH. Для такой задачи принятия решения, как задача PATH, подобный 
алгоритм распознавания разработать легко: вместо того чтобы работать бесконеч
 но долго, если не существует пути из вершины и в вершину v, количество ребер 
в котором не превышает к, этот алгоритм должен выводить значение 0 и останав
 ливаться. Для других задач, таких как задача останова Тьюринга, принимающий 
алгоритм существует, а алгоритма распознавания не существует.
 Можно неформально определить класс сложности (complexity class) как мно
 жество языков, принадлежность к которому определяется мерой сложности 
(complexity measure), такой, как время работы алгоритма, определяющего, при
 надлежит ли данная строка х языку L. Фактическое определение класса сложно
 сти носит более технический характер6.
 Воспользовавшись описанным выше формализмом теории языков, можно дать 
альтернативное определение класса сложности Р:
 Р = {L С {0,1}* : существует алгоритм А, разрешающий язык L 
за полиномиальное время} .
 Фактически Р является также классом языков, которые могут быть приняты за 
полиномиальное время.
 Теорема 34.2
 Р = {L : L принимается алгоритмом с полиномиальным временем работы} .
 6Интересующийся читатель найдет дополнительную информацию в статье Хартманиса (Hartmanis) 
и Стирнса (Steams) [161].
Глава 34. NP-полнота
 1109
 Доказательство. Поскольку класс языков, которые распознаются алгоритмами 
с полиномиальным временем работы, представляет собой подмножество класса 
языков, которые принимаются алгоритмами с полиномиальным временем работы, 
остается лишь показать, что если язык L принимается алгоритмом с полиноми
 альным временем работы, то он также распознается алгоритмом с полиномиаль
 ным временем работы. Пусть L — язык, который принимается некоторым ал
 горитмом с полиномиальным временем работы А. Воспользуемся классическим 
“модельным” доказательством, чтобы сконструировать другой алгоритм с поли
 номиальным временем работы А !, который бы распознавал язык L. Поскольку 
алгоритм А принимает язык L за время 0(пк), где к — некоторая константа, су
 ществует такая константа с, что алгоритм А принимает язык L не более чем за 
спк шагов. Для любой входной строки х алгоритм А' моделирует спк шагов ал
 горитма А. После этого алгоритм А' проверяет поведение алгоритма А. Если он 
принял строку х, то алгоритм А' также принимает эту строку, выводя значение 1. 
Если же алгоритм А не принял строку х, то алгоритм А' отвергает эту строку, 
выводя значение 0. Накладные расходы алгоритма А', моделирующего алгоритм 
А, приводят к увеличению времени работы не более чем на полиномиальный 
множитель, поэтому А! — алгоритм с полиномиальным временем работы, распо
 знающий язык L. 
я
 Заметим, что доказательство теоремы 34.2 является неконструктивным. Для 
данного языка L G Р граница времени работы алгоритма А, который принимает 
язык L, на самом деле может быть неизвестна. Тем не менее известно, что такая 
граница существует, поэтому существует алгоритм А', способный проверить эту 
границу, даже если его не всегда удается легко найти.
 Упражнения
 34.1.1
 Определим задачу оптимизации LONGEST-PATH-LENGTH как отношение, 
связывающее каждый экземпляр задачи, состоящий из неориентированного 
графа и двух его вершин, с количеством ребер в самом длинном простом 
пути между этими двумя вершинами. Определим задачу принятия решения 
LONGEST-PATH = {{G, и, v, к) : G = {V,E) — неориентированный граф, 
u,v G V, к > 0 — целое число, и существует простой путь из и в v 
в G, состоящий как минимум из к ребер}. Покажите, что задачу оптимиза
 ции LONGEST-PATH-LENGTH можно решить за полиномиальное время тогда 
и только тогда, когда LONGEST-PATH-LENGTH G Р.
 34.1.2
 Дайте формальное определение задачи поиска самого длинного простого цикла 
в неориентированном графе. Сформулируйте соответствующую задачу принятия 
решения. Опишите язык, соответствующий этой задаче принятия решения.
1110
 34.1.3
 Часть VII. Избранные темы
 Разработайте формальное кодирование ориентированного графа в виде бинарных 
строк для представления с помощью матриц смежности. Выполните то же самое 
для представления с использованием списка смежных вершин. Докажите, что эти 
два представления полиномиально связаны.
 34.1.4
 Является ли алгоритм динамического программирования для решения дискрет
 ной задачи о рюкзаке, который предлагалось разработать в упр. 16.2.2, алгорит
 мом с полиномиальным временем работы? Обоснуйте свой ответ.
 34.1.5
 Покажите, что алгоритм, который содержит не больше некоторого постоянного 
количества вызовов процедуры с полиномиальным временем работы, сам работа
 ет полиномиальное время. Если же алгоритм делает полиномиальное число вы
 зовов такой процедуры, то общее время работы может быть экспоненциальным.
 34.1.6
 Покажите, что класс Р, который рассматривается как множество языков, за
 мкнут относительно операций объединения, пересечения, конкатенации, допол
 нения и замыкания Клини. Другими словами, если Li,L2 G Р, то L\ U L>2 G Р,
 Li П Ь2 G Р, Ь\Ь2 G Р, Zi G Р и L\ G Р.
 34.2. Проверка за полиномиальное время
 Теперь рассмотрим алгоритм, проверяющий принадлежность языку. Напри
 мер, предположим, что в данном экземпляре (G, и, v, к) задачи принятия решения 
PATH задан также путь р из вершины и в вершину v. Легко проверить, превы
 шает ли длина пути р величину к. Если она не превышает эту величину, путь р 
можно рассматривать как “сертификат” того, что данный экземпляр действитель
 но принадлежит PATH. Для задачи принятия решения PATH такой сертификат, 
по-видимому, не дает ощутимых преимуществ. В конце концов, эта задача при
 надлежит классу Р (фактически ее можно решить за линейное время), поэтому 
проверка принадлежности с помощью такого сертификата занимает столько же 
времени, сколько и решение задачи. А теперь исследуем задачу, для которой пока 
неизвестен алгоритм принятия решения с полиномиальным временем работы, но 
если имеется сертификат, то выполнить его проверку очень легко.
 Гамильтоновы циклы
 Задача поиска гамильтоновых циклов в неориентированном графе изучается 
уже более ста лет. Формально гамильтонов цикл (hamiltonian cycle) неориен
 тированного графа G = (V, Е) представляет собой простой цикл, содержащий 
все вершины множества V. Граф, содержащий гамильтонов цикл, называют га
Глава 34. NP-полнота
 (а) 
1111
 (б)
 Рис. 34.2. (а) Граф, представляющий вершины, ребра и грани додекаэдра; штриховкой показан 
один из его гамильтоновых циклов, (б) Двудольный граф с нечетным количеством вершин. Все 
такие графы негамильтоновы.
 мильтоновым (hamiltonian); в противном случае он является негамильтоновым 
(nonhamiltonian). Он назван так в честь У.Р. Гамильтона (W.R. Hamilton), который 
описал математическую игру на додекаэдре (рис. 34.2, (а)), в которой один игрок 
отмечает пятью булавками пять произвольных последовательных вершин, а дру
 гой игрок должен так дополнить этот путь, чтобы в результате получился путь, 
содержащий все вершины7. Додекаэдр является гамильтоновым графом, и один из 
гамильтоновых циклов показан на рис. 34.2, (а). Однако не все графы являются га
 мильтоновыми. Например, на рис. 34.2, (б) показан двудольный граф с нечетным 
количеством вершин. В упр. 34.2.2 предлагается доказать, что все такие графы 
негамильтоновы.
 Задачу о гамильтоновых циклах (hamiltonian-cycle problem), в которой нуж
 но выяснить, содержит ли граф G гамильтонов цикл, можно определить как фор
 мальный язык:
 HAM-CYCLE = {(G) : G является гамильтоновым графом} .
 Как алгоритм мог бы распознать язык HAM-CYCLE? Для заданного экземпля
 ра задачи (G) можно предложить алгоритм принятия решения, который сначала 
формировал бы список всех перестановок вершин графа G, а затем проверял 
каждую перестановку, — не является ли она гамильтоновым путем? Чему рав
7В письме от 17 октября 1856 года своему другу Джону Грейвзу (John Т. Graves) Гамильтон пишет [156, 
р. 624]: “Я обнаружил, что некоторых молодых людей весьма позабавила новая математическая игра, в которой 
один человек ставит пять кнопок в любые пять последовательных точек ... а другой игрок затем пытается 
вставить остальные пятнадцать кнопок (что согласно теории, изложенной в данном письме, всегда возможно) 
так, чтобы получился цикл, так, чтобы были охвачены все точки, и чтобы он закончился рядом с точкой, 
с которой начал противник”
1112
 Часть VII. Избранные темы
 нялось бы время работы такого алгоритма? При использовании “рационального” 
кодирования графа с использованием матриц смежности количество вершин т 
графа равно П(а/п), где п = |(G)| — длина кода графа G. Всего имеется т! воз
 можных перестановок вершин, поэтому время работы алгоритма равно П(т!) = 
П{у/п\) = П(2^), и оно не ведет себя в асимптотическом пределе как 0(пк) ни 
для какой константы к. 
Таким образом, время работы подобного прямолинейно
 го алгоритма не выражается полиномиальной функцией. Фактически, как будет 
доказано в разделе 34.5, задача о гамильтоновых циклах является NP-полной.
 Алгоритмы верификации
 Рассмотрим несколько упрощенную задачу. Предположим, что приятель сооб
 щил вам, что данный граф G — гамильтонов, а затем предложил доказать это, 
предоставив последовательность вершин, образующих гамильтонов цикл. Оче
 видно, в такой ситуации доказательство было бы достаточно простым: следует 
просто проверить, является ли предоставленный цикл гамильтоновым, убедив
 шись, что данная последовательность вершин является перестановкой множества 
всех вершин V и что каждое встречающееся в цикле ребро действительно при
 надлежит графу. Легко понять, что подобный алгоритм верификации можно ре
 ализовать так, чтобы время его работы было равно 0(п2), где п — длина графа 
G в закодированном виде. Таким образом, доказательство того, что гамильтонов 
цикл в графе существует, можно проверить за полиномиальное время.
 Определим алгоритм верификации (verification algorithm) как алгоритм А 
с двумя аргументами, один из которых является обычной входной строкой х, 
а второй — бинарной строкой у под названием сертификат (certificate). Двух
 аргументный алгоритм А верифицирует (verifies) входную строку х, если суще
 ствует сертификат у, такой, что А(х,у) = 1. Язык, верифицированный алгорит
 мом верификации А, представляет собой множество
 L = {х е {0,1}* : существует у е {0,1}*, такое, что А(х,у) = 1} .
 Интуитивно понятно, что алгоритм А верифицирует язык L, если для любой 
строки х G L существует сертификат у, позволяющий доказать с помощью алго
 ритма А, что х G L. Кроме того, для любой строки х ^ L не должно существовать 
сертификата, доказывающего, что х G L. Например, в задаче о гамильтоновом 
цикле сертификатом является список вершин некоторого гамильтонового цикла. 
Если граф гамильтонов, то гамильтонов цикл сам по себе предоставляет доста
 точно информации для верификации этого факта. В обратном случае, т.е. если 
граф не является гамильтоновым, не существует списка вершин, позволяющего 
обмануть алгоритм верификации и установить, что граф является гамильтоновым, 
так как алгоритм верификации выполняет тщательную проверку предложенного 
“цикла”, чтобы убедиться в его правильности.
Глава 34. NP-полнота
 1113
 Класс сложности NP
 Класс сложности NP (complexity class NP) — это класс языков, которые мож
 но верифицировать с помощью алгоритма с полиномиальным временем работы8. 
Точнее говоря, язык L принадлежит классу NP тогда и только тогда, когда суще
 ствуют алгоритм А с двумя входными параметрами и полиномиальным временем 
работы, а также константа с, такая, что
 L = {х G {0,1}* : существует сертификат у с \у\ — 0(|х|с), 
такой, что А{х,у) = 1} .
 При этом говорят, что алгоритм А верифицирует язык L за полиномиальное 
время.
 Из проведенного ранее обсуждения задачи о гамильтоновых циклах следует, 
что задача HAM-CYCLE G NP (всегда приятно знать, что некоторое важное мно
 жество — не пустое). Кроме того, если L G Р, то L G NP, поскольку при наличии 
алгоритма с полиномиальным временем работы, способного распознать язык L, 
алгоритм легко преобразовать в алгоритм верификации с двумя аргументами, ко
 торый просто игнорирует сертификат и принимает именно те входные строки, для 
которых он устанавливает принадлежность языку L. Таким образом, Р С NP.
 Неизвестно, выполняется ли равенство Р = NP, но, по мнению большинства 
исследователей, классы Р и NP — не одно и то же. Интуитивно понятно, что класс 
Р состоит из задач, которые решаются быстро. Класс же NP состоит из задач, ре
 шение которых можно быстро проверить. Возможно, из своего опыта вы уже 
знаете, что часто сложнее решить задачу с самого начала, чем проверить пред
 ставленное решение, особенно если вы ограничены во времени. Среди ученых, 
занимающихся теорией вычислительных систем, распространено мнение, что эта 
аналогия распространяется и на классы Р и NP, а следовательно, что класс NP 
содержит языки, не принадлежащие классу Р.
 Существует более веское, хотя и не окончательное, свидетельство того, что 
Р ф NP, — наличие языков, являющихся “NP-полными” Класс этих задач рас
 сматривается в разделе 34.3.
 Помимо вопроса о выполнении соотношения Р ф NP, остаются нерешенны
 ми и многие другие фундаментальные вопросы. На рис. 34.3 показаны некоторые 
возможные сценарии. Несмотря на интенсивные исследования в этой области, 
никому не удалось установить, замкнут ли класс NP относительно операции до
 полнения. Другими словами, следует ли из соотношения L G NP соотношение 
L G NP? Можно определить класс сложности co-NP (complexity class co-NP) 
как множество языков L, таких, что L G NP. Вопрос о том, замкнут ли класс 
NP относительно дополнения, можно перефразировать как вопрос о выполне
 нии равенства NP = co-NP. Поскольку класс Р замкнут относительно допол
8Название “NP” означает “nondeterministic polynomial time” (недетерминистическое полиномиальное вре
 мя). Класс NP изначально изучался в контексте недетерминизма, но нами используется более простое, хотя 
и эквивалентное понятие верификации. В книге Хопкрофта (Hopcroft) и Ульмана (Ullman) [179] хорошо изло
 жено понятие NP-полноты в терминах недетерминистических вычислительных моделей.
1114
 Часть VII. Избранные темы
 (а)
 (в) 
(б)
 (г)
 Рис. 34.3. Четыре возможных вида отношений между классами сложности. На представленной 
диаграмме полное включение одной области в другую указывает на отношение истинного подмно
 жества. (а) Р — NP = co-NP. Большинство исследователей полагают, что эта возможность наиме
 нее правдоподобна, (б) Если NP замкнут относительно дополнения, то NP = co-NP, но при этом 
не обязательно выполняется соотношение Р — NP. (в) Р — NP П co-NP, но NP не замкнут отно
 сительно дополнения, (г) NP ф co-NP иР / NP П co-NP. Большинство исследователей полагают 
эту возможность наиболее правдоподобной.
 нения (упр. 34.1.6), из упр. 34.2.9 следует, что Р С NP П co-NP. Однако, опять 
же, неизвестно, выполняется ли равенство Р = NP П co-NP, или в множестве 
NP П co-NP — Р существует ли хотя бы один язык.
 Таким образом, к сожалению, наше понимание того, какие именно взаимоот
 ношения существуют между классами Р и NP, далеко не полное. Тем не менее, 
несмотря на то что мы неспособны доказать сложность конкретной задачи, дока
 зав ее NP-полноту, можно получить о ней очень важную информацию.
 Упражнения
 34.2.1
 Рассмотрим язык GRAPH-ISOMORPHISM = {(GbG^) : G\ и G2 являются изо
 морфными графами}. Докажите, что GRAPH-ISOMORPHISM е NP, описав ал
 горитм с полиномиальным временем работы, позволяющий верифицировать этот 
язык.
 34.2.2
 Докажите, что если G — неориентированный двудольный граф с нечетным коли
 чеством вершин, то он не является гамильтоновым.
 34.2.3
 Покажите, что если HAM-CYCLE 6 Р, то задача о выводе списка вершин га- 
мильтонового цикла в порядке их обхода разрешима в течение полиномиального 
времени.
Глава 34. NP-полнота
 34.2.4
 1115
 Докажите, что класс языков NP замкнут относительно операций объединения, 
пересечения, конкатенации и замыкания Клини. Обсудите замкнутость класса NP 
относительно дополнения.
 34.2.5
 Покажите, что любой язык из класса NP можно распознать с помощью алгоритма, 
время работы которого равно 2°^п \ где к — некоторая константа.
 34.2.6
 Гамильтонов путь (hamiltonian path) графа представляет собой простой путь, 
который проходит через каждую вершину ровно по одному разу. Покажите, что 
язык НАМ-PATH = {(G, u,v) : в графе G имеется гамильтонов путь из и в v} 
принадлежит NP.
 34.2.7
 Покажите, что задачу о гамильтоновом пути в ориентированном ациклическом 
графе из упр. 34.2.6 можно решить в течение полиномиального времени. Сфор
 мулируйте эффективный алгоритм ее решения.
 34.2.8
 Пусть ф — булева формула, составленная из булевых входных переменных х\, 
Х2,... ,%к, операторов НЕ (->), И (А), ИЛИ (V) и скобок. Формула ф называет
 ся тавтологией (tautology), если для всех возможных наборов входных пере
 менных в результате вычисления формулы получается значение 1. Определите 
язык булевых формул TAUTOLOGY, состоящий из тавтологий. Покажите, что 
TAUTOLOGY G co-NP.
 34.2.9
 Докажите, что Р С co-NP.
 34.2.10
 Докажите, что если NP ф co-NP, то Р ф NP.
 34.2.11
 Пусть G — связный неориентированный граф, содержащий не менее трех вершин, 
a G3 — граф, полученный путем соединения всех пар вершин, которые связаны 
в графе G путем, длина которого не превышает трех ребер. Докажите, что граф 
G3 гамильтонов. (Указание: постройте остовное дерево графа G и воспользуйтесь 
индукцией.)
 34.3. NP-полнота и приводимость
 Пожалуй, одна из наиболее веских причин, по которым специалисты в области 
теории вычислительных систем полагают, что Р ф NP, — наличие класса “NP
1116
 Часть VII. Избранные темы
 полных” задач. Этот класс обладает замечательным свойством, которое состоит 
в том, что если хоть одну {любую) NP-полную задачу можно решить в течение 
полиномиального времени, то и все задачи этого класса обладают решением за 
полиномиальное время, т.е. Р = NP. Однако, несмотря на многолетние исследо
 вания, до сих пор не обнаружено ни одного алгоритма с полиномиальным време
 нем работы ни для одной NP-полной задачи.
 Язык HAM-CYCLE — одна из NP-полных задач. Если бы этот язык мож
 но было распознать за полиномиальное время, то каждую задачу из класса NP 
можно было бы решить в течение полиномиального времени. Фактически, если 
бы множество NP — Р оказалось непустым, то с уверенностью можно было бы 
утверждать, что HAM-CYCLE G NP — Р.
 В определенном смысле NP-полные языки — “самые сложные” в классе NP. 
В этом разделе будет показано, как относительная “сложность” языков сравни
 вается с помощью точного понятия под названием “приводимость за полиноми
 альное время” Затем приводится формальное определение NP-полных языков, 
а в конце раздела дается набросок доказательства того, что один из таких язы
 ков — CIRCUIT-SAT — является NP-полным. В разделах 34.4 и 34.5 с помощью 
понятия приводимости демонстрируется, что многие другие задачи также явля
 ются NP-полными.
 Приводимость
 Интуитивно понятно, что задачу Q можно свести к другой задаче Q', если лю
 бой экземпляр задачи Q “легко перефразируется” в экземпляр задачи Q', решение 
которого позволяет получить решение соответствующего экземпляра задачи Q. 
Например, задача решения линейных уравнений относительно неизвестной вели
 чины х сводится к задаче решения квадратных уравнений. Если задан экземпляр 
ах + b = 0, его можно преобразовать в уравнение Ох2 4- ах 4- b = 0, решение 
которого совпадает с решением уравнения ах 4- b — 0. Таким образом, если зада
 ча Q сводится к другой задаче Q', то решить задачу Q в некотором смысле “не 
сложнее”, чем задачу Q'.
 Возвращаясь к применению системы формальных языков для решения задач, 
будем говорить, что язык Ь\ приводим за полиномиальное время (polynomial
 time reducible) к языку L2 (что обозначается как L\ <р L2, если существует 
вычислимая за полиномиальное время функция / : {0,1}* —> (0,1}*, такая что 
для всех х G {0,1}*
 х G Ь\ тогда и только тогда, когда f{x) G L2 . 
(34.1)
 Функцию / называют функцией приведения (reduction function), а алгоритм F 
с полиномиальным временем работы, вычисляющий функцию /, — алгоритмом 
приведения (reduction algorithm).
 На рис. 34.4 проиллюстрировано приведение языка Ь\ к другому языку L2 
за полиномиальное время. Каждый язык — это подмножество множества (0,1}*. 
Функция приведения / обеспечивает такое отображение за полиномиальное вре
 мя, что если х G Ь\, то f(x) G L2. Кроме того, если х £ Ь\, то f(x) £ L2. Таким
Глава 34. NP-полнота
 1117
 Рис. 34.4. Иллюстрация к приведению за полиномиальное время языка Li к языку Ь2 с помощью 
функции приведения /. Для любых входных данных х Е {0,1}* вопрос о том, справедливо ли 
соотношение х Е Li, имеет тот же ответ, что и вопрос о справедливости f(x) Е Ь2.
 Да, iE l i >
 X-----^
 t M ,----------- 1Д!Ц
 JH. Лг hiTT 1 
' ' — —
 Нет, f(x) L2 
ai
 Нет, х $ L\
 Рис. 34.5. Доказательство леммы 34.3. Алгоритм F представляет собой алгоритм приведения, ко
 торый вычисляет функцию приведения / из Ь\ в L2 за полиномиальное время, а А2 — алгоритм 
с полиномиальным временем работы, разрешающий язык L2. Алгоритм А\ выясняет справедли
 вость х Е Li, используя F для преобразования любого входа х в f(x), а затем применяет А2, 
чтобы выяснить справедливость f(x) Е Ь2.
 образом, функция приведения отображает любой экземпляр х задачи принятия 
решения, представленной языком Ь\, на экземпляр f(x) задачи, представленной 
языком L2. Ответ на вопрос о том, принадлежит ли экземпляр f(x) языку L?, 
непосредственно позволяет ответить на вопрос о том, принадлежит ли экземпляр 
х языку L\.
 Приведение за полиномиальное время служит мощным инструментом доказа
 тельства того, что различные языки принадлежат классу Р.
 Лемма 34.3
 Если Li, Z/2 С {0,1}* являются языками, такими, что L\ <р L2, то из L2 G Р 
следует L\ е Р.
 Доказательство. Пусть 
— алгоритм с полиномиальным временем работы, 
который распознает язык L?, a F — алгоритм приведения с полиномиальным 
временем работы, вычисляющий функцию приведения /. Построим алгоритм А\ 
с полиномиальным временем работы, который распознает язык Ь\.
 На рис. 34.5 проиллюстрирован процесс построения алгоритма А \. Для задан
 ного набора входных данных х € {0,1}* в алгоритме А\ с помощью алгоритма 
F входные данные х преобразуются в f(x), после чего с помощью алгоритма А2 
проверяется, выполняется ли f(x) G L2. Результат работы алгоритма Л2 выво
 дится алгоритмом А\ в качестве ответа.
1118
 Часть VII. Избранные темы
 Корректность алгоритма А\ следует из условия (34.1). Алгоритм выполняется 
за полиномиальное время, поскольку и алгоритм F, и алгоритм А2 завершают 
свою работу за полиномиальное время (см. упр. 34.1.5). 
■
 NP-полнота
 Приведения за полиномиальное время служат формальным средством, поз
 воляющим показать, что одна задача по сложности такая же, как и другая, по 
крайней мере с точностью до полиномиально-временного множителя. То есть, 
если L\ <р Z/2, сложность языка L\ превышает сложность языка L2 не более чем 
на полиномиальный множитель. Вот почему отношение “меньше или равно” для 
приведения является мнемоническим. Теперь можно определить множество NP- 
полных языков, являющихся самыми сложными задачами класса NP.
 Язык L С (0,1}* является NP-полным (NP-complete), если
 1. L £ NP;
 2. V <р L для каждого V £ NP.
 Если язык L удовлетворяет свойству 2, но не обязательно удовлетворяет свой
 ству 1, говорят, что L — NP-сложный (NP-hard). Определим также класс NPC 
как класс NP-полных языков.
 Как показано в приведенной далее теореме, NP-полнота — ключевая проблема 
в разрешении вопроса о том, равны ли на самом деле классы Р и NP.
 Теорема 34.4
 Если некоторая NP-полная задача разрешима за полиномиальное время, то 
Р = NP. Это эквивалентно утверждению о том, что если какая-нибудь задача из 
класса NP не решается за полиномиальное время, то ни одна из NP-полных задач 
не решается за полиномиальное время.
 Доказательство. Предположим, что L £ Р и что L £ NPC. Для любого языка 
V £ NP согласно свойству 2 определения NP-полноты справедливо V <р L. 
Таким образом, в соответствии с леммой 34.3 мы также имеем V £ Р, что и до
 казывает первое утверждение теоремы.
 Чтобы доказать второе утверждение, заметим, что оно является противопо
 ложностью первого. 
■
 Вот почему при исследовании вопроса Р ф NP внимание акцентируется на 
NP-полных задачах. Большинство специалистов по теории вычислительных си
 стем полагают, что Р ф NP, так что отношения между классами Р, NP и NPC 
являются такими, как показано на рис. 34.6. Но если кто-нибудь додумается до 
алгоритма с полиномиальным временем работы, способного решить NP-полную 
задачу, тем самым будет доказано, что Р = NP. Однако поскольку до сих пор та
 кой алгоритм не обнаружен ни для одной NP-полной задачи, доказательство NP- 
полноты задачи является веским свидетельством того, что ее трудно решить.
Глава 34. NP-тюлнота
 1119
 NP
 NPC
 Рис. 34.6. Представление большинства специалистов в области информатики об отношении меж
 ду классами Р, NP и NPC: классы Р и NPC полностью содержатся в классе NP, и Р П NPC = 0.
 Выполнимость схем
 Хотя определение NP-полноты нами уже сформулировано, до сих пор не была 
доказана NP-полнота ни одной задачи. Как только это будет сделано хотя бы 
для одной задачи, с помощью приводимости в течение полиномиального времени 
можно будет доказать NP-полноту других задач. Таким образом, сосредоточим 
внимание на том, чтобы продемонстрировать NP-полноту задачи о выполнимости 
схем.
 К сожалению, для формального доказательства того, что задача о выполни
 мости схем является NP-полной, требуются технические детали, выходящие за 
рамки настоящей книги. Вместо этого дадим неформальное описание доказатель
 ства, основанного на базовом понимании булевых комбинационных схем.
 Булевы комбинационные схемы составляются из булевых комбинацион
 ных элементов, соединенных между собой проводами. Булев комбинационный 
элемент (boolean combinational element), или комбинационный логический эле
 мент, — это любой элемент сети, обладающий фиксированным количеством бу
 левых входов и выходов, который выполняет вполне определенную функцию. 
Булевы значения выбираются из множества {0,1}, где 0 представляет значение 
false, а 1 — значение true.
 Комбинационные логические элементы, используемые в задаче о выполнимо
 сти схем, вычисляют простую булеву функцию и известны как логические эле
 менты (logic gates). На рис. 34.7 показаны три основных логических элемента, 
использующихся в задаче о выполнимости схем: логический элемент НЕ (NOT 
gate), или инвертор (inverter), логический элемент И (AND gate) и логический 
элемент ИЛИ (OR gate). На элемент НЕ поступает одна бинарная входная вели
 чина (input) х, значение которой равно 0 или 1; элемент выдает бинарную выход
 ную величину (output) 2, значение которой противоположно значению входной ве
 личины. На каждый из двух других элементов поступают две бинарные входные 
величины, х и у, а в результате получается одна бинарная выходная величина, 2.
 Работу каждого логического и каждого комбинационного элемента можно опи
 сать таблицей истинности (truth table), представленной под каждым элементом 
на рис. 34.7. В таблице истинности для всех возможных наборов входных вели
 чин перечисляются выходные значения данного комбинационного элемента. На
 пример, в таблице истинности элемента ИЛИ показано, что если его входные 
значения х = 0 и у = 1, то выходное значение равно 2 = 1. Для обозначения
1120
 Часть VII. Избранные темы
 X
 0
 1- I X
 1
 0
 (а) 
X
 Ух Ау
 0 0 0
 0 1 0
 1 0 0
 1 1 1
 (б) 
X
 УхУ у
 0 0 0
 0 1 1
 1 0 1
 1 1 1
 (в)
 Рис. 34.7. Три основных логических элемента с бинарными входами и выходами. Для каждого 
элемента приведена таблица истинности, описывающая его работу, (а) Элемент НЕ. (б) Элемент И. 
(в) Элемент ИЛИ.
 функции НЕ используется символ для обозначения функции И — символ А, 
а для обозначения функции ИЛИ — символ V. Например, О V 1 = 1.
 Элементы И и ИЛИ можно обобщить на случай, когда входных значений боль
 ше двух. Выходное значение элемента И равно 1, если все его входные значения 
равны 1; в противном случае его выходное значение равно 0. Выходное значе
 ние элемента ИЛИ равно 1, если хотя бы одно из его входных значений равно 1; 
в противном случае его выходное значение равно 0.
 Булева комбинационная схема (boolean combinational circuit) состоит из одно
 го или нескольких комбинационных логических элементов, соединенных прово
 дами (wires). Провод может соединять выход одного элемента со входом другого, 
подавая таким образом выходное значение первого элемента на вход второго. На 
рис. 34.8 изображены две похожие одна на другую булевы комбинационные схе
 мы, отличающиеся лишь одним элементом. В части (а) рисунка также приводятся 
значения, которые передаются по каждому проводу для входа {х\ = 1, Х2 = 1, 
хз = 0). Хотя к одному и тому же проводу нельзя подключить более одного выво
 да комбинационного элемента, сигнал с него может поступать одновременно на 
входы нескольких элементов. Количество элементов, для которых данный провод 
предоставляет входные данные, называется его коэффициентом ветвления (fan
 out). Если к проводу не подсоединены выходы никаких элементов, он называется 
входом схемы (circuit input), получающим входные данные из внешних источ
 ников. Если к проводу не подсоединен вход ни одного элемента, он называется 
выходом схемы (circuit output), по которому выдаются результаты работы схемы. 
(Ответвление внутреннего провода также может выступать в роли выхода.) Чтобы 
определить задачу о выполнимости схемы, следует ограничиться рассмотрением 
схем с одним выходом, хотя на практике при разработке аппаратного оборудова
 ния встречаются логические комбинационные схемы с несколькими выводами.
 Логическая комбинационная схема не содержит циклов. Поясним это нагляд
 нее. Предположим, что схеме сопоставляется ориентированный граф G = (V, Е) 
с вершинами в каждом комбинационном элементе и к ориентированными реб
 рами для каждого провода, коэффициент разветвления которых равен к. Ориен
 тированное ребро (и, v) в этом графе существует, если провод соединяет выход
Глава 34. NP-полнота
 (а) 
1121
 (б)
 Рис. 34.8. Два экземпляра задачи о выполнимости схем, (а) Входные значения {х\ = 1, xi = 1, 
хз = 0) приводят к появлению на выходе 1. Таким образом, эта схема выполнима, (б) Никакие 
входные значения не приводят к появлению 1 на выходе данной схемы. Таким образом, эта схема 
невыполнима.
 элемента и со входом элемента v. Полученный в результате такого построения 
граф должен быть ациклическим.
 Будем рассматривать наборы значений (truth assignment) булевых перемен
 ных, соответствующих входам схемы. Говорят, что логическая комбинационная 
схема выполнима (satisfiable), если она имеет выполняющий набор (satisfying 
assignment): набор значений, в результате подачи которого на вход схемы ее вы
 ходное значение равно 1. Например, для схемы, изображенной на рис. 34.8, (а), 
выполняющий набор имеет вид (х\ = 1, ж 2 = 1, хз = 0); следовательно, эта 
схема выполнима. В упр. 34.3.1 предлагается показать, что никакое присваива
 ние значений величинам xi, Х2 и хз не приведет к значению 1 на выходе схемы, 
изображенной на рис. 34.8, (б). Эта схема всегда выдает значение 0, поэтому она 
невыполнима.
 Задача о выполнимости схемы (circuit-satisfiability problem) формулируется 
следующим образом: выполнима ли заданная логическая комбинационная схе
 ма, состоящая из элементов И, ИЛИ и НЕ. Однако, чтобы поставить этот во
 прос формально, необходимо принять соглашение по поводу стандартного кода 
для таких схем. Размер (size) логической комбинационной схемы определяется 
как сумма количества логических комбинационных элементов и числа проводов 
в схеме. Можно предложить код, используемый при представлении графов, ко
 торый отображает каждую заданную схему С на бинарную строку (С), длина 
которой выражается не более чем полиномиальной функцией от размера схемы. 
Таким образом, можно определить формальный язык
 CIRCUIT-SAT = {(С) : С является выполнимой булевой схемой} .
 Задача о выполнимости схем возникает при оптимизации компьютерного ап
 паратного обеспечения. Если какая-то подсхема рассматриваемой схемы всегда 
выдает значение 0, то ее можно заменить более простой подсхемой, в которой 
опускаются все логические элементы, а на выход подается постоянное значе
 ние 0. Было бы полезно иметь алгоритм решения этой задачи, время которого 
выражалось бы полиномиальной функцией.
 36 Зак. 3726
1122
 Часть VII. Избранные темы
 Чтобы проверить, разрешима ли данная схема С, можно попытаться просто пе
 ребрать все возможные комбинации входных значений. К сожалению, если в схе
 ме к входов, то количество таких комбинаций равно 2к. Если размер схемы С 
выражается полиномиальной функцией от к, то проверка всех комбинаций зани
 мает время Q(2k), а эта функция по скорости роста превосходит полиномиальную 
функцию9. Как уже упоминалось, имеется веский аргумент в пользу того, что не 
существует алгоритмов с полиномиальным временем работы, способных решить 
задачу о выполнимости схем, так как эта задача является NP-полной. Разобьем 
доказательство NP-полноты этой задачи на две части, соответствующие двум ча
 стям определения NP-полноты.
 Лемма 34.5
 Задача о выполнимости схем принадлежит классу NP.
 Доказательство. В этом доказательстве будет сформулирован алгоритм А 
с двумя входными параметрами и полиномиальным временем работы, способ
 ный проверять решение задачи CIRCUIT-SAT. В роли одного из входных па
 раметров алгоритма А выступает логическая комбинационная схема С (точнее, 
ее стандартный код). Вторым входным параметром является сертификат, который 
представляет собой булевы значения в проводах схемы. (См. другой сертификат, 
меньшего объема, в упр. 34.3.4.)
 Алгоритм А строится следующим образом. Для каждого логического элемен
 та схемы проверяется, что предоставляемое сертификатом значение на выходном 
проводе правильно вычисляется как функция значений на входных проводах. Да
 лее, если на выход всей цепи подается значение 1, алгоритм также выдает значе
 ние 1, поскольку величины, поступившие на вход схемы С, являются выполняю
 щим набором. В противном случае алгоритм выводит значение 0.
 Для любой выполнимой схемы С, выступающей в роли входного параметра 
алгоритма А, существует сертификат, длина которого выражается полиномиаль
 ной функцией от размера схемы С, и который приводит к тому, что на выход 
алгоритма А подается значение 1. Для любой невыполнимой схемы, выступа
 ющей в роли входного параметра алгоритма А, никакой сертификат не может 
заставить этот алгоритм поверить в то, что эта схема выполнима. Алгоритм А 
выполняется за полиномиальное время: при хорошей реализации достаточно бу
 дет линейного времени. Таким образом, задачу CIRCUIT-SAT можно проверить 
за полиномиальное время, и CIRCUIT-SAT G NP. 
■
 Вторая часть доказательства NP-полноты задачи CIRCUIT-SAT заключает
 ся в том, чтобы показать, что ее язык является NP-сложным. Другими словами, 
необходимо показать, что каждый язык класса NP приводится за полиномиальное
 9С другой стороны, если размер схемы С равен 0(2fc), то алгоритм со временем работы 0(2к) завершается 
по истечении времени, выражаемого полиномиальной функцией от размера схемы. Даже если Р ф NP, эта 
ситуация не противоречит NP-полноте задачи; из наличия алгоритма с полиномиальным временем работы для 
частного случая не следует, что такой алгоритм существует в общем случае.
Глава 34. NP-полнота
 1123
 время к языку CIRCUIT-SAT. Само доказательство этого факта содержит много 
технических сложностей, поэтому здесь приводится набросок доказательства, ос
 нованный на некоторых принципах работы аппаратного обеспечения компьютера.
 Компьютерная программа хранится в памяти компьютера в виде последова
 тельности инструкций. Типичная инструкция содержит код операции, которую 
нужно выполнить, адреса операндов в памяти и адрес, куда следует поместить 
результат. Специальная ячейка памяти под названием счетчик команд (program 
counter — PC) следит за тем, какая инструкция должна выполняться следующей. 
При извлечении очередной инструкции показание счетчика команд автоматически 
увеличивается на единицу. Это приводит к последовательному выполнению ин
 струкций компьютером. Однако в результате выполнения определенных инструк
 ций в счетчик команд может быть записано некоторое значение, что приводит 
к изменению обычного последовательного порядка выполнения. Таким образом 
организуются циклы и условные ветвления.
 В любой момент выполнения программы состояние вычислений в целом мож
 но представить содержимым памяти компьютера. (Имеется в виду область па
 мяти, состоящая из самой программы, счетчика команд, рабочей области и всех 
других битов состояния, с помощью которых компьютер ведет учет выполне
 ния программы.) Назовем любое отдельное состояние памяти компьютера кон
 фигурацией (configuration). Выполнение команд можно рассматривать как отоб
 ражение одной конфигурации на другую. Важно то, что аппаратное обеспечение, 
осуществляющее это отображение, можно реализовать в виде логической комби
 национной схемы, которая при доказательстве приведенной ниже леммы будет 
обозначена как М.
 Лемма 34.6
 Задача о выполнимости схем является NP-сложной.
 Доказательство. Пусть L — язык класса NP. Опишем алгоритм F с полиноми
 альным временем работы, вычисляющий функцию приведения /, которая отоб
 ражает каждую бинарную строку х на схему С = f(x), такую, что х G L тогда 
и только тогда, когда С е CIRCUIT-SAT.
 Поскольку L Е NP, должен существовать алгоритм А, верифицирующий язык 
L за полиномиальное время. В алгоритме F, который будет построен ниже, для 
вычисления функции приведения / будет использован алгоритм А с двумя вход
 ными параметрами.
 Пусть Т(п) — время работы алгоритма А в наихудшем случае для входной 
строки длиной п, k > 1 — константа, такая, что Т(п) = 0(пк), а длина серти
 фиката равна 0(пк). (В действительности время работы алгоритма А выражается 
полиномиальной функцией от полного объема входных данных, в состав которых 
входят и входная строка, и сертификат, но так как длина сертификата полино
 миальным образом зависит от длины п входной строки, время работы алгоритма 
полиномиально зависит от п.)
 Основная идея доказательства заключается в том, чтобы представить выпол
 нение алгоритма А в виде последовательности конфигураций. Как видно из
1124
 Часть VII. Избранные темы
 со
 с \
 с2
 Рис. 34.9. Последовательность конфигураций, полученных в ходе работы алгоритма А, на вход 
которого поступили строка х и сертификат у. Каждая конфигурация представляет состояние ком
 пьютера для одного шага вычислений и, помимо А, х и у, включает счетчик команд (PC), регистры 
процессора и рабочую память. За исключением сертификата у, исходная конфигурация со является 
константной. Булева комбинаторная схема М отображает каждую конфигурацию на очередную. 
Выход представляет собой некоторый предопределенный бит в рабочей памяти.
 рис. 34.9, каждую конфигурацию можно разбить на следующие части: программа 
алгоритма А, счетчик команд PC, регистры процессора, входные данные х, сер
 тификат у и рабочая память. Начиная с исходной конфигурации со, каждая кон
 фигурация ci с помощью комбинационной схемы М, аппаратно реализованной 
в компьютере, отображается на следующую за ней конфигурацию c*+i. Выходное 
значение алгоритма А (0 или 1) по завершении выполнения алгоритма А запи
 сывается в некоторую специально предназначенную для этого ячейку рабочей 
памяти. При этом предполагается, что после останова алгоритма А это значение 
не изменяется. Таким образом, если выполнение алгоритма состоит не более чем 
из Т(п) шагов, результат его работы хранится в определенном бите в с>г(пу
Глава 34. NP-полнота
 1125
 Алгоритм приведения F конструирует единую комбинационную схему, вычис
 ляющую все конфигурации, которые получаются из заданной входной конфигу
 рации. Идея заключается в том, чтобы “склеить” вместе все Т(п) копий схемы 
М. Выходные данные г-й схемы, выдающей конфигурацию с*, подаются непо
 средственно на вход (г + 1)-й схемы. Таким образом, эти конфигурации вместо 
того, чтобы храниться в памяти компьютера, просто передаются по проводам, 
соединяющим копии схемы М.
 Теперь вспомним, что должен делать алгоритм приведения F, время работы 
которого выражается полиномиальной функцией. Для заданных входных данных 
х он должен вычислить схему С = f(x), которая была бы выполнима тогда 
и только тогда, когда существует сертификат у, такой, что А(х,у) = 1. Когда 
алгоритм F получает входное значение х, он сначала вычисляет п = \х\ и кон
 струирует комбинационную схему С , состоящую из Т(п) копий схемы М. На 
вход схемы С подается начальная конфигурация, соответствующая вычислению 
А(х,у), а выходом этой схемы является конфигурация сТ(пу
 Схема С = f(x), которую создает алгоритм F, получается путем небольшой 
модификации схемы С. Во-первых, входы схемы С, соответствующие програм
 ме алгоритма А, начальному значению счетчика команд, входной величине х и на
 чальному состоянию памяти, соединяются проводами непосредственно с этими 
известными величинами. Таким образом, оставшиеся входы схемы соответствуют 
сертификату у. Во-вторых, игнорируются все выходы схемы, за исключением од
 ного бита конфигурации ст(п), соответствующего выходному значению алгоритма 
А. Сконструированная таким образом схема С для любого входного параметра у 
длиной 0(пк) вычисляет величину С{у) = А(х,у). Алгоритм приведения F, на 
вход которого подается строка х, вычисляет описанную выше схему С и выда
 ет ее.
 Докажем два свойства. Во-первых, покажем, что алгоритм F правильно вы
 числяет функцию приведения /, т.е. что схема С выполнима тогда и только тогда, 
когда существует сертификат у, такой, что А(х,у) = 1. Во-вторых, покажем, что 
работа алгоритма F завершается за полиномиальное время.
 Чтобы показать, что алгоритм F корректно вычисляет функцию приведения, 
предположим, что существует сертификат у длиной 0(пк), такой, что А(х, у) = 1. 
Тогда при подаче битов сертификата у на вход схемы С на выходе этой схемы по
 лучим значение С(у) = А(х, у) = 1. Таким образом, если сертификат существует, 
то схема С выполнима. Для доказательства в обратном направлении предполо
 жим, что схема С выполнима. Тогда существует такое входное значение у, что 
С(у) = 1, откуда можно заключить, что А(х, у) = 1. Итак, алгоритм F корректно 
вычисляет функцию приведения.
 Чтобы завершить набросок доказательства, осталось лишь показать, что время 
работы алгоритма F выражается полиномиальной функцией от п = |х|. Пер
 вое наблюдение, которое можно сделать, заключается в том, что количество би
 тов, необходимое для представления конфигурации, полиномиально зависит от п. 
Объем программы самого алгоритма А фиксирован и не зависит от длины его 
входного параметра х. Длина входного параметра х равна п, а длина сертифика
 та у — 0(пк). Поскольку работа алгоритма состоит не более чем из 0(пк) ша
1126
 Часть VII. Избранные темы
 гов, объем необходимой ему рабочей памяти также выражается полиномиальной 
функцией от п. (Предполагается, что эта область памяти непрерывна; в упр. 34.3.5 
предлагается обобщить доказательство для случая, когда ячейки, к которым об
 ращается алгоритм А, разбросаны по памяти большего объема, причем разброс 
ячеек имеет свой вид для каждого входного параметра х.)
 Размер комбинационной схемы М, реализующей аппаратную часть компью
 тера, выражается полиномиальной функцией от длины конфигурации, которая, 
в свою очередь, является полиномиальной от величины 0{пк) и, следовательно, 
полиномиально зависит от п. (В большей части такой схемы реализуется логика 
системы памяти.) Схема С состоит не более чем из t = 0{пк) копий М, по
 этому ее размер полиномиально зависит от п. Схему С для входного параметра 
х можно составить в течение полиномиального времени с помощью алгоритма 
приведения F, поскольку каждый этап построения длится в течение полиноми
 ального времени. 
■
 Таким образом, язык CIRCUIT-SAT не проще любого языка класса NP, а по
 скольку он относится к классу NP, он является NP-полным.
 Теорема 34.7
 Задача о выполнимости схем является NP-полной.
 Доказательство. Справедливость теоремы непосредственно следует из 
лемм 34.5 и 34.6, а также из определения NP-полноты. 
■
 Упражнения
 34.3.1
 Убедитесь, что схема, изображенная на рис. 34.8, (б), невыполнима.
 34.3.2
 Покажите, что отношение <р является транзитивным в отношении языков; дру
 гими словами, покажите, что из L\ < Р L2 и L2 <р L3 следует L\ <Р L3.
 34.3.3
 Докажите, что L <р L тогда и только тогда, когда L <р L.
 34.3.4
 Покажите, что в качестве сертификата в альтернативном доказательстве лем
 мы 34.5 можно использовать выполняющий набор. С каким сертификатом легче 
провести доказательство?
 34.3.5
 В доказательстве леммы 34.6 предполагается, что рабочая память алгоритма А 
занимает непрерывную область полиномиального объема. В каком месте доказа
 тельства используется это предположение? Покажите, что оно не приводит к по
 тере общности.
Глава 34. NP-полнота
 1127
 34.3.6
 Язык L называется полным (complete) в классе языков С относительно приведе
 ния за полиномиальное время, если L е С и L' <р L для всех V G С. Покажите, 
что множества 0 и {0,1}* — единственные языки класса Р, которые не являются 
полными в этом классе относительно приведения за полиномиальное время.
 34.3.7
 Покажите, что по отношению к приведениям за полиномиальное время 
(см. упр. 34.3.6) L является полным в классе NP тогда и только тогда, когда 
L является полным в co-NP.
 34.3.8
 Алгоритм приведения F в доказательстве леммы 34.6 строит схему С = f(x) на 
основе знаний о х, А и к. Профессор заметил, что алгоритм F получает в каче
 стве аргумента только х. В то же время об алгоритме А и константе к, с помощью 
которой выражается его время работы 0(пк), известно лишь то, что они суще
 ствуют (поскольку язык L принадлежит к классу NP), но не сами их значения. Из 
этого профессор делает вывод, что алгоритм F может не суметь построить схе
 му С и что язык CIRCUIT-SAT не обязательно NP-сложный. Объясните, какая 
ошибка содержится в рассуждениях профессора.
 34.4. Доказательства NP-полноты
 NP-полнота для задачи о выполнимости схем основана на непосредственном 
доказательстве соотношения L < р CIRCUIT-SAT для каждого языка L G NP. 
В этом разделе будет показано, как доказать NP-полноту языка без непосредствен
 ного приведения каждого языка из класса NP к заданному языку. Мы проиллю
 стрируем эту методику, доказав NP-полноту различных задач на выполнимость 
формул. Намного большее количество примеров применения этой методики со
 держится в разделе 34.5.
 Основой рассматриваемого в этом разделе метода, позволяющего доказать NP- 
полноту задачи, служит сформулированная ниже лемма.
 Лемма 34.8
 Если язык L такой, что V <Р L для некоторого L' G NPC, то L является NP- 
сложным. Если, кроме того, L G NP, то L G NPC.
 Доказательство. Поскольку язык V NP-полный, для всех L" G NP мы имеем 
L" <р V. Согласно предположению V <Р L. Таким образом, из транзитивности 
(упр. 34.3.2) имеем L" <Р L, что показывает, что задача L NP-сложная. Если 
L G NP, кроме того, L G NPC. 
■
 Другими словами, если язык L', о котором известно, что он — NP-полный, 
удается свести к языку L, тем самым к этому языку неявно сводится любой язык
1128
 Часть VII. Избранные темы
 класса NP. Таким образом, лемма 34.8 предоставляет метод доказательства NP- 
полноты языка L, состоящий из перечисленных ниже этапов.
 1. Доказывается, что L Е NP.
 2. Выбирается язык V , о котором известно, что он NP-полный.
 3. Описывается алгоритм, который вычисляет функцию /, отображающую каж
 дый экземпляр х Е {0,1}* языка L' на экземпляр f(x) языка L.
 4. Доказывается, что для функции / соотношение х Е L' выполняется тогда 
и только тогда, когда f(x) Е L для всех х Е {0,1}*.
 5. Доказывается, что время работы алгоритма, вычисляющего функцию /, поли
 номиальное.
 (На шагах 2-5 доказывается NP-сложность языка L.) Эта методология приве
 дения с помощью одного языка, для которого известно, что он NP-полный, на
 много проще, чем процесс, когда непосредственно демонстрируется, как выпол
 нить приведение для каждого языка из класса NP. Доказательство соотношения 
CIRCUIT-SAT Е NPC — первый важный шаг в этом направлении. Знание того 
факта, что задача о выполнимости схемы является NP-полной, позволяет доказы
 вать NP-полноту других задач намного проще. Более того, по мере расширения 
списка известных NP-полных задач появляется все больше возможностей для вы
 бора языков, которые будут использоваться для приведения.
 Выполнимость формулы
 Проиллюстрируем методику приведения, доказав NP-полноту задачи опреде
 ления, выполнима ли не схема, а формула. Именно для этой задачи впервые была 
доказана NP-полнота.
 Сформулируем задачу о выполнимости формулы (formula satisfiability) в тер
 минах языка SAT. Экземпляр языка SAT — это булева формула ф, состоящая из 
перечисленных ниже элементов.
 1. п булевых переменных: х\, Х2 , ■ ■ ■, хп.
 2. т булевых соединяющих элементов, в роли которых выступает произвольная 
логическая функция с одним или двумя входными значениями и одним вы
 ходным значением, например А (И), V (ИЛИ), 
(НЕ), —> (импликация), <-»■ 
(эквивалентность).
 3. Скобки. (Без потери общности предполагается, что лишние скобки не упо
 требляются, т.е. что на каждый логический соединяющий элемент приходится 
не более одной пары скобок.)
 Логическую формулу ф легко закодировать строкой, длина которой выражается 
полиномиальной функцией от п+т. Как и для логических комбинационных схем, 
набором значений (truth assignment) логической формулы ф называется множе
 ство значений переменных этой формулы, а выполняющим набором (satisfying 
assignment) — такой набор значений, при котором результат вычисления формулы
Глава 34. NP-полнота
 1129
 равен 1. Формула, для которой существует выполняющий набор, является выпол
 нимой (satisfiable). В задаче о выполнимости спрашивается, выполнима ли данная 
формула. В терминах формальных языков эта задача имеет вид
 SAT = {(</>):</> — выполнимая булева формула} .
 В качестве примера приведем формулу
 ф = ((xi ->• Х2) V 
Х3) V Х4)) Л -1X2 ,
 у которой имеется выполняющий набор (х\ = О, Х2 = 0, х3 = 1, х4 = 1), по
 скольку
 ф = ((О-ИЗ) V-.((-(m 1) V I)) Л-0 
= (1 V -.(1 V 1)) Л 1 
= (1 V0)A1 
= 1,
 (34.2)
 так что данная формула ф принадлежит языку SAT.
 Простейший прямолинейный алгоритм, позволяющий определить, выполнима 
ли произвольная булева формула, не укладывается в полиномиально-временные 
рамки. В формуле ф с п переменными всего имеется 2П возможных вариантов 
присваивания. Если длина (ф) выражается полиномиальной функцией от п, то 
для проверки каждого варианта присваивания потребуется время П(2П), т.е. оно 
выражается функцией, показатель роста которой превосходит полиномиальную 
функцию от длины (ф). Как видно из приведенной ниже теоремы, существование 
алгоритма с полиномиальным временем маловероятно.
 Теорема 34.9
 Задача о выполнимости булевых формул является NP-полной.
 Доказательство. Сначала докажем, что SAT G NP. Затем покажем, что язык 
SAT NP-сложный, для чего продемонстрируем справедливость соотношения 
CIRCUIT-SAT < р SAT. Согласно лемме 34.8 этого достаточно для доказатель
 ства теоремы.
 Чтобы показать, что язык SAT относится к классу NP, покажем, что сертифи
 кат, состоящий из выполняющего набора входной формулы ф, можно верифици
 ровать за полиномиальное время. В алгоритме верификации каждая содержащая
 ся в формуле переменная просто заменяется соответствующим значением, после 
чего вычисляется выражение, как это было проделано выше с уравнением (34.2). 
Эту задачу легко выполнить за полиномиальное время. Если в результате полу
 чится значение 1, то формула выполнима. Таким образом, первое условие лем
 мы 34.8 выполняется.
 Чтобы доказать, что язык SAT NP-сложный, покажем, что CIRCUIT-SAT <р 
SAT. Другими словами, покажем, как любой экземпляр задачи о выполнимости 
схемы можно за полиномиальное время привести к экземпляру задачи о выпол
 нимости формулы. С помощью индукции любую логическую комбинационную
изо
 Часть VII. Избранные темы
 Рис. 34.10. Приведение задачи о выполнимости схем к задаче о выполнимости формул; формула, 
полученная в результате выполнения алгоритма приведения, содержит переменные, соответствую
 щие каждому проводу схемы.
 схему можно выразить в виде булевой формулы. Для этого достаточно рассмот
 реть элемент, который выдает выходное значение схемы, и по индукции выразить 
каждое входное значение этого элемента в виде формул. Формула схемы получа
 ется путем выписывания выражения, в котором функция элемента применяется 
к формулам входов.
 К сожалению, такой незамысловатый метод не может стать основой приве
 дения за полиномиальное время. Как предлагается показать в упр. 34.4.1, общие 
вспомогательные формулы, соответствующие элементам, коэффициент ветвления 
которых равен 2 или превышает это значение, могут привести к экспоненциаль
 ному росту размера формулы. Таким образом, алгоритм приведения должен быть 
несколько остроумнее.
 Основная идея приведения задачи CIRCUIT-SAT к задаче SAT для схемы из 
рис. 34.8, (а) проиллюстрирована на рис. 34.10. Каждому проводу Хг схемы С со
 поставляется одноименная переменная формулы ф. Тогда надлежащее действие 
элемента можно выразить в виде небольшой формулы, включающей в себя пе
 ременные, которые соответствуют проводам, подсоединенным к этому элементу. 
Например, действие элемента И выражается формулой яю <->■ (x7AxqAxq). Будем 
называть каждую такую небольшую формулу подвыражением (clause).
 Формула ф, которая является результатом выполнения алгоритма приведения, 
получается путем конъюнкции (элемент И) выходной переменной схемы с вы
 ражением, представляющим собой конъюнкцию взятых в скобки подвыражений, 
описывающих действие каждого элемента. Для схемы, изображенной на рисунке, 
формула имеет следующий вид:
 Ф = Я'Ю Л(х4«-»-■яз)
 Л(^5
 Л (а*
 {xi V*2))-^х4)
 Л (х7 (xi ЛХ2 Л Х4))
 Л(а*
 Л(^9
 {хъ VЯб))
 (х6 V*7))
 Л{хю (х7 Л х8 Л х9))
Глава 34. NP-палнота
 1131
 Для заданной схемы С легко получить такую формулу ф за полиномиальное 
время.
 Почему схема С выполнима именно тогда, когда выполнима формула ф? Если 
у схемы С имеется выполняющий набор, то по каждому проводу схемы переда
 ется вполне определенное значение, и на выходе схемы получается значение 1. 
Поэтому набор значений, передающихся по проводам схемы, в формуле ф при
 ведет к тому, что значение каждого подвыражения в скобках в формуле ф будет 
равно 1, вследствие чего конъюнкция всех этих подвыражений будет равна 1. Вер
 но и обратное: если существует набор данных, для которого значение формулы ф 
равно 1, то схема С выполнима (это можно показать аналогично). Таким образом, 
показана справедливость соотношения CIRCUIT-SAT <Р SAT, что и завершает 
доказательство теоремы. 
■
 3-С№-выполнимость
 NP-полноту многих задач можно доказать путем приведения к ним задачи 
о выполнимости формул. Однако алгоритм приведения должен работать с лю
 быми входными формулами, что может привести к огромному количеству случа
 ев, подлежащих рассмотрению. Поэтому часто желательно выполнять приведение 
с помощью упрощенной версии языка булевых формул, чтобы уменьшить коли
 чество рассматриваемых случаев (конечно же, ограничивать язык настолько, что
 бы он стал распознаваемым за полиномиальное время, при этом нельзя). Одним 
из таких удобных языков является язык формул в 3-конъюнктивной нормальной 
форме 3-CNF-SAT.
 Определим задачу о 3-CNF выполнимости в описанных ниже терминах. Лите
 рал (literal) в булевой формуле — это входящая в нее переменная или отрицание 
этой переменной. Булева формула приведена к конъюнктивной нормальной фор
 ме (conjunctive normal form — CNF), если она имеет вид конъюнкции (элемент И) 
выражений (clauses), каждое из которых представляет собой дизъюнкцию (эле
 мент ИЛИ) одного или нескольких литералов. Булева формула выражена в 3- 
конъюнктивной нормальной форме (3-conjunctive normal form), или 3-CNF, ес
 ли в каждом подвыражении в скобках содержится ровно три различных литерала.
 Например, булева формула
 ( x i V —'Xi V -1X2) А (хз V Х2 V Х4) А (-1X1 V -1X3 V -1X4)
 принадлежит классу 3-CNF. Первое из трех подвыражений в скобках имеет вид 
( x i V ->xi V -1x2) и содержит три литерала — х\, ->xi и -1x2.
 В задаче 3-CNF-SAT спрашивается, выполнима ли заданная формула ф, при
 надлежащая классу 3-CNF. В приведенной ниже теореме показано, что алгоритма 
с полиномиальным временем работы, способного определять выполнимость даже 
таких простых булевых формул, скорее всего, не существует.
 Теорема 34.10
 Задача о выполнимости булевых формул в 3-конъюнктивной нормальной форме 
является NP-полной.
1132
 Часть VII. Избранные темы
 Рис. 34.11. Дерево, соответствующее формуле ф = ((xi —> хг) V ->((->xi 
хз) V Х4)) Л ->Х2.
 Доказательство. Рассуждения, которые использовались в теореме 34.9 для до
 казательства того, что SAT G NP, применимы и для доказательства того, что 
3-CNF-SAT G NP. Таким образом, согласно лемме 34.8 нам требуется лишь по
 казать, что SAT <р 3-CNF-SAT.
 Алгоритм приведения можно разбить на три основных этапа. На каждом этапе 
входная формула ф последовательно приводится к 3-конъюнктивной нормальной 
форме.
 Первый этап аналогичен тому, который был использован при доказательстве 
CIRCUIT-SAT <р SAT в теореме 34.9. Сначала для входной формулы ф кон
 струируется бинарное “синтаксическое” дерево, листья которого соответствуют 
литералам, а узлы — соединительным элементам. На рис. 34.11 показано такое 
синтаксическое дерево для формулы
 ф = ((zi -> Х2) V —•((—ia:i <г+ х3) V ж4)) Л ->Х2 . 
(34.3)
 Если входная формула содержит подвыражение, такое как дизъюнкция или конъ
 юнкция нескольких литералов, то, воспользовавшись свойством ассоциативности, 
можно провести расстановку скобок в выражении таким образом, чтобы каждый 
внутренний узел полученного в результате дерева содержал 1 или 2 дочерних уз
 ла. Теперь такое бинарное синтаксическое дерево можно рассматривать как схему, 
предназначенную для вычисления функции.
 Имитируя приведение из доказательства теоремы 34.9, введем переменные yi 
для выхода из каждого внутреннего узла. Затем перепишем исходную формулу ф 
как конъюнкцию переменной, соответствующей корню дерева, и выражений, опи
 сывающих операции в каждом узле. Для формулы (34.3) полученное в результате
Глава 34. NP-полнота
 выражение имеет следующий вид:
 А (2/1
 А (2/2 о (2/3 V 2/4))
 А (2/з о (xi -> х2))
 А (2/4 о ~■2/5)
 А (2/5 о (2/6 V х4))
 А (2/6 о (^ 1
 1133
 (2/2 А->х2))
 х 3))
 Обратите внимание, что полученная таким образом формула ф' представляет со
 бой конъюнкцию выражений 0', каждое из которых содержит не более трех ли
 тералов. Единственное требование, которое может оказаться нарушенным, со
 стоит в том, что каждое выражение в скобках должно быть дизъюнкцией трех 
литералов.
 На втором этапе приведения каждое подвыражение в скобках ф\ преобразует
 ся в конъюнктивную нормальную форму. Составим таблицу истинности формулы 
ф\ путем ее вычисления при всех возможных наборах значений ее переменных. 
Каждая строка такой таблицы соответствует одному из вариантов набора пере
 менных выражения и содержит сам вариант и результат вычисления исследуемо
 го подвыражения. С помощью элементов таблицы истинности, которые приводят 
к нулевому результату в формуле, можно записать формулу, эквивалентную под
 выражению ->0^, в дизъюнктивной нормальной форме (disjunctive normal form — 
DNF), которая представляет собой дизъюнкцию конъюнкций. Затем эта формула 
с помощью законов де Моргана-|(о Л Ъ) = -io V ->b ,
 ~>(а V 6) = - <а Л —<6
 преобразуется в CNF-формулу ф" путем замены всех литералов их дополнениями 
и замены операций дизъюнкций и конъюнкций одна другой.
 В качестве примера преобразуем выражение ф[ = (у\ о (у2 А ->х2)) в CNF. 
Таблица истинности для этой формулы представлена на рис. 34.12. DNF-формула, 
эквивалентная выражению -<ф[, имеет вид
 (2/1 А 2/2 A х2) V (у 1 А —ij/2 А х2) V (yi A -iy2 А ->х2) V (—«j/i А у2 А ^х2) .
 Обращая и применяя законы де Моргана, получим CNF-формулу
 Ф\ = (~*2/1 v ~*2/2 V ^х2) А (—<2/1 V у2 V -^х2)
 A (-«yi V у2 V х2) A (yi V -пу2 V х2) ,
 которая эквивалентна исходной формуле ф[.
 Теперь каждое подвыражение ф\, содержащееся в формуле ф', преобразовано 
в CNF-формулу ф'[, так что ф' эквивалентно CNF-формуле ф", состоящей из конъ
1134
 Рис. 34.12. Таблица истинности для выражения (j/i 
Часть VII. Избранные темы
 1
 У\ У2 Х2 (у\ о (У2 А ->Х2))
 1
 1
 1
 1
 1
 0
 0
 1
 0
 0
 1
 1
 0
 1
 0
 1
 0
 0 0 1
 0 0 0
 0
 1
 0
 0
 1
 0
 1
 1
 (3/2 Л -1x2)).
 юнкции выражений ф". Кроме того, каждое подвыражение формулы ф" содержит 
не более трех литералов.
 На третьем (и последнем) этапе приведения формула преобразуется таким об
 разом, чтобы в каждой паре скобок содержалось ровно три различных литерала. 
Полученная в результате окончательная 3-CNF формула ф'" составлена из под
 выражений, входящих в CNF-формулу ф". В ней также используются две вспо
 могательные переменные, которые будут обозначаться как р и q. Для каждого 
подвыражения Ci из формулы ф” в формулу ф'" включаются следующие подвы
 ражения.
 • Если Ci содержит три различных литерала, то это подвыражение включается 
в формулу фш в неизменном виде.
 • Если подвыражение Ci содержит два различных литерала, т.е. если Ci = 
{h V I2 ), где li и I2 — литералы, то в качестве подвыражения в формулу ф'" 
включается выражение (/i V 1% V р) A (/i V I2 V ~^р). Литералы р и 
служат 
лишь для того, чтобы удовлетворялось требование о наличии в каждом подвы
 ражении в скобках ровно трех разных литералов: когда р = 0 или р = 1, одно 
из подвыражений эквивалентно V I2 , а второе — единице, что и обеспечива
 ет тождественность первому из упомянутых подвыражений при применении 
операции И.
 • Если подвыражение Ci содержит ровно один литерал I, то вместо него в каче
 стве подвыражения в формулу ф"' включается подвыражение (lVpVq)A(lV 
р V -Iq) A (I V ~>р V q) A (I V ~^р V -1 q). При любых значениях переменных р и q 
одно из четырех подвыражений равно I, а прочие три равны единице.
 Проверив каждый из описанных выше трех этапов, можно убедиться, что 
3-CNF формула ф'" выполнима тогда и только тогда, когда выполнима формула ф. 
Как и в случае приведения задачи CIRCUIT-SAT к задаче SAT, составление на 
первом этапе формулы ф' из формулы ф не влияет на выполнимость. На втором 
этапе конструируется CNF-формула ф", алгебраически эквивалентная формуле ф'. 
На третьем этапе конструируется 3-CNF формула ф'", результат которой эквива
 лентен формуле ф", поскольку присваивание любых значений переменным р и q 
приводит к формуле, алгебраически эквивалентной формуле ф".
Глава 34. NP-палнота
 1135
 Необходимо также показать, что приведение можно выполнить за полиноми
 альное время. В ходе конструирования формулы ф' по формуле ф приходится 
добавлять не более одной переменной и одного подвыражения на каждый соеди
 нительный элемент формулы ф. В процессе построения формулы ф" из формулы 
ф' в формулу ф" добавляется не более восьми подвыражений для каждого под
 выражения в скобках из формулы ф', поскольку каждое подвыражение в этой 
формуле содержит не более трех переменных и таблица его истинности состоит 
не более чем из 23 = 8 строк. В ходе конструирования формулы ф'" из формулы 
ф" в формулу ф'" добавляется не более четырех подвыражений на каждое подвы
 ражение формулы ф". Таким образом, размер полученной в результате формулы 
ф'" выражается полиномиальной функцией от длины исходной формулы. Следо
 вательно, каждый этап можно легко выполнить за полиномиальное время. 
■
 Упражнения
 34.4.1
 Рассмотрите простое приведение “в лоб” (время работы которого не выражается 
полиномиальной функцией) из теоремы 34.9. Опишите схему размера п, размер 
которой после преобразования этим методом превратится в формулу, размер ко
 торой выражается показательной функцией от п.
 34.4.2
 Приведите 3-CNF формулу, которая получится в результате применения метода, 
описанного в теореме 34.10, к формуле (34.3).
 34.4.3
 Профессор предложил показать, что SAT <р 3-CNF-SAT, лишь с помощью ме
 тода с использованием таблицы истинности, описанного в доказательстве теоре
 мы 34.10, исключая при этом другие этапы. Другими словами, профессор пред
 ложил взять булеву формулу ф, составить таблицу истинности для ее перемен
 ных, получить из нее формулу в 3-DNF, эквивалентную ->ф, после чего составить 
логическое отрицание полученной формулы и с помощью законов де Моргана 
получить формулу 3-CNF, эквивалентную формуле ф. Покажите, что в резуль
 тате применения такой стратегии не удается выполнить приведение формулы за 
полиномиальное время.
 34.4.4
 Покажите, что задача определения того, является ли тавтологией данная формула, 
является полной в классе co-NP. (Указание: см. упр. 34.3.7).
 34.4.5
 Покажите, что задача определения выполнимости булевых формул в дизъюнктив
 ной нормальной форме разрешима в течение полиномиального времени.
 34.4.6
 Предположим, что кто-то разработал алгоритм с полиномиальным временем вы
 полнения, позволяющий решить задачу о выполнимости формул. Опишите, как
1136
 Часть VII. Избранные темы
 с помощью этого алгоритма в течение полиномиального времени находить вы
 полняющие наборы.
 34.4.7
 Пусть 2-CNF-SAT — множество выполнимых булевых формул в CNF, у кото
 рых каждое выражение в скобках содержит ровно по два литерала. Покажите, 
что 2-CNF-SAT £ Р. Постарайтесь, чтобы ваш алгоритм был как можно более 
эффективным. (Указание: воспользуйтесь тем, что выражение х У у эквивалентно 
выражению ->х -» у. Приведите задачу 2-CNF-SAT к задаче на ориентированном 
графе, имеющей эффективное решение.)
 34.5. 
NP-полные задачи
 NP-полные задачи возникают в различных областях: в булевой логике, в тео
 рии графов, в арифметике, при разработке сетей, в теории множеств и разбиений, 
при хранении и поиске информации, при планировании вычислительных процес
 сов, в математическом программировании, в алгебре и теории чисел, при созда
 нии игр и головоломок, в теории автоматов и языков, при оптимизации программ, 
в биологии, в химии, физике и т.п. В настоящем разделе с помощью методики 
приведения будет доказана NP-полнота различных задач, возникающих в теории 
графов и при разбиении множеств.
 На рис. 34.13 приведена схема доказательства NP-полноты, которая использу
 ется в этом разделе и в разделе 34.4. Для каждого из представленных на рисун
 ке языков NP-полнота доказывается путем его приведения к языку, на который 
указывает идущая от этого языка стрелка. В качестве корневого выступает язык 
CIRCUIT-SAT, NP-полнота которого доказана в теореме 34.7.
 34.5.1. Задача о клике
 Клика (clique) неориентированного графа G = (V,E) — это подмножество 
V С V вершин, каждая пара в котором связана ребром из множества Е. Другими 
словами, клика — это полный подграф графа G. Размер (size) клики — это коли
 чество содержащихся в этом подграфе вершин. Задача о клике (clique problem) — 
это задача оптимизации, в которой требуется найти клику максимального размера, 
содержащуюся в заданном графе. В соответствующей задаче принятия решения 
спрашивается, содержится ли в графе клика заданного размера к. Формальное 
определение языка имеет вид
 CLIQUE = {(G, к) : G — граф, содержащий клику размером к} .
 Простейший алгоритм определения того, содержит ли граф G = (V,E) с |F| 
вершинами клику размером к, заключается в том, чтобы перечислить все к-эле
 ментные подмножества множества V и проверить, образует ли каждое из них 
клику. Время работы этого алгоритма равно П(/с2(^ )) и является полиномиаль
Глава 34. NP-полнота
 1137
 (circuit-sat)
 ( sat)
 3-CNF-SAf)
 (CLIQUE )
 '
 '
 (VERTEX-COVER)
 _
 (ham-cycle)
 ( tsp
 I subset-sum)
 Рис. 34.13. Схема доказательств NP-полноты задач, рассматриваемых в разделах 34.4 и 34.5. Все 
доказательства в конечном итоге сводятся к приведению NP-полной задачи CIRCUIT-SAT к рас
 сматриваемой.
 ным, если к — константа. Однако в общем случае величина к может достигать 
значения, близкого к |V| /2, и в этом случае время работы алгоритма превышает 
полиномиальное. Есть основания предполагать, что эффективного алгоритма для 
задачи о клике не существует.
 Теорема 34.11
 Задача о клике является NP-полной.
 Доказательство. Чтобы показать, что CLIQUE € NP, для заданного графа 
G = (V, Е), воспользуемся множеством V' С. V вершин клики в качестве серти
 фиката для данного графа. Проверить, является ли множество вершин V кликой, 
можно в течение полиномиального времени, проверяя для каждой пары вершин 
и, v € V , принадлежит ли соединяющее их ребро (и, v) множеству Е.
 Теперь докажем, что 3-CNF-SAT <р CLIQUE, откуда следует, что задача 
о клике является NP-сложной. То, что этот результат удается доказать, может 
показаться удивительным, потому что, на первый взгляд, логические формулы 
мало напоминают графы.
 Алгоритм приведения начинается с экземпляра задачи 3-CNF-SAT. Пусть ф = 
Ci А Сг А • • • А С/с — булева формула из класса 3-CNF с к подвыражениями. Каждое 
подвыражение СТ при г = 1,2,..., к содержит ровно три различных литерала — 
1\, Щ и /д. Сконструируем такой граф G, чтобы формула ф была выполнима тогда 
и только тогда, когда граф G содержит клику размера к.
 Граф G = (V, Е) мы строим следующим образом. Для каждого подвыражения 
Ст — (l\ V Щ V /3) в ф помещаем тройку вершин, v\, и v^, в V. Вершины v\ 
и Vj соединяются ребром, если справедливы оба следующих утверждения:
 • и Vs- находятся в разных тройках, т.е. г ф s\ и
 • их литералы совместимы, т.е. 1\ не является отрицанием I?.
1138
 С-2 = -'Xi V Х2 V Хз
 Часть VII. Избранные темы
 С\ = XI V ->Х2 V ->хз
 Сз = XI V х2 V Х3
 Рис. 34.14. Граф G, полученный в процессе приведения 3-CNF-SAT к задаче CLIQUE из 3-CNF- 
формулы ф = С\ A Ci А Сз, где С\ = (xi V -<Х2 V -<хз), Ci = (-<xi V хг V хз) и Сз = (xi V 
Х2 V хз). Выполняющий набор формулы включает хг = 0, хз = 1, a xi может быть как нулем, так 
и единицей. Этот набор выполняет С\ благодаря ->Х2, и Ci и Сз благодаря хз, соответствуя клике 
из выделенных светлой штриховкой вершин.
 Такой граф легко построить для формулы ф за полиномиальное время. В качестве 
примера на рис. 34.14 приведен граф G, соответствующий формуле
 ф= (х 1 V ~>х2 V ->х3) Л (~>х1 V х2 V Хз) A (zi V x2V х3) .
 Необходимо показать, что это преобразование формулы ф в граф G является 
приведением. Во-первых, предположим, что для формулы ф имеется выполняю
 щий набор. Тогда каждое подвыражение Сг содержит не менее одного литерала 
Ц, значение которого равно единице, и каждый такой литерал соответствует вер
 шине v\. В результате извлечения такого “истинного” литерала из каждого под
 выражения получается множество V , состоящее из к вершин. Мы утверждаем, 
что V — клика. Для любых двух вершин v^,Vj £ V', где г ф s, оба соответствую
 щих литерала, 1\ и Ц, при данном выполняющем наборе равны единице, поэтому 
они не могут быть отрицаниями один другого. Таким образом, в соответствии со 
способом построения графа G ребро 
принадлежит множеству Е.
 Проведем обратные рассуждения. Предположим, что граф G содержит клику 
V размером к. Ни одно из ее ребер не соединяет вершины одной и той же трой
 ки, поэтому клика V содержит ровно по одной вершине каждой тройки. Каждому 
литералу /[, такому, что v\ € V', можно присвоить значение 1, не опасаясь того, 
что оно будет присвоено как литералу, так и его дополнению, поскольку граф 
G не содержит ребер, соединяющих противоречивые литералы. Каждое подвы
 ражение является выполнимым, поэтому выполнима и формула ф. (Переменным, 
которым не соответствует ни одна вершина клики, можно присваивать произволь
 ные значения.) 
■
Глава 34. NP-полнота
 1139
 В примере, представленном на рис. 34.14, выполняющий набор для формулы 
ф имеет вид Х2 = 0 и хз = 1. Соответствующая клика размером к = 3 состоит 
из вершин, отвечающих литералу -1X2 из первого подвыражения в скобках, ли
 тералу хз из второго выражения в скобках и литералу хз из третьего выражения 
в скобках. Поскольку клика не содержит вершин, соответствующих литералу х\ 
или литералу ->х\, переменная х\ в выполняющем наборе может принимать как 
значение 0, так и значение 1.
 Заметим, что при доказательстве теоремы 34.11 произвольный экземпляр за
 дачи 3-CNF-SAT был сведен к экземпляру задачи CLIQUE, обладающему опре
 деленной структурой. Может показаться, что принадлежность задачи CLIQUE 
категории NP-сложных была доказана лишь для графов, все вершины которых 
можно разбить на тройки, причем таких, в которых отсутствуют ребра, соеди
 няющие вершины одной и той же тройки. В самом деле, NP-сложность задачи 
CLIQUE была показана только для этого ограниченного случая, однако этого до
 казательства достаточно, чтобы сделать вывод о NP-сложности этой задачи для 
графа общего вида. Почему? Дело в том, что из наличия алгоритма с полиноми
 альным временем работы, решающего задачу CLIQUE с графами общего вида, 
следует существование такого алгоритма решения этой задачи с графами, имею
 щими ограниченную структуру.
 Однако обратный подход — приведение экземпляров задачи 3-CNF-SAT, об
 ладающих какой-то особой структурой, к экземплярам задачи CLIQUE общего 
вида, был бы недостаточен. Почему? Может случиться так, что экземпляры зада
 чи 3-CNF-SAT, с помощью которых выполняется приведение, окажутся слишком 
“легкими”, и к задаче CLIQUE приводится задача, не являющаяся NP-сложной.
 Заметим также, что для приведения используется экземпляр задачи 
3-CNF-SAT, но не ее решение. Было бы ошибкой основывать приведение за по
 линомиальное время на знании того, выполнима ли формула ф, поскольку неиз
 вестно, как получить эту информацию за полиномиальное время.
 34.5.2. 
Задача о вершинном покрытии
 Вершинное покрытие (vertex cover) неориентированного графа G = (V, Е) — 
это такое подмножество V С V, что если (и, v) £ Е, то либо и £ V', либо v £ V', 
либо справедливы оба эти соотношения. Другими словами, каждая вершина “по
 крывает” инцидентные ребра, а вершинное покрытие графа G — это множество 
вершин, покрывающих все ребра из множества Е. Размером (size) вершинного 
покрытия называется количество содержащихся в нем вершин. Например, граф, 
изображенный на рис. 34.15,(6), имеет вершинное покрытие {w, zj размером 2.
 Задача о вершинном покрытии (vertex-cover problem) заключается в том, что
 бы найти в заданном графе вершинное покрытие минимального размера. Пере
 формулируем эту задачу оптимизации в виде задачи принятия решения, в которой 
требуется определить, содержит ли граф вершинное покрытие заданного разме
 ра к. Определим язык
 VERTEX-COVER = {(G, к) : граф G имеет вершинное покрытие размером к} .
1140
 Часть VII. Избранные темы
 Рис. 34.15. Приведение CLIQUE к VERTEX-COVER (а) Неориентированный граф G = (V, Е) 
с кликой V' = {u,v,x,y}. (б) Полученный алгоритмом приведения граф G, обладающий вершин
 ным покрытием V — V' = {ш, г).
 В сформулированной ниже теореме доказывается, что эта задача является NP- 
полной.
 Теорема 34.12
 Задача о вершинном покрытии является NP-полной.
 Доказательство. Сначала покажем, что VERTEX-COVER € NP. Предполо
 жим, что заданы граф G = (V, Е) и целое число к. В качестве сертификата выбе
 рем само вершинное покрытие V' С V. В алгоритме верификации проверяется, 
что \V'\ = к, а затем для каждого ребра (и, v) £ Е проверяется, что и £ V' или 
v £ V . Такую верификацию можно выполнить непосредственно, как описано 
выше, за полиномиальное время.
 Докажем, что задача о вершинном покрытии NP-сложная, для чего покажем 
справедливость соотношения CLIQUE <р VERTEX-COVER. Это приведение 
основывается на понятии “дополнения” графа. Дополнение (complement) дан
 ного неориентированного графа G = (V, Е) определяется как G = (V, Е), где 
Е = {(и, и) : и, v £ V, и ф v, и (u, v) ^ Е}. Другими словами, G — это граф, со
 держащий те ребра, которых нет в графе G. На рис. 34.15 показаны граф и его 
дополнение, а также проиллюстрировано приведение задачи CLIQUE к задаче 
VERTEX-COVER.
 Алгоритм приведения в качестве входных данных получает экземпляр (G, к) 
задачи о клике. В этом алгоритме вычисляется дополнение G, что легко осуще
 ствить за полиномиальное время. Выходом алгоритма приведения является экзем
 пляр (G, \V\-k) задачи о вершинном покрытии. Чтобы завершить доказательство, 
покажем, что это преобразование действительно является приведением: граф G 
содержит клику размера к тогда и только тогда, когда граф G имеет вершинное 
покрытие размером |V| — к.
 Предположим, что граф G содержит клику V' С V размером \У\ = к. Мы 
утверждаем, что V — V' — вершинное покрытие графа G. Пусть (и, v) — произ
 вольное ребро из множества Е. Тогда (и, г;) ^ Е, из чего следует, что хотя бы одна 
из вершин и и v не принадлежит множеству V , поскольку каждая пара вершин 
из V соединена ребром, входящим в множество Е. Эквивалентно хотя бы одна
Глава 34. NP-полнота
 1141
 из вершин и и v принадлежит множеству V — V', а следовательно, ребро (u, v) 
покрывается этим множеством. Поскольку ребро (u,v) выбрано из множества Е 
произвольным образом, каждое ребро из этого множества покрывается верши
 ной из множества V — V . Таким образом, множество V — V, размер которого — 
\V\ — к, образует вершинное покрытие графа G.
 Справедливо и обратное. Предположим, что граф G имеет вершинное покры
 тие V С V, где |V'\ = \V\ — к. Тогда для всех пар вершин u,v €. V из (u, v) Е Е 
следует, что или u Е V, или v Е V7, или справедливы оба эти утверждения. 
Обращение следствия дает, что для всех пар вершин и, v Е V, если и ^ V' 
и v £ V', то (и, v) Е Е. Другими словами, V — V' — это клика, а ее размер равен 
\V\ - \V'\ = к. 
и
 Поскольку задача VERTEX-COVER является NP-полной, маловероятным 
представляется то, что удастся разработать алгоритм поиска вершинного покры
 тия минимального размера за полиномиальное время. Однако в разделе 35.1 пред
 ставлен “приближенный алгоритм” с полиномиальным временем работы, позво
 ляющий находить “приближенные” решения этой задачи. Размер вершинного по
 крытия, полученного в результате работы этого алгоритма, не более чем в два 
раза превышает размер минимального вершинного покрытия.
 Таким образом, не стоит лишать себя надежды только из-за того, что задача 
NP-полная. Может оказаться, что для нее существует приближенный алгоритм 
с полиномиальным временем работы, позволяющий получать решения, близкие 
к оптимальным. В главе 35 описано несколько приближенных алгоритмов, пред
 назначенных для решения NP-полных задач.
 34.5.3. 
Задача о гамильтоновых циклах
 Вновь вернемся к задаче о гамильтоновых циклах, определенной в разде
 ле 34.2.
 Теорема 34.13
 Задача о гамильтоновых циклах является NP-полной.
 Доказательство. Сначала покажем, что задача HAM-CYCLE принадлежит 
классу NP. Для заданного графа G = (V, Е) сертификат задачи имеет вид после
 довательности, состоящей из \ V\ вершин, образующих гамильтонов цикл. В алго
 ритме верификации проверяется, что в эту последовательность каждая вершина 
из V входит ровно по одному разу и что, если повторить первую вершину по
 сле последней, образуется цикл в графе G. Другими словами, проверяется, что 
каждая пара последовательных вершин соединена ребром, а также что ребро со
 единяет первую и последнюю вершины последовательности. Подобную проверку 
можно выполнить за полиномиальное время.
 Докажем теперь, что VERTEX-COVER <р HAM-CYCLE, откуда следует, 
что задача HAM-CYCLE NP-полная. Построим для заданного неориентирован
 ного графа G = (V, Е) и целого числа к неориентированный граф G' = (V1, Е'),
1142
 Часть VII. Избранные темы
 Рис. 34.16. Структурный элемент графа, используемый в ходе приведения задачи о вершинном 
покрытии к задаче о гамильтоновых циклах. Ребро (и, v) графа G соответствует структурному 
элементу Wuv в графе G', создаваемом в процессе приведения, (а) Структурный элемент с поме
 ченными отдельными вершинами. (б)-(г) Выделенные штриховкой пути являются единственными 
возможными путями через структурный элемент, включающими все его вершины, в предполо
 жении, что структурные элементы соединены с остальной частью графа G' вершинами [u, v, 1], 
[и, V, 6], [v, и, 1] И [и, и, 6].
 в котором гамильтонов цикл содержится тогда и только тогда, когда размер вер
 шинного покрытия графа G равен к.
 Наше построение основывается на структурном элементе (widget), пред
 ставляющем собой фрагмент графа, обеспечивающий его определенные свойства. 
На рис. 34.16, (а) показан используемый нами структурный элемент. Для каждого 
ребра (u,v) € Е строящийся граф G' будет содержать одну копию этого структур
 ного элемента, обозначаемую как Wuv. Обозначим каждую вершину структурного 
элемента Wuv как [u,v,i\ или [v,u,i\, где 1 < i < 6, так что каждый структур
 ный элемент Wuv содержит 12 вершин. Кроме того, он содержит 14 ребер, как 
показано на рис. 34.16, (а).
 Требуемые свойства графа обеспечиваются не только внутренней структу
 рой описанного выше элемента, но и наложением ограничений на связи между 
структурным элементом и остальной частью строящегося графа G'. В частно
 сти, наружу структурного элемента Wuv будут выходить ребра только из вершин 
[u,v, 1], [гг, г», 6], [v,u, 1] и [г», и, 6]. Любой гамильтонов цикл G' должен прохо
 дить по ребрам структурного элемента Wuv одним из трех способов, показан
 ных на рис. 34.16, (б)—(г). Если цикл входит через вершину [u,v,l\, выйти он 
должен через вершину [гг, г», 6], и при этом он либо проходит через все 12 вер
 шин структурного элемента (рис. 34.16, (б)), либо только через 6 его вершин, 
с [гг, г», 1] по [гг, г;, 6] (рис. 34.16, (в)). В последнем случае цикл должен будет по
 вторно войти в структурный элемент, посещая вершины с [и, гг, 1] по [г», гг, 6]. 
Аналогично, если цикл входит в структурный элемент через вершину [v, и, 1], он 
должен выйти из вершины [г?, гг, 6], посетив на своем пути либо все 12 вершин 
(рис. 34.16, (г)), либо 6 вершин, начиная с вершины [г>, гг, 1] и заканчивая верши
 ной [v.u, 6] (рис. 34.16, (в)). Никакие другие варианты прохождения всех 12 вер
 шин структурного элемента невозможны. В частности, невозможно таким обра
 зом построить два непересекающихся пути, один из которых соединяет вершины 
[u, v, 1] и [и, и, 6], а другой — вершины [t>, u, 1] и [u, v, 6] так, чтобы объединение 
этих путей содержало все вершины структурного элемента.
Глава 34. NP-полнота
 1143
 Рис. 34.17. Приведение экземпляра задачи о вершинном покрытии к экземпляру задачи о гамиль
 тоновом цикле, (а) Неориентированный граф G с вершинным покрытием размером 2, состоящим из 
выделенных светлой штриховкой вершин w и у. (б) Неориентированный граф G', полученный пу
 тем приведения, с выделенным гамильтоновым путем. Вершинное покрытие {и;, у} соответствует 
ребрам (si, [w,x, 1]) и (s2, [у,х, 1]), встречающимся в гамильтоновом цикле.
 Единственные вершины, содержащиеся в множестве V , кроме вершин струк
 турных элементов, — переключающие вершины (selector vertex) si, S2, ..., Sfc. 
Ребра графа G', инцидентные переключающим вершинам, используются для вы
 бора к вершин из покрытия графа G.
 В дополнение к ребрам, входящим в состав структурных элементов, множе
 ство Е' содержит ребра двух других типов, показанных на рис. 34.17. Во-первых, 
для каждой вершины и € V добавляются ребра, соединяющие пары структурных 
элементов в таком порядке, чтобы получился путь, содержащий все структурные 
элементы, соответствующие ребрам, инцидентным вершине и графа G. Вершины, 
смежные с каждой вершиной и 6 V, упорядочиваются произвольным образом как 
. . ., i / degree(u)), где degree(u) — количество вершин, смежных с верши
 ной и. В графе G' создается путь, проходящий через все структурные элементы, 
соответствующие инцидентным ребрам вершины и. Для этого к множеству Е' 
добавляются ребра { ( [ и , 6], [и,и(г+1), 1]) : 1 < г < degree(u) — 1}. Например, 
на рис. 34.17 вершины, смежные с вершиной w, упорядочиваются как х, у, z, так 
что граф G', изображенный в части (б) рисунка, содержит ребра ([ш, х, 6], [ги, у, 1]) 
и ([ги,у, 6], [ги, г, 1]). Для каждой вершины и € V эти ребра графа G' заполняют 
путь, содержащий все структурные элементы, соответствующие ребрам, инци
 дентным вершине и графа G.
1144
 Часть VII. Избранные темы
 Интуитивные соображения, обосновывающие наличие этих ребер, заключа
 ются в том, что если из вершинного покрытия графа G выбирается вершина 
и 6 V, то в графе G' можно построить путь из вершины [и,и^, 1] в вершину 
[wy d e6ree(u))?6], “покрывающий” все структурные элементы, соответствующие 
ребрам, инцидентным вершине и. Другими словами, для каждого из этих струк
 турных элементов, скажем, структурного элемента Wuu(i), этот путь проходит 
либо по всем 12 вершинам (если вершина и входит в вершинное покрытие, а вер
 шина и^ — нет), либо только по 6 вершинам [и, иW, 1], [и, иW, 2],..., [и, v№, 6] 
(если вершинному покрытию принадлежат и вершина и, и вершина иW).
 Наконец последний тип ребер множества Е' соединяет первую [и, г/1), 1] и по
 следнюю [u, U(desree(u))j 6] вершины каждого из этих путей с каждой из переклю
 чающих вершин. Другими словами, в множество включаются ребра
 {(sj, [u, i / 1), 1]) : и 6 V и 1 < j < к}
 U {(sj, [w,w(degree(“))56]) :uEVnl<j<k} .
 Теперь покажем, что размер графа G' выражается полиномиальной функцией 
от размера графа G, поэтому граф G' можно сконструировать за полиномиаль
 ное от размера графа G время. Множество вершин графа G' состоит из вершин, 
входящих в состав структурных элементов, и переключающих вершин. Каждый 
структурный элемент содержит 12 вершин, и еще имеется к < \V\ переключаю
 щих вершин, поэтому в итоге получается
 \V'\ = 12 \Е\ + к 
< 12 \E\ + \V\
 вершин. Множество ребер графа G' состоит из ребер, которые принадлежат 
структурным элементам, ребер, которые соединяют структурные элементы, и ре
 бер, которые соединяют переключающие вершины со структурными элементами. 
Каждый структурный элемент содержит по 14 ребер, поэтому все структурные 
элементы в совокупности содержат 14 \Е\ ребер. Для каждой вершины и е V 
граф G' содержит degree (и) — 1 ребер между структурными элементами, так что 
в результате суммирования по всем вершинам множества V получается
 ]T(degree(u) - 1) = 2 \Е\ - \ V\
 u£V
 ребер, соединяющих структурные элементы. Наконец по два ребра приходится 
на каждую пару, состоящую из одной переключающей вершины и одной верши
 ны множества V . Всего таких ребер получается 2к \V\, а общее количество всех 
ребер графа G' равно
 1^1 = (14 |B|) + (2|E|-|V|) + (2fc|V|)
 = 16 |£| + (2к — 1) \V\
 <16 \Е\ + (2 \V\ — 1) \V\ .
Глава 34. NP-полнота
 1145
 Теперь покажем, что преобразование графа G в граф G' является приведением. 
Другими словами, покажем, что граф G имеет вершинное покрытие размером к 
тогда и только тогда, когда граф G' имеет гамильтонов цикл.
 Предположим, что граф G = (V, Е) содержит вершинное покрытие V* С V 
размером к. Пусть V* = {ui, щ, ■.., it*}. Как видно из рис. 34.17, гамильтонов 
цикл графа G' образуется путем включения в него следующих ребер10 для каж
 дой вершины uj 6 V*. В цикл включаются ребра {([uj,u^,6], [uj, Цг+1\ 1]) : 
1 < г < degree(uj) — 1}, которые соединяют все структурные элементы, соответ
 ствующие ребрам, инцидентным вершинам uj. Включаются также ребра, содер
 жащиеся в этих структурных элементах, как показано на рис. 34.16, (б)-(г), в за
 висимости от того, покрывается ребро одним или двумя вершинами множества 
V*. Гамильтонов цикл также включает в себя ребра
 : 1 < з < к]
 U {{sj+1, [«j,ujdegree(“j)),6]) : 1 < j < к - 1}
 U{(Sb[Wb ^ degreeK)),6])}.
 Ознакомившись с рис. 34.17, можно убедиться, что эти ребра действительно обра
 зуют цикл. Этот цикл начинается в вершине si, проходит через все структурные 
элементы, соответствующие ребрам, инцидентным вершине щ, затем направля
 ется к вершине U2, проходит через все структурные элементы, соответствующие 
ребрам, инцидентным вершине и2, и так до тех пор, пока снова не вернется к вер
 шине s 1. Каждый структурный элемент проходится однократно или дважды в за
 висимости от того, одна или две вершины множества V* покрывают соответству
 ющее ему ребро. Поскольку V* — вершинное покрытие графа G, каждое ребро из 
множества Е инцидентно некоторой вершине множества V*, поэтому цикл про
 ходит через все вершины каждого структурного элемента графа G'. Поскольку он 
также проходит через все переключающие вершины, этот цикл — гамильтонов.
 Проведем рассуждения в обратном направлении. Предположим, что граф G' = 
(V7, Е1) содержит гамильтонов цикл С С Е'. Мы утверждаем, что множество
 V* = {и е V : (Sj, 
1]) £ С для некоторого 1 < j < к} 
(34.4)
 является вершинным покрытием графа G. Чтобы убедиться, что это действитель
 но так, разобьем цикл С на максимальные пути, которые начинаются в некоторой 
переключающей вершине s*, проходят через ребро (s*, [и, i^1), 1]) для некоторой 
вершины и G V и оканчиваются в переключающей вершине Sj, не пересекая 
при этом никакие другие переключающие вершины. Назовем каждый такой путь 
“покрывающим’! По способу построения графа G' каждый покрывающий путь 
должен начинаться в некоторой вершине Sj, включать в себя ребро (s i,[u,W(1),l])
 10Технически определение цикла формулируется в терминах вершин, а не ребер (см. раздел Б.4). Для 
ясности здесь эти обозначения видоизменяются, а гамильтонов цикл определяется в терминах ребер.
1146
 Часть VII. Избранные темы
 для некоторой вершины и £ V, проходить через все структурные элементы, соот
 ветствующие ребрам из множества Е, инцидентным вершине и, и оканчиваться 
в некоторой переключающей вершине Sj. Обозначим такой покрывающий путь 
как ри и в соответствии с уравнением (34.4) включим вершину и в множество 
V*. Каждый структурный элемент, через который проходит путь ри, должен быть 
структурным элементом Wuv или структурным элементом Wvu для некоторой 
вершины v £ V. О каждом структурном элементе, через который проходит путь 
ри, можно сказать, что по его вершинам проходит один или два покрывающих пу
 ти. Если такой покрывающий путь один, то ребро (и, v) £ Е покрывается в графе 
G вершиной и. Если же через структурный элемент проходят два пути, то один 
из них, очевидно, путь ри, а другой должен быть путем pv. Из этого следует, что 
v £ V*, и ребро (u,v) £ Е покрывается и вершиной и, и вершиной v. Поскольку 
все вершины из каждого структурного элемента посещаются некоторым покры
 вающим путем, видно, что каждое ребро из множества Е покрывается некоторой 
вершиной из множества V*. 
■
 34.5.4. 
Задача о коммивояжере
 В задаче о коммивояжере (traveling-salesman problem), которая тесно связа
 на с задачей о гамильтоновом цикле, коммивояжер должен посетить п городов. 
Моделируя задачу в виде полного графа с п вершинами, можно сказать, что ком
 мивояжеру нужно совершить тур (tour), или гамильтонов цикл, посетив каждый 
город ровно по одному разу и завершив путешествие в том же городе, из кото
 рого он выехал. С каждым переездом из города i в город j связана некоторая 
стоимость c(i,j), выражаемая целым числом, и коммивояжеру нужно совершить 
тур таким образом, чтобы общая стоимость (т.е. сумма стоимостей всех переез
 дов) была минимальной. Например, на рис. 34.18 изображен самый дешевый тур 
(и, w, v, х, и), стоимость которого равна 7. Вот как выглядит формальный язык 
для соответствующей задачи принятия решения:
 TSP = {(G, c,k) : G = (V, Е) — полный граф, 
с — функция V х V —> N, 
к £ N, и
 G содержит тур стоимостью не более к} .
 Рис. 34.18. Экземпляр задачи о коммивояжере; выделенные серым цветом ребра представляют 
самый дешевый тур, стоимость которого равна 7.
Глава 34. NP-полнота
 1147
 Согласно сформулированной ниже теореме существование быстрого алгорит
 ма для решения задачи о коммивояжере маловероятно.
 Теорема 34.14
 Задача о коммивояжере является NP-полной.
 Доказательство. Сначала докажем, что TSP принадлежит классу NP. В каче
 стве сертификата для заданного экземпляра задачи будет использоваться последо
 вательность п вершин, из которых состоит тур. В алгоритме верификации прове
 ряется, что в этой последовательности все вершины содержатся ровно по одному 
разу, а также суммируются стоимости всех ребер тура и проверяется, что эта 
сумма не превышает к. Очевидно, что этот процесс можно выполнить за полино
 миальное время.
 Чтобы доказать, что задача TSP NP-сложная, покажем, что HAM-CYCLE <р 
TSP. Пусть G = (V, Е) — экземпляр задачи HAM-CYCLE. Экземпляр TSP кон
 струируется следующим образом. Сформируем полный граф G' = (V, Е'), где 
Е' = {{hj) : i,j G V и i ф j}. Определим также функцию стоимости с как
 0 , если (i,j) е Е ,
 1 , если (i,j) £ Е .
 (Заметим, что, поскольку граф G неориентированный, в нем отсутствуют петли, 
поэтому для всех вершин v 6 V выполняется равенство c(v, v) = 1.) Тогда в ка
 честве экземпляра TSP выступает набор (G1, с, 0), который легко составить за 
полиномиальное время.
 Покажем теперь, что граф G содержит гамильтонов цикл тогда и только то
 гда, когда граф G' включает в себя тур, стоимость которого не превышает 0. 
Предположим, что граф G содержит гамильтонов цикл h. Каждое ребро цикла 
h принадлежит множеству Е, поэтому его стоимость в графе G' равна 0. Таким 
образом, стоимость цикла h в графе G' равна 0. И обратно — предположим, что 
граф G' содержит тур h!, стоимость которого не превышает 0. Поскольку сто
 имость ребер графа G' равна 0 или 1, стоимость тура h! равна 0, и стоимость 
каждого ребра из тура должна равняться 0. Таким образом, тур h! содержит толь
 ко ребра из множества Е. Можно сделать вывод, что тур h! — это гамильтонов 
цикл в графе G. 
34.5.5. 
Задача о сумме подмножества
 ■
 Следующая NP-полная задача, которая будет рассмотрена, принадлежит к раз
 ряду арифметических. В задаче о сумме подмножества (subset-sum problem) за
 даются конечное множество S положительных целых чисел и целевое значение 
(target) t > 0. Спрашивается, существует ли подмножество S' С S, сумма элемен
 тов которого равна t. Например, если S = {1,2,7,14,49,98,343,686,2409, 2793, 
16808,17206,117705,117993} и t = 138457, то решением является подмножество 
S' = {1,2,7,98,343,686,2409,17206,117705}.
1148
 Как обычно, определим задачу как язык:
 Часть VII. Избранные темы
 SUBSET-SUM = {(5, t) : имеется S' С 5, такое, что t = YlseS' sl •
 Как в любой арифметической задаче, важно помнить, что в нашем стандартном 
коде предполагается, что входные целые числа кодируются бинарными значения
 ми. При этом предположении можно показать, что вероятность наличия быстрого 
алгоритма, позволяющего решить задачу о сумме подмножества, очень мала.
 Теорема 34.15
 Задача о сумме подмножества является NP-полной.
 Доказательство. Чтобы показать, что задача SUBSET-SUM принадлежит 
классу NP, для экземпляра (5, t) выберем в качестве сертификата подмножество 
S'. Проверку равенства t = XLeS' s в алгоритме верификации можно выполнить 
за полиномиальное время.
 Теперь покажем, что 3-CNF-SAT <р SUBSET-SUM. Если задана З-СЫЕ-фор- 
мула ф, зависящая от переменных х\,Х2 ,...,хп и содержащая подвыражения 
С\, С2 ,. ■ ., Сь в каждое из которых входит ровно по три различных литерала, 
то в алгоритме приведения строится такой экземпляр (5, t) задачи о сумме под
 множества, что формула ф выполнима тогда и только тогда, когда существует 
подмножество S, сумма элементов которого равна t. Не теряя общности, можно 
сделать два упрощающих предположения о формуле ф. Во-первых, ни в одном 
подвыражении не содержится одновременно и переменная, и ее отрицание, по
 тому что такое подвыражение автоматически выполняется при любых значениях 
этой переменной. Во-вторых, каждая переменная входит хотя бы в одно подвыра
 жение, так как в противном случае безразлично, какое значение ей присваивается.
 В процессе приведения в множестве S создается по два числа для каждой 
переменной Хг и для каждого выражения Cj. Эти числа будут создаваться в де
 сятичной системе счисления, и все они будут содержать по п + к цифр, каждая 
из которых соответствует переменной или подвыражению в скобках. Основание 
системы счисления 10 (и, как мы увидим, и другие основания) обладает свой
 ством, необходимым для предотвращения переноса значений из младших разря
 дов в старшие.
 Как видно из рис. 34.19, множество S и целевое значение t конструируются 
следующим образом. Присвоим каждому разряду числа метку, соответствующую 
либо переменной, либо подвыражению в скобках. Цифры, которые находятся в к 
младших разрядах, помечены подвыражениями, а цифры в п старших разрядах 
помечены переменивши. •
 • Все цифры целевого значения t, помеченные переменными, равны 1, а поме
 ченные подвыражениями — равны 4.
 • Для каждой переменной Хг в множестве S содержатся два целых числа — Vi 
и г»'. В каждом из них в разряде с меткой Xi находится значение 1, а в разрядах, 
соответствующих всем другим переменным, — значение 0. Если литерал Х{ 
входит в подвыражение Cj, то цифра с меткой Cj в числе vi равна 1. Если же
Глава 34. NP-полнота
 1149
 подвыражение Cj содержит литерал ~*Х{, цифра с меткой Cj в числе v\ равна 1. 
Все остальные цифры, метки которых соответствуют другим подвыражениям, 
в числах Vi и г»' равны 0.
 Значения vi и г»' в множестве S не повторяются. Почему? Если I ф г, то 
ни vi, ни v'i не могут быть равны Vi или v\ в п старших разрядах. Кроме 
того, согласно сделанным выше упрощающим предположениям, никакие Vi 
и г' не могут быть равны во всех к младших разрядах. Если бы числа Vi и v[ 
были равны, то литералы Xi и 
должны были бы входить в один и тот 
же набор подвыражений в скобках. Однако согласно предположению ни одно 
подвыражение не содержит одновременно и ^ ,и ->Xi, и хотя бы один из этих 
литералов входит в одно из подвыражений. Поэтому должно существовать 
какое-то подвыражение Cj, для которого Vi и г»' различаются.
 • Для каждого подвыражения Cj в множестве S содержатся два целых числа Sj 
и s^. Каждое из них содержит нули во всех разрядах, метки которых отлича
 ются от Cj. В числе Sj цифра с меткой Cj равна 1, а в числе s'- эта цифра 
равна 2. Такие целые числа выступают в роли “фиктивных переменных”, кото
 рые мы используем для того, чтобы получить в каждом разряде, помеченном 
подвыражением, целевое значение 4.
 Беглый взгляд на пример, проиллюстрированный на рис. 34.19, показывает, 
что никакие значения Sj и s' в множестве S не повторяются.
 Заметим, что максимальная сумма цифр в каждом из разрядов равна 6, что 
и осуществляется в цифрах, метки которых соответствуют подвыражениям (три 
единицы от значений Vi и г' плюс 1 и 2 от значений Sj и s'). Потому эти значения 
интерпретируются как числа в десятичной системе счисления, — чтобы не было 
переноса из младших разрядов в старшие11.
 Такое приведение можно выполнить за полиномиальное время. Множество S 
содержит 2п + 2 к значений, в каждом из которых по п + к цифр, поэтому время, 
необходимое для получения всех цифр, выражается полиномиальной функцией 
от п + к. Целевое значение t содержит п + к цифр, и в процессе приведения 
каждую из них можно получить за фиксированное время.
 Теперь покажем, что З-СЫЕ-формула ф выполнима тогда и только тогда, когда 
существует подмножество S' С S, сумма элементов которого равна t. Сначала 
предположим, что у формулы ф имеется выполняющий набор. Если в нем Xi — 1 
(где i = 1,2,..., п), то число Vi включается в множество S'. В противном случае 
в это множество включается число г»'. Другими словами, в множество S1 включа
 ются именно те значения Vi иг»', которым в выполняющем наборе соответствуют 
литералы, равные единице. Включая в множество S' либо число v^ либо число 
г»', но не оба этих числа для всех г, и помещая в значениях Sj и s' нули во все 
разряды с метками, соответствующими переменным, мы видим, что сумма цифр
 11 Фактически подошло бы любое основание b > 7. Так, экземпляр задачи, который рассматривается в на
 чале этого подраздела, представляет собой множество S и целевое значение t на рис. 34.19, где все значения 
рассматриваются как числа в семеричной системе счисления, а множество S перечислено в порядке убывания.
1150
 Часть VII. Избранные темы
 X i
 =
 =
 1
 1
 X2 Хз Cx c2 C3 c4
 0
 0
 0
 0
 t
 0
 0
 1
 0
 1
 l
 0
 ■ = 0 1 0 0 0 0 1|
 v 2 = 0 1 0 1 1 1 0
 =
 t ’3
 1
 v‘i
 •Si
 s \
 •S'J
 0
 =
 =
 =
 0
 0
 0
 0
 0
 0
 0
 0
 0
 1
 1
 0
 0
 0
 0
 1
 1
 2
 0
 0
 l
 0
 0
 1
 1
 0
 0
 0
 0
 1
 0
 0
 0
 0
 s 2 = 0 0 0 0 2 0 0
 •S3
 S.1
 S4
 t
 =
 =
 =
 =
 =
 0
 0
 0
 0
 1
 0
 0
 0
 0
 1
 0
 0
 0
 0
 1
 0
 0
 0
 0
 4
 0
 0
 0
 0
 4
 1
 2
 0
 0
 4
 0
 0
 1
 2
 4
 Рис. 34.19. Приведение 3-CNF-SAT к SUBSET-SUM. З-СОТ-формула имеет вид ф = С\ А 
С2 А Сз А С^, где Ci = (xi V ~>х2 V ->хз), С2 = (->xi V ->Х2 V ->хз), Сз = (->xi V ->хг V 
хз) и С4 — (xi V Х2 V хз). Выполняющий набор 0 представляет собой (xi = 0, Х2 = 0, 
хз = 1). Множество S, полученное в процессе приведения, состоит из представленных в таб
 лице чисел в десятичной системе счисления; считывая их сверху вниз, находим, что S = 
{1001001,1000110,100001,101110,10011,11100,1000,2000,100, 200,10,20,1,2}. Целевое значе
 ние t равно 1114444. Подмножество S' С S выделено светлым цветом и содержит v\, v'2 и V3, 
соответствующие выполняющему набору. В него также входят фиктивные переменные si, Sj. s2, 
S3 , s4 и«4, обеспечивающие получение значений 4 в цифрах целевого значения, помеченных под
 выражениями С1-С4.
 в этих разрядах по всем значениям множества S' должна быть равной единице, 
что совпадает с цифрами в этих разрядах целевого значения t. Поскольку все 
подвыражения в скобках выполняются, в каждом таком подвыражении имеется 
литерал, значение которого равно единице. Поэтому каждая цифра, помеченная 
подвыражением, включает как минимум одну единицу, вносимую в сумму бла
 годаря вкладу значения Vi или значения v[ из множества S'. В действительности 
в каждом подвыражении единице могут быть равны 1, 2 или 3 литерала, поэтому 
в каждом разряде, соответствующем подвыражению, сумма цифр по значениям 
Vi и v\ множества S' равна 1, 2 или 3. Так, в примере, проиллюстрированном 
на рис. 34.19, в выполняющем наборе единице равны литералы -1X1, ->Х2 и £3. 
Каждое из подвыражений С\ и С4 содержит ровно по одному из этих литера
 лов, поэтому числа v[, v'2 и 
в совокупности дают единичный вклад в цифры, 
соответствующие подвыражениям С\ и С4 . Подвыражение С2 содержит два из 
этих литералов, поэтому числа v\, v'2 и г>з в совокупности дают вклад 2 в цифру, 
соответствующую Сг- Подвыражение Сз содержит все три перечисленных лите
 рала, и числа v[, v2 и V3 дают вклад 3 в цифру, помеченную подвыражением С3. 
Целевое значение, равное 4, достигается в каждом разряде с меткой, отвечаю
 щей подвыражению Cj, путем добавления в множество S' непустого множества
Глава 34. NP-полнота
 1151
 из соответствующих фиктивных переменных {sj, s'}. На рис. 34.19 множество S' 
включает значения si, s'l5 s'2, S3, S4 и s\. Поскольку сумма цифр по всем зна
 чениям множества S' во всех разрядах совпадает с соответствующими цифрами 
целевого значения t, а при суммировании не производился перенос значений из 
младших разрядов в старшие, то сумма значений множества S' равна t.
 Теперь предположим, что имеется подмножество S' С S, сумма элементов ко
 торого равна t. Для каждого значения г = 1,2,..., п это подмножество должно 
включать в себя ровно по одному из значений Vi или v[, потому что в противном 
случае сумма цифр в разрядах, соответствующих переменным, не была бы равна 
единице. Если Vi G S', то выполняем присваивание х* = 1. В противном случае 
v[ е S', и выполняется присваивание хг = 0. Мы утверждаем, что в результа
 те такого присваивания выполняется каждое подвыражение Cj, j = 1, 2,..., к. 
Чтобы доказать это утверждение, заметим, что для того, чтобы сумма цифр в раз
 ряде с меткой Cj была равна 4, подмножество S' должно включать хотя бы одно 
из значений Vi или v[, в котором единица находится в разряде с меткой Cj, так 
как суммарный вклад фиктивных переменных Sj и s' не превышает 3. Если под
 множество S' включает в себя значение Vi, в котором в разряде с меткой Cj 
содержится единица, то в подвыражение Cj входит литерал хг. Поскольку при 
Vi 6 S' выполняется присваивание Xi = 1, подвыражение Cj выполняется. Если 
множество S' включает в себя значение v'{, в котором в этом разряде содержится 
единица, то в подвыражение Cj входит литерал -*хг. Так как при v[ 6 S' выполня
 ется присваивание Х{ — 0, подвыражение Cj снова выполняется. Таким образом, 
в формуле ф выполняются все подвыражения, и на этом доказательство теоремы 
завершается. 
■
 Упражнения
 34.5.1
 В задаче об изоморфизме подграфу (subgraph-isomorphism problem) задаются два 
графа (Gi и G2) и спрашивается, изоморфен ли граф G\ какому-либо подграфу 
графа G2 . Покажите, что эта задача NP-полная.
 34.5.2
 В задаче 0-1 целочисленного программирования (0-1 integer-programming prob
 lem) задаются целочисленная матрица А размером т х п и целочисленный т- 
компонентный вектор Ъ и спрашивается, существует ли целочисленный п-ком- 
понентный вектор х, элементы которого являются элементами множества {0, 1}, 
такой, что Ах < Ь. Докажите, что задача 0-1 целочисленного программирования 
является NP-полной. (Указание: приведите к этой задаче задачу 3-CNF-SAT.)
 34.5.3
 Задача целочисленного линейного программирования (integer linear-programm
 ing problem) похожа на задачу 0-1 целочисленного программирования, описанную 
в упр. 34.5.2, но в ней компоненты вектора х могут быть любыми целыми числа
 ми, а не только нулем и единицей. Исходя из предположения, согласно которому
1152
 Часть VII. Избранные темы
 задача 0-1 целочисленного программирования является NP-полной, покажите, что 
задача целочисленного линейного программирования также NP-полная.
 34.5.4
 Покажите, как решить задачу о сумме подмножества за полиномиальное время, 
если целевое значение t выражено в унарной системе счисления, т.е. представлено 
последовательностью из t единиц.
 34.5.5
 В задаче о разбиении множества (set-partition problem) в качестве входных дан
 ных выступает множество чисел S. Спрашивается, можно ли это числа разбить 
на два множества (А и А = S — А) таким образом, чтобы YlxeA х = 
х
Покажите, что задача о разбиении множества является NP-полной.
 34.5.6
 Покажите, что задача о гамильтоновом пути NP-полная.
 34.5.7
 Задача о самом длинном простом цикле (longest-simple-cycle problem) — это 
задача, в которой в заданном графе выполняется поиск простого (без повторения 
вершин) цикла максимальной длины. Покажите, что эта задача — NP-полная.
 34.5.8
 В половинной задаче о 3-CNF-выполнимости (half 3-CNF satisfiability problem) 
задается 3-С№-формула ф с п переменными и т подвыражениями, где т — 
четное. Нужно определить, существует ли набор значений переменных формулы 
ф, при котором результат ровно половины подвыражений в скобках равен нулю, 
а результат второй половины этих подвыражений равен единице. Докажите, что 
половинная задача о З-СОТ-выполнимости является NP-полной.
 Задачи
 34.1. Независимое множество
 Независимым множеством (independent set) графа G — (V,E) называется 
такое подмножество вершин V' С V, что каждое ребро из множества Е инци
 дентно хотя бы одной вершине из множества V'. Задача о независимом множе
 стве (independent-set problem) заключается в том, чтобы найти в заданном графе 
G независимое множество максимального размера.
 а. Сформулируйте задачу принятия решения, соответствующую задаче о незави
 симом множестве, и докажите, что она является NP-полной. (Указание: при
 ведите к этой задаче задачу о клике.)
 б. Предположим, что для задачи принятия решения, определенной в п. (а), име
 ется подпрограмма в виде “черного ящика”, решающего эту задачу. Сформу
 лируйте алгоритм поиска независимого множества, имеющего максимальный
Глава 34. NP-полнота
 1153
 размер. Время работы этого алгоритма должно выражаться полиномиальной 
функцией от величин \V\ и \Е\. При этом предполагается, что каждый запрос 
к черному ящику учитывается как одна операция.
 Несмотря на то что задача о независимом множестве является NP-полной, неко
 торые частные ее случаи разрешимы за полиномиальное время.
 в. Разработайте эффективный алгоритм, позволяющий решить задачу о незави
 симом множестве, если степень каждой вершины графа G равна 2. Проанали
 зируйте время работы этого алгоритма и докажите его корректность.
 г. Разработайте эффективный алгоритм, позволяющий решить задачу о незави
 симом множестве для двудольного графа G. Проанализируйте время работы 
этого алгоритма и докажите его корректность. (Указание: воспользуйтесь ре
 зультатами, полученными в разделе 26.3.)
 34.2. Бонни и Клайд
 Бонни и Клайд только что ограбили банк. У них есть мешок денег, который 
нужно разделить. В каждом из описанных ниже сценариев требуется либо сфор
 мулировать алгоритм с полиномиальным временем работы, либо доказать, что за
 дача NP-полная. В каждом случае в качестве входных данных выступает список, 
состоящий из п содержащихся в мешке элементов, а также стоимость каждого 
из них.
 а. В мешке п монет двух различных номинаций: одни монеты стоят х долларов, 
а другие — у долларов. Деньги следует разделить поровну.
 б. В мешке п монет произвольного количества различных номиналов, но при 
этом каждый номинал является неотрицательной целой степенью двойки, 
т.е. возможны такие номиналы: 1 доллар, 2 доллара, 4 доллара и т.д. День
 ги следует разделить поровну.
 в. В мешке лежат п чеков, по невероятному совпадению выписанных на имя 
“Бонни или Клайд”. Нужно разделить чеки таким образом, чтобы по ним мож
 но было получить одинаковые суммы.
 г. Как и в случае (в), в мешке лежит п чеков, но на этот раз допускается расхож
 дение в суммах, которое не должно превышать ста долларов.
 34.3. Раскраска графов
 Художник, изготавливающий карту, пытается использовать минимально воз
 можное количество красок для раскраски стран на карте так, чтобы никакие 
смежные страны не были окрашены в один и тот же цвет. Эту задачу можно мо
 делировать с помощью неориентированного графа G = (V, Е), в котором каждая 
вершина представляет страну, при этом страны, имеющие с ней общую границу, 
представлены вершинами, смежными с ней. Тогда k-раскрашивание представля
 ет собой функцию с : V —>• { 1 , 2 такую, что с(и) ^ c(v) для каждого ребра
 37 Зак. 3726
1154
 Часть VII. Избранные темы
 Рис. 34.20. Структурный элемент, который соответствует подвыражению (xVyVz) и используется 
в задаче 34.3.
 (и, v) е Е. Другими словами, числа 1,2,..., к представляют к цветов, и смежные 
вершины должны иметь разные цвета. Задача о раскраске графа (graph-coloring 
problem) состоит в определении минимального количества цветов, необходимых 
для раскраски данного графа.
 а . Разработайте эффективный алгоритм 2-раскрашивания графа, если такое рас
 крашивание возможно.
 б. Переформулируйте задачу о раскрашивании графов в виде задачи принятия 
решения. Покажите, что эта задача разрешима за полиномиальное время тогда 
и только тогда, когда за полиномиальное время разрешима задача о раскраши
 вании графов.
 в. Пусть язык 3-COLOR представляет собой множество графов, для которых 
возможно 3-раскрашивание. Покажите, что если задача 3-COLOR — NP-пол- 
ная, то задача принятия решения из п. (б) также NP-полная.
 Чтобы доказать NP-полноту задачи 3-COLOR, воспользуемся приведением к этой 
задаче задачи 3-CNF-SAT. Для заданной формулы ф, содержащей га подвыраже
 ний в скобках и п переменных жх,Ж2,...,жп, конструируется граф G — (V,E) 
описанным ниже способом. Множество V содержит по одной вершине для каж
 дой переменной, по одной вершине для каждого отрицания переменной, по 5 вер
 шин для каждого подвыражения и 3 специальные вершины: TRUE, FALSE и RED. 
Ребра в этом графе могут быть двух типов: “литеральные” ребра, которые не зави
 сят от подвыражений в скобках, и “дизъюнктивные” ребра, которые от них зави
 сят. Литеральные ребра образуют треугольник на специальных вершинах, а также 
треугольник на вершинах ж*, ->Х{ и RED для i = 1,2,..., п.
 г. 
Докажите, что при любом 3-раскрашивании с графа, состоящего из литераль
 ных ребер, из каждой пары вершин ж*, ~>xi одна окрашена как c(True), а дру
 гая — как c(False). Докажите, что для любого набора значений функции ф 
существует 3-раскрашивание графа, содержащего только литеральные ребра.
 Структурный элемент, изображенный на рис. 34.20, помогает обеспечить выпол
 нение условия, соответствующего подвыражению (ж У у У z). Каждое подвыраже
 ние требует своей копии пяти вершин, выделенных на рисунке темным цветом; 
они соединяются с литералами подвыражения и специальной вершиной TRUE.
Глава 34. NP-полнота
 1155
 д. Докажите, что если каждая из вершин х, у и z окрашена в один из двух цве
 тов — c(true) или c(false), — то для изображенного на рисунке структурного 
элемента правильное 3-раскрашивание возможно тогда и только тогда, когда 
цвет хотя бы одной из вершин х,у и z — c(True).
 е. Завершите доказательство NP-полноты 3-COLOR.
 34.4. Расписание с прибылью и предельными сроками
 Предположим, что имеется одна вычислительная машина и п заданий а\,
 02,... ,ап. Каждое задание aj характеризуется временем выполнения tj (време
 нем работы машины, необходимым для выполнения задания), прибылью pj и ко
 нечным сроком выполнения dj. В каждый момент времени машина может обра
 батывать только одно задание, причем задание Oj после запуска должно без пре
 рываний выполняться в течение времени tj. Если задание aj будет выполнено до 
наступления конечного срока его выполнения dj, то будет получена прибыль Pj, 
но если конечный срок выполнения будет сорван, то и прибыли не будет. Сфор
 мулируем такую задачу оптимизации: пусть для множества п заданий известны 
время обработки, прибыль и время выполнения; требуется составить расписание 
таким образом, чтобы были выполнены все задания и общая сумма прибыли была 
максимальной. Все величины — время выполнения, прибыль и конечный срок — 
неотрицательные числа.
 а. Сформулируйте эту задачу в виде задачи принятия решения.
 б. Покажите, что эта задача принятия решения NP-полная.
 в. Разработайте алгоритм с полиномиальным временем работы, позволяющий 
решить задачу принятия решения в предположении, что все времена выполне
 ния выражаются целыми числами от 1 до п. (Указание: воспользуйтесь мето
 дами динамического программирования.)
 г. Разработайте алгоритм с полиномиальным временем работы, позволяющий 
решить задачу оптимизации в предположении, что все времена выполнения 
выражаются целыми числами от 1 до п.
 Заключительные замечания
 Книга Гарея (Garey) и Джонсона (Johnson) [128] является замечательным учеб
 ником по вопросам NP-полноты; в ней не только подробно обсуждается тео
 рия, но и описываются многие задачи, NP-полнота которых была доказана до 
1979 года. Из этой книги заимствовано доказательство теоремы 34.13, а спи
 сок NP-полных задач, описанных в начале раздела 34.5, взят из содержания 
этой книги. В 1981-1992 годах Джонсон написал в Journal of Algorithms се
 рию из 23 статей о новых достижениях в исследованиях NP-полноты. В кни
 гах Хопкрофта (Hopcroft), Мотвани (Motwani) и Ульмана (Ullman) [176], Лью
1156
 Часть VII. Избранные темы
 иса (Lewis) и Пападимитриу (Papadimitriou) [235], Пападимитриу [268] и Сип- 
сера (Sipser) [315] проблема NP-полноты удачно трактуется в контексте теории 
сложности. В книгах Ахо (Aho), Хопкрофта (Hopcroft) и Ульмана (Ullman) [5], 
Дасгупты (Dasgupta), Пападимитриу (Papadimitriou) и Вазирани (Vazirani) [81], 
Джонсонбафа (Johnsonbaugh) и Шефера (Schaefer) [192] и Кляйнберга (Kleinberg) 
и Тардоса (Tardos) [207] также описывается NP-полнота и рассматриваются при
 меры приведений.
 Класс Р был введен в 1964 году Кобхемом (Cobham) [71] и независимо 
в 1965 году Эдмондсом (Edmonds) [99], который ввел также класс NP и выдви
 нул гипотезу о том, что Р 7^ NP. Понятие NP-полноты впервые было предложено 
Куком (Cook) [74] в 1971 году. Кук представил первое доказательство NP-полно
 ты задач о выполнимости формул и о 3-С№-выполнимости. Левин (Levin) [233] 
независимо пришел к этому понятию; он доказал NP-полноту задачи о мозаике. 
Карп (Karp) [198] в 1972 году предложил методику приведения и продемонстри
 ровал богатое разнообразие NP-полных задач. В статье Карпа впервые доказыва
 ется NP-полнота задач о клике, о вершинном покрытии и о гамильтоновом цик
 ле. С тех пор многими исследователями была доказана NP-полнота тысяч задач. 
В 1995 году на заседании, посвященном 60-летию Карпа, Пападимитриу в своем 
докладе заметил: .. каждый год выходит около шести тысяч статей, в заголовке,
 аннотации или списке ключевых слов которых содержится термин ‘NP-полный’. 
Он встречается чаще, чем термины ‘компилятор’, ‘база данных’, ‘экспертная си
 стема’, ‘нейронная сеть’ или ‘операционная система’ ’!
 Недавняя работа по теории сложности пролила свет на вопрос о сложности 
приближенных компьютерных вычислений. В ней приводится новое определение 
класса NP с помощью “вероятностно проверяемых доказательств’! В этом опре
 делении подразумевается, что для таких задач, как задача о клике, о вершинном 
покрытии, о коммивояжере, в которой выполняется неравенство треугольника, 
и во многих других получение хорошего приближенного решения является NP- 
сложным, поэтому оно не легче, чем получение оптимальных решений. Введе
 ние в эту область можно найти в диссертации Ароры (Агога) [20], в главе Ароры 
и Лунда (Lund) в [171], в обзорной статье Ароры [21], в книге под редакцией 
Мэйра (Мауг), Прёмеля (Promel) и Стиджера (Steger) [244], а также в обзорной 
статье Джонсона (Johnson) [190].
Глава 35. Приближенные алгоритмы
 Многие задачи, представляющие практический интерес, являются NP-пол- 
ными. Однако они слишком важны, чтобы отказаться от их решения лишь на 
том основании, что неизвестно, как получить их оптимальное решение за по
 линомиальное время. Но даже для NP-полных задач остается надежда. Во-пер
 вых, если объем входных данных небольшой, алгоритм, время работы которого 
выражается показательной функцией, вполне может подойти. Во-вторых, ино
 гда удается выделить важные частные случаи, разрешимые за полиномиальное 
время. В-третьих, остается возможность найти за полиномиальное время реше
 ние, близкое к оптимальному (в наихудшем либо в среднем случае). На практи
 ке такие решения часто являются достаточно хорошими. Алгоритм, возвращаю
 щий решения, близкие к оптимальным, называется приближенным алгоритмом 
(approximation algorithm). В этой главе описаны приближенные алгоритмы с по
 линомиальным временем выполнения, предназначенные для решения некоторых 
NP-полных задач.
 Оценка качества приближенных алгоритмов
 Предположим, мы работаем над задачей оптимизации, каждому из возможных 
решений которой сопоставляется положительная стоимость, и требуется найти 
решение, близкое к оптимальному. В зависимости от задачи оптимальное ре
 шение можно определить либо как такое, которому соответствует максимально 
возможная стоимость, либо как такое, которому соответствует минимально воз
 можная стоимость; другими словами, это может быть либо задача максимизации, 
либо задача минимизации.
 Говорят, что алгоритм решения задачи обладает отношением, или коэффи
 циентом, аппроксимации (приближения) (approximation ratio) р(п), если для 
произвольных входных данных размером п стоимость С решения, полученного 
в результате выполнения этого алгоритма, отличается от стоимости С* оптималь
 ного решения не более чем в р(п) раз:
 (35.1)
 Алгоритм, в котором достигается коэффициент аппроксимации р(п), будем на
 зывать р{п)-приближенным алгоритмом (р(тг)-approximation algorithm). Опре
1158
 Часть VII. Избранные темы
 деления коэффициента аппроксимации и р(тг)-приближенного алгоритма приме
 нимы и к задачам минимизации, и к задачам максимизации. Для задач макси
 мизации выполняется неравенство 0 < С < С*, и отношение С*/С равно ве
 личине, на которую стоимость оптимального решения больше стоимости при
 ближенного решения. Аналогично для задач минимизации выполняется неравен
 ство 0 < С* < С, и отношение С/С* дает ответ, во сколько раз стоимость 
приближенного решения больше стоимости оптимального решения. Поскольку 
предполагается, что стоимости всех решений положительные, эти коэффициенты 
вполне определены. Коэффициент аппроксимации приближенного алгоритма не 
может быть меньше 1, поскольку из неравенства С/С* < 1 следует неравенство 
С*/С > 1. Таким образом, 1-приближенный алгоритм1 выдает оптимальное ре
 шение, а приближенный алгоритм с большим отношением аппроксимации может 
возвратить решение, которое намного хуже оптимального.
 Для многих задач разработаны приближенные алгоритмы с полиномиальным 
временем работы и малыми постоянными отношениями аппроксимации. Есть 
также задачи, для которых лучшие из известных приближенных алгоритмов с по
 линомиальным временем работы характеризуются коэффициентами аппроксима
 ции, величина которых возрастает с ростом размера входных данных п. Приме
 ром такой задачи является задача о покрытии множества, представленная в раз
 деле 35.3.
 Некоторые NP-полные задачи допускают наличие приближенных алгоритмов 
с полиномиальным временем работы, коэффициент аппроксимации которых мож
 но уменьшать за счет увеличения времени их работы. Другими словами, в них 
допускается компромисс между временем вычисления и качеством приближения. 
В качестве примера можно привести задачу о сумме подмножества, которая ис
 следуется в разделе 35.5. Эта ситуация достаточно важна и заслуживает собствен
 ного имени.
 Схема аппроксимации (approximation scheme) задачи оптимизации — это при
 ближенный алгоритм, входные данные которого включают в себя не только пара
 метры экземпляра задачи, но и такое значение с > 0, что для любого фиксиро
 ванного значения е эта схема является (1 + б)-приближенным алгоритмом. Схему 
аппроксимации называют схемой аппроксимации с полиномиальным временем 
выполнения (polynomial-time approximation scheme), если для любого фиксиро
 ванного значения с > 0 работа этой схемы завершается за время, выраженное 
полиномиальной функцией от размера п входных данных.
 Время работы схемы аппроксимации с полиномиальным временем вычисле
 ния может очень быстро возрастать при уменьшении величины е. Например, это 
время может вести себя как 0(п2//е). В идеале, если величина е уменьшается на 
постоянный множитель, время, необходимое для достижения нужного прибли
 жения, не должно возрастать более чем на постоянный множитель (хотя и не 
обязательно на тот же, на который уменьшается значение б).
 1 Если коэффициент аппроксимации не зависит от п, мы используем термины “отношение аппроксимации 
р" и “р-приближенный алгоритм” указывающие на отсутствие зависимости от п.
Глава 35. Приближенные алгоритмы
 1159
 Говорят, что схема аппроксимации является схемой аппроксимации с полно
 стью полиномиальным временем работы (fully polynomial-time approximation 
scheme), если время ее работы выражается полиномом как от 1/е, так и от разме
 ра входных данных задачи п. Например, время работы такой схемы может вести 
себя как 0((1/е)2п3). В такой схеме любое уменьшение величины е на постоян
 ный множитель сопровождается соответствующим увеличением времени работы 
на постоянный множитель.
 Краткое содержание главы
 В первых четырех разделах этой главы приведены некоторые примеры при
 ближенных алгоритмов с полиномиальным временем работы, позволяющие по
 лучать приближенные решения NP-полных задач. В пятом разделе представлена 
схема аппроксимации с полностью полиномиальным временем работы. Начало 
раздела 35.1 посвящено исследованию задачи о вершинном покрытии, которая 
относится к классу NP-полных задач минимизации. Для этой задачи существует 
приближенный алгоритм, характеризующийся коэффициентом аппроксимации 2. 
В разделе 35.2 представлен приближенный алгоритм с коэффициентом аппрокси
 мации 2, предназначенный для решения частного случая задачи коммивояжера, 
когда функция стоимости удовлетворяет неравенству треугольника. Также пока
 зано, что если неравенство треугольника не соблюдается, то для любой константы 
р > 1 существование р-приближенного алгоритма связано с выполнением усло
 вия Р = NP. В разделе 35.3 показано, как использовать жадный метод в качестве 
эффективного приближенного алгоритма для решения задачи о покрытии множе
 ства. При этом возвращается покрытие, стоимость которого в наихудшем случае 
превышает оптимальную на множитель, выражающийся логарифмической функ
 цией. В разделе 35.4 представлены еще два приближенных алгоритма. В пер
 вом из них исследуется оптимизирующая версия задачи о З-СМР-выполнимости 
и приводится простой рандомизированный алгоритм, который выдает решение, 
характеризующееся ожидаемым коэффициентом аппроксимации, равным 8/7. За
 тем изучается взвешенный вариант задачи о вершинном покрытии и описывается, 
как с помощью методов линейного программирования разработать 2-приближен- 
ный алгоритм. Наконец в разделе 35.5 представлена схема аппроксимации с пол
 ностью полиномиальным временем работы, предназначенная для решения задачи 
о сумме подмножества.
 35.1. Задача о вершинном покрытии
 Задача о вершинном покрытии определена в разделе 34.5.2. В этом же разделе 
доказано, что эта задача является NP-полной. Напомним, что вершинное покры
 тие (vertex cover) неориентированного графа G = (V, Е) — это такое подмноже
 ство V С V, что если (и, v) — ребро графа G, то либо и е V , либо v е V , либо
1160
 Часть VII. Избранные темы
 справедливы оба эти соотношения. Размером вершинного покрытия называется 
количество содержащихся в нем вершин.
 Задача о вершинном покрытии (vertex-cover problem) состоит в том, чтобы 
найти для заданного неориентированного графа вершинное покрытие минималь
 ного размера. Назовем такое вершинное покрытие оптимальным вершинным 
покрытием (optimal vertex cover). Эта задача представляет собой оптимизирую
 щую версию NP-полной задачи принятия решения.
 Несмотря на то что мы не знаем, как найти оптимальное вершинное покрытие 
графа G за полиномиальное время, не так сложно найти вершинное покрытие, 
близкое к оптимальному. Приведенный ниже приближенный алгоритм принима
 ет в качестве входных данных параметры неориентированного графа G и воз
 вращает вершинное покрытие, размер которого превышает размер оптимального 
вершинного покрытия не более чем в два раза.
 Approx-Vertex-Cover (G)
 1 С = 0
 2 Е' = G.E
 3 while Е'
 4 
Пусть (и, v) — произвольное ребро из Е'
 5 
6 
С = С U {и, v}
 Удалить из Е' все ребра, инцидентные и или v
 7 return С
 На рис. 35.1 показано, как алгоритм Approx-Vertex-Cover строит вершинное 
покрытие для демонстрационного графа. Переменная С содержит создаваемое 
вершинное покрытие. В строке 1 выполняется инициализация С пустым множе
 ством. В строке 2 в множество Е' копируется множество ребер G. Е графа. Цикл 
в строках 3-6 поочередно выбирает ребра (u,v) из множества Е', добавляет их 
конечные точки и и v в С и удаляет из Е' все ребра, покрываемые либо и, либо v. 
Наконец в строке 7 возвращается вершинное покрытие С. Время работы этого 
алгоритма равно 0(V + Е) при использовании для представления Е' списков 
смежности.
 Теорема 35.1
 Алгоритм Approx-Vertex-Cover является 2-приближенным алгоритмом с по
 линомиальным временем работы.
 Доказательство. Мы уже показали, что алгоритм Approx-Vertex-Cover 
имеет полиномиальное время работы.
 Множество вершин С, которое возвращается алгоритмом Approx-Vertex- 
Cover, является вершинным покрытием, поскольку алгоритм не выходит из 
цикла, пока каждое ребро G.E не будет покрыто некоторой вершиной из мно
 жества С.
 Чтобы показать, что рассматриваемый алгоритм возвращает вершинное по
 крытие, размер которого превышает размер оптимального вершинного покрытия 
не более чем в два раза, обозначим через А множество ребер, выбираемых в стро
Глава 35. Приближенные алгоритмы
 1161
 Рис. 35.1. Работа алгоритма Approx-Vertex-Cover, (а) Исходный граф G с семью вершинами 
и восемью ребрами, (б) Ребро (6, с), выделенное серым цветом, — первое по счету ребро, выбран
 ное алгоритмом APPROX-VERTEX-COVER. Вершины Ъ и с, показанные светло-серой штриховкой, 
добавляются в множество С, в котором содержится создаваемое вершинное покрытие. Показан
 ные пунктиром ребра (а, Ь), (с, е) и (с, d) удаляются, поскольку они уже покрыты вершинами из 
множества С. (в) Алгоритмом выбрано ребро (е, /), а вершины е й / добавлены в множество С. 
(г) Алгоритмом выбрано ребро (d,g), а вершины dug добавлены в множество С. (д) Множество 
С, которое представляет собой вершинное покрытие, полученное в результате выполнения алго
 ритма APPROX-VERTEX-COVER. Оно состоит из шести вершин — b,c,d,e, f,g. (е) Оптимальное 
вершинное покрытие для рассмотренного экземпляра задачи, состоящее всего из трех вершин: b, d 
и е.
 ке 4 алгоритма APPROX-VERTEX-COVER. Чтобы покрыть ребра множества А, 
каждое вершинное покрытие, в том числе и оптимальное покрытие С*, должно 
содержать хотя бы одну конечную точку каждого ребра из множества А. Никакие 
два ребра из этого множества не имеют общих конечных точек, поскольку после 
того, как ребро выбирается в строке 4, все другие ребра с такими же конечными 
точками удаляются из множества Е' в строке 6. Таким образом, никакие два ребра 
из множества А не покрываются одной и той же вершиной из множества С*, из 
чего следует, что нижняя граница размера оптимального вершинного покрытия 
равна
 |С*| > \А\ . 
(35.2)
 При каждом выполнении строки 4 выбирается ребро, ни одна из конечных точек 
которого пока еще не вошла в множество С. Это позволяет оценить сверху (фак
 тически указать точную верхнюю границу) размер возвращаемого вершинного 
покрытия:
 \С\ = 2\А\ .
 (35.3)
1162
 Сопоставив уравнения (35.2) и (35.3), получаем
 |С|=2|Л| 
<2|С*| ,
 что и доказывает теорему. 
Часть VII. Избранные темы
 ■
 Еще раз вернемся к приведенному выше доказательству. На первый взгляд, 
может показаться удивительным, как можно доказать, что размер вершинного по
 крытия, возвращенного процедурой Approx-Vertex-Cover, не более чем в два 
раза превышает размер оптимального вершинного покрытия, если неизвестно, че
 му равен размер оптимального вершинного покрытия. Это становится возможным 
благодаря использованию нижней границы оптимального вершинного покрытия. 
Как предлагается показать в упр. 35.1.2, множество А, состоящее из ребер, вы
 бранных в строке 4 процедуры Approx-Vertex-Cover, фактически является 
максимальным паросочетанием вершин в графе G. {Максимальное паросочета- 
ние (maximal matching) — это паросочетание, которое не является собственным 
подмножеством ни одного другого паросочетания.) Как было показано при до
 казательстве теоремы 35.1, размер максимального паросочетания равен нижней 
границе размера оптимального вершинного покрытия. Алгоритм возвращает вер
 шинное покрытие, размер которого не более чем в два раза превышает размер 
максимального паросочетания множества А. Составив отношение размера воз
 вращаемого решения к полученной нижней границе, находим коэффициент ап
 проксимации. Эта методика будет использоваться и в следующих разделах.
 Упражнения
 35.1.1
 Приведите пример графа, для которого процедура Approx-Vertex-Cover все
 гда возвращает неоптимальное решение.
 35.1.2
 Докажите, что множество ребер, выбранных в строке 4 процедуры Approx- 
Vertex-Cover образует максимальное паросочетание в графе G.
 35.1.3 ★
 Профессор предложил такую эвристическую схему решения задачи о вершинном 
покрытии. Одна за другой выбираются вершины с максимальной степенью, и для 
каждой из них удаляются все инцидентные ребра. Приведите пример, демонстри
 рующий, что коэффициент аппроксимации, предложенной профессором, превы
 шает 2. {Указание: попытайтесь построить двудольный граф, вершины в левой 
части которого имеют одинаковые степени, а вершины в правой части — разные 
степени.)
Глава 35. Приближенные алгоритмы
 35.1.4
 1163
 Разработайте эффективный жадный алгоритм, позволяющий найти оптимальное 
вершинное покрытие дерева за линейное время.
 35.1.5
 Из доказательства теоремы 34.12 известно, что задача о вершинном покрытии 
и NP-полная задача о клике являются взаимодополняющими в том смысле, что 
оптимальное вершинное покрытие — это дополнение к клике максимального раз
 мера в дополняющем графе. Следует ли из этого, что для задачи о клике суще
 ствует приближенный алгоритм с полиномиальным временем решения, обладаю
 щий постоянным коэффициентом аппроксимации? Обоснуйте свой ответ.
 35.2. Задача о коммивояжере
 Обратимся к задаче о коммивояжере, представленной в разделе 34.5.4. В ней 
задается полный неориентированный граф G = (V, Е), каждому из ребер (и, v) Е 
Е которого сопоставляется неотрицательная целочисленная стоимость c(u,v), 
и в графе G требуется найти гамильтонов цикл минимальной стоимости. Введем 
дополнительное обозначение с(А) — полную стоимость всех ребер подмножества 
АСЕ\
 (u,v)€A
 Во многих практических ситуациях наиболее дешевый переход из места и 
в место w — по прямой, так что, если по пути зайти в какой-нибудь промежуточ
 ный путь v, это не может привести к уменьшению стоимости. Выражаясь дру
 гими словами, если срезать путь, пропустив какой-нибудь промежуточный пункт, 
это никогда не станет причиной увеличения стоимости. Формализуем это поня
 тие, выдвинув утверждение, что функция стоимости с удовлетворяет неравенству 
треугольника (triangle inequality), если для всех вершин u,v,w Е V
 с(и, W) < c(u, V) + c(v, W) .
 Неравенство треугольника имеет естественный характер и автоматически удо
 влетворяется во многих приложениях. Например, если вершины графа — точ
 ки на плоскости, а стоимость перехода от одной вершины к другой выражается 
обычным евклидовым расстоянием между ними, то неравенство треугольника вы
 полняется. (Кроме евклидова расстояния, существует множество других функций 
стоимости, удовлетворяющих неравенству треугольника.)
 Как видно из упр. 35.2.2, задача о коммивояжере является NP-полной даже 
в том случае, если потребовать, чтобы функция стоимости удовлетворяла нера
 венству треугольника. Таким образом, мало надежд найти алгоритм с полиноми
 альным временем работы, позволяющий получить точное решение этой задачи. 
Поэтому есть смысл заняться поиском хороших приближенных алгоритмов.
1164
 Часть VII. Избранные темы
 В разделе 35.2.1 исследуется 2-приближенный алгоритм, позволяющий решить 
задачу о коммивояжере, в которой выполняется неравенство треугольника. В раз
 деле 35.2.2 будет показано, что без соблюдения неравенства треугольника при
 ближенный алгоритм с полиномиальным временем работы, характеризующийся 
постоянным коэффициентом аппроксимации, не существует, если только не ока
 жется справедливым соотношение Р = NP.
 35.2.1. 
Задача о коммивояжере с неравенством треугольника
 Применив методику из предыдущего раздела, сначала вычислим структуру — 
минимальное остовное дерево, — вес которой является нижней границей длины 
оптимального тура коммивояжера. Затем с помощью этого минимального остов- 
ного дерева создадим тур, стоимость которого не более чем в два раза превышает 
вес этого дерева при условии, что функция стоимости удовлетворяет неравенству 
треугольника. Этот подход реализован в приведенном ниже алгоритме, в котором 
используется алгоритм построения минимального остовного дерева MST-Prim, 
описанный в разделе 23.2. Параметр G представляет собой полный неориентиро
 ванный граф, а функция стоимости удовлетворяет неравенству треугольника.
 Approx-TSP-Tour(G, с)
 1 Выбираем вершину г е G. V в качестве “корневой”
 2 Вычисляем минимальное остовное дерево Т для G из корня г
 с использованием алгоритма МST-Prim(G, с, г)
 3 Пусть Н — список вершин, упорядоченный в соответствии с
 моментом первого посещения при обходе дерева Т 
в прямом порядке
 4 return гамильтонов цикл Н
 Вспомним из раздела 12.1, что при прямом обходе дерева рекурсивно посеща
 ются все его вершины, причем вершина заносится в список при первом посеще
 нии, до посещения ее дочерних вершин.
 Работа процедуры Approx-TSP-Tour показана на рис. 35.2. В части (а) по
 казан полный неориентированный граф, а в части (б) — минимальное остовное 
дерево Т с корнем а, вычисленное процедурой MST-Prim. В части (в) показано, 
как прямой обход дерева Т посещает вершины, а в части (г) показан соответству
 ющий тур, возвращаемый процедурой Approx-TSP-Tour. В части (г) приведен 
оптимальный тур, который короче примерно на 23%.
 Согласно результатам упр. 23.2.2 даже при простой реализации алгоритма 
MST-Prim время работы алгоритма Approx-TSP-Tour равно 0(V2). Теперь 
покажем, что если функция стоимости в экземпляре задачи коммивояжера удовле
 творяет неравенству треугольника, то алгоритм Approx-TSP-Tour возвращает 
тур, стоимость которого не более чем в два раза превышает стоимость оптималь
 ного тура.
Глава 35. Приближенные алгоритмы
 1165
 Рис. 35.2. Работа процедуры APPROX-TSP-TOUR. (а) Полный неориентированный граф. Верши
 ны лежат на пересечении линий целочисленной решетки. Например, / находится на одну единицу 
правее и на две выше, чем h. Функция стоимости между двумя точками представляет собой обыч
 ное евклидово расстояние, (б) Минимальное остовное дерево Т полного графа, вычисленное про
 цедурой MST-PRIM. Корневой вершиной является вершина а. Показаны только те ребра, которые 
входят в минимальное остовное дерево. Метки присвоены вершинам таким образом, что они добав
 ляются алгоритмом MST-PRIM в основное дерево в алфавитном порядке, (в) Порядок посещения 
вершин при прямом обходе дерева Т, начиная с вершины а. При полном обходе дерева вершины 
посещаются в порядке а, b, с, b, h, b, а, d, е, /, е, д, е, d, а. При прямом обходе дерева Т составляется 
список вершин, посещенных впервые (на рисунке возле каждой такой вершины поставлена точка). 
Полученный в результате список имеет вид а, 6, с, h, d, е, /, д. (г) Тур Н, возвращенный алгоритмом 
Approx-TSP-TOUR. Его полная стоимость составляет приблизительно 19.074. (д) Оптимальный 
тур Н* в исходном полном графе. Его общая стоимость приблизительно равна 14.715.
 Т е о р е м а 3 5 .2
 Алгоритм Approx-TSP-Tour является 2-приближенным алгоритмом с полино
 миальным временем работы, решающим задачу коммивояжера, в которой удовле
 творяется неравенство треугольника.
 Д о к а за т ел ьст во . Ранее было показано, что время работы алгоритма APPROX- 
TSP-Tour выражается полиномиальной функцией.
 Обозначим через Н * тур, который является оптимальным для данного множе
 ства вершин. Поскольку путем удаления из этого тура одного ребра получается 
остовное дерево, вес минимального остовного дерева Т, вычисляемого в строке 2 
процедуры Approx-TSP-Tour, равен нижней границе стоимости оптимального 
тура, т.е. выполняется неравенство
 с(Г) < с(Я*) .
 (35.4)
1166
 Часть VII. Избранные темы
 При полном обходе (full walk) дерева Т составляется список вершин, которые 
посещаются впервые, а также когда к ним происходит возврат после посещения 
поддерева. Обозначим этот обход через W . При полном обходе в рассматривае
 мом примере вершины посещаются в следующем порядке:
 а, 6, с, 6, h, 6, a, d, е, /, е, g, е, d, а .
 Поскольку при полном обходе каждое ребро дерева Т проходится ровно по два 
раза, естественным образом обобщив определение стоимости с на множества, 
в которых ребра встречаются по несколько раз, получаем равенство
 c(W) = 2с(Т) . 
Из (35.4) и (35.5) вытекает, что
 c{W) < 2с{Н*) , 
(35.5)
 (35.6)
 так что стоимость обхода W превышает стоимость оптимального тура не более 
чем в два раза.
 К сожалению, полный обход W в общем случае не является туром, поскольку 
он посещает некоторые вершины более одного раза. Однако согласно неравенству 
треугольника посещение любой из вершин в обходе W можно отменить, и при 
этом стоимость не возрастет. (Если из маршрута W удалить вершину v, которая 
посещается в этом маршруте на пути от вершины и к вершине w, то в полученном 
в результате такой операции упорядоченном списке вершин будет определяться 
переход непосредственно от вершины и к вершине w.) Путем неоднократного 
выполнения этой операции из обхода W можно исключить все посещения каж
 дой вершины, кроме первого. В рассматриваемом примере упорядоченный список 
вершин принимает вид
 й
 , 6, с, Л., d, е, f , g .
 Этот порядок совпадает с тем, который получается при прямом обходе дерева Т. 
Пусть Н — цикл, соответствующий данному прямому обходу. Это гамильтонов 
цикл, так как каждая вершина посещается по одному разу. Именно этот цикл 
и вычисляется алгоритмом Approx-TSP-Tour. Поскольку цикл Н получается 
путем удаления вершин из полного обхода W, выполняется неравенство
 с(Н) < c(W) . 
(35.7)
 Объединив неравенства (35.6) и (35.7), получаем с(Н) < 2с(Н*), что и завершает 
доказательство. 
■
 Несмотря на то что теорема 35.2 позволяет добиться неплохого коэффициента 
аппроксимации, обычно на практике алгоритм Approx-TSP-Tour — не лучший 
выбор для решения этой задачи. Существует другой приближенный алгоритм, ко
 торый обычно дает намного лучшие практические результаты (см. ссылки в конце 
этой главы).
Глава 35. Приближенные алгоритмы
 35.2.2. 
Общая задача о коммивояжере
 1167
 Если отказаться от предположения о том, что функция стоимости с удовлетво
 ряет неравенству треугольника, то нельзя найти туры с хорошим приближением 
за полиномиальное время, если только не выполняется условие Р = NP.
 Теорема 35.3
 Если Р ф NP, то для любой константы р > 1 не существует приближенного 
алгоритма с полиномиальным временем работы и коэффициентом аппроксимации 
р, позволяющего решить задачу о коммивояжере в общем случае.
 Доказательство. Докажем теорему “от противного” Предположим, что для 
некоторого числа р > 1 существует приближенный алгоритм А с полиномиаль
 ным временем работы и коэффициентом аппроксимации р. Без потери общности 
предположим, что число р — целое, при необходимости округлив его. Затем пока
 жем, как с помощью алгоритма А можно решать экземпляры задачи о гамильто
 новом цикле (определенной в разделе 34.2) за полиномиальное время. Поскольку 
задача о гамильтоновом цикле согласно теореме 34.13 NP-полная, из ее разреши
 мости за полиномиальное время и теоремы 34.4 следует равенство Р = NP.
 Пусть G = (F, Е) — экземпляр задачи о гамильтоновом цикле. Мы хотим эф
 фективно определить с помощью гипотетического приближенного алгоритма А, 
содержит ли граф G гамильтонов цикл. Преобразуем граф G в экземпляр задачи 
о коммивояжере. Пусть G' = (V, Е') — полный граф на множестве V, т.е.
 Е' = {(ц,г;) : u,v € V и и ф v} .
 Назначим каждому ребру из множества Е' целочисленную стоимость:
 Г 1 , 
если (u, v) е Е ,
 c(u,v) = < ( р | V| + 1 в противном случае .
 Представление графа G' и функции с можно получить из представления графа G 
за время, полиномиально зависящее от величин |Р| и \Е\.
 Теперь рассмотрим задачу о коммивояжере (G',c). Если исходный граф G со
 держит гамильтонов цикл Н, то функция стоимости с сопоставляет каждому реб
 ру цикла Н единичную стоимость, а значит, экземпляр (G', с) содержит тур сто
 имостью |V|. С другой стороны, если граф G не содержит гамильтонова цикла, 
то в любом туре по графу G' должно использоваться некоторое ребро, отсутству
 ющее в множестве Е. Однако стоимость любого тура, в котором используется 
ребро, не содержащееся в множестве Е, не меньше величины
 (p|V| + l) + (|V |-l) = p|V| + |V|
 >p\V\ .
 Из-за большой стоимости ребер, отсутствующих в графе G, между стоимостью 
тура, который представляет собой гамильтонов цикл в графе G (она равна |У|), 
и стоимостью любого другого тура (его величина не меньше р | V'l + I V|) существу
1168
 Часть VII. Избранные темы
 ет интервал, величина которого не меньше р \V\. Следовательно, стоимость тура, 
не являющегося гамильтоновым циклом в G, как минимум в р + 1 раз больше 
стоимости тура, являющегося гамильтоновым циклом в G.
 Теперь предположим, что мы применяем к задаче о коммивояжере (G', с) ал
 горитм А. Поскольку этот алгоритм гарантированно возвращает тур, стоимость 
которого не более чем в р раз превышает стоимость оптимального тура, если 
граф G содержит гамильтонов цикл, алгоритм А должен его возвратить. Если 
же граф G не содержит гамильтоновых циклов, то алгоритм А возвращает тур, 
стоимость которого превышает величину p\V\. Поэтому с помощью алгоритма А 
задачу о гамильтоновом цикле можно решить за полиномиальное время. 
■
 Доказательство теоремы 35.3 служит примером общей методики доказатель
 ства того, что задачу нельзя очень хорошо аппроксимировать. Предположим, что 
заданной NP-сложной задаче X в течение полиномиального времени можно со
 поставить такую задачу минимизации У, что “да”-экземпляры задачи X будут 
соответствовать экземплярам задачи Y, стоимость которых не превышает к (где 
к — некоторая фиксированная величина), а “нет”-экземпляры задачи X будут со
 ответствовать экземплярам задачи Y, стоимость которых превышает рк. Затем 
мы должны показать, что, если только не выполняется равенство Р = NP, не су
 ществует р-приближенного алгоритма с полиномиальным временем работы, поз
 воляющего решить задачу У.
 Упражнения
 35.2.1
 Предположим, что полный неориентированный граф G = (V, Е), содержащий 
не менее трех вершин, характеризуется функцией стоимости с, удовлетворяющей 
неравенству треугольника. Докажите, что для всех и, v Е V выполняется нера
 венство с(и, v) > 0.
 35.2.2
 Покажите, как за полиномиальное время один экземпляр задачи о коммивояже
 ре можно преобразовать в другой экземпляр, функция стоимости которого удо
 влетворяет неравенству треугольника. Оба экземпляра должны содержать одно 
и то же множество оптимальных туров. Объясните, почему такое полиномиаль
 но-временное преобразование не противоречит теореме 35.3, в предположении, 
что Р / NP.
 35.2.3
 Рассмотрим описанный ниже эвристический метод ближайшей точки (closest- 
point heuristic), позволяющий создавать приближенные туры в задаче о комми
 вояжере, функция стоимости которой удовлетворяет неравенству треугольника. 
Начнем построение с тривиального цикла, состоящего из одной произвольным 
образом выбранной вершины. На каждом этапе находится вершина и, не при
 надлежащая циклу, причем такая, расстояние от которой до цикла является ми
 нимальным. Предположим, что ближе всех к вершине и в цикле расположена
Глава 35. Приближенные алгоритмы
 1169
 вершина v. Цикл расширяется за счет включения в него вершины и сразу после 
вершины v. Описанные действия повторяются до тех пор, пока в цикл не будут 
включены все вершины. Докажите, что этот эвристический метод возвращает тур, 
полная стоимость которого не более чем в два раза превышает полную стоимость 
оптимального тура.
 35.2.4
 Задача о коммивояжере с устранением узких мест (bottleneck travelling-sales
 man problem) — это задача поиска такого гамильтонова цикла, для которого ми
 нимизируется стоимость самого дорогостоящего входящего в этот цикл ребра. 
Предполагая, что функция стоимости удовлетворяет неравенству треугольника, 
покажите, что для этой задачи существует приближенный алгоритм с полиноми
 альным временем работы, коэффициент аппроксимации которого равен 3. (Ука
 зание: воспользовавшись рекурсией, покажите, что все узлы остовного дерева 
с узкими местами можно обойти ровно по одному разу, беря полный обход дере
 ва и выполняя в нем пропуски таким образом, чтобы не пропускать более двух 
последовательных промежуточных узлов (см. задачу 23.3). Покажите, что стои
 мость самого дорогостоящего ребра в остовном дереве с узкими местами не пре
 вышает стоимости самого дорогостоящего ребра в гамильтоновом цикле с узкими 
местами.)
 35.2.5
 Предположим, что вершины экземпляра задачи о коммивояжере расположены на 
плоскости и что стоимость с(и, г;) равна евклидову расстоянию между точками и 
и v. Покажите, что в оптимальном туре никогда не будет самопересечений.
 35.3. Задача о покрытии множества
 Задача о покрытии множества — это задача оптимизации, моделирующая мно
 гие задачи распределения ресурсов. Соответствующая ей задача принятия реше
 ния представляет собой обобщение NP-полной задачи о вершинном покрытии 
и, таким образом, является NP-cложной. Однако приближенный алгоритм, раз
 работанный для задачи о вершинном покрытии, в данном случае неприменим, 
поэтому следует попытаться поискать другие подходы. Исследуем простой эв
 ристический жадный метод, коэффициент аппроксимации которого выражается 
логарифмической функцией. Другими словами, по мере того как растет размер 
экземпляра задачи, размер приближенного решения также может возрастать от
 носительно размера оптимального решения. Однако, так как логарифмическая 
функция возрастает достаточно медленно, этот приближенный алгоритм может 
давать полезные результаты.
 Экземпляр (X, Т) задачи о покрытии множества (set-covering problem) со
 стоит из конечного множества X и такого семейства Т подмножеств множества 
X, что каждый элемент множества X принадлежит хотя бы одному подмножеству
1170
 Часть VII. Избранные темы
 Рис. 35.3. Экземпляр (X, Т) задачи о покрытии множества, где X состоит из 12 черных точек, 
а Т = {Si, 5г, S3, S4, S5, Se}. Минимальным является покрытие С = {S3, S4, S5}, размер которого 
равен 3. Жадный алгоритм дает покрытие размером 4, выбирая либо множества 5х, 54, S5 и S3, 
либо множества Si, S4, S5 и Se в указанном порядке.
 из семейства Т:
 * = U 5
se?
 Говорят, что подмножество S € Т покрывает (covers) содержащиеся в нем эле
 менты. Задача состоит в том, чтобы найти подмножество С С X минимального 
размера, члены которого покрывают все множество X :
 X = |J S . 
sec
 (35.8)
 Говорят, что любое семейство С, удовлетворяющее уравнению (35.8), покрывает 
(covers) множество X. Задача о покрытии множества иллюстрируется на рис. 35.3. 
Размер семейства С определяется как количество содержащихся в нем подмно
 жеств, а не как суммарное количество отдельных элементов в этих множествах. 
В примере, проиллюстрированном на рис. 35.3, размер минимального покрытия 
множества равен 3.
 Задача о покрытии множества абстрагирует многие часто возникающие ком
 бинаторные задачи. В качестве простого примера предположим, что множество 
X представляет набор знаний, необходимых для решения задачи, над которой 
работает определенный коллектив сотрудников. Нужно сформировать комитет, 
состоящий из минимально возможного количества сотрудников, причем такой, 
что при необходимости получения любой информации из множества X окажет
 ся, что в комитете есть сотрудник, обладающий необходимыми знаниями. Если 
преобразовать эту задачу в задачу принятия решений, то в ней будет спрашивать
 ся, существует ли покрытие, размер которого не превышает к, где к — дополни
 тельный параметр, определенный в экземпляре задачи. Как предлагается показать 
в упр. 35.3.2, версия этой задачи в форме задачи принятия решений является NP- 
полной.
Глава 35. Приближенные алгоритмы
 1171
 Жадный приближенный алгоритм
 Жадный метод работает путем выбора на каждом этапе множества S, покры
 вающего максимальное количество элементов, оставшихся непокрытыми.
 Greedy-Set-Cover (X, X)
 1 U = X
 2 С = 0
 3 while U ф 0
 4 
Выбрать S € Т, максимизирующее \S П U\
 5 
6 
U = U-S
 C = CU{5}
 7 return С
 В примере на рис. 35.3 процедура Greedy-Set-Cover поочередно добавляет к С 
множества S\, S4 и 5s, после чего добавляется либо S3, либо Sq.
 Алгоритм работает следующим образом. На каждом этапе его работы мно
 жество U содержит элементы, оставшиеся непокрытыми. Множество С содер
 жит покрытие, которое строится алгоритмом. Строка 4 представляет собой этап 
принятия решения в жадном методе. Выбирается подмножество S, покрывающее 
максимально возможное количество еще непокрытых элементов (с произвольным 
разрешением неоднозначностей). После выбора подмножества S его элементы 
удаляются из множества U, а само подмножество S помещается в семейство С. 
Когда алгоритм завершит свою работу, множество С будет содержать подсемей
 ство семейства Т, покрывающее множество X.
 Алгоритм Greedy-Set-Cover легко реализовать таким образом, чтобы вре
 мя его работы выражалось полиномиальной функцией от величин \Х\ и |.F|. По
 скольку количество итераций цикла в строках 3-6 ограничено сверху величиной 
min(|X|, l^l), а тело цикла можно реализовать таким образом, чтобы его вы
 полнение завершалось за время 0(|Х| 1^1), простая реализация алгоритма имеет 
время работы, равное 0(|Х| \Х\ 0110(1X1, |.F|)). В упр. 35.3.3 предлагается разра
 ботать алгоритм с линейным временем работы.
 Анализ
 Теперь покажем, что жадный алгоритм возвращает покрытие множества, не 
слишком сильно превышающее оптимальное покрытие. Для удобства в этой гла
 ве d-e по порядку гармоническое число На = Yli= 1 V* (см- раздел А.1) будет 
обозначаться как H(d). В качестве граничного условия определим Я(0) = 0.
 Теорема 35.4
 Алгоритм Greedy-Set-Cover является р{п)-приближенным алгоритмом с по
 линомиальным временем работы, где
 р(п) = Н(max {|5| : S G ^}) .
1172
 Часть VII. Избранные темы
 Доказательство. Мы уже показали, что алгоритм Greedy-Set-Cover выпол
 няется за полиномиальное время.
 Чтобы показать, что Greedy-Set-Cover является р(п)-приближенным алго
 ритмом, присвоим каждому из выбранных алгоритмом множеств стоимость 1, 
распределим ее по всем элементам, покрытым за первый раз, а затем с помо
 щью этих стоимостей получим искомое соотношение между размером оптималь
 ного покрытия множества С* и размером покрытия С, возвращенного алгорит
 мом. Обозначим г-е подмножество, выбранное алгоритмом Greedy-Set-Cover, 
как Si; добавление подмножества Si в множество С приводит к увеличению стои
 мости на единицу. Равномерно распределим стоимость, соответствующую выбору 
подмножества Si, между элементами, которые впервые покрываются этим под
 множеством. Обозначим через сх стоимость, выделенную элементу х, для каждо
 го х G X. Стоимость выделяется каждому элементу только один раз, когда этот 
элемент покрывается впервые. Если элемент х первый раз покрывается подмно
 жеством Si, то выполняется равенство
 1
 Cl “ \Si-{S1uS2U---uSi-1)\ '
 На каждом шаге алгоритма присваивается единичная стоимость, поэтому
 i d = J 2 с* • 
хех
 <35-9)
 Каждый элемент х 6 X находится как минимум в одном множестве из оптималь
 ного покрытия С*, так что
 5Z 5Z Cl - 5Z сх . 
sec* xes 
хех
 Объединив (35.9) и (35.10), получаем соотношение
 | С |< £ Е с*- 
sec*xes
 (35.10)
 (35.11)
 Оставшаяся часть доказательства основана на приведенном ниже ключевом 
неравенстве, которое будет доказано чуть позже. Для любого множества S, при
 надлежащего семейству Т, выполняется неравенство
 ^ с х<Я(|5|). 
xes
 Из неравенств (35.11) и (35.12) следует, что
 |С| < £ Я(|Я|)
 sec*
 < \С*\ • tf(max{|S| : S Е Т}) ,
 (35.12)
 что и доказывает теорему.
Глава 35. Приближенные алгоритмы
 1173
 Все, что осталось сделать — это доказать неравенство (35.12). Рассмотрим про
 извольные множество S G Т и индекс г = 1,2,..., \С\ и введем величину
 Wi = |S — (Si U S2 U • • • U Si)\ ,
 которая равна количеству элементов множества S, оставшихся непокрытыми по
 сле того, как в алгоритме были выбраны множества Si, S2,..., S*. Определим 
величину щ = |S|, равную количеству элементов множества S, которые изна
 чально непокрыты. Пусть к — минимальный индекс, при котором выполняется 
равенство и^ = 0, т.е. каждый элемент множества S покрывается хотя бы одним 
из множеств Si, S2, •.., S^. Тогда Щ-\ > щ, и при г = 1,2,..., к множеством S{ 
впервые покрываются щ-\ — щ элементов множества S. Таким образом,
 Заметим, что
 \Si - (Si U S2 U • • • U Si_i)| > |S - (Si U S2 U • • • U Si_i)|
 поскольку при жадном выборе множества Si гарантируется, что множество S не 
может покрыть больше новых элементов, чем множество S{ (в противном слу
 чае вместо множества S{ было бы выбрано множество S). Таким образом, мы 
получаем неравенство
 Теперь ограничим эту величину следующим образом:
 г=1 j=ut + l
 к
 J2 (H(4i-i) - Н(щ))
 (поскольку j < Щ-1)
1174
 что и завершает доказательство неравенства (35.12). 
Часть VII. Избранные темы
 = Н(щ) — Н(иь) 
= я Ы - Я(0)
 = Н(щ) 
= Я(|5|),
 (благодаря телескопичности суммы)
 (поскольку Я(0) = 0)
 ■
 Следствие 35.5
 Алгоритм Greedy-Set-Cover является (In \Х\ + 1)-приближенным алгоритмом 
с полиномиальным временем работы.
 Доказательство. Достаточно воспользоваться неравенством (А. 14) и теоре
 мой 35.4. 
■
 В некоторых приложениях величина max{|5| : S G Т} представляет собой 
небольшую константу, поэтому решение, которое возвращается алгоритмом 
Greedy-Set-Cover, больше оптимального на множитель, не превышающий ма
 лую константу. Одно из таких приложений — получение с помощью описанного 
выше эвристического метода приближенного вершинного покрытия графа, сте
 пень вершин которого не превышает 3. В этом случае решение, найденное алго
 ритмом Greedy-Set-Cover, не более чем в Я(3) = 11/6 раз больше оптималь
 ного решения, т.е. оно несколько лучше решения, предоставляемого алгоритмом 
Approx-Vertex-Cover.
 Упражнения
 35.3.1
 Будем рассматривать каждое из приведенных далее слов как множество букв: 
{arid, dash, drain, heard, lost, nose, shun, slate, snare, thread}. 
Приведите покрытие множества, которое будет возвращено алгоритмом Greedy- 
Set-Cover, если неоднозначности разрешаются в пользу слов, которые находят
 ся в словаре раньше других.
 35.3.2
 Покажите, что задача о покрытии множества в форме задачи принятия решения 
является NP-полной. Для этого приведите к ней задачу о вершинном покрытии.
 35.3.3
 Покажите, как реализовать процедуру Greedy-Set-Cover, чтобы она выполня
 лась за время 
|5|^.
 35.3.4
 Покажите, что приведенное ниже неравенство (более слабое по сравнению с ис
 пользованным в теореме 35.4) выполняется тривиальным образом:
 \С\ < \С*\ max {|S'| : S G T} .
Глава 35. Приближенные алгоритмы
 35.3.5
 1175
 В зависимости от принципа разрешения неоднозначностей в строке 4 алгоритм 
Greedy-Set-Cover может возвращать несколько разных решений. Разработайте 
процедуру Bad-Set-Cover-Instance(7i), возвращающую гг-элементный экзем
 пляр задачи о покрытии множества, для которого процедура Greedy-Set-Cover 
при разной организации разрешения неоднозначностей в строке 4 могла бы воз
 вращать различные решения, количество которых выражалось бы показательной 
функцией от п.
 35.4. Рандомизация и линейное программирование
 В этом разделе мы изучим два весьма полезных для разработки приближенных 
алгоритмов метода: рандомизацию и линейное программирование. Здесь будет 
приведен простой рандомизированный алгоритм, позволяющий создать оптими
 зирующую версию решения задачи о Э-СОТ-выполнимости, после чего с помо
 щью методов линейного программирования будет разработан приближенный ал
 горитм для взвешенной версии задачи о вершинном покрытии. В тексте раздела 
эти два мощных метода рассматриваются лишь поверхностно, но в заключитель
 ных замечаниях к главе даются ссылки для дальнейшего изучения этой темы.
 Рандомизированный приближенный алгоритм для задачи 
о МАХ-З-С^-выполнимости
 Рандомизированные алгоритмы могут применяться для поиска как точных, так 
и приближенных решений. Говорят, что рандомизированный алгоритм решения 
задачи имеет коэффициент аппроксимации (approximation ratio) р(п), если для 
любых входных данных размера п ожидаемая стоимость С решения, получен
 ного с помощью этого рандомизированного алгоритма, не более чем в р(п) раз 
превышает стоимость С* оптимального решения:
 (35.13)
 Рандомизированный алгоритм, позволяющий получить коэффициент аппрокси
 мации р(п), называют рандомизированным р(ть)-приближенным алгоритмом 
(randomized p(n)-approximation algorithm). Другими словами, рандомизированный 
приближенный алгоритм похож на детерминистический приближенный алгоритм, 
с тем отличием, что его коэффициент аппроксимации относится к ожидаемой сто
 имости.
 Конкретный экземпляр задачи о З-СОТ-выполнимости, определенной в разде
 ле 34.4, может не выполняться. Чтобы он был выполнимым, должен существо
 вать такой вариант присвоения переменных, при котором каждое подвыражение 
в скобках принимает значение 1. Если экземпляр невыполнимый, может возник
 нуть потребность оценить, насколько он “близок” к выполнимому. Другими сло
1176
 Часть VII. Избранные темы
 вами, может возникнуть желание определить, какие значения следует присво
 ить переменным, чтобы выполнялось максимально возможное количество под
 выражений в скобках. Назовем задачу, которая получилась в результате, задачей 
о MAX-3-CNF-выполнимости (MAX-3-CNF satisfiability). Входные данные этой 
задачи совпадают с входными данными задачи о З-СОТ-выполнимости, а цель 
состоит в том, чтобы найти присваиваемые переменным значения, при которых 
значение 1 принимает максимальное количество подвыражений в скобках. Теперь 
покажем, что если значения присваиваются каждой переменной случайным обра
 зом, причем значения 0 и 1 присваивается с вероятностью 1/2, то получается 
рандомизированный 8/7-приближенный алгоритм. В соответствии с определени
 ем 3-С№-выполнимости, приведенном в разделе 34.4, требуется, чтобы в каждом 
подвыражении в скобках содержалось ровно три различных литерала. Кроме того, 
предполагается, что ни одно из выражений в скобках не содержит одновремен
 но переменной и ее отрицания. (В упр. 35.4.1 предлагается отказаться от этого 
предположения.)
 Теорема 35.6
 Для заданного экземпляра задачи о МАХ-З-СОТ-выполнимости с п переменны
 ми xi, Х2,..., хп и т подвыражениями в скобках рандомизированный алгоритм, 
в котором каждой переменной независимо с вероятностью 1 /2 присваивается зна
 чение 1 и с той же вероятностью 1/2 — значение 0, является рандомизированным 
8/7-приближенным алгоритмом.
 Доказательство. Предположим, что каждой переменной независимо с вероят
 ностью 1/2 присваивается значение 1 и с той же вероятностью 1/2 — значение 0. 
Определим для г = 1,2,..., га индикаторную случайную величину
 Yi = I {подвыражение г выполняется} ,
 так что равенство Yi = I выполняется, если хотя бы одному из литералов, содер
 жащихся в г-м выражении в скобках, присвоено значение 1. Поскольку ни один 
из литералов не входит в одно и то же подвыражение в скобках более одного раза 
и поскольку предполагается, что одни и те же скобки не содержат одновременно 
переменную и ее отрицание, присвоение значений трем переменным в каждых 
скобках выполняется независимым образом. Выражение в скобках не выполняет
 ся только тогда, когда всем трем его литералам присваивается значение 0, поэтому 
Рг {подвыражение i не выполняется} = (1/2)3 = 1/8. Таким образом, мы имеем 
Рг {подвыражение г выполняется} = 1 — 1/8 = 7/8, и согласно лемме 5.1 имеем 
Е [Vf] = 7/8. Пусть У — общее количество выполняющихся подвыражений, так 
что У = Yi + Y2 -I-------Ь Ym. Тогда
 Е [У] = Е
 (из линейности математического ожидания)
 г = 1
Глава 35. Приближенные алгоритмы
 т
 = Е 7/8
 — 7га/8 .
 1177
 Очевидно, что верхняя граница количества выполняющихся подвыражений 
в скобках равна га, поэтому коэффициент аппроксимации не превышает значе
 ния га/(7га/8) — 8/7. 
■
 Аппроксимация взвешенного вершинного покрытия с помощью линейного 
программирования
 В задаче о вершинном покрытии с минимальным весом (minimum-weight 
vertex-cover problem) задается неориентированный граф G — (V, Е), в котором 
каждой вершине v £ V назначается положительный вес w(v). Вес любого вер
 шинного покрытия V1 С V определяется как w{V') = ^2vey> w(v). В задаче 
нужно найти вершинное покрытие с минимальным весом.
 К этой задаче нельзя применить ни алгоритм, который использовался для по
 иска невзвешенного вершинного покрытия, ни рандомизированное решение, так 
как оба эти метода могут дать решение, далекое от оптимального. Однако с по
 мощью задачи линейного программирования можно вычислить нижнюю границу 
веса, который может возникать в задаче о вершинном покрытии минимального 
веса. Затем мы “округлим” это решение и с его помощью получим вершинное 
покрытие.
 Предположим, что каждой вершине v £ V сопоставляется переменная x(v), 
и поставим условие, чтобы x(v) было равно либо 0, либо 1 для каждой вершины 
v £ V. Равенство x(v) = 1 интерпретируется как принадлежность вершины v 
вершинному покрытию, а равенство x(v) = 0 — как ее отсутствие в вершинном 
покрытии. Тогда ограничение, согласно которому для любого ребра (и, v) хотя бы 
одна из вершин и и v должна входить в вершинное покрытие, можно наложить 
с помощью неравенства х(и) + x(v) > 1. Такой подход приводит нас к 0-1-це- 
лочисленной задаче линейного программирования (0-1 integer program) поиска 
вершинного покрытия с минимальным весом:
 минимизировать 
при условиях
 w(v) x(v) 
vGV
 х(и) + x(v) > 1 
для каждого (u, v) £ Е 
x(v) £ {0,1} для каждой v £ V .
 (35.14)
 (35.15)
 (35.16)
 В частном случае, когда все веса w(v) равны 1, мы получаем NP-сложную 
оптимизирующую версию задачи о вершинном покрытии. Предположим, однако, 
что ограничение x(v) £ {0,1} убирается, а вместо него накладывается условие 
О < x{v) < 1. Тогда мы получим ослабленную задачу линейного программиро
1178
 вания (linear-programming relaxation):
 минимизировать
 при условиях
 w(v) x(v)
 vEV
 Часть VII. Избранные темы
 (35.17)
 x(u) + x(v) > 1 для каждого (и, v) G E
 x(v) < 1 для каждой v 6 V
 x(v) > 0 для каждой v e V .
 (35.18)
 (35.19)
 (35.20)
 Любое допустимое решение 0-1 целочисленной задачи линейного программиро
 вания, определенной в (35.14)—(35.16), является также допустимым решением за
дачи линейного программирования, определенной в (35.17)—(35.20). Поэтому оп
 тимальное решение задачи линейного программирования является нижней грани
 цей оптимального решения 0-1 целочисленной задачи, а следовательно, нижней 
границей оптимального решения задачи о вершинном покрытии с минимальным 
весом.
 В приведенной ниже процедуре с помощью решения сформулированной вы
 ше задачи линейного программирования строится приближенное решение задачи
 0 вершинном покрытии с минимальным весом.
 Approx-Min-Weight-VC (G, w)
 1 С = 0
 2 Вычисление х, оптимального решения задачи
 линейного программирования (35.17)—(35.20)
 3 for каждой v е V
 4 
if x(v) >1/2
 5 
С = С UM
 6 return С
 Процедура Approx-Min-Weight-VC работает следующим образом. В стро
 ке 1 вершинное покрытие инициализируется пустым множеством. В строке 2 
формулируется и решается задача линейного программирования, определенная 
в (35.17)—(35.20). В оптимальном решении с каждой вершиной v связано значе
 ние 0 < x(v) < 1. С помощью этой величины в строках 3-5 определяется, какие 
вершины добавятся в вершинное покрытие С. Если x(v) > 1/2, вершина v добав
 ляется в покрытие С; в противном случае она не добавляется. В результате каж
 дая дробная величина, входящая в решение задачи линейного программирования, 
“округляется” и получается решение 0-1 целочисленной задачи, определенной 
в (35.14)-(35.16). Наконец в строке 6 возвращается вершинное покрытие С.
 Теорема 35.7
 Алгоритм Approx-Min-Weight-VC является 2-приближенным алгоритмом 
с полиномиальным временем работы, позволяющим решить задачу о вершинном 
покрытии с минимальным весом.
Глава 35. Приближенные алгоритмы
 1179
 Доказательство. Поскольку существует алгоритм с полиномиальным време
 нем решения, позволяющий решить задачу линейного программирования в стро
 ке 2, и поскольку цикл for в строках 3-5 выполняется за полиномиальное время, 
алгоритм Approx-Min-Weight-VC имеет полиномиальное время работы.
 Теперь покажем, что он является 2-приближенным алгоритмом. Пусть С* — 
оптимальное решение задачи о вершинном покрытии с минимальным весом, 
а г* — значение оптимального решения задачи линейного программирования, 
определенной в (35.17)—(35.20). Поскольку оптимальное вершинное покрытие яв
 ляется допустимым решением этой задачи, величина г* должна быть нижней 
границей величины w(C*), т.е. выполняется неравенство
 г* < w(C*) .
 (35.21)
 Далее, утверждается, что при округлении дробных значений переменных x(v) 
получается множество С, которое является вершинным покрытием, удовлетворя
 ющим неравенству w(C) < 2z*. Чтобы убедиться, что С — вершинное покрытие, 
рассмотрим произвольное ребро (u,v) е Е. Согласно ограничению (35.18) долж
 но выполняться неравенство х(и) + x(v) > 1, из которого следует, что хотя бы 
одна из величин х(и) и x(v) не меньше 1/2. Поэтому хотя бы одна из вершин 
и и v будет включена в вершинное покрытие, а следовательно, будут покрыты 
все ребра.
 Теперь рассмотрим, чему равен вес этого покрытия. Имеем следующую це
 почку соотношений:
 vev
 >
 v€V:x(v)>l/2
 > w(v) ■ 
v€V:x(v)>l/2
 veC
 vec
 = -2ги(С) .
 Объединение неравенств (35.21) и (35.22) дает
 w(C) < 2z* < 2w(C*) ,
 (35.22)
 а следовательно, Approx-Min-Weight-VC является 2-приближенным алгорит
1180
 Упражнения
 35.4.1
 Часть VII. Избранные темы
 Покажите, что даже если бы подвыражение в скобках могло содержать одно
 временно переменную и ее отрицание, то в результате независимого присвоения 
каждой переменной значения 1 с вероятностью 1/2 и значения 0 с той же веро
 ятностью все равно получился бы рандомизированный 8/7-приближенный алго
 ритм.
 35.4.2
 Задача о MAX-CNF-выполнимости (MAX-CNF satisfiability problem) похожа на 
задачу о МАХ-З-СОТ-выполнимости с тем исключением, что в каждом подвыра
 жении в скобках необязательно содержится по три литерала. Разработайте рандо
 мизированный 2-приближенный алгоритм, позволяющий решить задачу о MAX- 
CNF-выполнимости.
 35.4.3
 В задаче MAX-CUT задан невзвешенный неориентированный граф G = {V,E). 
Определим разрез (5, V — 5), как это было сделано в главе 23, а вес (weight) этого 
разреза, как количество пересекающих его ребер. Требуется найти разрез с мак
 симальным весом. Предположим, что каждая вершина v случайно и независимо 
с вероятностью 1/2 помещается в множество S или V — S. Покажите, что этот 
алгоритм является рандомизированным 2-приближенным алгоритмом.
 35.4.4
 Покажите, что ограничение (35.19) избыточно в том смысле, что если опустить 
его из задачи линейного программирования, определенной в (35.17)—(35.20), то 
любое оптимальное решение полученной в результате задачи линейного про
 граммирования для каждой вершины v £ V должно удовлетворять неравенству
 x(v) < 1.
 35.5. Задача о сумме подмножества
 Вспомним из раздела 34.5.5, что экземпляр задачи о сумме подмножества име
 ет вид пары (S,t), где S — множество {х\,Х2,...,хп} положительных целых 
чисел, a t — положительное целое число. В этой задаче принятия решений спра
 шивается, существует ли подмножество множества 5, сумма элементов которого 
равна целевому значению t. Эта задача является NP-полной (см. раздел 34.5.5).
 Задача оптимизации, связанная с этой задачей принятия решений, возникает 
в различных практических приложениях. В такой задаче оптимизации требуется 
найти подмножество множества {xi, Х2,..., хп}, сумма элементов которого при
 нимает максимально возможное значение, не большее t. Например, пусть имеется 
грузовик, грузоподъемность которого не превышает t кг, и п различных ящиков, 
которые нужно перевезти. Вес г-го ящика равен х* кг. Требуется загрузить грузо
Глава 35. Приближенные алгоритмы
 1181
 вик максимально возможным весом, но так, чтобы не превысить его грузоподъ
 емность.
 В этом разделе приведен алгоритм, позволяющий решить задачу оптимизации 
за экспоненциальное время. Затем показано, как модифицировать приведенный 
алгоритм, чтобы он превратился в схему аппроксимации с полностью полиноми
 альным временем решения. (Напомним, что время работы схемы аппроксимации 
с полностью полиномиальным временем выполнения выражается полиномиаль
 ной функцией от величины 1/е и от размера входных данных.)
 Точный алгоритм с экспоненциальным временем работы
 Предположим, что для каждого подмножества S' множества S вычисляется 
сумма его элементов, после чего из всех подмножеств, сумма элементов кото
 рых не превышает t, выбирается подмножество, для которого эта сумма меньше 
других отличается от t. Очевидно, что такой алгоритм возвратит оптимальное 
решение, но время его работы выражается показательной функцией. Для реали
 зации этого алгоритма можно было бы воспользоваться итеративной процедурой, 
в которой в г-й итерации вычислялись бы суммы элементов всех подмножеств 
множества {xi, Х2,..., х*} на основе вычисленных ранее сумм всех подмножеств 
множества {xi,X2,... , x^-i}. Если пойти этим путем, то легко понять, что нет 
смысла продолжать обработку некоторого подмножества S' после того, как сум
 ма его элементов превысит t, поскольку никакое надмножество S' не может быть 
оптимальным решением. Реализуем эту стратегию.
 В качестве входных данных процедуры Exact-Subset-Sum, с псевдокодом 
которой мы скоро ознакомимся, выступают множество S = {xi, Х2,..., хп} и це
 левое значение t. В этой процедуре итеративно вычисляется список Li, содержа
 щий суммы всех подмножеств множества {xi,..., х*}, которые не превышают t. 
Затем возвращается максимальное значение из списка Ln.
 Если L — список положительных целых чисел, ах — еще одно положитель
 ное целое число, тогда через L + х будет обозначаться список целых чисел, по
 лученный из списка L путем увеличения каждого его элемента на величину х. 
Например, если L = (1, 2, 3, 5, 9), то L + 2 = (3, 4, 5, 7,11). Воспользуемся этим 
обозначением и для множеств, так что
 5 + x = {s + x:se5} .
 Кроме того, нам понадобится вспомогательная процедура MERGE- 
LlSTS (L,L'), которая возвращает отсортированный список, представляющий 
собой объединение входных отсортированных списков L и L' с исключением 
повторяющихся значений. Время выполнения процедуры Merge-Lists, как 
и время выполнения процедуры Merge, используемой для сортировки слия
 нием и описанной в разделе 2.3.1, равно 0(\L\ + \L'\). (Псевдокод процедуры 
Merge-Lists опущен.)
1182
 Exact-Subset-Sum (5, t)
 1 n = \S\
 2 
L0 = (0)
 3 for i = 1 to n
 4 
Li = Merge-Li s t s , Z/j—i -t-Xj)
 5 
Удалить из L* все элементы, превышающие t
 6 return наибольший элемент в Ln
 Часть VII. Избранные темы
 Рассмотрим, как работает процедура Exact-Subset-Sum . Обозначим через 
Pi множество всех значений, которые можно получить, выбрав (возможно, пу
 стое) подмножество множества {х\,Х2,... ,£*} и просуммировав его элементы. 
Например, если S = {1,4,5}, то
 Л = {0,1} ,
 Я! = {0,1,4,5} ,
 Р3 = {0,1,4,5,6,9,10} .
 Воспользовавшись тождеством
 Pi = Pi-1 U (Pi-1 + Xi) ,
 (35.23)
 методом математической индукции по г можно доказать (см. упр. 35.5.1), что Li — 
отсортированный список, содержащий все элементы множества Pi, значения ко
 торых не превышают t. Поскольку длина списка Li может достигать значения 
2\ в общем случае время выполнения алгоритма Exact-Subset-Sum ведет себя 
как показательная функция, хотя в некоторых частных случаях, когда величина t 
представляет собой полином от \S\ или все содержащиеся в множестве S числа 
ограничены сверху полиномиальными величинами от |5|, это время также поли
 номиально зависит от \S\.
 Схема аппроксимации с полностью полиномиальным временем работы
 Схему аппроксимации с полностью полиномиальным временем работы, позво
 ляющую получить приближенное решение задачи о сумме подмножеств, можно 
составить путем “сокращения” каждого списка Li после его создания. Идея за
 ключается в том, что если два значения в списке L мало отличаются одно от дру
 гого, то для получения приближенного решения нет смысла явно поддерживать 
оба эти значения. Точнее говоря, используется некоторый параметр сокращения 8, 
удовлетворяющий неравенству 0 < <5 < 1. Чтобы сократить (trim) список L по 
параметру 8, нужно удалить из этого списка максимальное количество элементов 
таким образом, чтобы в полученном в результате этого сокращения списке L' для 
каждого удаленного из списка L элемента у содержался элемент 2, аппроксими
 рующий элемент у, т.е.
 (35.24)
Глава 35. Приближенные алгоритмы
 1183
 Можно считать, что элемент 2 “представляет” элемент у в новом списке V , 
т.е. каждый удаленный элемент у представлен элементом 2, удовлетворяющим 
неравенству (35.24). Например, если £ = 0.1 и
 L = (10,11,12,15,20,21,22,23,24, 29) ,
 то путем сокращения списка L можно получить список
 U = (10,12,15,20,23,29) ,
 где удаленное значение 11 представлено значением 10, удаленные значения 21 
и 22 представлены значением 20, а удаленное значение 24 представлено значени
 ем 23. Поскольку каждый элемент измененной версии списка является одновре
 менно элементом исходного списка, сокращение может значительно уменьшить 
количество элементов, сохраняя в списке близкие (несколько меньшие) предста
 вительные значения каждого удаленного элемента.
 Приведенная ниже процедура по заданным параметрам L и S сокращает спи
 сок L = (2/1,1/2, • • •, Ут) за время 0 (т); при этом предполагается, что элементы 
списка L отсортированы в неубывающем порядке. На выходе процедуры получа
 ется сокращенный отсортированный список.
 Trim(L,£)
 1 Пусть т — длина списка L
 2 V = Ы
 3 last = у\
 4 
for г = 2 to т
 5 
6 
7 
if 2/г > lost ■ (1 + <5) // yi > last (список L отсортирован)
 Добавить yi в конец списка V
 last = yi
 8 return L'
 Элементы списка L сканируются в неубывающем порядке, и в возвращаемый 
список V элемент помещается, только если это первый элемент списка L или 
если его нельзя представить последним помещенным в список V элементом.
 Располагая процедурой Trim, схему аппроксимации можно построить следую
 щим образом. В качестве входных данных в эту процедуру передается множество 
S = {х\,Х2
 ,... ,хп}, состоящее из п целых чисел (расположенных в произволь
 ном порядке), целевое значение t и “параметр аппроксимации” е, где
 0 < е < 1 . 
(35.25)
 Процедура возвращает значение 2, величина которого отличается от оптимально
 го решения не более чем в 1 + е раз.
1184
 Approx-Subset-Sum (5, t, е)
 1 п = |5|
 2 Lo = (0)
 3 for г = 1 to n
 4 
Li = Merge-Lists 
5 
6 
Li = Trim (Li, e/2n)
 Удалить из Li все элементы, которые больше t
 7 Пусть 2* — наибольшее значение в Ln
 8 return 2*
 Часть VII. Избранные темы
 + xi)
 В строке 2 список Lo инициализируется таким образом, чтобы в нем содержал
 ся только элемент 0. Цикл for в строках 3-6 вычисляет отсортированный список 
Li, содержащий соответствующим образом сокращенную версию множества Pi, 
из которого удалены все элементы, превышающие величину t. Поскольку список 
Li создается на основе списка Li_i, необходимо гарантировать, что повторное 
сокращение не внесет слишком большой неточности. Скоро станет понятно, что 
процедура Approx-Subset-Sum возвращает корректное приближение, если та
 ковое существует.
 В качестве примера предположим, что имеется экземпляр задачи
 S = (104,102,201,101)
 с t = 308 и е = 0.40. Параметр сокращения 8 равен е/8 = 0.05. Процедура 
Approx-Subset-Sum в указанных строках вычисляет следующие значения:
 Строка 2:
 о
 II
 Строка 4: L, = (0,104) ,
 Строка 5:
 О
 сГ
 II
 Строка 6:
 о
 сГ
 II
 Строка 4: L2 = (0,102,104,206) ,
 Строка 5: L2 = (0,102,206) ,
 Строка 6: L2 = (0,102,206) ,
 Строка 4: L3 = (0,102,201,206,303,407) ,
 Строка 5: L3 = (0,102,201,303,407) ,
 Строка 6: L3 = (0,102,201,303) ,
 Строка 4: L4 = (0,101,102,201,203,302,303,404)
 Строка 5: L4 = (0,101,201,302,404) ,
 Строка 6: L4 = (0,101,201,302) .
 Алгоритм возвращает значение 2* = 302, которое приближает оптимальное ре
 шение 307 = 104 + 102 + 101 в пределах погрешности е = 40%; фактически 
погрешность составляет 2%.
Глава 35. Приближенные алгоритмы
 Теорема 35.8
 1185
 Процедура A pprox-Subset-Sum является схемой аппроксимации с полностью 
полиномиальным временем выполнения, позволяющей решить задачу о сумме 
подмножеств.
 Доказательство. В результате сокращения списка Li в строке 5 и удаления из 
этого списка всех элементов, превышающих значение t, поддерживается свой
 ство, что каждый элемент списка Li также является элементом списка Pi. Поэто
 му значение 2*, которое возвращается в строке 8, на самом деле является суммой 
некоторого подмножества множества S. Обозначим оптимальное решение задачи 
о сумме подмножества у* £ Рп. Тогда из строки 6 известно, что г* < у*. Согласно 
неравенству (35.1) нужно показать, что у*/г* <1+6. Необходимо также пока
 зать, что время работы этого алгоритма выражается полиномиальной функцией 
и от 1/е, и от размера входных данных.
 В упр. 35.5.2 предлагается для каждого элемента у из Pi, который не превы
 шает t, показать, что существует элемент z £ Li, такой, что
 У
 (1 + е/2п)г < z <у .
 (35.26)
 Неравенство (35.26) должно выполняться для у* £ Рп, поэтому существует эле
 мент z £ Ln, такой, что
 (1 + б/2п)п <Z<y'
 и, таким образом,
 (35.27)
 Поскольку существует элемент 2 £ Ln, удовлетворяющий неравенству (35.27), это 
неравенство должно быть справедливым для элемента 2*, который имеет самое 
большое значение в списке Ln, т.е.
 ?^(1+^Г 
(35-28)
 Теперь покажем, что у*/z* < 1 + 6. Для этого покажем, что (1 + е/2п)п < 
1 + 6. Согласно уравнению (3.14) имеем lim ^oo^ + е/2п)п — е6/2 В упр. 35.5.3 
предлагается показать, что
 d_
 dn
 (35.29)
 Следовательно, функция (1 + е/2п)п с ростом п увеличивается и стремится к сво
 ему пределу е6/2, и мы имеем
 71
 ( )
 < е6/2
 < 1 + б/2 + (б/2)
 < 1 + е 38
 (согласно (3.13)) 
(согласно (35.25)) .
 (35.30)
 38 Зак. 3726
1186
 Часть VII. Избранные темы
 Объединение неравенств (35.28) и (35.30) завершает анализ коэффициента ап
 проксимации.
 Чтобы показать, что процедура A pprox-Subset-Sum представляет собой схе
 му аппроксимации с полностью полиномиальным временем выполнения, оценим 
границу длины списка L*. После сокращения последовательные элементы гиг' 
в списке Li должны удовлетворять соотношению г'/г > 1 + е/2п. Другими слова
 ми, они должны отличаться не менее чем в 1 + е/2п раз. Поэтому каждый список 
содержит значение 0, возможно, значение 1 и до [log1+f/2n дополнительных 
значений. Количество элементов в каждом списке Li не превышает
 _ 
Ini
 t + 2 = ln(l + f/2n)+2
 ^ 2п(1 + б/2п) Ini о 
^ 
е
 Зп In i
 <--------+ 2
 "I- 2 
(согласно (3.17))
 (согласно (35.25))
 б
 Эта граница является полиномиальной функцией от размера входных данных, ко
 торый равен сумме количества битов lg t, необходимых для представления числа 
t, и количества битов, необходимых для представления множества 5, которое, 
в свою очередь, полиномиально зависит от п и от 1 /е. Поскольку время выпол
 нения процедуры Approx-Subset-Sum выражается полиномиальной функцией 
от длины списка L*, эта процедура является схемой аппроксимации с полностью 
полиномиальным временем выполнения. 
Упражнения
 35.5.1
 ■
 Докажите уравнение (35.23). Затем покажите, что после выполнения строки 5 
процедуры Exact-Subset-Sum список Li является отсортированным и содер
 жит все элементы списка Pi, значения которых не превышают t.
 35.5.2
 Докажите неравенство (35.26) по индукции по г.
 35.5.3
 Докажите неравенство (35.29).
 35.5.4
 Как следовало бы модифицировать представленную в этом разделе схему аппрок
 симации, чтобы она позволяла найти хорошее приближение наименьшего значе
 ния суммы элементов некоторого подмножества заданного входного списка, не 
меньшего заданной величины i?
 35.5.5
 Измените процедуру A pprox-Subset-Sum таким образом, чтобы она возвраща
 ла также подмножество S, дающее сумму г*.
Глава 35. Приближенные алгоритмы
 Задачи
 35.1. Расфасовка по контейнерам
 1187
 Предположим, что имеется множество, состоящее из п предметов, причем раз
 мер г-го предмета Sj удовлетворяет неравенству 0 < s* < 1. Нужно упаковать все 
предметы в контейнеры единичного размера, использовав при этом минимальное 
количество контейнеров. Каждый контейнер вмещает произвольное количество 
объектов, лишь бы их суммарный размер не превышал I2.
 а. Докажите, что задача по определению минимального количества необходимых 
контейнеров является NP-полной. (Указание: приведите к ней задачу о сумме 
подмножества.)
 При эвристическом методе выбора первого подходящего (first-fit) по очереди вы
 бираются все предметы, и каждый помещается в первый же контейнер, в который 
этот предмет может поместиться. Пусть 5 = 
s*.
 б. Докажите, что оптимальное количество контейнеров, необходимых для упа
 ковки всех предметов, не меньше [5].
 в. Докажите, что при использовании эвристического метода выбора первого под
 ходящего все контейнеры, кроме, возможно, одного, будут заполнены не менее, 
чем наполовину.
 г. 
Докажите, что количество контейнеров, которые используются в эвристиче
 ском методе выбора первого подходящего, никогда не превышает величи
 ну [25].
 д. Докажите, что коэффициент аппроксимации эвристического метода выбора 
первого подходящего равен 2.
 е. Представьте эффективную реализацию эвристического метода выбора первого 
подходящего и проанализируйте время работы полученного алгоритма.
 35.2. Приближение размера максимальной клики
 Пусть G = (V, Е) является неориентированным графом. Определим для лю
 бого числа k > 1 граф 
как неориентированный граф (V^k\ Е^), где V^ — 
множество всех упорядоченных fc-кортежей вершин из множества V, а Е^> 
определяется таким образом, что (i>i, V2,..., Vk) смежны с (wi,W2,..., Wk) то
 гда и только тогда, когда для г = 1,2,..., А; каждая вершина V{ является смежной 
в графе G вершине Wi (либо когда и* = Wi).
 2 Еще не так давно с этой задачей на практике приходилось сталкиваться множеству пользователей компью
 теров, которые старались разместить как можно больше файлов на как можно меньшем количестве дискет... — 
Примеч. пер.
1188
 а. Докажите, что размер максимальной клики в графе 
размера максимальной клики в графе G.
 Часть VII. Избранные темы
 равен к-й степени 
б. Докажите, что если существует приближенный алгоритм, позволяющий найти 
клику максимального размера и обладающий постоянным коэффициентом ап
 проксимации, то для решения данной задачи существует схема аппроксимации 
с полиномиальным временем работы.
 35.3. Взвешенная задача о покрытии множества
 Предположим, что задача о покрытии множества обобщается таким образом, 
что каждому множеству Si из семейства J- сопоставляется вес Wi, а вес покрытия 
С вычисляется как 
wi• Требуется найти покрытие с минимальным весом.
 (В разделе 35.3 рассматривается случай, когда Wi = 1 для всех г.)
 Покажите, как естественным образом обобщить жадный эвристический под
 ход, который применяется в задаче о покрытии множества, так, чтобы он позволял 
получить приближенное решение любого экземпляра взвешенной задачи о покры
 тии множества. Покажите, что коэффициент аппроксимации этого эвристического 
подхода равен H(d), где d — максимальный размер любого множества Si.
 35.4. Паросочетание максимальной мощности
 Вспомним, что в неориентированном графе G паросочетанием называется та
 кое множество ребер, в котором никакие два ребра не инцидентны одной и той 
же вершине. Из раздела 26.3 мы узнали, как найти максимальное паросочетание 
в двудольном графе. В настоящей задаче будет выполняться поиск паросочетаний 
в неориентированных графах общего вида (т.е. в графах, которые необязательно 
являются двудольными).
 а. Максимальным паросочетанием (maximal matching) называется паросочета
 ние, которое не является собственным подмножеством никакого другого паро- 
сочетания. Покажите, что максимальное паросочетание необязательно совпа
 дает с паросочетанием максимальной мощности. Для этого приведите пример 
неориентированного графа G, максимальное паросочетание М в котором не 
является паросочетанием максимальной мощности. (Указание: имеется граф 
всего лишь с четырьмя вершинами, обладающий указанным свойством.)
 б. Рассмотрим неориентированный граф G = (V, Е). Сформулируйте жадный 
алгоритм поиска максимального паросочетания в графе G, время работы ко
 торого было бы равно 0{Е).
 В этой задаче внимание сосредоточивается на поиске приближенного алгоритма 
с полиномиальным временем работы, позволяющего найти паросочетание макси
 мальной мощности. Время работы самого быстрого из известных на сегодняш
 ний день алгоритмов, предназначенных для поиска паросочетания максимальной 
мощности, превышает линейное (хотя и является полиномиальным); рассматри
 ваемый же здесь приближенный алгоритм завершает свою работу строго в те
 чение линейного времени. Вы должны будете показать, что жадный алгоритм
Глава 35. Приближенные алгоритмы
 1189
 поиска максимального паросочетания с линейным временем выполнения, разра
 ботанный в п. (б), для задачи о паросочетании максимальной мощности является 
2-приближенным алгоритмом.
 в. Покажите, что размер паросочетания максимальной мощности в графе G пред
 ставляет собой нижнюю границу размера произвольного вершинного покры
 тия в этом графе.
 г. Рассмотрим максимальное паросочетание М в графе G — (V, Е). Пусть
 Т = {v G V : некоторое ребро в М инцидентно г>} .
 Что можно сказать о подграфе графа G, порожденном теми вершинами графа 
G, которые не принадлежат Т?
 д. На основании результатов п. (г) сделайте вывод о том, что величина 2|М| 
равна размеру вершинного покрытия графа G.
 е. Воспользовавшись результатами решения пп. (в) и (д) задачи, докажите, что 
сформулированный в п. (б) жадный алгоритм является 2-приближенным алго
 ритмом для задачи о паросочетании максимальной мощности.
 35.5. Расписание работы параллельной вычислительной машины
 В задаче о расписании работы параллельной вычислительной машины (pa
 rallel-machine-scheduling problem) исходные данные представляют собой набор из 
п заданий Л, J2 
, • ■ •, Jn, каждое из которых характеризуется временем обработ
 ки pk- Для выполнения этих заданий в нашем распоряжении имеется т иден
 тичных машин Mi, М2,..., Мт. Любое задание может выполняться на любой 
машине. Требуется составить расписание, в котором для каждого задания J*. сле
 дует указать машину, на которой это задание будет выполняться, и выделенный 
ему интервал времени. Каждое задание 
должно непрерывно выполняться толь
 ко на одной машине Mi в течение времени рь, и в это время на машине Mi не 
может выполняться никакое другое задание. Обозначим через Ck время заверше
 ния (completion time) задания J*, т.е. момент времени, когда завершается обра
 ботка задания J*.. Для каждого расписания определяется его момент завершения 
(makespan), равный Стах = maxi<j<n Cj. В задаче нужно найти расписание с ми
 нимальным моментом завершения.
 Например, предположим, что имеется две машины, М\ и М2, и что нужно 
выполнить четыре задания, Ji, -./2, -h, J4, для которых р\ = 2, р2 = 12, рз = 4 
и р4 = 5. Можно предложить расписание, при котором на машине Mi сначала 
выполняется задание J\, а затем — задание J2, а на машине М2 сначала выпол
 няется задание J4, а затем — задание J3. В этом расписании С\ = 2, Сч = 14, 
Сз = 9, С4 — 5 и Стах = 14. В оптимальном расписании на машине М\ выпол
 няется задание J2, а на машине М2 — задания J\, J3 и J4. В этом расписании 
Ci = 2, С2 = 12, С3 = 6, С4 = И и Стах = 12.
 В данной задаче о расписании работы параллельной вычислительной машины 
обозначим время завершения оптимального расписания через С^ах
1190
 Часть VII. Избранные темы
 а. Покажите, что оптимальное время завершения по величине не меньше самого 
большого времени обработки, т.е. что выполняется неравенство
 С*шах > шах рк . 
l<fc<n
 б. Покажите, что оптимальное время завершения по величине не меньше средней 
загрузки машин, т.е. что справедливо неравенство
 1<А;<п
 Предположим, что для составления расписания параллельных вычислительных 
машин используется следующий жадный алгоритм: как только машина освобож
 дается, на ней начинает выполняться очередное задание, еще не внесенное в рас
 писание.
 в. Предложите псевдокод, реализующий этот жадный алгоритм. Чему равно вре
 мя работы этого алгоритма?
 г. Покажите, что для расписания, которое возвращается жадным алгоритмом, 
выполняется неравенство
 l<fc<n
 Сделайте вывод, согласно которому этот алгоритм является 2-приближенным 
алгоритмом с полиномиальным временем работы.
 35.6. Приближенное вычисление наибольшего остовного дерева
 Пусть G = (V,E) представляет собой неориентированный граф с различными 
весами w(u, v) каждого ребра (и, v) е Е. Пусть для каждой вершины v € V ве
 личина max (г;) = argmax^ V)G£ {w(u, г;)} указывает ребро максимального веса, 
инцидентное этой вершине. Обозначим через Sg = {max(i;) : v G V} множество 
ребер с максимальным весом, инцидентных каждой вершине, и пусть То пред
 ставляет собой остовное дерево графа G с максимальным весом, т.е. остовное 
дерево с наибольшим общим весом. Для любого подмножества ребер Е' С Е
 определим w(E') = £ (U|„)€£y w(u,v).
 а. Приведите пример графа как минимум с четырьмя вершинами, для которо
 го Sg = То.
 б. Приведите пример графа как минимум с четырьмя вершинами, для которо
 го So ф То.
 в. Докажите, что So С Тс для любого графа G.
 г. Докажите, что w(Sg) > w(Tg)/2 для любого графа G.
Глава 35. Приближенные алгоритмы
 1191
 д. Разработайте алгоритм со временем работы 0(V + Е) для 2-приближенного 
вычисления наибольшего остовного дерева.
 35.7. Приближенный алгоритм решения 0-1 задачи о рюкзаке
 Вспомним задачу о рюкзаке из раздела 16.2. Имеется п предметов, причем г-й 
предмет стоит Vi долларов и весит Wi килограммов. У нас есть рюкзак, вмещаю
 щий не более W килограммов. Добавим дополнительные предположения о том, 
что каждый вес 
не превышает W и что предметы проиндексированы в невоз
 растающем порядке их стоимости: v\ > V2 > • ■ ■ > vn.
 В 0-1-задаче о рюкзаке требуется найти подмножество предметов, общий вес 
которого не превышает W, а суммарная стоимость максимальна. Непрерывная 
задача о рюкзаке подобна 0-1-задаче, но в ней позволено брать части предме
 тов, а не руководствоваться принципом “все или ничего” Если мы берем долю х* 
предмета г, где 0 < х* < 1, то мы добавляем XiWi к весу рюкзака и получа
 ем стоимость XiVi. Наша цель — разработать полиномиальный 2-приближенный 
алгоритм для решения 0-1 задачи о рюкзаке.
 Чтобы разработать алгоритм с полиномиальным временем работы, рассмот
 рим ограниченные экземпляры 0-1-задачи о рюкзаке. Для заданного экземпляра 
задачи о рюкзаке I мы образуем ограниченные экземпляры Ij, где j = 1,2,..., п, 
путем удаления предметов 1 ,2,... ,j — 1 и требования, чтобы решение включало 
предмет j (весь предмет j как в непрерывной задаче, так и в 0-1-задаче о рюкзаке). 
В экземпляре 1\ не удаляются никакие предметы. Обозначим для экземпляра Ij 
через Pj оптимальное решение 0-1-задачи, а через Qj — оптимальное решение 
непрерывной задачи.
 а. Докажите, что оптимальное решение экземпляра / 0-1-задачи о рюкзаке явля
 ется ОДНИМ ИЗ {РЬ Р2, • • ■ , Рп}
б. Докажите, что можно найти оптимальное решение Qj непрерывной задачи для 
экземпляра Ij путем включения предмета j с последующим применением жад
 ного алгоритма, в котором на каждом шагу мы берем максимально возможное 
количество невыбранного предмета из множества {j + l,j + 2,... ,п} с мак
 симальной удельной стоимостью Vi/wi.
 в. Докажите, что всегда можно построить оптимальное решение Qj непрерывной 
задачи для экземпляра Ij, которое включает не более одного разделенного на 
части предмета. То есть для всех предметов за исключением, возможно, одного 
мы либо полностью кладем этот предмет в рюкзак, либо полностью от него 
отказываемся.
 г. Для заданного оптимального решения Qj экземпляра Ij непрерывной задачи 
постройте решение Rj из Qj путем удаления разделенных на части предме
 тов из Qj. Пусть v(S) обозначает общую стоимость предметов в решении S. 
Докажите, что v(Rj) > v{Qj)/2 > v(Pj)/2.
1192
 Часть VII. Избранные темы
 д. Разработайте алгоритм с полиномиальным временем работы, который возвра
 щает решение с наибольшей стоимостью из множества {J?i, R2,..., Rn}, и до
 кажите, что ваш алгоритм представляет собой полиномиальный 2-приближен- 
ный алгоритм для 0-1-задачи о рюкзаке.
 Заключительные замечания
 Несмотря на то что методы, которые необязательно вычисляют точные ре
 шения, были известны тысячи лет назад (например, методы приближенного 
вычисления числа 7г), понятие приближенного алгоритма имеет намного более 
короткую историю. Заслуги по формализации концепции приближенного алго
 ритма с полиномиальным временем работы Хохбаум (Hochbaum) [171] припи
 сывает Гарею (Garey), Грэхему (Graham) и Ульману (Ullman) [127], а также 
Джонсону (Johnson) [189]. Первый такой алгоритм часто приписывается Грэхе
 му (Graham) [148].
 Со времени публикации этой ранней работы были разработаны тысячи при
 ближенных алгоритмов, позволяющих решать самые разнообразные задачи. По 
этой теме имеется большое количество литературы. Недавно вышедшие книги 
Осиэлло (Ausiello) и др. [25], Хохбаума [171] и Вазирани (Vazirani) [343] полно
 стью посвящены приближенным алгоритмам. То же самое можно сказать об обзо
 рах Шмойса (Shmoys) [313] и Клейна (Klein) и Юнга (Young) [206]. В нескольких 
других книгах, таких как книги Гарея (Garey) и Джонсона (Johnson) [128], а также 
Пападимитриу (Papadimitriou) и Штейглица (Steiglitz) [269], также значительное 
внимание уделяется приближенным алгоритмам. В книге Лоулера (Lawler), Лен- 
стры (Lenstra), Ринноя Кана (Rinnooy Кап) и Шмойса (Shmoys) [224] подробно 
рассматриваются приближенные алгоритмы, предназначенные для решения зада
 чи о коммивояжере.
 В книге Пападимитриу (Papadimitriou) и Штейглица (Steiglitz) авторство алго
 ритма APPROX-VERTEX-COVER приписывается Ф. Гаврилу (F. Gavril) и М. Янна- 
какису (М. Yannakakis). Большое количество усилий было направлено на иссле
 дование задачи о вершинном покрытии (в книге Хохбаума (Hochbaum) [171] пе
 речислены 16 различных приближенных алгоритмов, предназначенных для реше
 ния этой задачи), однако значение всех коэффициентов аппроксимации не меньше 
2-о(1).
 Алгоритм Approx-TSP-Tour был предложен в статье Розенкранца (Rosen- 
krantz), Стирнса (Steams) и Льюиса (Lewis) [296]. Кристофидис (Christofides) 
усовершенствовал этот алгоритм и предложил 3/2-приближенный алгоритм, поз
 воляющий решить задачу о коммивояжере с неравенством треугольника. Арора 
(Агога) [22] и Митчелл (Mitchell) [255] показали, что если точки находятся на ев
 клидовой плоскости, то существует схема аппроксимации с полиномиальным вре
 менем работы. Теорема 35.3 доказана Сани (Sahni) и Гонзалезом (Gonzalez) [299].
 Анализ жадного эвристического подхода к задаче о покрытии множества по
 строен по аналогии с доказательством более общего результата, опубликованным
Глава 35. Приближенные алгоритмы
 1193
 в статье Чватала (Chvatal) [67]; представленный здесь основной результат доказан 
Джонсоном (Johnson) [189] и Ловасом (Lovasz) [237].
 Описание алгоритма A pprox-Subset-Sum и его анализ с некоторыми изме
 нениями взяты из статьи Ибарры (Ibarra) и Кима (Kim) [186], где приведены при
 ближенные алгоритмы, предназначенные для решения задач о рюкзаке и о сумме 
подмножества.
 Задача 35.7 представляет собой комбинаторную версию более общего резуль
 тата по приближению целочисленной задачи о рюкзаке, полученного Бинстоком 
(Bienstock) и Мак-Клоски (McClosky) [44].
 Рандомизированный алгоритм решения задачи о МАХ-З-С^-выполнимости 
можно найти в неявном виде в работе Джонсона (Johnson) [189]. Автором алго
 ритма, предназначенного для решения задачи о взвешенном вершинном покры
 тии, является Хохбаум (Hochbaum) [170]. Раздел 35.4 дает лишь поверхностное 
представление о тех возможностях, которые открываются благодаря использова
 нию рандомизации и линейного программирования при разработке приближен
 ных алгоритмов. Сочетание этих двух идей привело к появлению метода под 
названием “рандомизированное округление”, в котором задача сначала форму
 лируется как целочисленная задача линейного программирования. После этого 
решается ослабленный вариант задачи, а переменные в этом решении интерпре
 тируются как вероятности. Затем эти вероятности используются для решения ис
 ходной задачи. Впервые этот метод был предложен Рагаваном (Raghavan) и Том
 соном (Thompson) [288], после чего он нашел широкое применение. (Для озна
 комления с этой темой см. обзорную статью Мотвани (Motwani), Наора (Naor) 
и Рагавана (Raghavan) [259].) К другим заслуживающим внимания идеям в этой 
области, предложенным в последнее время, относятся метод прямой двойственно
 сти (primal dual) (см. обзор Гоманса (Goemans) и Вильямсона (Williamson) [134]), 
поиск разреженных разрезов (sparse cuts) для использования в алгоритмах разби
 ения [228], а также применение полуопределенного программирования [133].
 Как упоминалось в заключительных замечаниях к главе 34, последние до
 стижения в области вероятностно проверяемых доказательств позволяют найти 
нижние границы аппроксимируемости многих задач, в том числе некоторых из 
тех, которые рассматриваются в настоящей главе. В дополнение к приведенным 
здесь ссылкам заметим, что глава из книги Ароры (Агога) и Ланда (Lund) [23] 
содержит хорошее описание отношения между вероятностно проверяемыми до
 казательствами и степенью сложности приближенных алгоритмов решения раз
 личных задач.

VIII Приложения: математические основы
Введение
 Анализ алгоритмов требует серьезного математического аппарата. Иногда до
 статочно знаний из простейшего курса высшей математики, но зачастую исполь
 зуемые в данной книге математические концепции и методы могут оказаться но
 выми для вас. В части I вы уже познакомились с асимптотическими обозначения
 ми и решением рекуррентных соотношений; в этой части вы найдете ряд других 
математических концепций и методов, используемых в ходе анализа алгоритмов. 
Как упоминалось во введении к части I, вы могли быть знакомы со многими рас
 сматриваемыми здесь вопросами еще до того, как приступили к чтению данной 
книги, так что материал, представленный в приложениях, следует рассматривать, 
в первую очередь, как справочный. Тем не менее здесь, как и в основных главах, 
приведены упражнения и задачи, которые помогут вам повысить свою квалифи
 кацию в рассматриваемых областях математики.
 В приложении А рассматриваются методы вычисления и оценки рядов, часто 
встречающихся в процессе анализа тех или иных алгоритмов. Многие из при
 водимых здесь формул можно найти в различных учебниках по математике, но 
гораздо удобнее, когда все эти формулы собраны в одном месте.
 В приложении Б приведены основные определения и обозначения, используе
 мые при работе с множествами, отношениями, функциями, графами и деревьями. 
В нем вы также найдете некоторые основные свойства этих математических объ
 ектов.
 Приложение В начинается с элементарных принципов комбинаторики — пе
 рестановок, сочетаний и т.п. Остальной материал приложения посвящен основам 
теории вероятности. Большинство алгоритмов в этой книге не требуют использо
 вания теории вероятности в ходе анализа, так что можете пропустить эту часть 
приложения. Вы сможете вернуться к нему позже, при желании детально разо
 браться в вероятностном анализе алгоритмов. В этом случае вы убедитесь, что 
данное приложение можно рассматривать и как хорошо организованный спра
 вочник.
Часть VIII. Приложения: математические основы
 1197
 Приложение Г посвящено матрицам, операциям с ними и некоторым основ
 ным свойствам матриц. Вероятно, вы уже сталкивались с большей частью пред
 ставленного здесь материала при прослушивании курса линейной алгебры, но 
может оказаться очень удобным иметь такой раздел, в который всегда можно за
 глянуть, чтобы освежить свою память.
Приложение А. Суммы и ряды
 Если алгоритм содержит итеративную управляющую конструкцию, такую как 
цикл while или for, время его работы можно выразить в виде суммы значений 
времени выполнения отдельных итераций. Например, в разделе 2.2 указывалось, 
что j-я итерация алгоритма сортировки вставкой выполняется за время, в худ
 шем случае пропорциональное j. Суммируя значения времени, затраченного на 
выполнение отдельных итераций, мы получим сумму, или ряд,
 71
 3 =2
 Вычисление этой суммы приводит нас к границе для времени работы алгоритма, 
равной 0(п2) в худшем случае. Этот пример свидетельствует о важности пони
 мания и умения вычислять суммы и оценивать их границы.
 В разделе А. 1 перечислены некоторые основные формулы, связанные с сумми
 рованием, а в разделе А.2 — некоторые полезные методы оценки сумм. Формулы 
в разделе А.1 приведены без доказательств, однако в разделе А.2 в качестве ил
 люстрации описываемые здесь методы использованы для доказательства некото
 рых формул из раздела А. 1. Остальные доказательства можно найти в различных 
учебниках по математике.
 А.1. Суммы и их свойства
 Для данной последовательности чисел ai, a2,..., ап, где п — неотрицательное 
целое число, конечная сумма а\ + 02 + • • • 4- ап кратко записывается как
 п
 к= 1
 Если п = 0, значение суммы считается равным 0. Значение конечного ряда всегда 
определено и не зависит от порядка слагаемых.
Приложение А. Суммы и ряды
 1199
 Для заданной последовательности чисел а\,а2,... бесконечная сумма а\ + 
а2 + • • • кратко записывается как
 оо 
к= 1
 что рассматривается как
 71
 lim У2 ак .
 к=1
 Если данный предел не существует, ряд расходится (diverges); в противном слу
 чае ряд сходится (converges). Члены сходящегося ряда не могут быть сумми
 рованы в произвольном порядке. Однако можно переставлять члены абсолютно 
сходящегося ряда, т.е. ряда YlT=i ак> 
которого ряд 
сходящимся.
 Линейность
 la^l также является
 Для любого действительного числа с и любых конечных последовательностей
 ai, 02,..., ап и Ь\, &2, • ■ •, Ьп
 5Z^cak +Ък) = с'£ а к + '£Ък
к=1 
к—1 
к= 1
 Свойство линейности справедливо также для бесконечных сходящихся рядов.
 Это свойство может использоваться при работе с суммами, в которые входят 
асимптотические обозначения, например
 71 
/ 
71
 £e(/(fc)) = e £/(fc)
 к—1 
\к=1
 В этом уравнении ©-обозначение в левой части применяется к переменной к, 
а в правой — к п. Аналогичные действия применимы и к бесконечным сходящим
 ся рядам.
 Арифметическая прогрессия
 Сумма
 71
 ^ ^ к = 1 + 2 + • • • + п
 к= 1
 называется арифметической прогрессией и равна
 ] Г А; = in(7i + 1) 
k=\
 = 0(n2) .
 (А.1)
 (А.2)




























































































































АЛГОРИТМЫ
 ПОСТРОЕНИЕ И АНАЛИЗ
 ТРЕТЬЕ ИЗДАНИЕ
 Томас Кормен, Чарльз Лейзерсон, Рональд Ривест и Клиффорд Штайн
 Ряд книг, посвященных алгоритмам, отличается строгостью изложения материала, но страдает определен
 ной неполнотой: другие книга охватывают огромный объем материала, но недостаточно строго излагают 
его. Эта книга удачно объединяет в себе полноту охвата и строгость изложения. В ней описаны самые раз
 нообразные алгоритмы, сочетается широкий диапазон тем с глубиной и полнотой изложения; при этом 
изложение доступно для читателей самого разного уровня подготовки. Каждая глава книги относительно 
самодостаточна и может использоваться в качестве отдельной темы для изучения. Алгоритмы описаны 
простым языком и с применением псевдокода, который понятен любому, кто хоть в небольшой степени 
знаком с программированием, а пояснения принципов их работы даны без излишней математической 
строгости и требуют лишь элементарных знаний.
 Первое издание данной книга давно стало стандартным справочным руководством для профессионалов 
и учебным пособием хтя студентов университетов. Второе издание было дополнено новыми главами, рас
 крывающими такие темы, как вероятностный анализ и рандомизированные алгоритмы, линейное про
 граммирование. Третье издание также существенно дополнено и пересмотрено. В него вошли две совер
 шенно новые главы, посвященные деревьям ван Эмде Боаса и многопоточным алгоритмам, а глава, 
посвященная рекуррентности, су шественно расширена. Изменена подача такого материала, как динами
 ческое программирование и жадные алгоритмы, и введено новое понятие потока, основанного на ребрах, 
в материале о транспортных сетях. В третье издание также было добавлено множество новых упражнений 
и задач.
 Томас Кормен — профессор информатики в колледже Дартмута и бывший директор Института литературы 
и риторики Дартмутского колледжа. Чарльз Лейзерсон — профессор информатики и электротехники 
в Массачусетсском технологическом институте, тле также работает и профессор Рональд Ривест. Клиффорд 
Штайн — профессор организации производства и исследования операций в Колумбийском университете.
 "В свете взрывного роста количества данных и распространения вычислительных приложений эффективные 
алгоритмы востребованы в еще балыией степени, неи ранее. Эта прекрасно написанная, тщательно проду
 манная и организованная книга является отличным введением в разработку и анализ алгоритмов. Первая ее 
половина представыет собой эффективный учебник теории алгоритмов, а вторая в большей степени пред
 назначена для научных работников и любознательных студентов, которые хотели бы получить дополни- 
тельные знания об этой интересной науке'.
 Шан-Хуа Тенг, Университет Южной Каролины
 " Это настоящая библия в указанной обиэсти. исчерпывающий учебник, охватывающий весь спектр совре
 менных алгоритмов: от быстрых алгоритмов и структур данных до алгоритмов с полиномиальным временем 
работы для решения очень сложных задач, от классических алгоритмов теории графов до специализирован
 ных алгоритмов поиска подстрок, вычислительной геометрии и теории чисел. Нельзя не упомянуть появив
 шиеся в третьем издании деревья ван Эмде Боаса и многопоточные алгоритмы, важность которых посто
 янно увеличивается'.
 Дэниел Шпильман, факультет информатики Йельского университета
 “ Как преподаватель и исследователь в области алгоритмов с более чем Овадиатилетним стажем, могу 
с уверенностью утверждать, что книга Кормена — лучший из встречавшихся мне учебников. Это умный, 
энциклопедичный и современный подход к изучению алгоритмов: нала факультет продолжит использовать 
эту книгу как в качестве учебника для сту дентов и аспирантов, так и в качестве рекомендуемого справоч
 ного пособия'.
 Габриэль Робинс, факультет информатики Университета Виргинии
 Издательский дом “Вильямс”
 www.williamspublishing.com
 The MIT Press
 Massachusetts Institute of Technology 
Cambridge, Massachusetts 02142 
http://mitpress.mit.edu
 ISBN 978-5-8459-1794-2 
1 203 1
 9 785845 917942